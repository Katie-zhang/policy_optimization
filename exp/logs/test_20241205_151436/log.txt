2024-12-05 15:14:36,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 0 loss: 0.6777 acc: 0.77
2024-12-05 15:14:36,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 2 loss: 0.6746 acc: 0.77
2024-12-05 15:14:36,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 4 loss: 0.6717 acc: 0.77
2024-12-05 15:14:36,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 6 loss: 0.6688 acc: 0.77
2024-12-05 15:14:36,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 8 loss: 0.6659 acc: 0.77
2024-12-05 15:14:36,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 10 loss: 0.6632 acc: 0.77
2024-12-05 15:14:36,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 12 loss: 0.6605 acc: 0.77
2024-12-05 15:14:36,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 14 loss: 0.6579 acc: 0.77
2024-12-05 15:14:36,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 16 loss: 0.6554 acc: 0.77
2024-12-05 15:14:36,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 18 loss: 0.6529 acc: 0.77
2024-12-05 15:14:36,939 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: -0.2827 reward: 0.2827 ref_reward: 0.2734 improvement: 3.39%
2024-12-05 15:14:37,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: -0.2833 reward: 0.2833 ref_reward: 0.2734 improvement: 3.64%
2024-12-05 15:14:37,427 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: -0.2831 reward: 0.2831 ref_reward: 0.2734 improvement: 3.55%
2024-12-05 15:14:37,669 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.65%
2024-12-05 15:14:37,912 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.65%
2024-12-05 15:14:38,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: -0.2833 reward: 0.2833 ref_reward: 0.2734 improvement: 3.61%
2024-12-05 15:14:38,403 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.65%
2024-12-05 15:14:38,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.66%
2024-12-05 15:14:38,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.65%
2024-12-05 15:14:39,088 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.65%
2024-12-05 15:14:39,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.66%
2024-12-05 15:14:39,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.66%
2024-12-05 15:14:39,629 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.65%
2024-12-05 15:14:39,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.66%
2024-12-05 15:14:39,988 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:40,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.66%
2024-12-05 15:14:40,348 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.66%
2024-12-05 15:14:40,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:40,706 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.66%
2024-12-05 15:14:40,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.66%
2024-12-05 15:14:41,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:41,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:41,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.66%
2024-12-05 15:14:41,604 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:41,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:41,965 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.66%
2024-12-05 15:14:42,145 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:42,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:42,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:42,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:42,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:43,046 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:43,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:43,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:43,586 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:43,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:43,946 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:44,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:44,306 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:44,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:44,665 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:44,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:45,026 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:45,206 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:45,386 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:45,566 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:45,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:45,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:46,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:46,289 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: -0.2834 reward: 0.2834 ref_reward: 0.2734 improvement: 3.67%
2024-12-05 15:14:46,699 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: 0.1651 reward: -0.1651 ref_reward: 0.3541 improvement: -146.62%
2024-12-05 15:14:46,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: 0.0981 reward: -0.0981 ref_reward: 0.3541 improvement: -127.70%
2024-12-05 15:14:47,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: 0.0391 reward: -0.0391 ref_reward: 0.3541 improvement: -111.05%
2024-12-05 15:14:47,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: -0.0135 reward: 0.0135 ref_reward: 0.3541 improvement: -96.20%
2024-12-05 15:14:47,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: -0.0602 reward: 0.0602 ref_reward: 0.3541 improvement: -83.00%
2024-12-05 15:14:47,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: -0.1026 reward: 0.1026 ref_reward: 0.3541 improvement: -71.03%
2024-12-05 15:14:47,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: -0.1403 reward: 0.1403 ref_reward: 0.3541 improvement: -60.39%
2024-12-05 15:14:47,956 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: -0.1741 reward: 0.1741 ref_reward: 0.3541 improvement: -50.83%
2024-12-05 15:14:48,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: -0.2044 reward: 0.2044 ref_reward: 0.3541 improvement: -42.27%
2024-12-05 15:14:48,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: -0.2317 reward: 0.2317 ref_reward: 0.3541 improvement: -34.55%
2024-12-05 15:14:48,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: -0.2562 reward: 0.2562 ref_reward: 0.3541 improvement: -27.64%
2024-12-05 15:14:48,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: -0.2771 reward: 0.2771 ref_reward: 0.3541 improvement: -21.73%
2024-12-05 15:14:48,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: -0.2955 reward: 0.2955 ref_reward: 0.3541 improvement: -16.54%
2024-12-05 15:14:49,037 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: -0.3112 reward: 0.3112 ref_reward: 0.3541 improvement: -12.12%
2024-12-05 15:14:49,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: -0.3243 reward: 0.3243 ref_reward: 0.3541 improvement: -8.41%
2024-12-05 15:14:49,399 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: -0.3349 reward: 0.3349 ref_reward: 0.3541 improvement: -5.41%
2024-12-05 15:14:49,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: -0.3431 reward: 0.3431 ref_reward: 0.3541 improvement: -3.10%
2024-12-05 15:14:49,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: -0.3490 reward: 0.3490 ref_reward: 0.3541 improvement: -1.43%
2024-12-05 15:14:49,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: -0.3529 reward: 0.3529 ref_reward: 0.3541 improvement: -0.34%
2024-12-05 15:14:50,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: -0.3551 reward: 0.3551 ref_reward: 0.3541 improvement: 0.30%
2024-12-05 15:14:50,304 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: -0.3561 reward: 0.3561 ref_reward: 0.3541 improvement: 0.58%
2024-12-05 15:14:50,484 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: -0.3563 reward: 0.3563 ref_reward: 0.3541 improvement: 0.64%
2024-12-05 15:14:50,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: -0.3560 reward: 0.3560 ref_reward: 0.3541 improvement: 0.56%
2024-12-05 15:14:50,845 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: -0.3556 reward: 0.3556 ref_reward: 0.3541 improvement: 0.43%
2024-12-05 15:14:51,026 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: -0.3552 reward: 0.3552 ref_reward: 0.3541 improvement: 0.31%
2024-12-05 15:14:51,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: -0.3549 reward: 0.3549 ref_reward: 0.3541 improvement: 0.24%
2024-12-05 15:14:51,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: -0.3548 reward: 0.3548 ref_reward: 0.3541 improvement: 0.22%
2024-12-05 15:14:51,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: -0.3550 reward: 0.3550 ref_reward: 0.3541 improvement: 0.25%
2024-12-05 15:14:52,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: -0.3552 reward: 0.3552 ref_reward: 0.3541 improvement: 0.33%
2024-12-05 15:14:52,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: -0.3556 reward: 0.3556 ref_reward: 0.3541 improvement: 0.43%
2024-12-05 15:14:52,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: -0.3560 reward: 0.3560 ref_reward: 0.3541 improvement: 0.54%
2024-12-05 15:14:53,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: -0.3563 reward: 0.3563 ref_reward: 0.3541 improvement: 0.64%
2024-12-05 15:14:53,335 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: -0.3566 reward: 0.3566 ref_reward: 0.3541 improvement: 0.73%
2024-12-05 15:14:53,621 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: -0.3569 reward: 0.3569 ref_reward: 0.3541 improvement: 0.79%
2024-12-05 15:14:53,862 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: -0.3570 reward: 0.3570 ref_reward: 0.3541 improvement: 0.83%
2024-12-05 15:14:54,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: -0.3571 reward: 0.3571 ref_reward: 0.3541 improvement: 0.85%
2024-12-05 15:14:54,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: -0.3571 reward: 0.3571 ref_reward: 0.3541 improvement: 0.86%
2024-12-05 15:14:54,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: -0.3571 reward: 0.3571 ref_reward: 0.3541 improvement: 0.85%
2024-12-05 15:14:54,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: -0.3571 reward: 0.3571 ref_reward: 0.3541 improvement: 0.85%
2024-12-05 15:14:54,793 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: -0.3570 reward: 0.3570 ref_reward: 0.3541 improvement: 0.84%
2024-12-05 15:14:54,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: -0.3570 reward: 0.3570 ref_reward: 0.3541 improvement: 0.83%
2024-12-05 15:14:55,169 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: -0.3570 reward: 0.3570 ref_reward: 0.3541 improvement: 0.83%
2024-12-05 15:14:55,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: -0.3570 reward: 0.3570 ref_reward: 0.3541 improvement: 0.83%
2024-12-05 15:14:55,694 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: -0.3570 reward: 0.3570 ref_reward: 0.3541 improvement: 0.84%
2024-12-05 15:14:56,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: -0.3571 reward: 0.3571 ref_reward: 0.3541 improvement: 0.85%
2024-12-05 15:14:56,332 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: -0.3571 reward: 0.3571 ref_reward: 0.3541 improvement: 0.85%
2024-12-05 15:14:56,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: -0.3571 reward: 0.3571 ref_reward: 0.3541 improvement: 0.86%
2024-12-05 15:14:56,969 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: -0.3571 reward: 0.3571 ref_reward: 0.3541 improvement: 0.86%
2024-12-05 15:14:57,269 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: -0.3571 reward: 0.3571 ref_reward: 0.3541 improvement: 0.87%
2024-12-05 15:14:57,521 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: -0.3572 reward: 0.3572 ref_reward: 0.3541 improvement: 0.87%
2024-12-05 15:14:58,009 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: 14.3008 reward: -14.3008 ref_reward: 0.3861 improvement: -3804.28%
2024-12-05 15:14:58,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: 13.6974 reward: -13.6974 ref_reward: 0.3861 improvement: -3647.98%
2024-12-05 15:14:58,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: 13.1060 reward: -13.1060 ref_reward: 0.3861 improvement: -3494.79%
2024-12-05 15:14:58,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: 12.5316 reward: -12.5316 ref_reward: 0.3861 improvement: -3346.02%
2024-12-05 15:14:58,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: 11.9487 reward: -11.9487 ref_reward: 0.3861 improvement: -3195.02%
2024-12-05 15:14:58,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: 11.3890 reward: -11.3890 ref_reward: 0.3861 improvement: -3050.04%
2024-12-05 15:14:59,102 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: 10.8746 reward: -10.8746 ref_reward: 0.3861 improvement: -2916.81%
2024-12-05 15:14:59,281 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: 10.3707 reward: -10.3707 ref_reward: 0.3861 improvement: -2786.27%
2024-12-05 15:14:59,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: 9.8564 reward: -9.8564 ref_reward: 0.3861 improvement: -2653.06%
2024-12-05 15:14:59,637 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: 9.3285 reward: -9.3285 ref_reward: 0.3861 improvement: -2516.31%
2024-12-05 15:14:59,814 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: 8.7808 reward: -8.7808 ref_reward: 0.3861 improvement: -2374.46%
2024-12-05 15:14:59,993 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: 8.2125 reward: -8.2125 ref_reward: 0.3861 improvement: -2227.26%
2024-12-05 15:15:00,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: 7.6274 reward: -7.6274 ref_reward: 0.3861 improvement: -2075.69%
2024-12-05 15:15:00,350 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: 7.0297 reward: -7.0297 ref_reward: 0.3861 improvement: -1920.87%
2024-12-05 15:15:00,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: 6.4306 reward: -6.4306 ref_reward: 0.3861 improvement: -1765.68%
2024-12-05 15:15:00,705 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: 5.8384 reward: -5.8384 ref_reward: 0.3861 improvement: -1612.31%
2024-12-05 15:15:00,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: 5.2527 reward: -5.2527 ref_reward: 0.3861 improvement: -1460.58%
2024-12-05 15:15:01,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: 4.6814 reward: -4.6814 ref_reward: 0.3861 improvement: -1312.60%
2024-12-05 15:15:01,237 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: 4.1324 reward: -4.1324 ref_reward: 0.3861 improvement: -1170.40%
2024-12-05 15:15:01,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: 3.6131 reward: -3.6131 ref_reward: 0.3861 improvement: -1035.87%
2024-12-05 15:15:01,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: 3.1294 reward: -3.1294 ref_reward: 0.3861 improvement: -910.59%
2024-12-05 15:15:01,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: 2.6859 reward: -2.6859 ref_reward: 0.3861 improvement: -795.71%
2024-12-05 15:15:01,946 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: 2.2853 reward: -2.2853 ref_reward: 0.3861 improvement: -691.95%
2024-12-05 15:15:02,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: 1.9286 reward: -1.9286 ref_reward: 0.3861 improvement: -599.55%
2024-12-05 15:15:02,301 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: 1.6149 reward: -1.6149 ref_reward: 0.3861 improvement: -518.30%
2024-12-05 15:15:02,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: 1.3422 reward: -1.3422 ref_reward: 0.3861 improvement: -447.67%
2024-12-05 15:15:02,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: 1.1073 reward: -1.1073 ref_reward: 0.3861 improvement: -386.81%
2024-12-05 15:15:02,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: 0.9064 reward: -0.9064 ref_reward: 0.3861 improvement: -334.79%
2024-12-05 15:15:03,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: 0.7357 reward: -0.7357 ref_reward: 0.3861 improvement: -290.57%
2024-12-05 15:15:03,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: 0.5911 reward: -0.5911 ref_reward: 0.3861 improvement: -253.12%
2024-12-05 15:15:03,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: 0.4690 reward: -0.4690 ref_reward: 0.3861 improvement: -221.49%
2024-12-05 15:15:03,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: 0.3659 reward: -0.3659 ref_reward: 0.3861 improvement: -194.78%
2024-12-05 15:15:03,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: 0.2788 reward: -0.2788 ref_reward: 0.3861 improvement: -172.21%
2024-12-05 15:15:03,897 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: 0.2051 reward: -0.2051 ref_reward: 0.3861 improvement: -153.12%
2024-12-05 15:15:04,075 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: 0.1426 reward: -0.1426 ref_reward: 0.3861 improvement: -136.93%
2024-12-05 15:15:04,252 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: 0.0894 reward: -0.0894 ref_reward: 0.3861 improvement: -123.15%
2024-12-05 15:15:04,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: 0.0439 reward: -0.0439 ref_reward: 0.3861 improvement: -111.37%
2024-12-05 15:15:04,607 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: 0.0049 reward: -0.0049 ref_reward: 0.3861 improvement: -101.26%
2024-12-05 15:15:04,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: -0.0288 reward: 0.0288 ref_reward: 0.3861 improvement: -92.55%
2024-12-05 15:15:04,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: -0.0579 reward: 0.0579 ref_reward: 0.3861 improvement: -85.00%
2024-12-05 15:15:05,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: -0.0833 reward: 0.0833 ref_reward: 0.3861 improvement: -78.43%
2024-12-05 15:15:05,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: -0.1055 reward: 0.1055 ref_reward: 0.3861 improvement: -72.67%
2024-12-05 15:15:05,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: -0.1250 reward: 0.1250 ref_reward: 0.3861 improvement: -67.61%
2024-12-05 15:15:05,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: -0.1423 reward: 0.1423 ref_reward: 0.3861 improvement: -63.13%
2024-12-05 15:15:05,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: -0.1577 reward: 0.1577 ref_reward: 0.3861 improvement: -59.16%
2024-12-05 15:15:06,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: -0.1714 reward: 0.1714 ref_reward: 0.3861 improvement: -55.61%
2024-12-05 15:15:06,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: -0.1837 reward: 0.1837 ref_reward: 0.3861 improvement: -52.42%
2024-12-05 15:15:06,381 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: -0.1948 reward: 0.1948 ref_reward: 0.3861 improvement: -49.55%
2024-12-05 15:15:06,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: -0.2048 reward: 0.2048 ref_reward: 0.3861 improvement: -46.95%
2024-12-05 15:15:06,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: -0.2139 reward: 0.2139 ref_reward: 0.3861 improvement: -44.59%
2024-12-05 15:15:07,305 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: -0.0470 reward: 0.0470 ref_reward: 0.1811 improvement: -74.03%
2024-12-05 15:15:07,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: -0.0722 reward: 0.0722 ref_reward: 0.1811 improvement: -60.16%
2024-12-05 15:15:07,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: -0.0944 reward: 0.0944 ref_reward: 0.1811 improvement: -47.90%
2024-12-05 15:15:08,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: -0.1133 reward: 0.1133 ref_reward: 0.1811 improvement: -37.45%
2024-12-05 15:15:08,578 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: -0.1303 reward: 0.1303 ref_reward: 0.1811 improvement: -28.07%
2024-12-05 15:15:08,838 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: -0.1449 reward: 0.1449 ref_reward: 0.1811 improvement: -20.01%
2024-12-05 15:15:09,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: -0.1572 reward: 0.1572 ref_reward: 0.1811 improvement: -13.20%
2024-12-05 15:15:09,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: -0.1674 reward: 0.1674 ref_reward: 0.1811 improvement: -7.59%
2024-12-05 15:15:09,423 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: -0.1752 reward: 0.1752 ref_reward: 0.1811 improvement: -3.25%
2024-12-05 15:15:09,604 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: -0.1814 reward: 0.1814 ref_reward: 0.1811 improvement: 0.13%
2024-12-05 15:15:09,783 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: -0.1859 reward: 0.1859 ref_reward: 0.1811 improvement: 2.63%
2024-12-05 15:15:09,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: -0.1890 reward: 0.1890 ref_reward: 0.1811 improvement: 4.37%
2024-12-05 15:15:10,143 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: -0.1910 reward: 0.1910 ref_reward: 0.1811 improvement: 5.46%
2024-12-05 15:15:10,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: -0.1921 reward: 0.1921 ref_reward: 0.1811 improvement: 6.03%
2024-12-05 15:15:10,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.21%
2024-12-05 15:15:10,683 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: -0.1923 reward: 0.1923 ref_reward: 0.1811 improvement: 6.14%
2024-12-05 15:15:10,863 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: -0.1919 reward: 0.1919 ref_reward: 0.1811 improvement: 5.94%
2024-12-05 15:15:11,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: -0.1915 reward: 0.1915 ref_reward: 0.1811 improvement: 5.71%
2024-12-05 15:15:11,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: -0.1911 reward: 0.1911 ref_reward: 0.1811 improvement: 5.52%
2024-12-05 15:15:11,486 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: -0.1909 reward: 0.1909 ref_reward: 0.1811 improvement: 5.42%
2024-12-05 15:15:11,666 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: -0.1909 reward: 0.1909 ref_reward: 0.1811 improvement: 5.39%
2024-12-05 15:15:11,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: -0.1910 reward: 0.1910 ref_reward: 0.1811 improvement: 5.43%
2024-12-05 15:15:12,026 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: -0.1911 reward: 0.1911 ref_reward: 0.1811 improvement: 5.53%
2024-12-05 15:15:12,206 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: -0.1914 reward: 0.1914 ref_reward: 0.1811 improvement: 5.66%
2024-12-05 15:15:12,386 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: -0.1916 reward: 0.1916 ref_reward: 0.1811 improvement: 5.80%
2024-12-05 15:15:12,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: -0.1919 reward: 0.1919 ref_reward: 0.1811 improvement: 5.93%
2024-12-05 15:15:12,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: -0.1921 reward: 0.1921 ref_reward: 0.1811 improvement: 6.05%
2024-12-05 15:15:12,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: -0.1922 reward: 0.1922 ref_reward: 0.1811 improvement: 6.13%
2024-12-05 15:15:13,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: -0.1923 reward: 0.1923 ref_reward: 0.1811 improvement: 6.18%
2024-12-05 15:15:13,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.21%
2024-12-05 15:15:13,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.22%
2024-12-05 15:15:13,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.21%
2024-12-05 15:15:13,822 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.20%
2024-12-05 15:15:13,998 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: -0.1923 reward: 0.1923 ref_reward: 0.1811 improvement: 6.19%
2024-12-05 15:15:14,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: -0.1923 reward: 0.1923 ref_reward: 0.1811 improvement: 6.18%
2024-12-05 15:15:14,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: -0.1923 reward: 0.1923 ref_reward: 0.1811 improvement: 6.18%
2024-12-05 15:15:14,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: -0.1923 reward: 0.1923 ref_reward: 0.1811 improvement: 6.18%
2024-12-05 15:15:14,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: -0.1923 reward: 0.1923 ref_reward: 0.1811 improvement: 6.19%
2024-12-05 15:15:14,899 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: -0.1923 reward: 0.1923 ref_reward: 0.1811 improvement: 6.19%
2024-12-05 15:15:15,080 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.20%
2024-12-05 15:15:15,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.21%
2024-12-05 15:15:15,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.21%
2024-12-05 15:15:15,625 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.22%
2024-12-05 15:15:15,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.22%
2024-12-05 15:15:15,985 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.22%
2024-12-05 15:15:16,162 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.22%
2024-12-05 15:15:16,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.22%
2024-12-05 15:15:16,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.22%
2024-12-05 15:15:16,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.22%
2024-12-05 15:15:16,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: -0.1924 reward: 0.1924 ref_reward: 0.1811 improvement: 6.22%
2024-12-05 15:15:17,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 0 loss: 0.7014 grad norm: 0.4403 policy: 0.3039 0.3668
2024-12-05 15:15:18,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 5 loss: 0.6630 grad norm: 0.3568 policy: 0.3408 0.3820
2024-12-05 15:15:18,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 10 loss: 0.6330 grad norm: 0.2723 policy: 0.3779 0.3930
2024-12-05 15:15:18,936 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 15 loss: 0.6128 grad norm: 0.1862 policy: 0.4121 0.4012
2024-12-05 15:15:19,374 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 20 loss: 0.6020 grad norm: 0.0946 policy: 0.4416 0.4061
2024-12-05 15:15:19,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 25 loss: 0.5990 grad norm: 0.0250 policy: 0.4676 0.4041
2024-12-05 15:15:20,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 30 loss: 0.5997 grad norm: 0.0540 policy: 0.4877 0.3967
2024-12-05 15:15:20,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 35 loss: 0.6004 grad norm: 0.0724 policy: 0.4997 0.3875
2024-12-05 15:15:21,122 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 40 loss: 0.6001 grad norm: 0.0640 policy: 0.5002 0.3833
2024-12-05 15:15:21,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 45 loss: 0.5993 grad norm: 0.0402 policy: 0.4914 0.3855
2024-12-05 15:15:21,998 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 50 loss: 0.5989 grad norm: 0.0133 policy: 0.4794 0.3912
2024-12-05 15:15:22,436 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 55 loss: 0.5988 grad norm: 0.0081 policy: 0.4701 0.3964
2024-12-05 15:15:22,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 60 loss: 0.5989 grad norm: 0.0177 policy: 0.4663 0.3985
2024-12-05 15:15:23,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 65 loss: 0.5989 grad norm: 0.0174 policy: 0.4676 0.3975
2024-12-05 15:15:23,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 70 loss: 0.5989 grad norm: 0.0112 policy: 0.4714 0.3952
2024-12-05 15:15:24,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 75 loss: 0.5988 grad norm: 0.0040 policy: 0.4749 0.3936
2024-12-05 15:15:24,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 80 loss: 0.5988 grad norm: 0.0030 policy: 0.4768 0.3933
2024-12-05 15:15:25,101 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 85 loss: 0.5988 grad norm: 0.0053 policy: 0.4770 0.3937
2024-12-05 15:15:25,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 90 loss: 0.5988 grad norm: 0.0049 policy: 0.4764 0.3941
2024-12-05 15:15:25,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 95 loss: 0.5988 grad norm: 0.0026 policy: 0.4756 0.3941
2024-12-05 15:15:26,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 0 loss: 1.1267 grad norm: 0.9166 policy: 0.2985 0.3851
2024-12-05 15:15:27,103 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 5 loss: 1.0492 grad norm: 0.8646 policy: 0.3387 0.3855
2024-12-05 15:15:27,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 10 loss: 0.9777 grad norm: 0.8539 policy: 0.3783 0.3849
2024-12-05 15:15:27,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 15 loss: 0.9105 grad norm: 0.8460 policy: 0.4199 0.3787
2024-12-05 15:15:28,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 20 loss: 0.8455 grad norm: 0.8372 policy: 0.4686 0.3621
2024-12-05 15:15:28,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 25 loss: 0.7833 grad norm: 0.8140 policy: 0.5236 0.3373
2024-12-05 15:15:29,314 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 30 loss: 0.7247 grad norm: 0.7499 policy: 0.5847 0.3046
2024-12-05 15:15:29,751 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 35 loss: 0.6740 grad norm: 0.6358 policy: 0.6450 0.2700
2024-12-05 15:15:30,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 40 loss: 0.6356 grad norm: 0.4770 policy: 0.6948 0.2421
2024-12-05 15:15:30,625 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 45 loss: 0.6117 grad norm: 0.2966 policy: 0.7339 0.2194
2024-12-05 15:15:31,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 50 loss: 0.6010 grad norm: 0.1260 policy: 0.7667 0.1974
2024-12-05 15:15:31,502 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 55 loss: 0.5988 grad norm: 0.0117 policy: 0.7895 0.1811
2024-12-05 15:15:31,940 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 60 loss: 0.5999 grad norm: 0.0924 policy: 0.7994 0.1745
2024-12-05 15:15:32,378 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 65 loss: 0.6009 grad norm: 0.1263 policy: 0.8029 0.1722
2024-12-05 15:15:32,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 70 loss: 0.6008 grad norm: 0.1226 policy: 0.8025 0.1722
2024-12-05 15:15:33,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 75 loss: 0.6000 grad norm: 0.0949 policy: 0.7974 0.1759
2024-12-05 15:15:33,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 80 loss: 0.5993 grad norm: 0.0581 policy: 0.7913 0.1803
2024-12-05 15:15:34,127 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 85 loss: 0.5989 grad norm: 0.0238 policy: 0.7865 0.1835
2024-12-05 15:15:34,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 90 loss: 0.5988 grad norm: 0.0023 policy: 0.7824 0.1865
2024-12-05 15:15:35,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 95 loss: 0.5989 grad norm: 0.0175 policy: 0.7801 0.1881
2024-12-05 15:15:35,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 0 loss: 9.0553 grad norm: 1.1574 policy: 0.3652 0.3544
2024-12-05 15:15:36,100 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 5 loss: 8.9285 grad norm: 1.1687 policy: 0.4396 0.3225
2024-12-05 15:15:36,538 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 10 loss: 8.8045 grad norm: 1.2360 policy: 0.5155 0.2858
2024-12-05 15:15:36,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 15 loss: 8.6890 grad norm: 1.3774 policy: 0.5870 0.2491
2024-12-05 15:15:37,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 20 loss: 8.5624 grad norm: 1.5723 policy: 0.6635 0.2076
2024-12-05 15:15:37,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 25 loss: 8.4136 grad norm: 1.7859 policy: 0.7437 0.1620
2024-12-05 15:15:38,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 30 loss: 8.2389 grad norm: 2.0185 policy: 0.8205 0.1163
2024-12-05 15:15:38,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 35 loss: 8.0346 grad norm: 2.2711 policy: 0.8862 0.0756
2024-12-05 15:15:39,173 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 40 loss: 7.7968 grad norm: 2.5440 policy: 0.9355 0.0439
2024-12-05 15:15:39,611 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 45 loss: 7.5217 grad norm: 2.8381 policy: 0.9676 0.0225
2024-12-05 15:15:40,049 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 50 loss: 7.2044 grad norm: 3.1545 policy: 0.9857 0.0101
2024-12-05 15:15:40,489 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 55 loss: 6.8407 grad norm: 3.4939 policy: 0.9945 0.0040
2024-12-05 15:15:40,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 60 loss: 6.4265 grad norm: 3.8564 policy: 0.9981 0.0014
2024-12-05 15:15:41,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 65 loss: 5.9578 grad norm: 4.2418 policy: 0.9995 0.0004
2024-12-05 15:15:41,802 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 70 loss: 5.4312 grad norm: 4.6501 policy: 0.9999 0.0001
2024-12-05 15:15:42,241 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 75 loss: 4.8428 grad norm: 5.0809 policy: 1.0000 0.0000
2024-12-05 15:15:42,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 80 loss: 4.1892 grad norm: 5.5338 policy: 1.0000 0.0000
2024-12-05 15:15:43,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 85 loss: 3.4671 grad norm: 6.0063 policy: 1.0000 0.0000
2024-12-05 15:15:43,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 90 loss: 2.6743 grad norm: 6.4762 policy: 1.0000 0.0000
2024-12-05 15:15:44,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 95 loss: 1.8219 grad norm: 6.7144 policy: 1.0000 0.0000
2024-12-05 15:15:44,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 0 loss: 0.6540 grad norm: 0.3619 policy: 0.3074 0.3177
2024-12-05 15:15:45,164 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 5 loss: 0.6253 grad norm: 0.2462 policy: 0.2790 0.3753
2024-12-05 15:15:45,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 10 loss: 0.6091 grad norm: 0.1542 policy: 0.2511 0.4277
2024-12-05 15:15:46,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 15 loss: 0.6017 grad norm: 0.0784 policy: 0.2247 0.4720
2024-12-05 15:15:46,508 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 20 loss: 0.5996 grad norm: 0.0403 policy: 0.2013 0.5024
2024-12-05 15:15:46,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 25 loss: 0.5998 grad norm: 0.0588 policy: 0.1852 0.5129
2024-12-05 15:15:47,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 30 loss: 0.5998 grad norm: 0.0611 policy: 0.1789 0.5058
2024-12-05 15:15:47,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 35 loss: 0.5994 grad norm: 0.0433 policy: 0.1807 0.4920
2024-12-05 15:15:48,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 40 loss: 0.5991 grad norm: 0.0241 policy: 0.1869 0.4810
2024-12-05 15:15:48,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 45 loss: 0.5989 grad norm: 0.0159 policy: 0.1936 0.4766
2024-12-05 15:15:49,164 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 50 loss: 0.5989 grad norm: 0.0148 policy: 0.1982 0.4778
2024-12-05 15:15:49,606 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 55 loss: 0.5989 grad norm: 0.0135 policy: 0.1997 0.4814
2024-12-05 15:15:50,048 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 60 loss: 0.5989 grad norm: 0.0108 policy: 0.1986 0.4847
2024-12-05 15:15:50,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 65 loss: 0.5988 grad norm: 0.0068 policy: 0.1962 0.4861
2024-12-05 15:15:50,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 70 loss: 0.5988 grad norm: 0.0032 policy: 0.1940 0.4857
2024-12-05 15:15:51,378 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 75 loss: 0.5988 grad norm: 0.0038 policy: 0.1929 0.4846
2024-12-05 15:15:51,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 80 loss: 0.5988 grad norm: 0.0042 policy: 0.1929 0.4839
2024-12-05 15:15:52,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 85 loss: 0.5988 grad norm: 0.0026 policy: 0.1937 0.4838
2024-12-05 15:15:52,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 90 loss: 0.5988 grad norm: 0.0003 policy: 0.1946 0.4842
2024-12-05 15:15:53,144 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 95 loss: 0.5988 grad norm: 0.0014 policy: 0.1951 0.4844
2024-12-05 15:17:20,553 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 0.0093 grad norm: 0.3378 
2024-12-05 15:17:21,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.0117 grad norm: 0.3052 
2024-12-05 15:17:22,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.0009 grad norm: 0.0928 
2024-12-05 15:17:22,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0002 grad norm: 0.0366 
2024-12-05 15:17:23,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0016 grad norm: 0.1040 
2024-12-05 15:17:23,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0006 grad norm: 0.0718 
2024-12-05 15:17:24,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0000 grad norm: 0.0145 
2024-12-05 15:17:24,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0003 grad norm: 0.0464 
2024-12-05 15:17:25,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0001 grad norm: 0.0282 
2024-12-05 15:17:25,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0000 grad norm: 0.0039 
2024-12-05 15:17:25,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0000 grad norm: 0.0156 
2024-12-05 15:17:26,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0175 
2024-12-05 15:17:26,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0113 
2024-12-05 15:17:27,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0023 
2024-12-05 15:17:27,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0019 
2024-12-05 15:17:28,168 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0011 
2024-12-05 15:17:28,617 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:17:29,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:17:29,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:17:29,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:17:30,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 1.3425 grad norm: 4.3522 
2024-12-05 15:17:31,073 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.0378 grad norm: 0.8964 
2024-12-05 15:17:31,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.0110 grad norm: 0.3382 
2024-12-05 15:17:31,972 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0143 grad norm: 0.3629 
2024-12-05 15:17:32,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0007 grad norm: 0.0873 
2024-12-05 15:17:32,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0040 grad norm: 0.2395 
2024-12-05 15:17:33,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0009 grad norm: 0.1070 
2024-12-05 15:17:33,753 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0013 grad norm: 0.1209 
2024-12-05 15:17:34,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0005 grad norm: 0.0733 
2024-12-05 15:17:34,636 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0003 grad norm: 0.0574 
2024-12-05 15:17:35,078 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0002 grad norm: 0.0535 
2024-12-05 15:17:35,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0001 grad norm: 0.0304 
2024-12-05 15:17:35,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0001 grad norm: 0.0334 
2024-12-05 15:17:36,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0232 
2024-12-05 15:17:36,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0054 
2024-12-05 15:17:37,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0139 
2024-12-05 15:17:37,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0022 
2024-12-05 15:17:38,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0088 
2024-12-05 15:17:38,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:17:39,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0048 
2024-12-05 15:17:39,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 672.1763 grad norm: 51.9193 
2024-12-05 15:17:40,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.1813 grad norm: 2.1099 
2024-12-05 15:17:40,835 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.1672 grad norm: 2.0678 
2024-12-05 15:17:41,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0360 grad norm: 0.8075 
2024-12-05 15:17:41,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0016 grad norm: 0.1495 
2024-12-05 15:17:42,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0073 grad norm: 0.3002 
2024-12-05 15:17:43,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0058 grad norm: 0.2706 
2024-12-05 15:17:43,926 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0016 grad norm: 0.1502 
2024-12-05 15:17:44,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0002 grad norm: 0.0543 
2024-12-05 15:17:44,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0005 grad norm: 0.0797 
2024-12-05 15:17:45,255 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0000 grad norm: 0.0140 
2024-12-05 15:17:45,697 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0002 grad norm: 0.0490 
2024-12-05 15:17:46,138 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0093 
2024-12-05 15:17:46,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0222 
2024-12-05 15:17:47,019 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0104 
2024-12-05 15:17:47,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0113 
2024-12-05 15:17:47,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0075 
2024-12-05 15:17:48,344 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0059 
2024-12-05 15:17:48,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0052 
2024-12-05 15:17:49,224 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0038 
2024-12-05 15:17:50,069 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 1.2307 grad norm: 4.0802 
2024-12-05 15:17:50,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.0127 grad norm: 0.5150 
2024-12-05 15:17:51,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.0134 grad norm: 0.4671 
2024-12-05 15:17:52,090 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0014 grad norm: 0.1609 
2024-12-05 15:17:52,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0024 grad norm: 0.1995 
2024-12-05 15:17:52,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0015 grad norm: 0.1503 
2024-12-05 15:17:53,424 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0003 grad norm: 0.0697 
2024-12-05 15:17:53,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0008 grad norm: 0.1088 
2024-12-05 15:17:54,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0000 grad norm: 0.0044 
2024-12-05 15:17:54,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0003 grad norm: 0.0606 
2024-12-05 15:17:55,201 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0000 grad norm: 0.0235 
2024-12-05 15:17:55,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0001 grad norm: 0.0269 
2024-12-05 15:17:56,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0258 
2024-12-05 15:17:56,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0035 
2024-12-05 15:17:56,994 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:17:57,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0018 
2024-12-05 15:17:57,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0014 
2024-12-05 15:17:58,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:17:58,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:17:59,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:18:00,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.3333, 0.3333, 0.3333]), new_distribution = tensor([0.3336, 0.3334, 0.3330])
2024-12-05 15:18:00,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.3336, 0.3334, 0.3330]), new_distribution = tensor([0.3338, 0.3335, 0.3327])
2024-12-05 15:18:00,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.3338, 0.3335, 0.3327]), new_distribution = tensor([0.3340, 0.3336, 0.3324])
2024-12-05 15:18:00,300 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.3340, 0.3336, 0.3324]), new_distribution = tensor([0.3342, 0.3337, 0.3321])
2024-12-05 15:18:00,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.3342, 0.3337, 0.3321]), new_distribution = tensor([0.3344, 0.3338, 0.3318])
2024-12-05 15:18:00,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.3344, 0.3338, 0.3318]), new_distribution = tensor([0.3346, 0.3339, 0.3315])
2024-12-05 15:18:00,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.3346, 0.3339, 0.3315]), new_distribution = tensor([0.3349, 0.3340, 0.3312])
2024-12-05 15:18:00,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.3349, 0.3340, 0.3312]), new_distribution = tensor([0.3351, 0.3341, 0.3309])
2024-12-05 15:18:00,574 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.3351, 0.3341, 0.3309]), new_distribution = tensor([0.3353, 0.3341, 0.3306])
2024-12-05 15:18:00,629 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.3353, 0.3341, 0.3306]), new_distribution = tensor([0.3355, 0.3342, 0.3302])
2024-12-05 15:18:00,683 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.3355, 0.3342, 0.3302]), new_distribution = tensor([0.3357, 0.3343, 0.3299])
2024-12-05 15:18:00,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.3357, 0.3343, 0.3299]), new_distribution = tensor([0.3360, 0.3344, 0.3296])
2024-12-05 15:18:00,792 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.3360, 0.3344, 0.3296]), new_distribution = tensor([0.3362, 0.3345, 0.3293])
2024-12-05 15:18:00,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.3362, 0.3345, 0.3293]), new_distribution = tensor([0.3364, 0.3346, 0.3290])
2024-12-05 15:18:00,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.3364, 0.3346, 0.3290]), new_distribution = tensor([0.3366, 0.3347, 0.3287])
2024-12-05 15:18:00,955 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.3366, 0.3347, 0.3287]), new_distribution = tensor([0.3369, 0.3347, 0.3284])
2024-12-05 15:18:01,009 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.3369, 0.3347, 0.3284]), new_distribution = tensor([0.3371, 0.3348, 0.3281])
2024-12-05 15:18:01,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.3371, 0.3348, 0.3281]), new_distribution = tensor([0.3373, 0.3349, 0.3278])
2024-12-05 15:18:01,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.3373, 0.3349, 0.3278]), new_distribution = tensor([0.3375, 0.3350, 0.3275])
2024-12-05 15:18:01,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.3375, 0.3350, 0.3275]), new_distribution = tensor([0.3377, 0.3351, 0.3272])
2024-12-05 15:18:01,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.3377, 0.3351, 0.3272]), new_distribution = tensor([0.3380, 0.3352, 0.3269])
2024-12-05 15:18:01,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.3380, 0.3352, 0.3269]), new_distribution = tensor([0.3382, 0.3352, 0.3266])
2024-12-05 15:18:01,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.3382, 0.3352, 0.3266]), new_distribution = tensor([0.3384, 0.3353, 0.3263])
2024-12-05 15:18:01,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.3384, 0.3353, 0.3263]), new_distribution = tensor([0.3386, 0.3354, 0.3260])
2024-12-05 15:18:01,445 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.3386, 0.3354, 0.3260]), new_distribution = tensor([0.3389, 0.3355, 0.3257])
2024-12-05 15:18:01,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.3389, 0.3355, 0.3257]), new_distribution = tensor([0.3391, 0.3356, 0.3253])
2024-12-05 15:18:01,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.3391, 0.3356, 0.3253]), new_distribution = tensor([0.3393, 0.3356, 0.3250])
2024-12-05 15:18:01,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.3393, 0.3356, 0.3250]), new_distribution = tensor([0.3395, 0.3357, 0.3247])
2024-12-05 15:18:01,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.3395, 0.3357, 0.3247]), new_distribution = tensor([0.3398, 0.3358, 0.3244])
2024-12-05 15:18:01,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.3398, 0.3358, 0.3244]), new_distribution = tensor([0.3400, 0.3359, 0.3241])
2024-12-05 15:18:01,772 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.3400, 0.3359, 0.3241]), new_distribution = tensor([0.3402, 0.3360, 0.3238])
2024-12-05 15:18:01,826 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.3402, 0.3360, 0.3238]), new_distribution = tensor([0.3404, 0.3360, 0.3235])
2024-12-05 15:18:01,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.3404, 0.3360, 0.3235]), new_distribution = tensor([0.3407, 0.3361, 0.3232])
2024-12-05 15:18:01,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.3407, 0.3361, 0.3232]), new_distribution = tensor([0.3409, 0.3362, 0.3229])
2024-12-05 15:18:01,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.3409, 0.3362, 0.3229]), new_distribution = tensor([0.3411, 0.3363, 0.3226])
2024-12-05 15:18:02,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.3411, 0.3363, 0.3226]), new_distribution = tensor([0.3414, 0.3363, 0.3223])
2024-12-05 15:18:02,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.3414, 0.3363, 0.3223]), new_distribution = tensor([0.3416, 0.3364, 0.3220])
2024-12-05 15:18:02,152 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.3416, 0.3364, 0.3220]), new_distribution = tensor([0.3418, 0.3365, 0.3217])
2024-12-05 15:18:02,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.3418, 0.3365, 0.3217]), new_distribution = tensor([0.3420, 0.3365, 0.3214])
2024-12-05 15:18:02,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.3420, 0.3365, 0.3214]), new_distribution = tensor([0.3423, 0.3366, 0.3211])
2024-12-05 15:18:02,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.3423, 0.3366, 0.3211]), new_distribution = tensor([0.3425, 0.3367, 0.3208])
2024-12-05 15:18:02,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.3425, 0.3367, 0.3208]), new_distribution = tensor([0.3427, 0.3368, 0.3205])
2024-12-05 15:18:02,423 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.3427, 0.3368, 0.3205]), new_distribution = tensor([0.3430, 0.3368, 0.3202])
2024-12-05 15:18:02,477 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.3430, 0.3368, 0.3202]), new_distribution = tensor([0.3432, 0.3369, 0.3199])
2024-12-05 15:18:02,532 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.3432, 0.3369, 0.3199]), new_distribution = tensor([0.3434, 0.3370, 0.3196])
2024-12-05 15:18:02,586 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.3434, 0.3370, 0.3196]), new_distribution = tensor([0.3436, 0.3370, 0.3193])
2024-12-05 15:18:02,640 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.3436, 0.3370, 0.3193]), new_distribution = tensor([0.3439, 0.3371, 0.3190])
2024-12-05 15:18:02,694 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.3439, 0.3371, 0.3190]), new_distribution = tensor([0.3441, 0.3372, 0.3187])
2024-12-05 15:18:02,749 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.3441, 0.3372, 0.3187]), new_distribution = tensor([0.3443, 0.3372, 0.3184])
2024-12-05 15:18:02,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.3443, 0.3372, 0.3184]), new_distribution = tensor([0.3446, 0.3373, 0.3181])
2024-12-05 15:18:02,857 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.3446, 0.3373, 0.3181]), new_distribution = tensor([0.3448, 0.3374, 0.3178])
2024-12-05 15:18:02,912 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.3448, 0.3374, 0.3178]), new_distribution = tensor([0.3450, 0.3374, 0.3175])
2024-12-05 15:18:02,966 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.3450, 0.3374, 0.3175]), new_distribution = tensor([0.3453, 0.3375, 0.3172])
2024-12-05 15:18:03,021 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.3453, 0.3375, 0.3172]), new_distribution = tensor([0.3455, 0.3376, 0.3169])
2024-12-05 15:18:03,075 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.3455, 0.3376, 0.3169]), new_distribution = tensor([0.3457, 0.3376, 0.3166])
2024-12-05 15:18:03,129 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.3457, 0.3376, 0.3166]), new_distribution = tensor([0.3460, 0.3377, 0.3163])
2024-12-05 15:18:03,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.3460, 0.3377, 0.3163]), new_distribution = tensor([0.3462, 0.3378, 0.3160])
2024-12-05 15:18:03,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.3462, 0.3378, 0.3160]), new_distribution = tensor([0.3464, 0.3378, 0.3157])
2024-12-05 15:18:03,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.3464, 0.3378, 0.3157]), new_distribution = tensor([0.3467, 0.3379, 0.3154])
2024-12-05 15:18:03,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.3467, 0.3379, 0.3154]), new_distribution = tensor([0.3469, 0.3380, 0.3151])
2024-12-05 15:18:03,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.3469, 0.3380, 0.3151]), new_distribution = tensor([0.3471, 0.3380, 0.3149])
2024-12-05 15:18:03,456 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.3471, 0.3380, 0.3149]), new_distribution = tensor([0.3474, 0.3381, 0.3146])
2024-12-05 15:18:03,510 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.3474, 0.3381, 0.3146]), new_distribution = tensor([0.3476, 0.3381, 0.3143])
2024-12-05 15:18:03,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.3476, 0.3381, 0.3143]), new_distribution = tensor([0.3478, 0.3382, 0.3140])
2024-12-05 15:18:03,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.3478, 0.3382, 0.3140]), new_distribution = tensor([0.3481, 0.3383, 0.3137])
2024-12-05 15:18:03,673 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.3481, 0.3383, 0.3137]), new_distribution = tensor([0.3483, 0.3383, 0.3134])
2024-12-05 15:18:03,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.3483, 0.3383, 0.3134]), new_distribution = tensor([0.3485, 0.3384, 0.3131])
2024-12-05 15:18:03,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.3485, 0.3384, 0.3131]), new_distribution = tensor([0.3488, 0.3384, 0.3128])
2024-12-05 15:18:03,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.3488, 0.3384, 0.3128]), new_distribution = tensor([0.3490, 0.3385, 0.3125])
2024-12-05 15:18:03,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.3490, 0.3385, 0.3125]), new_distribution = tensor([0.3493, 0.3385, 0.3122])
2024-12-05 15:18:03,945 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.3493, 0.3385, 0.3122]), new_distribution = tensor([0.3495, 0.3386, 0.3119])
2024-12-05 15:18:03,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.3495, 0.3386, 0.3119]), new_distribution = tensor([0.3497, 0.3386, 0.3116])
2024-12-05 15:18:04,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.3497, 0.3386, 0.3116]), new_distribution = tensor([0.3500, 0.3387, 0.3113])
2024-12-05 15:18:04,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.3500, 0.3387, 0.3113]), new_distribution = tensor([0.3502, 0.3388, 0.3110])
2024-12-05 15:18:04,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.3502, 0.3388, 0.3110]), new_distribution = tensor([0.3504, 0.3388, 0.3107])
2024-12-05 15:18:04,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.3504, 0.3388, 0.3107]), new_distribution = tensor([0.3507, 0.3389, 0.3104])
2024-12-05 15:18:04,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.3507, 0.3389, 0.3104]), new_distribution = tensor([0.3509, 0.3389, 0.3102])
2024-12-05 15:18:04,326 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.3509, 0.3389, 0.3102]), new_distribution = tensor([0.3512, 0.3390, 0.3099])
2024-12-05 15:18:04,380 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.3512, 0.3390, 0.3099]), new_distribution = tensor([0.3514, 0.3390, 0.3096])
2024-12-05 15:18:04,434 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.3514, 0.3390, 0.3096]), new_distribution = tensor([0.3516, 0.3391, 0.3093])
2024-12-05 15:18:04,489 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.3516, 0.3391, 0.3093]), new_distribution = tensor([0.3519, 0.3391, 0.3090])
2024-12-05 15:18:04,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.3519, 0.3391, 0.3090]), new_distribution = tensor([0.3521, 0.3392, 0.3087])
2024-12-05 15:18:04,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.3521, 0.3392, 0.3087]), new_distribution = tensor([0.3524, 0.3392, 0.3084])
2024-12-05 15:18:04,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.3524, 0.3392, 0.3084]), new_distribution = tensor([0.3526, 0.3393, 0.3081])
2024-12-05 15:18:04,708 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.3526, 0.3393, 0.3081]), new_distribution = tensor([0.3528, 0.3393, 0.3078])
2024-12-05 15:18:04,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.3528, 0.3393, 0.3078]), new_distribution = tensor([0.3531, 0.3394, 0.3075])
2024-12-05 15:18:04,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.3531, 0.3394, 0.3075]), new_distribution = tensor([0.3533, 0.3394, 0.3073])
2024-12-05 15:18:04,871 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.3533, 0.3394, 0.3073]), new_distribution = tensor([0.3536, 0.3395, 0.3070])
2024-12-05 15:18:04,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.3536, 0.3395, 0.3070]), new_distribution = tensor([0.3538, 0.3395, 0.3067])
2024-12-05 15:18:04,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.3538, 0.3395, 0.3067]), new_distribution = tensor([0.3541, 0.3396, 0.3064])
2024-12-05 15:18:05,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.3541, 0.3396, 0.3064]), new_distribution = tensor([0.3543, 0.3396, 0.3061])
2024-12-05 15:18:05,091 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.3543, 0.3396, 0.3061]), new_distribution = tensor([0.3545, 0.3396, 0.3058])
2024-12-05 15:18:05,145 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.3545, 0.3396, 0.3058]), new_distribution = tensor([0.3548, 0.3397, 0.3055])
2024-12-05 15:18:05,199 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.3548, 0.3397, 0.3055]), new_distribution = tensor([0.3550, 0.3397, 0.3052])
2024-12-05 15:18:05,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.3550, 0.3397, 0.3052]), new_distribution = tensor([0.3553, 0.3398, 0.3050])
2024-12-05 15:18:05,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.3553, 0.3398, 0.3050]), new_distribution = tensor([0.3555, 0.3398, 0.3047])
2024-12-05 15:18:05,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.3555, 0.3398, 0.3047]), new_distribution = tensor([0.3558, 0.3399, 0.3044])
2024-12-05 15:18:05,418 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.3558, 0.3399, 0.3044]), new_distribution = tensor([0.3560, 0.3399, 0.3041])
2024-12-05 15:18:05,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.3560, 0.3399, 0.3041]), new_distribution = tensor([0.3562, 0.3399, 0.3038])
2024-12-05 15:18:05,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.3562, 0.3399, 0.3038]), new_distribution = tensor([0.3565, 0.3400, 0.3035])
2024-12-05 15:18:05,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.7000, 0.2000, 0.1000]), new_distribution = tensor([0.7003, 0.1997, 0.1000])
2024-12-05 15:18:05,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.7003, 0.1997, 0.1000]), new_distribution = tensor([0.7006, 0.1994, 0.0999])
2024-12-05 15:18:05,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.7006, 0.1994, 0.0999]), new_distribution = tensor([0.7009, 0.1991, 0.0999])
2024-12-05 15:18:05,969 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.7009, 0.1991, 0.0999]), new_distribution = tensor([0.7013, 0.1988, 0.0999])
2024-12-05 15:18:06,024 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.7013, 0.1988, 0.0999]), new_distribution = tensor([0.7016, 0.1986, 0.0999])
2024-12-05 15:18:06,078 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.7016, 0.1986, 0.0999]), new_distribution = tensor([0.7019, 0.1983, 0.0998])
2024-12-05 15:18:06,133 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.7019, 0.1983, 0.0998]), new_distribution = tensor([0.7022, 0.1980, 0.0998])
2024-12-05 15:18:06,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.7022, 0.1980, 0.0998]), new_distribution = tensor([0.7025, 0.1977, 0.0998])
2024-12-05 15:18:06,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.7025, 0.1977, 0.0998]), new_distribution = tensor([0.7028, 0.1974, 0.0998])
2024-12-05 15:18:06,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.7028, 0.1974, 0.0998]), new_distribution = tensor([0.7031, 0.1971, 0.0997])
2024-12-05 15:18:06,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.7031, 0.1971, 0.0997]), new_distribution = tensor([0.7035, 0.1968, 0.0997])
2024-12-05 15:18:06,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.7035, 0.1968, 0.0997]), new_distribution = tensor([0.7038, 0.1965, 0.0997])
2024-12-05 15:18:06,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.7038, 0.1965, 0.0997]), new_distribution = tensor([0.7041, 0.1963, 0.0997])
2024-12-05 15:18:06,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.7041, 0.1963, 0.0997]), new_distribution = tensor([0.7044, 0.1960, 0.0996])
2024-12-05 15:18:06,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.7044, 0.1960, 0.0996]), new_distribution = tensor([0.7047, 0.1957, 0.0996])
2024-12-05 15:18:06,624 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.7047, 0.1957, 0.0996]), new_distribution = tensor([0.7050, 0.1954, 0.0996])
2024-12-05 15:18:06,678 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.7050, 0.1954, 0.0996]), new_distribution = tensor([0.7053, 0.1951, 0.0996])
2024-12-05 15:18:06,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.7053, 0.1951, 0.0996]), new_distribution = tensor([0.7056, 0.1948, 0.0995])
2024-12-05 15:18:06,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.7056, 0.1948, 0.0995]), new_distribution = tensor([0.7059, 0.1945, 0.0995])
2024-12-05 15:18:06,841 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.7059, 0.1945, 0.0995]), new_distribution = tensor([0.7062, 0.1943, 0.0995])
2024-12-05 15:18:06,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.7062, 0.1943, 0.0995]), new_distribution = tensor([0.7066, 0.1940, 0.0995])
2024-12-05 15:18:06,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.7066, 0.1940, 0.0995]), new_distribution = tensor([0.7069, 0.1937, 0.0994])
2024-12-05 15:18:07,005 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.7069, 0.1937, 0.0994]), new_distribution = tensor([0.7072, 0.1934, 0.0994])
2024-12-05 15:18:07,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.7072, 0.1934, 0.0994]), new_distribution = tensor([0.7075, 0.1931, 0.0994])
2024-12-05 15:18:07,114 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.7075, 0.1931, 0.0994]), new_distribution = tensor([0.7078, 0.1928, 0.0994])
2024-12-05 15:18:07,168 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.7078, 0.1928, 0.0994]), new_distribution = tensor([0.7081, 0.1926, 0.0994])
2024-12-05 15:18:07,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.7081, 0.1926, 0.0994]), new_distribution = tensor([0.7084, 0.1923, 0.0993])
2024-12-05 15:18:07,281 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.7084, 0.1923, 0.0993]), new_distribution = tensor([0.7087, 0.1920, 0.0993])
2024-12-05 15:18:07,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.7087, 0.1920, 0.0993]), new_distribution = tensor([0.7090, 0.1917, 0.0993])
2024-12-05 15:18:07,390 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.7090, 0.1917, 0.0993]), new_distribution = tensor([0.7093, 0.1914, 0.0993])
2024-12-05 15:18:07,445 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.7093, 0.1914, 0.0993]), new_distribution = tensor([0.7096, 0.1912, 0.0992])
2024-12-05 15:18:07,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.7096, 0.1912, 0.0992]), new_distribution = tensor([0.7099, 0.1909, 0.0992])
2024-12-05 15:18:07,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.7099, 0.1909, 0.0992]), new_distribution = tensor([0.7102, 0.1906, 0.0992])
2024-12-05 15:18:07,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.7102, 0.1906, 0.0992]), new_distribution = tensor([0.7105, 0.1903, 0.0992])
2024-12-05 15:18:07,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.7105, 0.1903, 0.0992]), new_distribution = tensor([0.7108, 0.1900, 0.0991])
2024-12-05 15:18:07,718 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.7108, 0.1900, 0.0991]), new_distribution = tensor([0.7111, 0.1897, 0.0991])
2024-12-05 15:18:07,772 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.7111, 0.1897, 0.0991]), new_distribution = tensor([0.7114, 0.1895, 0.0991])
2024-12-05 15:18:07,827 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.7114, 0.1895, 0.0991]), new_distribution = tensor([0.7117, 0.1892, 0.0991])
2024-12-05 15:18:07,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.7117, 0.1892, 0.0991]), new_distribution = tensor([0.7120, 0.1889, 0.0991])
2024-12-05 15:18:07,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.7120, 0.1889, 0.0991]), new_distribution = tensor([0.7123, 0.1886, 0.0990])
2024-12-05 15:18:07,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.7123, 0.1886, 0.0990]), new_distribution = tensor([0.7126, 0.1883, 0.0990])
2024-12-05 15:18:08,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.7126, 0.1883, 0.0990]), new_distribution = tensor([0.7129, 0.1881, 0.0990])
2024-12-05 15:18:08,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.7129, 0.1881, 0.0990]), new_distribution = tensor([0.7132, 0.1878, 0.0990])
2024-12-05 15:18:08,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.7132, 0.1878, 0.0990]), new_distribution = tensor([0.7135, 0.1875, 0.0990])
2024-12-05 15:18:08,208 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.7135, 0.1875, 0.0990]), new_distribution = tensor([0.7138, 0.1872, 0.0989])
2024-12-05 15:18:08,262 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.7138, 0.1872, 0.0989]), new_distribution = tensor([0.7141, 0.1870, 0.0989])
2024-12-05 15:18:08,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.7141, 0.1870, 0.0989]), new_distribution = tensor([0.7144, 0.1867, 0.0989])
2024-12-05 15:18:08,371 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.7144, 0.1867, 0.0989]), new_distribution = tensor([0.7147, 0.1864, 0.0989])
2024-12-05 15:18:08,427 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.7147, 0.1864, 0.0989]), new_distribution = tensor([0.7150, 0.1861, 0.0988])
2024-12-05 15:18:08,481 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.7150, 0.1861, 0.0988]), new_distribution = tensor([0.7153, 0.1858, 0.0988])
2024-12-05 15:18:08,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.7153, 0.1858, 0.0988]), new_distribution = tensor([0.7156, 0.1856, 0.0988])
2024-12-05 15:18:08,590 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.7156, 0.1856, 0.0988]), new_distribution = tensor([0.7159, 0.1853, 0.0988])
2024-12-05 15:18:08,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.7159, 0.1853, 0.0988]), new_distribution = tensor([0.7162, 0.1850, 0.0988])
2024-12-05 15:18:08,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.7162, 0.1850, 0.0988]), new_distribution = tensor([0.7165, 0.1847, 0.0987])
2024-12-05 15:18:08,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.7165, 0.1847, 0.0987]), new_distribution = tensor([0.7168, 0.1845, 0.0987])
2024-12-05 15:18:08,809 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.7168, 0.1845, 0.0987]), new_distribution = tensor([0.7171, 0.1842, 0.0987])
2024-12-05 15:18:08,864 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.7171, 0.1842, 0.0987]), new_distribution = tensor([0.7174, 0.1839, 0.0987])
2024-12-05 15:18:08,918 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.7174, 0.1839, 0.0987]), new_distribution = tensor([0.7177, 0.1836, 0.0987])
2024-12-05 15:18:08,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.7177, 0.1836, 0.0987]), new_distribution = tensor([0.7180, 0.1834, 0.0986])
2024-12-05 15:18:09,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.7180, 0.1834, 0.0986]), new_distribution = tensor([0.7183, 0.1831, 0.0986])
2024-12-05 15:18:09,081 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.7183, 0.1831, 0.0986]), new_distribution = tensor([0.7186, 0.1828, 0.0986])
2024-12-05 15:18:09,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.7186, 0.1828, 0.0986]), new_distribution = tensor([0.7189, 0.1825, 0.0986])
2024-12-05 15:18:09,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.7189, 0.1825, 0.0986]), new_distribution = tensor([0.7192, 0.1823, 0.0986])
2024-12-05 15:18:09,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.7192, 0.1823, 0.0986]), new_distribution = tensor([0.7195, 0.1820, 0.0985])
2024-12-05 15:18:09,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.7195, 0.1820, 0.0985]), new_distribution = tensor([0.7197, 0.1817, 0.0985])
2024-12-05 15:18:09,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.7197, 0.1817, 0.0985]), new_distribution = tensor([0.7200, 0.1815, 0.0985])
2024-12-05 15:18:09,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.7200, 0.1815, 0.0985]), new_distribution = tensor([0.7203, 0.1812, 0.0985])
2024-12-05 15:18:09,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.7203, 0.1812, 0.0985]), new_distribution = tensor([0.7206, 0.1809, 0.0985])
2024-12-05 15:18:09,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.7206, 0.1809, 0.0985]), new_distribution = tensor([0.7209, 0.1806, 0.0985])
2024-12-05 15:18:09,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.7209, 0.1806, 0.0985]), new_distribution = tensor([0.7212, 0.1804, 0.0984])
2024-12-05 15:18:09,625 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.7212, 0.1804, 0.0984]), new_distribution = tensor([0.7215, 0.1801, 0.0984])
2024-12-05 15:18:09,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.7215, 0.1801, 0.0984]), new_distribution = tensor([0.7218, 0.1798, 0.0984])
2024-12-05 15:18:09,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.7218, 0.1798, 0.0984]), new_distribution = tensor([0.7221, 0.1795, 0.0984])
2024-12-05 15:18:09,788 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.7221, 0.1795, 0.0984]), new_distribution = tensor([0.7224, 0.1793, 0.0984])
2024-12-05 15:18:09,842 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.7224, 0.1793, 0.0984]), new_distribution = tensor([0.7226, 0.1790, 0.0983])
2024-12-05 15:18:09,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.7226, 0.1790, 0.0983]), new_distribution = tensor([0.7229, 0.1787, 0.0983])
2024-12-05 15:18:09,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.7229, 0.1787, 0.0983]), new_distribution = tensor([0.7232, 0.1785, 0.0983])
2024-12-05 15:18:10,005 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.7232, 0.1785, 0.0983]), new_distribution = tensor([0.7235, 0.1782, 0.0983])
2024-12-05 15:18:10,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.7235, 0.1782, 0.0983]), new_distribution = tensor([0.7238, 0.1779, 0.0983])
2024-12-05 15:18:10,114 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.7238, 0.1779, 0.0983]), new_distribution = tensor([0.7241, 0.1777, 0.0983])
2024-12-05 15:18:10,169 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.7241, 0.1777, 0.0983]), new_distribution = tensor([0.7244, 0.1774, 0.0982])
2024-12-05 15:18:10,224 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.7244, 0.1774, 0.0982]), new_distribution = tensor([0.7247, 0.1771, 0.0982])
2024-12-05 15:18:10,278 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.7247, 0.1771, 0.0982]), new_distribution = tensor([0.7249, 0.1769, 0.0982])
2024-12-05 15:18:10,332 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.7249, 0.1769, 0.0982]), new_distribution = tensor([0.7252, 0.1766, 0.0982])
2024-12-05 15:18:10,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.7252, 0.1766, 0.0982]), new_distribution = tensor([0.7255, 0.1763, 0.0982])
2024-12-05 15:18:10,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.7255, 0.1763, 0.0982]), new_distribution = tensor([0.7258, 0.1761, 0.0982])
2024-12-05 15:18:10,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.7258, 0.1761, 0.0982]), new_distribution = tensor([0.7261, 0.1758, 0.0981])
2024-12-05 15:18:10,549 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.7261, 0.1758, 0.0981]), new_distribution = tensor([0.7264, 0.1755, 0.0981])
2024-12-05 15:18:10,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.7264, 0.1755, 0.0981]), new_distribution = tensor([0.7266, 0.1753, 0.0981])
2024-12-05 15:18:10,657 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.7266, 0.1753, 0.0981]), new_distribution = tensor([0.7269, 0.1750, 0.0981])
2024-12-05 15:18:10,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.7269, 0.1750, 0.0981]), new_distribution = tensor([0.7272, 0.1747, 0.0981])
2024-12-05 15:18:10,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.7272, 0.1747, 0.0981]), new_distribution = tensor([0.7275, 0.1745, 0.0981])
2024-12-05 15:18:10,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.7275, 0.1745, 0.0981]), new_distribution = tensor([0.7278, 0.1742, 0.0980])
2024-12-05 15:18:10,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.7278, 0.1742, 0.0980]), new_distribution = tensor([0.7280, 0.1739, 0.0980])
2024-12-05 15:18:10,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.7280, 0.1739, 0.0980]), new_distribution = tensor([0.7283, 0.1737, 0.0980])
2024-12-05 15:18:10,983 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.7283, 0.1737, 0.0980]), new_distribution = tensor([0.7286, 0.1734, 0.0980])
2024-12-05 15:18:11,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.7286, 0.1734, 0.0980]), new_distribution = tensor([0.7289, 0.1731, 0.0980])
2024-12-05 15:18:11,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.7289, 0.1731, 0.0980]), new_distribution = tensor([0.7292, 0.1729, 0.0980])
2024-12-05 15:18:11,147 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.7292, 0.1729, 0.0980]), new_distribution = tensor([0.7294, 0.1726, 0.0980])
2024-12-05 15:18:11,201 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.7294, 0.1726, 0.0980]), new_distribution = tensor([0.7297, 0.1723, 0.0979])
2024-12-05 15:18:11,469 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:11,524 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:11,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:11,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:11,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:11,742 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:11,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:11,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:11,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:11,961 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,181 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,235 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,349 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,403 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,512 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,566 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,620 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,838 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:12,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,001 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,110 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,164 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,219 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,436 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,490 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,544 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,598 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:13,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,304 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,413 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,467 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,521 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,739 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,794 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,902 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:14,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,556 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,718 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,827 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:15,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,152 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,370 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,424 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,478 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,751 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:16,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:18:17,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.1000, 0.3000, 0.6000]), new_distribution = tensor([0.1000, 0.3005, 0.5994])
2024-12-05 15:18:17,194 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.1000, 0.3005, 0.5994]), new_distribution = tensor([0.1001, 0.3011, 0.5989])
2024-12-05 15:18:17,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.1001, 0.3011, 0.5989]), new_distribution = tensor([0.1001, 0.3016, 0.5983])
2024-12-05 15:18:17,303 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.1001, 0.3016, 0.5983]), new_distribution = tensor([0.1002, 0.3021, 0.5977])
2024-12-05 15:18:17,357 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.1002, 0.3021, 0.5977]), new_distribution = tensor([0.1002, 0.3027, 0.5971])
2024-12-05 15:18:17,412 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.1002, 0.3027, 0.5971]), new_distribution = tensor([0.1002, 0.3032, 0.5966])
2024-12-05 15:18:17,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.1002, 0.3032, 0.5966]), new_distribution = tensor([0.1003, 0.3037, 0.5960])
2024-12-05 15:18:17,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.1003, 0.3037, 0.5960]), new_distribution = tensor([0.1003, 0.3043, 0.5954])
2024-12-05 15:18:17,575 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.1003, 0.3043, 0.5954]), new_distribution = tensor([0.1004, 0.3048, 0.5948])
2024-12-05 15:18:17,629 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.1004, 0.3048, 0.5948]), new_distribution = tensor([0.1004, 0.3053, 0.5942])
2024-12-05 15:18:17,683 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.1004, 0.3053, 0.5942]), new_distribution = tensor([0.1005, 0.3059, 0.5937])
2024-12-05 15:18:17,738 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.1005, 0.3059, 0.5937]), new_distribution = tensor([0.1005, 0.3064, 0.5931])
2024-12-05 15:18:17,792 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.1005, 0.3064, 0.5931]), new_distribution = tensor([0.1005, 0.3069, 0.5925])
2024-12-05 15:18:17,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.1005, 0.3069, 0.5925]), new_distribution = tensor([0.1006, 0.3075, 0.5919])
2024-12-05 15:18:17,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.1006, 0.3075, 0.5919]), new_distribution = tensor([0.1006, 0.3080, 0.5913])
2024-12-05 15:18:17,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.1006, 0.3080, 0.5913]), new_distribution = tensor([0.1007, 0.3086, 0.5908])
2024-12-05 15:18:18,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.1007, 0.3086, 0.5908]), new_distribution = tensor([0.1007, 0.3091, 0.5902])
2024-12-05 15:18:18,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.1007, 0.3091, 0.5902]), new_distribution = tensor([0.1008, 0.3096, 0.5896])
2024-12-05 15:18:18,116 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.1008, 0.3096, 0.5896]), new_distribution = tensor([0.1008, 0.3102, 0.5890])
2024-12-05 15:18:18,170 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.1008, 0.3102, 0.5890]), new_distribution = tensor([0.1009, 0.3107, 0.5884])
2024-12-05 15:18:18,224 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.1009, 0.3107, 0.5884]), new_distribution = tensor([0.1009, 0.3112, 0.5879])
2024-12-05 15:18:18,278 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.1009, 0.3112, 0.5879]), new_distribution = tensor([0.1009, 0.3118, 0.5873])
2024-12-05 15:18:18,332 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.1009, 0.3118, 0.5873]), new_distribution = tensor([0.1010, 0.3123, 0.5867])
2024-12-05 15:18:18,386 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.1010, 0.3123, 0.5867]), new_distribution = tensor([0.1010, 0.3129, 0.5861])
2024-12-05 15:18:18,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.1010, 0.3129, 0.5861]), new_distribution = tensor([0.1011, 0.3134, 0.5855])
2024-12-05 15:18:18,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.1011, 0.3134, 0.5855]), new_distribution = tensor([0.1011, 0.3139, 0.5849])
2024-12-05 15:18:18,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.1011, 0.3139, 0.5849]), new_distribution = tensor([0.1012, 0.3145, 0.5843])
2024-12-05 15:18:18,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.1012, 0.3145, 0.5843]), new_distribution = tensor([0.1012, 0.3150, 0.5838])
2024-12-05 15:18:18,657 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.1012, 0.3150, 0.5838]), new_distribution = tensor([0.1013, 0.3156, 0.5832])
2024-12-05 15:18:18,713 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.1013, 0.3156, 0.5832]), new_distribution = tensor([0.1013, 0.3161, 0.5826])
2024-12-05 15:18:18,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.1013, 0.3161, 0.5826]), new_distribution = tensor([0.1014, 0.3166, 0.5820])
2024-12-05 15:18:18,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.1014, 0.3166, 0.5820]), new_distribution = tensor([0.1014, 0.3172, 0.5814])
2024-12-05 15:18:18,875 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.1014, 0.3172, 0.5814]), new_distribution = tensor([0.1015, 0.3177, 0.5808])
2024-12-05 15:18:18,930 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.1015, 0.3177, 0.5808]), new_distribution = tensor([0.1015, 0.3183, 0.5802])
2024-12-05 15:18:18,984 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.1015, 0.3183, 0.5802]), new_distribution = tensor([0.1016, 0.3188, 0.5796])
2024-12-05 15:18:19,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.1016, 0.3188, 0.5796]), new_distribution = tensor([0.1016, 0.3193, 0.5791])
2024-12-05 15:18:19,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.1016, 0.3193, 0.5791]), new_distribution = tensor([0.1016, 0.3199, 0.5785])
2024-12-05 15:18:19,147 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.1016, 0.3199, 0.5785]), new_distribution = tensor([0.1017, 0.3204, 0.5779])
2024-12-05 15:18:19,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.1017, 0.3204, 0.5779]), new_distribution = tensor([0.1017, 0.3210, 0.5773])
2024-12-05 15:18:19,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.1017, 0.3210, 0.5773]), new_distribution = tensor([0.1018, 0.3215, 0.5767])
2024-12-05 15:18:19,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.1018, 0.3215, 0.5767]), new_distribution = tensor([0.1018, 0.3221, 0.5761])
2024-12-05 15:18:19,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.1018, 0.3221, 0.5761]), new_distribution = tensor([0.1019, 0.3226, 0.5755])
2024-12-05 15:18:19,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.1019, 0.3226, 0.5755]), new_distribution = tensor([0.1019, 0.3231, 0.5749])
2024-12-05 15:18:19,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.1019, 0.3231, 0.5749]), new_distribution = tensor([0.1020, 0.3237, 0.5743])
2024-12-05 15:18:19,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.1020, 0.3237, 0.5743]), new_distribution = tensor([0.1020, 0.3242, 0.5737])
2024-12-05 15:18:19,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.1020, 0.3242, 0.5737]), new_distribution = tensor([0.1021, 0.3248, 0.5731])
2024-12-05 15:18:19,636 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.1021, 0.3248, 0.5731]), new_distribution = tensor([0.1021, 0.3253, 0.5725])
2024-12-05 15:18:19,690 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.1021, 0.3253, 0.5725]), new_distribution = tensor([0.1022, 0.3259, 0.5719])
2024-12-05 15:18:19,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.1022, 0.3259, 0.5719]), new_distribution = tensor([0.1022, 0.3264, 0.5713])
2024-12-05 15:18:19,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.1022, 0.3264, 0.5713]), new_distribution = tensor([0.1023, 0.3270, 0.5707])
2024-12-05 15:18:19,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.1023, 0.3270, 0.5707]), new_distribution = tensor([0.1023, 0.3275, 0.5702])
2024-12-05 15:18:19,907 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.1023, 0.3275, 0.5702]), new_distribution = tensor([0.1024, 0.3281, 0.5696])
2024-12-05 15:18:19,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.1024, 0.3281, 0.5696]), new_distribution = tensor([0.1024, 0.3286, 0.5690])
2024-12-05 15:18:20,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.1024, 0.3286, 0.5690]), new_distribution = tensor([0.1025, 0.3291, 0.5684])
2024-12-05 15:18:20,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.1025, 0.3291, 0.5684]), new_distribution = tensor([0.1025, 0.3297, 0.5678])
2024-12-05 15:18:20,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.1025, 0.3297, 0.5678]), new_distribution = tensor([0.1026, 0.3302, 0.5672])
2024-12-05 15:18:20,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.1026, 0.3302, 0.5672]), new_distribution = tensor([0.1027, 0.3308, 0.5666])
2024-12-05 15:18:20,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.1027, 0.3308, 0.5666]), new_distribution = tensor([0.1027, 0.3313, 0.5660])
2024-12-05 15:18:20,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.1027, 0.3313, 0.5660]), new_distribution = tensor([0.1028, 0.3319, 0.5654])
2024-12-05 15:18:20,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.1028, 0.3319, 0.5654]), new_distribution = tensor([0.1028, 0.3324, 0.5648])
2024-12-05 15:18:20,395 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.1028, 0.3324, 0.5648]), new_distribution = tensor([0.1029, 0.3330, 0.5642])
2024-12-05 15:18:20,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.1029, 0.3330, 0.5642]), new_distribution = tensor([0.1029, 0.3335, 0.5636])
2024-12-05 15:18:20,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.1029, 0.3335, 0.5636]), new_distribution = tensor([0.1030, 0.3341, 0.5630])
2024-12-05 15:18:20,557 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.1030, 0.3341, 0.5630]), new_distribution = tensor([0.1030, 0.3346, 0.5624])
2024-12-05 15:18:20,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.1030, 0.3346, 0.5624]), new_distribution = tensor([0.1031, 0.3352, 0.5618])
2024-12-05 15:18:20,666 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.1031, 0.3352, 0.5618]), new_distribution = tensor([0.1031, 0.3357, 0.5612])
2024-12-05 15:18:20,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.1031, 0.3357, 0.5612]), new_distribution = tensor([0.1032, 0.3363, 0.5606])
2024-12-05 15:18:20,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.1032, 0.3363, 0.5606]), new_distribution = tensor([0.1032, 0.3368, 0.5600])
2024-12-05 15:18:20,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.1032, 0.3368, 0.5600]), new_distribution = tensor([0.1033, 0.3374, 0.5593])
2024-12-05 15:18:20,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.1033, 0.3374, 0.5593]), new_distribution = tensor([0.1033, 0.3379, 0.5587])
2024-12-05 15:18:20,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.1033, 0.3379, 0.5587]), new_distribution = tensor([0.1034, 0.3385, 0.5581])
2024-12-05 15:18:20,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.1034, 0.3385, 0.5581]), new_distribution = tensor([0.1035, 0.3390, 0.5575])
2024-12-05 15:18:21,046 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.1035, 0.3390, 0.5575]), new_distribution = tensor([0.1035, 0.3396, 0.5569])
2024-12-05 15:18:21,101 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.1035, 0.3396, 0.5569]), new_distribution = tensor([0.1036, 0.3401, 0.5563])
2024-12-05 15:18:21,155 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.1036, 0.3401, 0.5563]), new_distribution = tensor([0.1036, 0.3407, 0.5557])
2024-12-05 15:18:21,209 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.1036, 0.3407, 0.5557]), new_distribution = tensor([0.1037, 0.3412, 0.5551])
2024-12-05 15:18:21,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.1037, 0.3412, 0.5551]), new_distribution = tensor([0.1037, 0.3418, 0.5545])
2024-12-05 15:18:21,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.1037, 0.3418, 0.5545]), new_distribution = tensor([0.1038, 0.3423, 0.5539])
2024-12-05 15:18:21,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.1038, 0.3423, 0.5539]), new_distribution = tensor([0.1038, 0.3429, 0.5533])
2024-12-05 15:18:21,427 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.1038, 0.3429, 0.5533]), new_distribution = tensor([0.1039, 0.3434, 0.5527])
2024-12-05 15:18:21,482 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.1039, 0.3434, 0.5527]), new_distribution = tensor([0.1040, 0.3440, 0.5521])
2024-12-05 15:18:21,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.1040, 0.3440, 0.5521]), new_distribution = tensor([0.1040, 0.3445, 0.5515])
2024-12-05 15:18:21,590 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.1040, 0.3445, 0.5515]), new_distribution = tensor([0.1041, 0.3451, 0.5509])
2024-12-05 15:18:21,644 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.1041, 0.3451, 0.5509]), new_distribution = tensor([0.1041, 0.3456, 0.5503])
2024-12-05 15:18:21,698 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.1041, 0.3456, 0.5503]), new_distribution = tensor([0.1042, 0.3462, 0.5496])
2024-12-05 15:18:21,753 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.1042, 0.3462, 0.5496]), new_distribution = tensor([0.1043, 0.3467, 0.5490])
2024-12-05 15:18:21,807 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.1043, 0.3467, 0.5490]), new_distribution = tensor([0.1043, 0.3473, 0.5484])
2024-12-05 15:18:21,861 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.1043, 0.3473, 0.5484]), new_distribution = tensor([0.1044, 0.3478, 0.5478])
2024-12-05 15:18:21,916 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.1044, 0.3478, 0.5478]), new_distribution = tensor([0.1044, 0.3484, 0.5472])
2024-12-05 15:18:21,970 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.1044, 0.3484, 0.5472]), new_distribution = tensor([0.1045, 0.3489, 0.5466])
2024-12-05 15:18:22,024 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.1045, 0.3489, 0.5466]), new_distribution = tensor([0.1045, 0.3495, 0.5460])
2024-12-05 15:18:22,078 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.1045, 0.3495, 0.5460]), new_distribution = tensor([0.1046, 0.3500, 0.5454])
2024-12-05 15:18:22,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.1046, 0.3500, 0.5454]), new_distribution = tensor([0.1047, 0.3506, 0.5448])
2024-12-05 15:18:22,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.1047, 0.3506, 0.5448]), new_distribution = tensor([0.1047, 0.3511, 0.5441])
2024-12-05 15:18:22,241 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.1047, 0.3511, 0.5441]), new_distribution = tensor([0.1048, 0.3517, 0.5435])
2024-12-05 15:18:22,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.1048, 0.3517, 0.5435]), new_distribution = tensor([0.1048, 0.3522, 0.5429])
2024-12-05 15:18:22,350 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.1048, 0.3522, 0.5429]), new_distribution = tensor([0.1049, 0.3528, 0.5423])
2024-12-05 15:18:22,405 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.1049, 0.3528, 0.5423]), new_distribution = tensor([0.1050, 0.3533, 0.5417])
2024-12-05 15:18:22,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.1050, 0.3533, 0.5417]), new_distribution = tensor([0.1050, 0.3539, 0.5411])
2024-12-05 15:18:22,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.1050, 0.3539, 0.5411]), new_distribution = tensor([0.1051, 0.3544, 0.5405])
2024-12-05 15:21:29,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 0.0149 grad norm: 0.4436 
2024-12-05 15:21:30,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.0206 grad norm: 0.4339 
2024-12-05 15:21:31,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.0003 grad norm: 0.0525 
2024-12-05 15:21:31,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0038 grad norm: 0.1895 
2024-12-05 15:21:32,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0023 grad norm: 0.1247 
2024-12-05 15:21:32,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0004 grad norm: 0.0570 
2024-12-05 15:21:33,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0012 grad norm: 0.1014 
2024-12-05 15:21:33,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0000 grad norm: 0.0173 
2024-12-05 15:21:34,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0000 grad norm: 0.0074 
2024-12-05 15:21:34,511 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0000 grad norm: 0.0044 
2024-12-05 15:21:34,953 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0000 grad norm: 0.0080 
2024-12-05 15:21:35,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0047 
2024-12-05 15:21:35,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:21:36,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0032 
2024-12-05 15:21:36,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0027 
2024-12-05 15:21:37,170 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0012 
2024-12-05 15:21:37,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:21:38,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:21:38,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0010 
2024-12-05 15:21:38,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:21:39,568 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 1.5734 grad norm: 3.8402 
2024-12-05 15:21:40,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.0426 grad norm: 0.8116 
2024-12-05 15:21:40,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.0010 grad norm: 0.0938 
2024-12-05 15:21:40,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0098 grad norm: 0.2481 
2024-12-05 15:21:41,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0048 grad norm: 0.1822 
2024-12-05 15:21:41,754 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0001 grad norm: 0.0204 
2024-12-05 15:21:42,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0023 grad norm: 0.1506 
2024-12-05 15:21:42,629 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0000 grad norm: 0.0139 
2024-12-05 15:21:43,080 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0000 grad norm: 0.0068 
2024-12-05 15:21:43,524 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0000 grad norm: 0.0057 
2024-12-05 15:21:43,965 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0000 grad norm: 0.0074 
2024-12-05 15:21:44,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0028 
2024-12-05 15:21:44,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0034 
2024-12-05 15:21:45,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0029 
2024-12-05 15:21:45,711 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0017 
2024-12-05 15:21:46,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:21:46,585 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:21:47,020 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:21:47,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:21:47,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:21:48,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 681.8371 grad norm: 67.1205 
2024-12-05 15:21:49,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.8131 grad norm: 8.2585 
2024-12-05 15:21:49,452 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.3392 grad norm: 4.4541 
2024-12-05 15:21:49,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0187 grad norm: 0.7132 
2024-12-05 15:21:50,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0216 grad norm: 0.6655 
2024-12-05 15:21:50,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0452 grad norm: 0.8561 
2024-12-05 15:21:51,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0428 grad norm: 0.8034 
2024-12-05 15:21:51,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0007 grad norm: 0.1029 
2024-12-05 15:21:52,116 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0017 grad norm: 0.1617 
2024-12-05 15:21:52,552 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0016 grad norm: 0.1548 
2024-12-05 15:21:52,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0008 grad norm: 0.1102 
2024-12-05 15:21:53,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0002 grad norm: 0.0551 
2024-12-05 15:21:53,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0092 
2024-12-05 15:21:54,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0245 
2024-12-05 15:21:54,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0001 grad norm: 0.0359 
2024-12-05 15:21:55,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0001 grad norm: 0.0318 
2024-12-05 15:21:55,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0197 
2024-12-05 15:21:56,116 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0062 
2024-12-05 15:21:56,665 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0049 
2024-12-05 15:21:57,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0033 
2024-12-05 15:21:58,368 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 1.2777 grad norm: 3.0285 
2024-12-05 15:21:58,814 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.0276 grad norm: 0.5265 
2024-12-05 15:21:59,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.0027 grad norm: 0.1428 
2024-12-05 15:21:59,699 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0046 grad norm: 0.1698 
2024-12-05 15:22:00,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0002 grad norm: 0.0347 
2024-12-05 15:22:01,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0003 grad norm: 0.0454 
2024-12-05 15:22:01,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0003 grad norm: 0.0453 
2024-12-05 15:22:02,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0001 grad norm: 0.0214 
2024-12-05 15:22:02,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0001 grad norm: 0.0178 
2024-12-05 15:22:03,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0000 grad norm: 0.0078 
2024-12-05 15:22:03,446 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0000 grad norm: 0.0129 
2024-12-05 15:22:03,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0056 
2024-12-05 15:22:04,421 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0061 
2024-12-05 15:22:04,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0014 
2024-12-05 15:22:05,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0013 
2024-12-05 15:22:05,743 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:22:06,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:22:06,630 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0000 
2024-12-05 15:22:07,072 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:22:07,517 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:24:30,390 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 0.0399 grad norm: 0.6619 
2024-12-05 15:24:31,185 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.0001 grad norm: 0.0298 
2024-12-05 15:24:31,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.0039 grad norm: 0.1318 
2024-12-05 15:24:32,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0001 grad norm: 0.0218 
2024-12-05 15:24:32,988 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0009 grad norm: 0.0650 
2024-12-05 15:24:33,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0000 grad norm: 0.0048 
2024-12-05 15:24:33,863 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0003 grad norm: 0.0348 
2024-12-05 15:24:34,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0000 grad norm: 0.0066 
2024-12-05 15:24:34,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0000 grad norm: 0.0044 
2024-12-05 15:24:35,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0000 grad norm: 0.0013 
2024-12-05 15:24:35,617 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0000 grad norm: 0.0030 
2024-12-05 15:24:36,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0024 
2024-12-05 15:24:36,492 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0015 
2024-12-05 15:24:36,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:24:37,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:24:37,807 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:24:38,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:24:38,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:24:39,138 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0000 
2024-12-05 15:24:39,578 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:24:40,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:24:40,458 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:24:40,897 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:24:41,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:24:41,777 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:24:42,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:24:42,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:24:43,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:24:43,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:24:43,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:24:44,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0000 
2024-12-05 15:24:44,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:24:45,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:24:45,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:24:46,169 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:24:46,607 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:24:47,046 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:24:47,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:24:47,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:24:48,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:24:48,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:24:49,239 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:24:49,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:24:50,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:24:50,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:24:50,993 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:24:51,431 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:24:51,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:24:52,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:24:52,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:24:53,185 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:24:53,624 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:24:54,061 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:24:54,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:24:54,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:24:55,378 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:24:55,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:24:56,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:24:56,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:24:57,133 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:24:57,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 1.4385 grad norm: 4.5674 
2024-12-05 15:24:58,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.0110 grad norm: 0.5514 
2024-12-05 15:24:58,670 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.0347 grad norm: 0.7360 
2024-12-05 15:24:59,111 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0000 grad norm: 0.0242 
2024-12-05 15:24:59,550 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0077 grad norm: 0.4379 
2024-12-05 15:24:59,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0017 grad norm: 0.1793 
2024-12-05 15:25:00,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0019 grad norm: 0.1913 
2024-12-05 15:25:00,872 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0014 grad norm: 0.1710 
2024-12-05 15:25:01,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0000 grad norm: 0.0218 
2024-12-05 15:25:01,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0004 grad norm: 0.0894 
2024-12-05 15:25:02,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0001 grad norm: 0.0531 
2024-12-05 15:25:02,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0247 
2024-12-05 15:25:03,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0001 grad norm: 0.0460 
2024-12-05 15:25:03,511 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0113 
2024-12-05 15:25:03,951 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0037 
2024-12-05 15:25:04,390 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0040 
2024-12-05 15:25:04,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0052 
2024-12-05 15:25:05,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0020 
2024-12-05 15:25:05,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0013 
2024-12-05 15:25:06,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0028 
2024-12-05 15:25:06,590 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0010 
2024-12-05 15:25:07,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:25:07,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0012 
2024-12-05 15:25:07,912 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:25:08,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:08,794 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0010 
2024-12-05 15:25:09,241 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:25:09,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:25:10,134 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:25:10,575 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:25:11,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:11,456 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:25:11,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:12,335 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:12,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:25:13,215 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:25:13,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:14,096 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0008 
2024-12-05 15:25:14,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:14,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:25:15,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:15,855 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:25:16,294 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:16,734 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0008 
2024-12-05 15:25:17,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:25:17,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:25:18,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:25:18,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:25:18,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:25:19,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0008 
2024-12-05 15:25:19,831 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:25:20,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:21,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:25:22,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:25:22,517 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:25:22,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:25:23,405 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:25:23,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:25:24,297 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:24,744 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:25,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 680.2136 grad norm: 67.5688 
2024-12-05 15:25:25,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.6362 grad norm: 6.2632 
2024-12-05 15:25:26,301 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.2626 grad norm: 3.4569 
2024-12-05 15:25:26,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0017 grad norm: 0.2168 
2024-12-05 15:25:27,193 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0436 grad norm: 1.0292 
2024-12-05 15:25:27,639 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0244 grad norm: 0.8071 
2024-12-05 15:25:28,085 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0093 grad norm: 0.6018 
2024-12-05 15:25:28,531 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0048 grad norm: 0.3864 
2024-12-05 15:25:29,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0005 grad norm: 0.1177 
2024-12-05 15:25:29,511 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0013 grad norm: 0.1851 
2024-12-05 15:25:29,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0005 grad norm: 0.1129 
2024-12-05 15:25:30,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0002 grad norm: 0.0770 
2024-12-05 15:25:30,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0003 grad norm: 0.0862 
2024-12-05 15:25:31,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0001 grad norm: 0.0506 
2024-12-05 15:25:31,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0237 
2024-12-05 15:25:32,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0269 
2024-12-05 15:25:32,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0169 
2024-12-05 15:25:33,031 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0145 
2024-12-05 15:25:33,470 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0108 
2024-12-05 15:25:33,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0107 
2024-12-05 15:25:34,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0025 
2024-12-05 15:25:34,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0064 
2024-12-05 15:25:35,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0011 
2024-12-05 15:25:35,686 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0039 
2024-12-05 15:25:36,127 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:25:36,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0022 
2024-12-05 15:25:37,007 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0011 
2024-12-05 15:25:37,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0015 
2024-12-05 15:25:37,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:25:38,327 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:25:38,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:25:39,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0014 
2024-12-05 15:25:39,647 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0013 
2024-12-05 15:25:40,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0008 
2024-12-05 15:25:40,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:25:40,985 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:25:41,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:41,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0015 
2024-12-05 15:25:42,326 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0013 
2024-12-05 15:25:42,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:25:43,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:25:43,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:44,106 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:25:44,553 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0015 
2024-12-05 15:25:45,001 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0011 
2024-12-05 15:25:45,448 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:25:45,895 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:25:46,355 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:25:46,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:25:47,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0014 
2024-12-05 15:25:47,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0010 
2024-12-05 15:25:48,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:25:48,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:25:49,032 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:25:49,478 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:25:49,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0014 
2024-12-05 15:25:50,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0008 
2024-12-05 15:25:50,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:25:51,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:25:51,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:25:52,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 1.4408 grad norm: 4.6095 
2024-12-05 15:25:53,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.0540 grad norm: 0.9052 
2024-12-05 15:25:53,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.0013 grad norm: 0.0943 
2024-12-05 15:25:53,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0110 grad norm: 0.2317 
2024-12-05 15:25:54,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0073 grad norm: 0.1803 
2024-12-05 15:25:54,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0001 grad norm: 0.0232 
2024-12-05 15:25:55,241 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0006 grad norm: 0.0657 
2024-12-05 15:25:55,686 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0001 grad norm: 0.0303 
2024-12-05 15:25:56,131 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0002 grad norm: 0.0376 
2024-12-05 15:25:56,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0000 grad norm: 0.0068 
2024-12-05 15:25:57,019 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0001 grad norm: 0.0180 
2024-12-05 15:25:57,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0051 
2024-12-05 15:25:57,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0111 
2024-12-05 15:25:58,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0052 
2024-12-05 15:25:58,798 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0015 
2024-12-05 15:25:59,243 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0033 
2024-12-05 15:25:59,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:26:00,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0019 
2024-12-05 15:26:00,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:26:01,021 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:26:01,467 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:26:01,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:26:02,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:26:02,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:26:03,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:26:03,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:26:04,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:26:04,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:26:05,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:26:05,472 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:26:05,918 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:26:06,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:26:06,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:26:07,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:26:07,708 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:26:08,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:26:08,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:26:09,048 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:26:09,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:26:09,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:26:10,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:26:10,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:26:11,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:26:11,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:26:12,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:26:12,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:26:13,077 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:26:13,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:26:13,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:26:14,412 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:26:14,857 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:26:15,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:26:15,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:26:16,192 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:26:16,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:26:17,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:26:17,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:26:17,972 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:26:18,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:26:18,862 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:30:33,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 0.0582 grad norm: 1.0254 
2024-12-05 15:30:34,080 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.0162 grad norm: 0.4297 
2024-12-05 15:30:34,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.0007 grad norm: 0.0900 
2024-12-05 15:30:35,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0032 grad norm: 0.1844 
2024-12-05 15:30:35,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0032 grad norm: 0.1588 
2024-12-05 15:30:36,262 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0001 grad norm: 0.0318 
2024-12-05 15:30:36,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0013 grad norm: 0.1120 
2024-12-05 15:30:37,168 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0003 grad norm: 0.0479 
2024-12-05 15:30:37,614 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0000 grad norm: 0.0206 
2024-12-05 15:30:38,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0000 grad norm: 0.0167 
2024-12-05 15:30:38,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0001 grad norm: 0.0229 
2024-12-05 15:30:38,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0120 
2024-12-05 15:30:39,378 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0034 
2024-12-05 15:30:39,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0103 
2024-12-05 15:30:40,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0068 
2024-12-05 15:30:40,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0018 
2024-12-05 15:30:41,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0024 
2024-12-05 15:30:41,617 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0035 
2024-12-05 15:30:42,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0028 
2024-12-05 15:30:42,511 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0010 
2024-12-05 15:30:42,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:30:43,404 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:30:43,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:30:44,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:30:44,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:30:45,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:30:45,639 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:30:46,078 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:30:46,517 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:30:46,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:30:47,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:30:47,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:30:48,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:30:48,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:30:49,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:30:49,599 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:30:50,039 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:30:50,484 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:30:50,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:30:51,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:30:51,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:30:52,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:30:52,682 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:30:53,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:30:53,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:30:54,003 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:30:54,442 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:30:54,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:30:55,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:30:55,763 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0008 
2024-12-05 15:30:56,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:30:56,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:30:57,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:30:57,518 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:30:57,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:30:58,398 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0008 
2024-12-05 15:30:58,838 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:30:59,277 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:30:59,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:00,157 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:31:00,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 1.5002 grad norm: 4.2627 
2024-12-05 15:31:01,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.0381 grad norm: 0.8816 
2024-12-05 15:31:01,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.0157 grad norm: 0.3760 
2024-12-05 15:31:02,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0168 grad norm: 0.3764 
2024-12-05 15:31:02,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0000 grad norm: 0.0123 
2024-12-05 15:31:03,072 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0065 grad norm: 0.3033 
2024-12-05 15:31:03,512 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0001 grad norm: 0.0287 
2024-12-05 15:31:03,965 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0018 grad norm: 0.1349 
2024-12-05 15:31:04,404 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0006 grad norm: 0.0769 
2024-12-05 15:31:04,852 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0004 grad norm: 0.0679 
2024-12-05 15:31:05,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0003 grad norm: 0.0556 
2024-12-05 15:31:05,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0001 grad norm: 0.0393 
2024-12-05 15:31:06,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0001 grad norm: 0.0329 
2024-12-05 15:31:06,611 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0001 grad norm: 0.0283 
2024-12-05 15:31:07,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0055 
2024-12-05 15:31:07,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0173 
2024-12-05 15:31:07,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0010 
2024-12-05 15:31:08,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0106 
2024-12-05 15:31:08,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0020 
2024-12-05 15:31:09,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0054 
2024-12-05 15:31:09,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:31:10,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0029 
2024-12-05 15:31:10,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0017 
2024-12-05 15:31:11,005 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0010 
2024-12-05 15:31:11,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0014 
2024-12-05 15:31:11,884 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:12,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:31:12,763 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:13,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:31:13,640 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:14,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:31:14,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:14,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:31:15,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:31:15,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:31:16,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:16,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:31:17,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:17,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:31:18,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:31:18,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:31:18,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:31:19,355 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:19,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:31:20,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:31:20,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:31:21,114 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:31:21,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0000 
2024-12-05 15:31:21,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:31:22,435 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:31:22,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:31:23,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:31:23,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:31:24,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:31:24,644 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:31:25,085 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:31:25,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:31:25,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:31:26,402 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:31:26,841 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:27,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 641.1761 grad norm: 49.4679 
2024-12-05 15:31:27,943 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.4025 grad norm: 4.1884 
2024-12-05 15:31:28,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.2915 grad norm: 3.4406 
2024-12-05 15:31:28,826 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0217 grad norm: 0.7434 
2024-12-05 15:31:29,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0131 grad norm: 0.5146 
2024-12-05 15:31:29,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0415 grad norm: 0.8770 
2024-12-05 15:31:30,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0245 grad norm: 0.6611 
2024-12-05 15:31:30,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0027 grad norm: 0.2172 
2024-12-05 15:31:31,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0049 grad norm: 0.2923 
2024-12-05 15:31:31,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0023 grad norm: 0.1992 
2024-12-05 15:31:31,945 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0001 grad norm: 0.0466 
2024-12-05 15:31:32,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0003 grad norm: 0.0697 
2024-12-05 15:31:32,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0006 grad norm: 0.1022 
2024-12-05 15:31:33,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0086 
2024-12-05 15:31:33,729 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0115 
2024-12-05 15:31:34,168 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0064 
2024-12-05 15:31:34,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0008 
2024-12-05 15:31:35,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0046 
2024-12-05 15:31:35,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0039 
2024-12-05 15:31:35,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:31:36,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0017 
2024-12-05 15:31:36,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0011 
2024-12-05 15:31:37,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:37,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:31:38,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:31:38,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:31:39,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:31:39,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:31:39,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:31:40,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:31:40,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:41,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:31:41,763 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:42,211 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:31:42,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:31:43,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:31:43,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:44,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:31:44,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:31:44,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:31:45,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:45,798 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:46,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:46,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:31:47,137 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:31:47,585 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:31:48,032 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:31:48,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:31:48,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:31:49,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:31:49,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:31:50,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:31:50,713 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:31:51,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:31:51,605 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:31:52,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:31:52,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:31:52,945 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:31:53,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:31:53,842 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:31:54,512 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 0 loss: 1.1022 grad norm: 3.6805 
2024-12-05 15:31:54,966 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 5 loss: 0.0362 grad norm: 0.8082 
2024-12-05 15:31:55,413 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 10 loss: 0.0200 grad norm: 0.4174 
2024-12-05 15:31:55,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 15 loss: 0.0156 grad norm: 0.3655 
2024-12-05 15:31:56,304 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 20 loss: 0.0009 grad norm: 0.1055 
2024-12-05 15:31:56,744 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 25 loss: 0.0062 grad norm: 0.2884 
2024-12-05 15:31:57,182 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 30 loss: 0.0003 grad norm: 0.0605 
2024-12-05 15:31:57,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 35 loss: 0.0013 grad norm: 0.1133 
2024-12-05 15:31:58,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 40 loss: 0.0004 grad norm: 0.0608 
2024-12-05 15:31:58,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 45 loss: 0.0004 grad norm: 0.0629 
2024-12-05 15:31:58,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 50 loss: 0.0001 grad norm: 0.0400 
2024-12-05 15:31:59,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 55 loss: 0.0001 grad norm: 0.0375 
2024-12-05 15:31:59,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 60 loss: 0.0001 grad norm: 0.0229 
2024-12-05 15:32:00,266 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 65 loss: 0.0001 grad norm: 0.0271 
2024-12-05 15:32:00,705 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0022 
2024-12-05 15:32:01,144 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0163 
2024-12-05 15:32:01,584 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0021 
2024-12-05 15:32:02,022 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0092 
2024-12-05 15:32:02,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0042 
2024-12-05 15:32:02,901 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0036 
2024-12-05 15:32:03,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:32:03,780 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0022 
2024-12-05 15:32:04,219 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0008 
2024-12-05 15:32:04,659 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0009 
2024-12-05 15:32:05,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0010 
2024-12-05 15:32:05,538 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:32:05,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:32:06,416 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:32:06,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:32:07,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:32:07,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:32:08,173 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:32:08,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:32:09,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:32:09,490 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:32:09,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:32:10,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:32:10,809 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:32:11,252 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:32:11,697 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:32:12,140 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:32:12,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:32:13,022 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:32:13,463 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0006 
2024-12-05 15:32:13,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:32:14,342 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0005 
2024-12-05 15:32:14,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:32:15,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:32:15,660 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:32:16,100 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:32:16,538 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:32:16,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:32:17,416 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:32:17,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:32:18,295 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0001 
2024-12-05 15:32:18,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0007 
2024-12-05 15:32:19,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0002 
2024-12-05 15:32:19,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:32:20,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0004 
2024-12-05 15:32:20,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:472] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0003 
2024-12-05 15:33:00,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.3565, 0.3400, 0.3035]), new_distribution = tensor([0.3573, 0.3398, 0.3028])
2024-12-05 15:33:00,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.3573, 0.3398, 0.3028]), new_distribution = tensor([0.3582, 0.3397, 0.3021])
2024-12-05 15:33:00,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.3582, 0.3397, 0.3021]), new_distribution = tensor([0.3590, 0.3396, 0.3014])
2024-12-05 15:33:00,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.3590, 0.3396, 0.3014]), new_distribution = tensor([0.3599, 0.3394, 0.3007])
2024-12-05 15:33:00,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.3599, 0.3394, 0.3007]), new_distribution = tensor([0.3607, 0.3393, 0.3000])
2024-12-05 15:33:00,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.3607, 0.3393, 0.3000]), new_distribution = tensor([0.3616, 0.3391, 0.2993])
2024-12-05 15:33:00,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.3616, 0.3391, 0.2993]), new_distribution = tensor([0.3624, 0.3390, 0.2986])
2024-12-05 15:33:00,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.3624, 0.3390, 0.2986]), new_distribution = tensor([0.3633, 0.3388, 0.2979])
2024-12-05 15:33:00,760 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.3633, 0.3388, 0.2979]), new_distribution = tensor([0.3641, 0.3386, 0.2972])
2024-12-05 15:33:00,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.3641, 0.3386, 0.2972]), new_distribution = tensor([0.3650, 0.3385, 0.2965])
2024-12-05 15:33:00,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.3650, 0.3385, 0.2965]), new_distribution = tensor([0.3659, 0.3383, 0.2958])
2024-12-05 15:33:00,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.3659, 0.3383, 0.2958]), new_distribution = tensor([0.3667, 0.3382, 0.2951])
2024-12-05 15:33:01,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.3667, 0.3382, 0.2951]), new_distribution = tensor([0.3676, 0.3380, 0.2944])
2024-12-05 15:33:01,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.3676, 0.3380, 0.2944]), new_distribution = tensor([0.3684, 0.3378, 0.2937])
2024-12-05 15:33:01,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.3684, 0.3378, 0.2937]), new_distribution = tensor([0.3693, 0.3377, 0.2930])
2024-12-05 15:33:01,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.3693, 0.3377, 0.2930]), new_distribution = tensor([0.3701, 0.3375, 0.2924])
2024-12-05 15:33:01,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.3701, 0.3375, 0.2924]), new_distribution = tensor([0.3710, 0.3373, 0.2917])
2024-12-05 15:33:01,477 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.3710, 0.3373, 0.2917]), new_distribution = tensor([0.3719, 0.3372, 0.2910])
2024-12-05 15:33:01,556 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.3719, 0.3372, 0.2910]), new_distribution = tensor([0.3727, 0.3370, 0.2903])
2024-12-05 15:33:01,636 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.3727, 0.3370, 0.2903]), new_distribution = tensor([0.3736, 0.3368, 0.2896])
2024-12-05 15:33:01,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.3736, 0.3368, 0.2896]), new_distribution = tensor([0.3745, 0.3366, 0.2889])
2024-12-05 15:33:01,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.3745, 0.3366, 0.2889]), new_distribution = tensor([0.3753, 0.3364, 0.2882])
2024-12-05 15:33:01,875 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.3753, 0.3364, 0.2882]), new_distribution = tensor([0.3762, 0.3363, 0.2875])
2024-12-05 15:33:01,955 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.3762, 0.3363, 0.2875]), new_distribution = tensor([0.3771, 0.3361, 0.2869])
2024-12-05 15:33:02,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.3771, 0.3361, 0.2869]), new_distribution = tensor([0.3779, 0.3359, 0.2862])
2024-12-05 15:33:02,114 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.3779, 0.3359, 0.2862]), new_distribution = tensor([0.3788, 0.3357, 0.2855])
2024-12-05 15:33:02,193 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.3788, 0.3357, 0.2855]), new_distribution = tensor([0.3797, 0.3355, 0.2848])
2024-12-05 15:33:02,269 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.3797, 0.3355, 0.2848]), new_distribution = tensor([0.3805, 0.3353, 0.2841])
2024-12-05 15:33:02,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.3805, 0.3353, 0.2841]), new_distribution = tensor([0.3814, 0.3351, 0.2835])
2024-12-05 15:33:02,408 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.3814, 0.3351, 0.2835]), new_distribution = tensor([0.3823, 0.3349, 0.2828])
2024-12-05 15:33:02,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.3823, 0.3349, 0.2828]), new_distribution = tensor([0.3832, 0.3347, 0.2821])
2024-12-05 15:33:02,534 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.3832, 0.3347, 0.2821]), new_distribution = tensor([0.3840, 0.3345, 0.2814])
2024-12-05 15:33:02,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.3840, 0.3345, 0.2814]), new_distribution = tensor([0.3849, 0.3343, 0.2808])
2024-12-05 15:33:02,649 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.3849, 0.3343, 0.2808]), new_distribution = tensor([0.3858, 0.3341, 0.2801])
2024-12-05 15:33:02,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.3858, 0.3341, 0.2801]), new_distribution = tensor([0.3867, 0.3339, 0.2794])
2024-12-05 15:33:02,758 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.3867, 0.3339, 0.2794]), new_distribution = tensor([0.3875, 0.3337, 0.2787])
2024-12-05 15:33:02,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.3875, 0.3337, 0.2787]), new_distribution = tensor([0.3884, 0.3335, 0.2781])
2024-12-05 15:33:02,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.3884, 0.3335, 0.2781]), new_distribution = tensor([0.3893, 0.3333, 0.2774])
2024-12-05 15:33:02,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.3893, 0.3333, 0.2774]), new_distribution = tensor([0.3902, 0.3331, 0.2767])
2024-12-05 15:33:02,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.3902, 0.3331, 0.2767]), new_distribution = tensor([0.3910, 0.3329, 0.2761])
2024-12-05 15:33:03,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.3910, 0.3329, 0.2761]), new_distribution = tensor([0.3919, 0.3327, 0.2754])
2024-12-05 15:33:03,083 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.3919, 0.3327, 0.2754]), new_distribution = tensor([0.3928, 0.3325, 0.2747])
2024-12-05 15:33:03,137 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.3928, 0.3325, 0.2747]), new_distribution = tensor([0.3937, 0.3322, 0.2741])
2024-12-05 15:33:03,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.3937, 0.3322, 0.2741]), new_distribution = tensor([0.3946, 0.3320, 0.2734])
2024-12-05 15:33:03,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.3946, 0.3320, 0.2734]), new_distribution = tensor([0.3955, 0.3318, 0.2727])
2024-12-05 15:33:03,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.3955, 0.3318, 0.2727]), new_distribution = tensor([0.3963, 0.3316, 0.2721])
2024-12-05 15:33:03,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.3963, 0.3316, 0.2721]), new_distribution = tensor([0.3972, 0.3313, 0.2714])
2024-12-05 15:33:03,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.3972, 0.3313, 0.2714]), new_distribution = tensor([0.3981, 0.3311, 0.2708])
2024-12-05 15:33:03,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.3981, 0.3311, 0.2708]), new_distribution = tensor([0.3990, 0.3309, 0.2701])
2024-12-05 15:33:03,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.3990, 0.3309, 0.2701]), new_distribution = tensor([0.3999, 0.3307, 0.2695])
2024-12-05 15:33:03,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.3999, 0.3307, 0.2695]), new_distribution = tensor([0.4008, 0.3304, 0.2688])
2024-12-05 15:33:03,624 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.4008, 0.3304, 0.2688]), new_distribution = tensor([0.4017, 0.3302, 0.2681])
2024-12-05 15:33:03,680 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.4017, 0.3302, 0.2681]), new_distribution = tensor([0.4026, 0.3300, 0.2675])
2024-12-05 15:33:03,734 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.4026, 0.3300, 0.2675]), new_distribution = tensor([0.4034, 0.3297, 0.2668])
2024-12-05 15:33:03,788 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.4034, 0.3297, 0.2668]), new_distribution = tensor([0.4043, 0.3295, 0.2662])
2024-12-05 15:33:03,842 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.4043, 0.3295, 0.2662]), new_distribution = tensor([0.4052, 0.3292, 0.2655])
2024-12-05 15:33:03,897 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.4052, 0.3292, 0.2655]), new_distribution = tensor([0.4061, 0.3290, 0.2649])
2024-12-05 15:33:03,951 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.4061, 0.3290, 0.2649]), new_distribution = tensor([0.4070, 0.3287, 0.2642])
2024-12-05 15:33:04,005 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.4070, 0.3287, 0.2642]), new_distribution = tensor([0.4079, 0.3285, 0.2636])
2024-12-05 15:33:04,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.4079, 0.3285, 0.2636]), new_distribution = tensor([0.4088, 0.3283, 0.2629])
2024-12-05 15:33:04,114 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.4088, 0.3283, 0.2629]), new_distribution = tensor([0.4097, 0.3280, 0.2623])
2024-12-05 15:33:04,168 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.4097, 0.3280, 0.2623]), new_distribution = tensor([0.4106, 0.3278, 0.2617])
2024-12-05 15:33:04,223 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.4106, 0.3278, 0.2617]), new_distribution = tensor([0.4115, 0.3275, 0.2610])
2024-12-05 15:33:04,277 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.4115, 0.3275, 0.2610]), new_distribution = tensor([0.4124, 0.3272, 0.2604])
2024-12-05 15:33:04,331 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.4124, 0.3272, 0.2604]), new_distribution = tensor([0.4133, 0.3270, 0.2597])
2024-12-05 15:33:04,385 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.4133, 0.3270, 0.2597]), new_distribution = tensor([0.4142, 0.3267, 0.2591])
2024-12-05 15:33:04,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.4142, 0.3267, 0.2591]), new_distribution = tensor([0.4151, 0.3265, 0.2585])
2024-12-05 15:33:04,494 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.4151, 0.3265, 0.2585]), new_distribution = tensor([0.4160, 0.3262, 0.2578])
2024-12-05 15:33:04,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.4160, 0.3262, 0.2578]), new_distribution = tensor([0.4169, 0.3259, 0.2572])
2024-12-05 15:33:04,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.4169, 0.3259, 0.2572]), new_distribution = tensor([0.4178, 0.3257, 0.2565])
2024-12-05 15:33:04,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.4178, 0.3257, 0.2565]), new_distribution = tensor([0.4187, 0.3254, 0.2559])
2024-12-05 15:33:04,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.4187, 0.3254, 0.2559]), new_distribution = tensor([0.4196, 0.3251, 0.2553])
2024-12-05 15:33:04,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.4196, 0.3251, 0.2553]), new_distribution = tensor([0.4205, 0.3249, 0.2547])
2024-12-05 15:33:04,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.4205, 0.3249, 0.2547]), new_distribution = tensor([0.4214, 0.3246, 0.2540])
2024-12-05 15:33:04,875 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.4214, 0.3246, 0.2540]), new_distribution = tensor([0.4223, 0.3243, 0.2534])
2024-12-05 15:33:04,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.4223, 0.3243, 0.2534]), new_distribution = tensor([0.4232, 0.3241, 0.2528])
2024-12-05 15:33:04,983 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.4232, 0.3241, 0.2528]), new_distribution = tensor([0.4241, 0.3238, 0.2521])
2024-12-05 15:33:05,037 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.4241, 0.3238, 0.2521]), new_distribution = tensor([0.4250, 0.3235, 0.2515])
2024-12-05 15:33:05,091 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.4250, 0.3235, 0.2515]), new_distribution = tensor([0.4259, 0.3232, 0.2509])
2024-12-05 15:33:05,145 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.4259, 0.3232, 0.2509]), new_distribution = tensor([0.4268, 0.3229, 0.2503])
2024-12-05 15:33:05,199 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.4268, 0.3229, 0.2503]), new_distribution = tensor([0.4277, 0.3227, 0.2496])
2024-12-05 15:33:05,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.4277, 0.3227, 0.2496]), new_distribution = tensor([0.4286, 0.3224, 0.2490])
2024-12-05 15:33:05,307 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.4286, 0.3224, 0.2490]), new_distribution = tensor([0.4295, 0.3221, 0.2484])
2024-12-05 15:33:05,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.4295, 0.3221, 0.2484]), new_distribution = tensor([0.4304, 0.3218, 0.2478])
2024-12-05 15:33:05,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.4304, 0.3218, 0.2478]), new_distribution = tensor([0.4313, 0.3215, 0.2472])
2024-12-05 15:33:05,469 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.4313, 0.3215, 0.2472]), new_distribution = tensor([0.4323, 0.3212, 0.2465])
2024-12-05 15:33:05,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.4323, 0.3212, 0.2465]), new_distribution = tensor([0.4332, 0.3209, 0.2459])
2024-12-05 15:33:05,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.4332, 0.3209, 0.2459]), new_distribution = tensor([0.4341, 0.3206, 0.2453])
2024-12-05 15:33:05,632 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.4341, 0.3206, 0.2453]), new_distribution = tensor([0.4350, 0.3203, 0.2447])
2024-12-05 15:33:05,686 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.4350, 0.3203, 0.2447]), new_distribution = tensor([0.4359, 0.3200, 0.2441])
2024-12-05 15:33:05,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.4359, 0.3200, 0.2441]), new_distribution = tensor([0.4368, 0.3197, 0.2435])
2024-12-05 15:33:05,794 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.4368, 0.3197, 0.2435]), new_distribution = tensor([0.4377, 0.3194, 0.2429])
2024-12-05 15:33:05,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.4377, 0.3194, 0.2429]), new_distribution = tensor([0.4386, 0.3191, 0.2422])
2024-12-05 15:33:05,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.4386, 0.3191, 0.2422]), new_distribution = tensor([0.4395, 0.3188, 0.2416])
2024-12-05 15:33:05,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.4395, 0.3188, 0.2416]), new_distribution = tensor([0.4405, 0.3185, 0.2410])
2024-12-05 15:33:06,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.4405, 0.3185, 0.2410]), new_distribution = tensor([0.4414, 0.3182, 0.2404])
2024-12-05 15:33:06,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.4414, 0.3182, 0.2404]), new_distribution = tensor([0.4423, 0.3179, 0.2398])
2024-12-05 15:33:06,119 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.4423, 0.3179, 0.2398]), new_distribution = tensor([0.4432, 0.3176, 0.2392])
2024-12-05 15:33:06,173 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.4432, 0.3176, 0.2392]), new_distribution = tensor([0.4441, 0.3173, 0.2386])
2024-12-05 15:33:06,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.4441, 0.3173, 0.2386]), new_distribution = tensor([0.4450, 0.3170, 0.2380])
2024-12-05 15:33:06,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.7000, 0.2000, 0.1000]), new_distribution = tensor([0.7008, 0.1995, 0.0997])
2024-12-05 15:33:06,718 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.7008, 0.1995, 0.0997]), new_distribution = tensor([0.7016, 0.1990, 0.0994])
2024-12-05 15:33:06,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.7016, 0.1990, 0.0994]), new_distribution = tensor([0.7023, 0.1985, 0.0991])
2024-12-05 15:33:06,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.7023, 0.1985, 0.0991]), new_distribution = tensor([0.7031, 0.1980, 0.0989])
2024-12-05 15:33:07,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.7031, 0.1980, 0.0989]), new_distribution = tensor([0.7039, 0.1975, 0.0986])
2024-12-05 15:33:07,144 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.7039, 0.1975, 0.0986]), new_distribution = tensor([0.7047, 0.1970, 0.0983])
2024-12-05 15:33:07,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.7047, 0.1970, 0.0983]), new_distribution = tensor([0.7055, 0.1965, 0.0980])
2024-12-05 15:33:07,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.7055, 0.1965, 0.0980]), new_distribution = tensor([0.7062, 0.1960, 0.0977])
2024-12-05 15:33:07,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.7062, 0.1960, 0.0977]), new_distribution = tensor([0.7070, 0.1956, 0.0974])
2024-12-05 15:33:07,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.7070, 0.1956, 0.0974]), new_distribution = tensor([0.7078, 0.1951, 0.0972])
2024-12-05 15:33:07,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.7078, 0.1951, 0.0972]), new_distribution = tensor([0.7086, 0.1946, 0.0969])
2024-12-05 15:33:07,778 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.7086, 0.1946, 0.0969]), new_distribution = tensor([0.7093, 0.1941, 0.0966])
2024-12-05 15:33:07,884 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.7093, 0.1941, 0.0966]), new_distribution = tensor([0.7101, 0.1936, 0.0963])
2024-12-05 15:33:07,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.7101, 0.1936, 0.0963]), new_distribution = tensor([0.7109, 0.1931, 0.0960])
2024-12-05 15:33:08,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.7109, 0.1931, 0.0960]), new_distribution = tensor([0.7116, 0.1926, 0.0958])
2024-12-05 15:33:08,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.7116, 0.1926, 0.0958]), new_distribution = tensor([0.7124, 0.1921, 0.0955])
2024-12-05 15:33:08,278 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.7124, 0.1921, 0.0955]), new_distribution = tensor([0.7132, 0.1916, 0.0952])
2024-12-05 15:33:08,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.7132, 0.1916, 0.0952]), new_distribution = tensor([0.7139, 0.1911, 0.0949])
2024-12-05 15:33:08,445 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.7139, 0.1911, 0.0949]), new_distribution = tensor([0.7147, 0.1907, 0.0947])
2024-12-05 15:33:08,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.7147, 0.1907, 0.0947]), new_distribution = tensor([0.7154, 0.1902, 0.0944])
2024-12-05 15:33:08,594 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.7154, 0.1902, 0.0944]), new_distribution = tensor([0.7162, 0.1897, 0.0941])
2024-12-05 15:33:08,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.7162, 0.1897, 0.0941]), new_distribution = tensor([0.7170, 0.1892, 0.0938])
2024-12-05 15:33:08,728 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.7170, 0.1892, 0.0938]), new_distribution = tensor([0.7177, 0.1887, 0.0936])
2024-12-05 15:33:08,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.7177, 0.1887, 0.0936]), new_distribution = tensor([0.7185, 0.1882, 0.0933])
2024-12-05 15:33:08,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.7185, 0.1882, 0.0933]), new_distribution = tensor([0.7192, 0.1877, 0.0930])
2024-12-05 15:33:08,907 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.7192, 0.1877, 0.0930]), new_distribution = tensor([0.7200, 0.1873, 0.0928])
2024-12-05 15:33:08,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.7200, 0.1873, 0.0928]), new_distribution = tensor([0.7207, 0.1868, 0.0925])
2024-12-05 15:33:09,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.7207, 0.1868, 0.0925]), new_distribution = tensor([0.7215, 0.1863, 0.0922])
2024-12-05 15:33:09,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.7215, 0.1863, 0.0922]), new_distribution = tensor([0.7222, 0.1858, 0.0920])
2024-12-05 15:33:09,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.7222, 0.1858, 0.0920]), new_distribution = tensor([0.7230, 0.1853, 0.0917])
2024-12-05 15:33:09,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.7230, 0.1853, 0.0917]), new_distribution = tensor([0.7237, 0.1848, 0.0914])
2024-12-05 15:33:09,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.7237, 0.1848, 0.0914]), new_distribution = tensor([0.7245, 0.1844, 0.0912])
2024-12-05 15:33:09,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.7245, 0.1844, 0.0912]), new_distribution = tensor([0.7252, 0.1839, 0.0909])
2024-12-05 15:33:09,342 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.7252, 0.1839, 0.0909]), new_distribution = tensor([0.7260, 0.1834, 0.0906])
2024-12-05 15:33:09,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.7260, 0.1834, 0.0906]), new_distribution = tensor([0.7267, 0.1829, 0.0904])
2024-12-05 15:33:09,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.7267, 0.1829, 0.0904]), new_distribution = tensor([0.7274, 0.1824, 0.0901])
2024-12-05 15:33:09,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.7274, 0.1824, 0.0901]), new_distribution = tensor([0.7282, 0.1820, 0.0899])
2024-12-05 15:33:09,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.7282, 0.1820, 0.0899]), new_distribution = tensor([0.7289, 0.1815, 0.0896])
2024-12-05 15:33:09,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.7289, 0.1815, 0.0896]), new_distribution = tensor([0.7296, 0.1810, 0.0893])
2024-12-05 15:33:09,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.7296, 0.1810, 0.0893]), new_distribution = tensor([0.7304, 0.1805, 0.0891])
2024-12-05 15:33:09,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.7304, 0.1805, 0.0891]), new_distribution = tensor([0.7311, 0.1801, 0.0888])
2024-12-05 15:33:09,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.7311, 0.1801, 0.0888]), new_distribution = tensor([0.7318, 0.1796, 0.0886])
2024-12-05 15:33:09,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.7318, 0.1796, 0.0886]), new_distribution = tensor([0.7326, 0.1791, 0.0883])
2024-12-05 15:33:09,884 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.7326, 0.1791, 0.0883]), new_distribution = tensor([0.7333, 0.1786, 0.0881])
2024-12-05 15:33:09,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.7333, 0.1786, 0.0881]), new_distribution = tensor([0.7340, 0.1782, 0.0878])
2024-12-05 15:33:09,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.7340, 0.1782, 0.0878]), new_distribution = tensor([0.7348, 0.1777, 0.0875])
2024-12-05 15:33:10,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.7348, 0.1777, 0.0875]), new_distribution = tensor([0.7355, 0.1772, 0.0873])
2024-12-05 15:33:10,102 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.7355, 0.1772, 0.0873]), new_distribution = tensor([0.7362, 0.1767, 0.0870])
2024-12-05 15:33:10,157 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.7362, 0.1767, 0.0870]), new_distribution = tensor([0.7369, 0.1763, 0.0868])
2024-12-05 15:33:10,211 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.7369, 0.1763, 0.0868]), new_distribution = tensor([0.7377, 0.1758, 0.0865])
2024-12-05 15:33:10,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.7377, 0.1758, 0.0865]), new_distribution = tensor([0.7384, 0.1753, 0.0863])
2024-12-05 15:33:10,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.7384, 0.1753, 0.0863]), new_distribution = tensor([0.7391, 0.1749, 0.0860])
2024-12-05 15:33:10,374 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.7391, 0.1749, 0.0860]), new_distribution = tensor([0.7398, 0.1744, 0.0858])
2024-12-05 15:33:10,428 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.7398, 0.1744, 0.0858]), new_distribution = tensor([0.7405, 0.1739, 0.0855])
2024-12-05 15:33:10,482 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.7405, 0.1739, 0.0855]), new_distribution = tensor([0.7413, 0.1735, 0.0853])
2024-12-05 15:33:10,537 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.7413, 0.1735, 0.0853]), new_distribution = tensor([0.7420, 0.1730, 0.0850])
2024-12-05 15:33:10,591 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.7420, 0.1730, 0.0850]), new_distribution = tensor([0.7427, 0.1725, 0.0848])
2024-12-05 15:33:10,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.7427, 0.1725, 0.0848]), new_distribution = tensor([0.7434, 0.1721, 0.0845])
2024-12-05 15:33:10,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.7434, 0.1721, 0.0845]), new_distribution = tensor([0.7441, 0.1716, 0.0843])
2024-12-05 15:33:10,754 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.7441, 0.1716, 0.0843]), new_distribution = tensor([0.7448, 0.1711, 0.0841])
2024-12-05 15:33:10,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.7448, 0.1711, 0.0841]), new_distribution = tensor([0.7455, 0.1707, 0.0838])
2024-12-05 15:33:10,862 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.7455, 0.1707, 0.0838]), new_distribution = tensor([0.7462, 0.1702, 0.0836])
2024-12-05 15:33:10,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.7462, 0.1702, 0.0836]), new_distribution = tensor([0.7469, 0.1697, 0.0833])
2024-12-05 15:33:10,971 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.7469, 0.1697, 0.0833]), new_distribution = tensor([0.7476, 0.1693, 0.0831])
2024-12-05 15:33:11,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.7476, 0.1693, 0.0831]), new_distribution = tensor([0.7483, 0.1688, 0.0828])
2024-12-05 15:33:11,080 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.7483, 0.1688, 0.0828]), new_distribution = tensor([0.7490, 0.1684, 0.0826])
2024-12-05 15:33:11,134 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.7490, 0.1684, 0.0826]), new_distribution = tensor([0.7497, 0.1679, 0.0824])
2024-12-05 15:33:11,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.7497, 0.1679, 0.0824]), new_distribution = tensor([0.7504, 0.1674, 0.0821])
2024-12-05 15:33:11,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.7504, 0.1674, 0.0821]), new_distribution = tensor([0.7511, 0.1670, 0.0819])
2024-12-05 15:33:11,297 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.7511, 0.1670, 0.0819]), new_distribution = tensor([0.7518, 0.1665, 0.0817])
2024-12-05 15:33:11,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.7518, 0.1665, 0.0817]), new_distribution = tensor([0.7525, 0.1661, 0.0814])
2024-12-05 15:33:11,405 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.7525, 0.1661, 0.0814]), new_distribution = tensor([0.7532, 0.1656, 0.0812])
2024-12-05 15:33:11,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.7532, 0.1656, 0.0812]), new_distribution = tensor([0.7539, 0.1652, 0.0809])
2024-12-05 15:33:11,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.7539, 0.1652, 0.0809]), new_distribution = tensor([0.7546, 0.1647, 0.0807])
2024-12-05 15:33:11,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.7546, 0.1647, 0.0807]), new_distribution = tensor([0.7553, 0.1642, 0.0805])
2024-12-05 15:33:11,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.7553, 0.1642, 0.0805]), new_distribution = tensor([0.7560, 0.1638, 0.0802])
2024-12-05 15:33:11,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.7560, 0.1638, 0.0802]), new_distribution = tensor([0.7567, 0.1633, 0.0800])
2024-12-05 15:33:11,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.7567, 0.1633, 0.0800]), new_distribution = tensor([0.7573, 0.1629, 0.0798])
2024-12-05 15:33:11,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.7573, 0.1629, 0.0798]), new_distribution = tensor([0.7580, 0.1624, 0.0795])
2024-12-05 15:33:11,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.7580, 0.1624, 0.0795]), new_distribution = tensor([0.7587, 0.1620, 0.0793])
2024-12-05 15:33:11,895 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.7587, 0.1620, 0.0793]), new_distribution = tensor([0.7594, 0.1615, 0.0791])
2024-12-05 15:33:11,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.7594, 0.1615, 0.0791]), new_distribution = tensor([0.7601, 0.1611, 0.0788])
2024-12-05 15:33:12,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.7601, 0.1611, 0.0788]), new_distribution = tensor([0.7608, 0.1606, 0.0786])
2024-12-05 15:33:12,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.7608, 0.1606, 0.0786]), new_distribution = tensor([0.7614, 0.1602, 0.0784])
2024-12-05 15:33:12,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.7614, 0.1602, 0.0784]), new_distribution = tensor([0.7621, 0.1597, 0.0782])
2024-12-05 15:33:12,166 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.7621, 0.1597, 0.0782]), new_distribution = tensor([0.7628, 0.1593, 0.0779])
2024-12-05 15:33:12,221 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.7628, 0.1593, 0.0779]), new_distribution = tensor([0.7635, 0.1588, 0.0777])
2024-12-05 15:33:12,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.7635, 0.1588, 0.0777]), new_distribution = tensor([0.7641, 0.1584, 0.0775])
2024-12-05 15:33:12,329 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.7641, 0.1584, 0.0775]), new_distribution = tensor([0.7648, 0.1579, 0.0773])
2024-12-05 15:33:12,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.7648, 0.1579, 0.0773]), new_distribution = tensor([0.7655, 0.1575, 0.0770])
2024-12-05 15:33:12,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.7655, 0.1575, 0.0770]), new_distribution = tensor([0.7661, 0.1571, 0.0768])
2024-12-05 15:33:12,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.7661, 0.1571, 0.0768]), new_distribution = tensor([0.7668, 0.1566, 0.0766])
2024-12-05 15:33:12,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.7668, 0.1566, 0.0766]), new_distribution = tensor([0.7675, 0.1562, 0.0764])
2024-12-05 15:33:12,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.7675, 0.1562, 0.0764]), new_distribution = tensor([0.7681, 0.1557, 0.0761])
2024-12-05 15:33:12,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.7681, 0.1557, 0.0761]), new_distribution = tensor([0.7688, 0.1553, 0.0759])
2024-12-05 15:33:12,708 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.7688, 0.1553, 0.0759]), new_distribution = tensor([0.7695, 0.1549, 0.0757])
2024-12-05 15:33:12,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.7695, 0.1549, 0.0757]), new_distribution = tensor([0.7701, 0.1544, 0.0755])
2024-12-05 15:33:12,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.7701, 0.1544, 0.0755]), new_distribution = tensor([0.7708, 0.1540, 0.0753])
2024-12-05 15:33:12,871 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.7708, 0.1540, 0.0753]), new_distribution = tensor([0.7714, 0.1535, 0.0750])
2024-12-05 15:33:12,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.7714, 0.1535, 0.0750]), new_distribution = tensor([0.7721, 0.1531, 0.0748])
2024-12-05 15:33:13,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,255 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,309 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,418 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,472 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,581 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,635 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,744 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,798 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,852 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,906 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:13,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,342 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,666 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:14,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,100 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,208 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,262 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,316 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,371 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,858 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,912 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:15,966 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,021 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,075 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,129 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,456 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,510 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,673 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,728 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,945 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:16,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,053 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,166 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,873 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,928 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:17,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:18,036 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:18,090 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:18,145 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:18,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:18,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:18,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:18,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:18,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:18,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:18,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:18,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:33:18,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.1000, 0.3000, 0.6000]), new_distribution = tensor([0.1003, 0.3005, 0.5992])
2024-12-05 15:33:18,899 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.1003, 0.3005, 0.5992]), new_distribution = tensor([0.1006, 0.3009, 0.5984])
2024-12-05 15:33:18,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.1006, 0.3009, 0.5984]), new_distribution = tensor([0.1010, 0.3014, 0.5976])
2024-12-05 15:33:19,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.1010, 0.3014, 0.5976]), new_distribution = tensor([0.1013, 0.3019, 0.5968])
2024-12-05 15:33:19,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.1013, 0.3019, 0.5968]), new_distribution = tensor([0.1016, 0.3024, 0.5960])
2024-12-05 15:33:19,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.1016, 0.3024, 0.5960]), new_distribution = tensor([0.1019, 0.3028, 0.5952])
2024-12-05 15:33:19,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.1019, 0.3028, 0.5952]), new_distribution = tensor([0.1022, 0.3033, 0.5944])
2024-12-05 15:33:19,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.1022, 0.3033, 0.5944]), new_distribution = tensor([0.1026, 0.3038, 0.5936])
2024-12-05 15:33:19,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.1026, 0.3038, 0.5936]), new_distribution = tensor([0.1029, 0.3043, 0.5928])
2024-12-05 15:33:19,335 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.1029, 0.3043, 0.5928]), new_distribution = tensor([0.1032, 0.3047, 0.5920])
2024-12-05 15:33:19,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.1032, 0.3047, 0.5920]), new_distribution = tensor([0.1036, 0.3052, 0.5913])
2024-12-05 15:33:19,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.1036, 0.3052, 0.5913]), new_distribution = tensor([0.1039, 0.3057, 0.5905])
2024-12-05 15:33:19,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.1039, 0.3057, 0.5905]), new_distribution = tensor([0.1042, 0.3061, 0.5897])
2024-12-05 15:33:19,551 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.1042, 0.3061, 0.5897]), new_distribution = tensor([0.1045, 0.3066, 0.5889])
2024-12-05 15:33:19,606 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.1045, 0.3066, 0.5889]), new_distribution = tensor([0.1049, 0.3071, 0.5881])
2024-12-05 15:33:19,660 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.1049, 0.3071, 0.5881]), new_distribution = tensor([0.1052, 0.3075, 0.5872])
2024-12-05 15:33:19,714 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.1052, 0.3075, 0.5872]), new_distribution = tensor([0.1055, 0.3080, 0.5864])
2024-12-05 15:33:19,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.1055, 0.3080, 0.5864]), new_distribution = tensor([0.1059, 0.3085, 0.5856])
2024-12-05 15:33:19,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.1059, 0.3085, 0.5856]), new_distribution = tensor([0.1062, 0.3089, 0.5848])
2024-12-05 15:33:19,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.1062, 0.3089, 0.5848]), new_distribution = tensor([0.1066, 0.3094, 0.5840])
2024-12-05 15:33:19,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.1066, 0.3094, 0.5840]), new_distribution = tensor([0.1069, 0.3099, 0.5832])
2024-12-05 15:33:19,985 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.1069, 0.3099, 0.5832]), new_distribution = tensor([0.1072, 0.3103, 0.5824])
2024-12-05 15:33:20,039 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.1072, 0.3103, 0.5824]), new_distribution = tensor([0.1076, 0.3108, 0.5816])
2024-12-05 15:33:20,093 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.1076, 0.3108, 0.5816]), new_distribution = tensor([0.1079, 0.3113, 0.5808])
2024-12-05 15:33:20,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.1079, 0.3113, 0.5808]), new_distribution = tensor([0.1083, 0.3117, 0.5800])
2024-12-05 15:33:20,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.1083, 0.3117, 0.5800]), new_distribution = tensor([0.1086, 0.3122, 0.5792])
2024-12-05 15:33:20,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.1086, 0.3122, 0.5792]), new_distribution = tensor([0.1089, 0.3127, 0.5784])
2024-12-05 15:33:20,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.1089, 0.3127, 0.5784]), new_distribution = tensor([0.1093, 0.3131, 0.5776])
2024-12-05 15:33:20,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.1093, 0.3131, 0.5776]), new_distribution = tensor([0.1096, 0.3136, 0.5768])
2024-12-05 15:33:20,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.1096, 0.3136, 0.5768]), new_distribution = tensor([0.1100, 0.3140, 0.5760])
2024-12-05 15:33:20,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.1100, 0.3140, 0.5760]), new_distribution = tensor([0.1103, 0.3145, 0.5752])
2024-12-05 15:33:20,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.1103, 0.3145, 0.5752]), new_distribution = tensor([0.1107, 0.3150, 0.5744])
2024-12-05 15:33:20,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.1107, 0.3150, 0.5744]), new_distribution = tensor([0.1110, 0.3154, 0.5735])
2024-12-05 15:33:20,637 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.1110, 0.3154, 0.5735]), new_distribution = tensor([0.1114, 0.3159, 0.5727])
2024-12-05 15:33:20,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.1114, 0.3159, 0.5727]), new_distribution = tensor([0.1117, 0.3163, 0.5719])
2024-12-05 15:33:20,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.1117, 0.3163, 0.5719]), new_distribution = tensor([0.1121, 0.3168, 0.5711])
2024-12-05 15:33:20,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.1121, 0.3168, 0.5711]), new_distribution = tensor([0.1124, 0.3173, 0.5703])
2024-12-05 15:33:20,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.1124, 0.3173, 0.5703]), new_distribution = tensor([0.1128, 0.3177, 0.5695])
2024-12-05 15:33:20,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.1128, 0.3177, 0.5695]), new_distribution = tensor([0.1132, 0.3182, 0.5687])
2024-12-05 15:33:20,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.1132, 0.3182, 0.5687]), new_distribution = tensor([0.1135, 0.3186, 0.5679])
2024-12-05 15:33:21,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.1135, 0.3186, 0.5679]), new_distribution = tensor([0.1139, 0.3191, 0.5670])
2024-12-05 15:33:21,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.1139, 0.3191, 0.5670]), new_distribution = tensor([0.1142, 0.3195, 0.5662])
2024-12-05 15:33:21,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.1142, 0.3195, 0.5662]), new_distribution = tensor([0.1146, 0.3200, 0.5654])
2024-12-05 15:33:21,289 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.1146, 0.3200, 0.5654]), new_distribution = tensor([0.1150, 0.3205, 0.5646])
2024-12-05 15:33:21,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.1150, 0.3205, 0.5646]), new_distribution = tensor([0.1153, 0.3209, 0.5638])
2024-12-05 15:33:21,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.1153, 0.3209, 0.5638]), new_distribution = tensor([0.1157, 0.3214, 0.5630])
2024-12-05 15:33:21,605 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.1157, 0.3214, 0.5630]), new_distribution = tensor([0.1160, 0.3218, 0.5621])
2024-12-05 15:33:21,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.1160, 0.3218, 0.5621]), new_distribution = tensor([0.1164, 0.3223, 0.5613])
2024-12-05 15:33:21,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.1164, 0.3223, 0.5613]), new_distribution = tensor([0.1168, 0.3227, 0.5605])
2024-12-05 15:33:21,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.1168, 0.3227, 0.5605]), new_distribution = tensor([0.1172, 0.3232, 0.5597])
2024-12-05 15:33:22,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.1172, 0.3232, 0.5597]), new_distribution = tensor([0.1175, 0.3236, 0.5589])
2024-12-05 15:33:22,133 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.1175, 0.3236, 0.5589]), new_distribution = tensor([0.1179, 0.3241, 0.5580])
2024-12-05 15:33:22,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.1179, 0.3241, 0.5580]), new_distribution = tensor([0.1183, 0.3245, 0.5572])
2024-12-05 15:33:22,344 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.1183, 0.3245, 0.5572]), new_distribution = tensor([0.1186, 0.3250, 0.5564])
2024-12-05 15:33:22,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.1186, 0.3250, 0.5564]), new_distribution = tensor([0.1190, 0.3254, 0.5556])
2024-12-05 15:33:22,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.1190, 0.3254, 0.5556]), new_distribution = tensor([0.1194, 0.3259, 0.5548])
2024-12-05 15:33:22,659 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.1194, 0.3259, 0.5548]), new_distribution = tensor([0.1198, 0.3263, 0.5539])
2024-12-05 15:33:22,760 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.1198, 0.3263, 0.5539]), new_distribution = tensor([0.1201, 0.3267, 0.5531])
2024-12-05 15:33:22,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.1201, 0.3267, 0.5531]), new_distribution = tensor([0.1205, 0.3272, 0.5523])
2024-12-05 15:33:22,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.1205, 0.3272, 0.5523]), new_distribution = tensor([0.1209, 0.3276, 0.5515])
2024-12-05 15:33:23,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.1209, 0.3276, 0.5515]), new_distribution = tensor([0.1213, 0.3281, 0.5506])
2024-12-05 15:33:23,114 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.1213, 0.3281, 0.5506]), new_distribution = tensor([0.1217, 0.3285, 0.5498])
2024-12-05 15:33:23,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.1217, 0.3285, 0.5498]), new_distribution = tensor([0.1220, 0.3290, 0.5490])
2024-12-05 15:33:23,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.1220, 0.3290, 0.5490]), new_distribution = tensor([0.1224, 0.3294, 0.5482])
2024-12-05 15:33:23,332 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.1224, 0.3294, 0.5482]), new_distribution = tensor([0.1228, 0.3298, 0.5474])
2024-12-05 15:33:23,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.1228, 0.3298, 0.5474]), new_distribution = tensor([0.1232, 0.3303, 0.5465])
2024-12-05 15:33:23,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.1232, 0.3303, 0.5465]), new_distribution = tensor([0.1236, 0.3307, 0.5457])
2024-12-05 15:33:23,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.1236, 0.3307, 0.5457]), new_distribution = tensor([0.1240, 0.3311, 0.5449])
2024-12-05 15:33:23,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.1240, 0.3311, 0.5449]), new_distribution = tensor([0.1244, 0.3316, 0.5440])
2024-12-05 15:33:23,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.1244, 0.3316, 0.5440]), new_distribution = tensor([0.1248, 0.3320, 0.5432])
2024-12-05 15:33:23,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.1248, 0.3320, 0.5432]), new_distribution = tensor([0.1251, 0.3325, 0.5424])
2024-12-05 15:33:23,739 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.1251, 0.3325, 0.5424]), new_distribution = tensor([0.1255, 0.3329, 0.5416])
2024-12-05 15:33:23,794 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.1255, 0.3329, 0.5416]), new_distribution = tensor([0.1259, 0.3333, 0.5407])
2024-12-05 15:33:23,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.1259, 0.3333, 0.5407]), new_distribution = tensor([0.1263, 0.3338, 0.5399])
2024-12-05 15:33:23,902 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.1263, 0.3338, 0.5399]), new_distribution = tensor([0.1267, 0.3342, 0.5391])
2024-12-05 15:33:23,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.1267, 0.3342, 0.5391]), new_distribution = tensor([0.1271, 0.3346, 0.5383])
2024-12-05 15:33:24,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.1271, 0.3346, 0.5383]), new_distribution = tensor([0.1275, 0.3350, 0.5374])
2024-12-05 15:33:24,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.1275, 0.3350, 0.5374]), new_distribution = tensor([0.1279, 0.3355, 0.5366])
2024-12-05 15:33:24,119 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.1279, 0.3355, 0.5366]), new_distribution = tensor([0.1283, 0.3359, 0.5358])
2024-12-05 15:33:24,174 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.1283, 0.3359, 0.5358]), new_distribution = tensor([0.1287, 0.3363, 0.5349])
2024-12-05 15:33:24,228 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.1287, 0.3363, 0.5349]), new_distribution = tensor([0.1291, 0.3368, 0.5341])
2024-12-05 15:33:24,282 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.1291, 0.3368, 0.5341]), new_distribution = tensor([0.1295, 0.3372, 0.5333])
2024-12-05 15:33:24,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.1295, 0.3372, 0.5333]), new_distribution = tensor([0.1299, 0.3376, 0.5324])
2024-12-05 15:33:24,390 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.1299, 0.3376, 0.5324]), new_distribution = tensor([0.1303, 0.3380, 0.5316])
2024-12-05 15:33:24,445 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.1303, 0.3380, 0.5316]), new_distribution = tensor([0.1308, 0.3385, 0.5308])
2024-12-05 15:33:24,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.1308, 0.3385, 0.5308]), new_distribution = tensor([0.1312, 0.3389, 0.5300])
2024-12-05 15:33:24,553 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.1312, 0.3389, 0.5300]), new_distribution = tensor([0.1316, 0.3393, 0.5291])
2024-12-05 15:33:24,607 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.1316, 0.3393, 0.5291]), new_distribution = tensor([0.1320, 0.3397, 0.5283])
2024-12-05 15:33:24,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.1320, 0.3397, 0.5283]), new_distribution = tensor([0.1324, 0.3401, 0.5275])
2024-12-05 15:33:24,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.1324, 0.3401, 0.5275]), new_distribution = tensor([0.1328, 0.3406, 0.5266])
2024-12-05 15:33:24,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.1328, 0.3406, 0.5266]), new_distribution = tensor([0.1332, 0.3410, 0.5258])
2024-12-05 15:33:24,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.1332, 0.3410, 0.5258]), new_distribution = tensor([0.1336, 0.3414, 0.5250])
2024-12-05 15:33:24,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.1336, 0.3414, 0.5250]), new_distribution = tensor([0.1341, 0.3418, 0.5241])
2024-12-05 15:33:24,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.1341, 0.3418, 0.5241]), new_distribution = tensor([0.1345, 0.3422, 0.5233])
2024-12-05 15:33:24,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.1345, 0.3422, 0.5233]), new_distribution = tensor([0.1349, 0.3426, 0.5225])
2024-12-05 15:33:25,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.1349, 0.3426, 0.5225]), new_distribution = tensor([0.1353, 0.3431, 0.5216])
2024-12-05 15:33:25,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.1353, 0.3431, 0.5216]), new_distribution = tensor([0.1357, 0.3435, 0.5208])
2024-12-05 15:33:25,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.1357, 0.3435, 0.5208]), new_distribution = tensor([0.1362, 0.3439, 0.5200])
2024-12-05 15:33:25,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.1362, 0.3439, 0.5200]), new_distribution = tensor([0.1366, 0.3443, 0.5191])
2024-12-05 15:33:25,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.1366, 0.3443, 0.5191]), new_distribution = tensor([0.1370, 0.3447, 0.5183])
2024-12-05 15:34:07,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.4450, 0.3170, 0.2380]), new_distribution = tensor([0.4459, 0.3167, 0.2374])
2024-12-05 15:34:07,326 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.4459, 0.3167, 0.2374]), new_distribution = tensor([0.4469, 0.3163, 0.2368])
2024-12-05 15:34:07,405 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.4469, 0.3163, 0.2368]), new_distribution = tensor([0.4478, 0.3160, 0.2362])
2024-12-05 15:34:07,484 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.4478, 0.3160, 0.2362]), new_distribution = tensor([0.4487, 0.3157, 0.2356])
2024-12-05 15:34:07,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.4487, 0.3157, 0.2356]), new_distribution = tensor([0.4496, 0.3154, 0.2350])
2024-12-05 15:34:07,643 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.4496, 0.3154, 0.2350]), new_distribution = tensor([0.4505, 0.3151, 0.2344])
2024-12-05 15:34:07,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.4505, 0.3151, 0.2344]), new_distribution = tensor([0.4514, 0.3147, 0.2338])
2024-12-05 15:34:07,802 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.4514, 0.3147, 0.2338]), new_distribution = tensor([0.4524, 0.3144, 0.2332])
2024-12-05 15:34:07,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.4524, 0.3144, 0.2332]), new_distribution = tensor([0.4533, 0.3141, 0.2326])
2024-12-05 15:34:07,961 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.4533, 0.3141, 0.2326]), new_distribution = tensor([0.4542, 0.3138, 0.2320])
2024-12-05 15:34:08,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.4542, 0.3138, 0.2320]), new_distribution = tensor([0.4551, 0.3134, 0.2314])
2024-12-05 15:34:08,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.4551, 0.3134, 0.2314]), new_distribution = tensor([0.4560, 0.3131, 0.2309])
2024-12-05 15:34:08,199 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.4560, 0.3131, 0.2309]), new_distribution = tensor([0.4570, 0.3128, 0.2303])
2024-12-05 15:34:08,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.4570, 0.3128, 0.2303]), new_distribution = tensor([0.4579, 0.3124, 0.2297])
2024-12-05 15:34:08,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.4579, 0.3124, 0.2297]), new_distribution = tensor([0.4588, 0.3121, 0.2291])
2024-12-05 15:34:08,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.4588, 0.3121, 0.2291]), new_distribution = tensor([0.4597, 0.3118, 0.2285])
2024-12-05 15:34:08,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.4597, 0.3118, 0.2285]), new_distribution = tensor([0.4606, 0.3114, 0.2279])
2024-12-05 15:34:08,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.4606, 0.3114, 0.2279]), new_distribution = tensor([0.4616, 0.3111, 0.2273])
2024-12-05 15:34:08,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.4616, 0.3111, 0.2273]), new_distribution = tensor([0.4625, 0.3107, 0.2268])
2024-12-05 15:34:08,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.4625, 0.3107, 0.2268]), new_distribution = tensor([0.4634, 0.3104, 0.2262])
2024-12-05 15:34:08,834 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.4634, 0.3104, 0.2262]), new_distribution = tensor([0.4643, 0.3101, 0.2256])
2024-12-05 15:34:08,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.4643, 0.3101, 0.2256]), new_distribution = tensor([0.4653, 0.3097, 0.2250])
2024-12-05 15:34:08,993 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.4653, 0.3097, 0.2250]), new_distribution = tensor([0.4662, 0.3094, 0.2245])
2024-12-05 15:34:09,072 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.4662, 0.3094, 0.2245]), new_distribution = tensor([0.4671, 0.3090, 0.2239])
2024-12-05 15:34:09,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.4671, 0.3090, 0.2239]), new_distribution = tensor([0.4680, 0.3087, 0.2233])
2024-12-05 15:34:09,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.4680, 0.3087, 0.2233]), new_distribution = tensor([0.4689, 0.3083, 0.2227])
2024-12-05 15:34:09,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.4689, 0.3083, 0.2227]), new_distribution = tensor([0.4699, 0.3080, 0.2222])
2024-12-05 15:34:09,385 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.4699, 0.3080, 0.2222]), new_distribution = tensor([0.4708, 0.3076, 0.2216])
2024-12-05 15:34:09,456 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.4708, 0.3076, 0.2216]), new_distribution = tensor([0.4717, 0.3073, 0.2210])
2024-12-05 15:34:09,524 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.4717, 0.3073, 0.2210]), new_distribution = tensor([0.4726, 0.3069, 0.2204])
2024-12-05 15:34:09,588 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.4726, 0.3069, 0.2204]), new_distribution = tensor([0.4736, 0.3065, 0.2199])
2024-12-05 15:34:09,650 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.4736, 0.3065, 0.2199]), new_distribution = tensor([0.4745, 0.3062, 0.2193])
2024-12-05 15:34:09,709 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.4745, 0.3062, 0.2193]), new_distribution = tensor([0.4754, 0.3058, 0.2187])
2024-12-05 15:34:09,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.4754, 0.3058, 0.2187]), new_distribution = tensor([0.4763, 0.3055, 0.2182])
2024-12-05 15:34:09,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.4763, 0.3055, 0.2182]), new_distribution = tensor([0.4773, 0.3051, 0.2176])
2024-12-05 15:34:09,873 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.4773, 0.3051, 0.2176]), new_distribution = tensor([0.4782, 0.3047, 0.2171])
2024-12-05 15:34:09,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.4782, 0.3047, 0.2171]), new_distribution = tensor([0.4791, 0.3044, 0.2165])
2024-12-05 15:34:09,981 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.4791, 0.3044, 0.2165]), new_distribution = tensor([0.4801, 0.3040, 0.2159])
2024-12-05 15:34:10,035 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.4801, 0.3040, 0.2159]), new_distribution = tensor([0.4810, 0.3036, 0.2154])
2024-12-05 15:34:10,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.4810, 0.3036, 0.2154]), new_distribution = tensor([0.4819, 0.3033, 0.2148])
2024-12-05 15:34:10,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.4819, 0.3033, 0.2148]), new_distribution = tensor([0.4828, 0.3029, 0.2143])
2024-12-05 15:34:10,197 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.4828, 0.3029, 0.2143]), new_distribution = tensor([0.4838, 0.3025, 0.2137])
2024-12-05 15:34:10,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.4838, 0.3025, 0.2137]), new_distribution = tensor([0.4847, 0.3022, 0.2132])
2024-12-05 15:34:10,305 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.4847, 0.3022, 0.2132]), new_distribution = tensor([0.4856, 0.3018, 0.2126])
2024-12-05 15:34:10,359 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.4856, 0.3018, 0.2126]), new_distribution = tensor([0.4865, 0.3014, 0.2120])
2024-12-05 15:34:10,412 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.4865, 0.3014, 0.2120]), new_distribution = tensor([0.4875, 0.3010, 0.2115])
2024-12-05 15:34:10,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.4875, 0.3010, 0.2115]), new_distribution = tensor([0.4884, 0.3007, 0.2109])
2024-12-05 15:34:10,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.4884, 0.3007, 0.2109]), new_distribution = tensor([0.4893, 0.3003, 0.2104])
2024-12-05 15:34:10,574 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.4893, 0.3003, 0.2104]), new_distribution = tensor([0.4902, 0.2999, 0.2098])
2024-12-05 15:34:10,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.4902, 0.2999, 0.2098]), new_distribution = tensor([0.4912, 0.2995, 0.2093])
2024-12-05 15:34:10,682 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.4912, 0.2995, 0.2093]), new_distribution = tensor([0.4921, 0.2991, 0.2088])
2024-12-05 15:34:10,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.4921, 0.2991, 0.2088]), new_distribution = tensor([0.4930, 0.2988, 0.2082])
2024-12-05 15:34:10,789 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.4930, 0.2988, 0.2082]), new_distribution = tensor([0.4940, 0.2984, 0.2077])
2024-12-05 15:34:10,843 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.4940, 0.2984, 0.2077]), new_distribution = tensor([0.4949, 0.2980, 0.2071])
2024-12-05 15:34:10,897 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.4949, 0.2980, 0.2071]), new_distribution = tensor([0.4958, 0.2976, 0.2066])
2024-12-05 15:34:10,951 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.4958, 0.2976, 0.2066]), new_distribution = tensor([0.4967, 0.2972, 0.2060])
2024-12-05 15:34:11,005 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.4967, 0.2972, 0.2060]), new_distribution = tensor([0.4977, 0.2968, 0.2055])
2024-12-05 15:34:11,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.4977, 0.2968, 0.2055]), new_distribution = tensor([0.4986, 0.2964, 0.2050])
2024-12-05 15:34:11,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.4986, 0.2964, 0.2050]), new_distribution = tensor([0.4995, 0.2960, 0.2044])
2024-12-05 15:34:11,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.4995, 0.2960, 0.2044]), new_distribution = tensor([0.5005, 0.2957, 0.2039])
2024-12-05 15:34:11,221 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.5005, 0.2957, 0.2039]), new_distribution = tensor([0.5014, 0.2953, 0.2034])
2024-12-05 15:34:11,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.5014, 0.2953, 0.2034]), new_distribution = tensor([0.5023, 0.2949, 0.2028])
2024-12-05 15:34:11,329 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.5023, 0.2949, 0.2028]), new_distribution = tensor([0.5032, 0.2945, 0.2023])
2024-12-05 15:34:11,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.5032, 0.2945, 0.2023]), new_distribution = tensor([0.5042, 0.2941, 0.2018])
2024-12-05 15:34:11,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.5042, 0.2941, 0.2018]), new_distribution = tensor([0.5051, 0.2937, 0.2012])
2024-12-05 15:34:11,490 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.5051, 0.2937, 0.2012]), new_distribution = tensor([0.5060, 0.2933, 0.2007])
2024-12-05 15:34:11,544 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.5060, 0.2933, 0.2007]), new_distribution = tensor([0.5069, 0.2929, 0.2002])
2024-12-05 15:34:11,598 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.5069, 0.2929, 0.2002]), new_distribution = tensor([0.5079, 0.2925, 0.1996])
2024-12-05 15:34:11,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.5079, 0.2925, 0.1996]), new_distribution = tensor([0.5088, 0.2921, 0.1991])
2024-12-05 15:34:11,706 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.5088, 0.2921, 0.1991]), new_distribution = tensor([0.5097, 0.2917, 0.1986])
2024-12-05 15:34:11,759 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.5097, 0.2917, 0.1986]), new_distribution = tensor([0.5107, 0.2913, 0.1981])
2024-12-05 15:34:11,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.5107, 0.2913, 0.1981]), new_distribution = tensor([0.5116, 0.2909, 0.1975])
2024-12-05 15:34:11,867 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.5116, 0.2909, 0.1975]), new_distribution = tensor([0.5125, 0.2905, 0.1970])
2024-12-05 15:34:11,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.5125, 0.2905, 0.1970]), new_distribution = tensor([0.5134, 0.2900, 0.1965])
2024-12-05 15:34:11,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.5134, 0.2900, 0.1965]), new_distribution = tensor([0.5144, 0.2896, 0.1960])
2024-12-05 15:34:12,029 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.5144, 0.2896, 0.1960]), new_distribution = tensor([0.5153, 0.2892, 0.1955])
2024-12-05 15:34:12,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.5153, 0.2892, 0.1955]), new_distribution = tensor([0.5162, 0.2888, 0.1950])
2024-12-05 15:34:12,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.5162, 0.2888, 0.1950]), new_distribution = tensor([0.5172, 0.2884, 0.1944])
2024-12-05 15:34:12,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.5172, 0.2884, 0.1944]), new_distribution = tensor([0.5181, 0.2880, 0.1939])
2024-12-05 15:34:12,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.5181, 0.2880, 0.1939]), new_distribution = tensor([0.5190, 0.2876, 0.1934])
2024-12-05 15:34:12,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.5190, 0.2876, 0.1934]), new_distribution = tensor([0.5199, 0.2872, 0.1929])
2024-12-05 15:34:12,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.5199, 0.2872, 0.1929]), new_distribution = tensor([0.5209, 0.2868, 0.1924])
2024-12-05 15:34:12,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.5209, 0.2868, 0.1924]), new_distribution = tensor([0.5218, 0.2863, 0.1919])
2024-12-05 15:34:12,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.5218, 0.2863, 0.1919]), new_distribution = tensor([0.5227, 0.2859, 0.1914])
2024-12-05 15:34:12,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.5227, 0.2859, 0.1914]), new_distribution = tensor([0.5236, 0.2855, 0.1909])
2024-12-05 15:34:12,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.5236, 0.2855, 0.1909]), new_distribution = tensor([0.5246, 0.2851, 0.1904])
2024-12-05 15:34:12,621 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.5246, 0.2851, 0.1904]), new_distribution = tensor([0.5255, 0.2847, 0.1898])
2024-12-05 15:34:12,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.5255, 0.2847, 0.1898]), new_distribution = tensor([0.5264, 0.2842, 0.1893])
2024-12-05 15:34:12,729 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.5264, 0.2842, 0.1893]), new_distribution = tensor([0.5273, 0.2838, 0.1888])
2024-12-05 15:34:12,783 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.5273, 0.2838, 0.1888]), new_distribution = tensor([0.5283, 0.2834, 0.1883])
2024-12-05 15:34:12,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.5283, 0.2834, 0.1883]), new_distribution = tensor([0.5292, 0.2830, 0.1878])
2024-12-05 15:34:12,891 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.5292, 0.2830, 0.1878]), new_distribution = tensor([0.5301, 0.2825, 0.1873])
2024-12-05 15:34:12,945 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.5301, 0.2825, 0.1873]), new_distribution = tensor([0.5310, 0.2821, 0.1868])
2024-12-05 15:34:12,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.5310, 0.2821, 0.1868]), new_distribution = tensor([0.5320, 0.2817, 0.1863])
2024-12-05 15:34:13,053 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.5320, 0.2817, 0.1863]), new_distribution = tensor([0.5329, 0.2813, 0.1858])
2024-12-05 15:34:13,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.5329, 0.2813, 0.1858]), new_distribution = tensor([0.5338, 0.2808, 0.1853])
2024-12-05 15:34:13,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.5338, 0.2808, 0.1853]), new_distribution = tensor([0.5347, 0.2804, 0.1848])
2024-12-05 15:34:13,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.5347, 0.2804, 0.1848]), new_distribution = tensor([0.5357, 0.2800, 0.1844])
2024-12-05 15:34:13,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.5357, 0.2800, 0.1844]), new_distribution = tensor([0.5366, 0.2795, 0.1839])
2024-12-05 15:34:13,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.5366, 0.2795, 0.1839]), new_distribution = tensor([0.5375, 0.2791, 0.1834])
2024-12-05 15:34:13,713 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.7000, 0.2000, 0.1000]), new_distribution = tensor([0.7008, 0.1995, 0.0997])
2024-12-05 15:34:13,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.7008, 0.1995, 0.0997]), new_distribution = tensor([0.7016, 0.1990, 0.0994])
2024-12-05 15:34:13,930 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.7016, 0.1990, 0.0994]), new_distribution = tensor([0.7023, 0.1985, 0.0991])
2024-12-05 15:34:14,036 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.7023, 0.1985, 0.0991]), new_distribution = tensor([0.7031, 0.1980, 0.0989])
2024-12-05 15:34:14,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.7031, 0.1980, 0.0989]), new_distribution = tensor([0.7039, 0.1975, 0.0986])
2024-12-05 15:34:14,247 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.7039, 0.1975, 0.0986]), new_distribution = tensor([0.7047, 0.1970, 0.0983])
2024-12-05 15:34:14,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.7047, 0.1970, 0.0983]), new_distribution = tensor([0.7055, 0.1965, 0.0980])
2024-12-05 15:34:14,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.7055, 0.1965, 0.0980]), new_distribution = tensor([0.7062, 0.1960, 0.0977])
2024-12-05 15:34:14,566 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.7062, 0.1960, 0.0977]), new_distribution = tensor([0.7070, 0.1956, 0.0974])
2024-12-05 15:34:14,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.7070, 0.1956, 0.0974]), new_distribution = tensor([0.7078, 0.1951, 0.0972])
2024-12-05 15:34:14,777 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.7078, 0.1951, 0.0972]), new_distribution = tensor([0.7086, 0.1946, 0.0969])
2024-12-05 15:34:14,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.7086, 0.1946, 0.0969]), new_distribution = tensor([0.7093, 0.1941, 0.0966])
2024-12-05 15:34:14,988 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.7093, 0.1941, 0.0966]), new_distribution = tensor([0.7101, 0.1936, 0.0963])
2024-12-05 15:34:15,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.7101, 0.1936, 0.0963]), new_distribution = tensor([0.7109, 0.1931, 0.0960])
2024-12-05 15:34:15,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.7109, 0.1931, 0.0960]), new_distribution = tensor([0.7116, 0.1926, 0.0958])
2024-12-05 15:34:15,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.7116, 0.1926, 0.0958]), new_distribution = tensor([0.7124, 0.1921, 0.0955])
2024-12-05 15:34:15,374 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.7124, 0.1921, 0.0955]), new_distribution = tensor([0.7132, 0.1916, 0.0952])
2024-12-05 15:34:15,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.7132, 0.1916, 0.0952]), new_distribution = tensor([0.7139, 0.1911, 0.0949])
2024-12-05 15:34:15,541 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.7139, 0.1911, 0.0949]), new_distribution = tensor([0.7147, 0.1907, 0.0947])
2024-12-05 15:34:15,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.7147, 0.1907, 0.0947]), new_distribution = tensor([0.7154, 0.1902, 0.0944])
2024-12-05 15:34:15,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.7154, 0.1902, 0.0944]), new_distribution = tensor([0.7162, 0.1897, 0.0941])
2024-12-05 15:34:15,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.7162, 0.1897, 0.0941]), new_distribution = tensor([0.7170, 0.1892, 0.0938])
2024-12-05 15:34:15,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.7170, 0.1892, 0.0938]), new_distribution = tensor([0.7177, 0.1887, 0.0936])
2024-12-05 15:34:15,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.7177, 0.1887, 0.0936]), new_distribution = tensor([0.7185, 0.1882, 0.0933])
2024-12-05 15:34:15,939 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.7185, 0.1882, 0.0933]), new_distribution = tensor([0.7192, 0.1877, 0.0930])
2024-12-05 15:34:15,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.7192, 0.1877, 0.0930]), new_distribution = tensor([0.7200, 0.1873, 0.0928])
2024-12-05 15:34:16,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.7200, 0.1873, 0.0928]), new_distribution = tensor([0.7207, 0.1868, 0.0925])
2024-12-05 15:34:16,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.7207, 0.1868, 0.0925]), new_distribution = tensor([0.7215, 0.1863, 0.0922])
2024-12-05 15:34:16,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.7215, 0.1863, 0.0922]), new_distribution = tensor([0.7222, 0.1858, 0.0920])
2024-12-05 15:34:16,213 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.7222, 0.1858, 0.0920]), new_distribution = tensor([0.7230, 0.1853, 0.0917])
2024-12-05 15:34:16,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.7230, 0.1853, 0.0917]), new_distribution = tensor([0.7237, 0.1848, 0.0914])
2024-12-05 15:34:16,322 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.7237, 0.1848, 0.0914]), new_distribution = tensor([0.7245, 0.1844, 0.0912])
2024-12-05 15:34:16,376 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.7245, 0.1844, 0.0912]), new_distribution = tensor([0.7252, 0.1839, 0.0909])
2024-12-05 15:34:16,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.7252, 0.1839, 0.0909]), new_distribution = tensor([0.7260, 0.1834, 0.0906])
2024-12-05 15:34:16,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.7260, 0.1834, 0.0906]), new_distribution = tensor([0.7267, 0.1829, 0.0904])
2024-12-05 15:34:16,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.7267, 0.1829, 0.0904]), new_distribution = tensor([0.7274, 0.1824, 0.0901])
2024-12-05 15:34:16,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.7274, 0.1824, 0.0901]), new_distribution = tensor([0.7282, 0.1820, 0.0899])
2024-12-05 15:34:16,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.7282, 0.1820, 0.0899]), new_distribution = tensor([0.7289, 0.1815, 0.0896])
2024-12-05 15:34:16,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.7289, 0.1815, 0.0896]), new_distribution = tensor([0.7296, 0.1810, 0.0893])
2024-12-05 15:34:16,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.7296, 0.1810, 0.0893]), new_distribution = tensor([0.7304, 0.1805, 0.0891])
2024-12-05 15:34:16,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.7304, 0.1805, 0.0891]), new_distribution = tensor([0.7311, 0.1801, 0.0888])
2024-12-05 15:34:16,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.7311, 0.1801, 0.0888]), new_distribution = tensor([0.7318, 0.1796, 0.0886])
2024-12-05 15:34:16,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.7318, 0.1796, 0.0886]), new_distribution = tensor([0.7326, 0.1791, 0.0883])
2024-12-05 15:34:16,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.7326, 0.1791, 0.0883]), new_distribution = tensor([0.7333, 0.1786, 0.0881])
2024-12-05 15:34:17,029 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.7333, 0.1786, 0.0881]), new_distribution = tensor([0.7340, 0.1782, 0.0878])
2024-12-05 15:34:17,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.7340, 0.1782, 0.0878]), new_distribution = tensor([0.7348, 0.1777, 0.0875])
2024-12-05 15:34:17,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.7348, 0.1777, 0.0875]), new_distribution = tensor([0.7355, 0.1772, 0.0873])
2024-12-05 15:34:17,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.7355, 0.1772, 0.0873]), new_distribution = tensor([0.7362, 0.1767, 0.0870])
2024-12-05 15:34:17,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.7362, 0.1767, 0.0870]), new_distribution = tensor([0.7369, 0.1763, 0.0868])
2024-12-05 15:34:17,305 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.7369, 0.1763, 0.0868]), new_distribution = tensor([0.7377, 0.1758, 0.0865])
2024-12-05 15:34:17,360 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.7377, 0.1758, 0.0865]), new_distribution = tensor([0.7384, 0.1753, 0.0863])
2024-12-05 15:34:17,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.7384, 0.1753, 0.0863]), new_distribution = tensor([0.7391, 0.1749, 0.0860])
2024-12-05 15:34:17,469 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.7391, 0.1749, 0.0860]), new_distribution = tensor([0.7398, 0.1744, 0.0858])
2024-12-05 15:34:17,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.7398, 0.1744, 0.0858]), new_distribution = tensor([0.7405, 0.1739, 0.0855])
2024-12-05 15:34:17,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.7405, 0.1739, 0.0855]), new_distribution = tensor([0.7413, 0.1735, 0.0853])
2024-12-05 15:34:17,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.7413, 0.1735, 0.0853]), new_distribution = tensor([0.7420, 0.1730, 0.0850])
2024-12-05 15:34:17,686 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.7420, 0.1730, 0.0850]), new_distribution = tensor([0.7427, 0.1725, 0.0848])
2024-12-05 15:34:17,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.7427, 0.1725, 0.0848]), new_distribution = tensor([0.7434, 0.1721, 0.0845])
2024-12-05 15:34:17,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.7434, 0.1721, 0.0845]), new_distribution = tensor([0.7441, 0.1716, 0.0843])
2024-12-05 15:34:17,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.7441, 0.1716, 0.0843]), new_distribution = tensor([0.7448, 0.1711, 0.0841])
2024-12-05 15:34:17,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.7448, 0.1711, 0.0841]), new_distribution = tensor([0.7455, 0.1707, 0.0838])
2024-12-05 15:34:17,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.7455, 0.1707, 0.0838]), new_distribution = tensor([0.7462, 0.1702, 0.0836])
2024-12-05 15:34:18,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.7462, 0.1702, 0.0836]), new_distribution = tensor([0.7469, 0.1697, 0.0833])
2024-12-05 15:34:18,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.7469, 0.1697, 0.0833]), new_distribution = tensor([0.7476, 0.1693, 0.0831])
2024-12-05 15:34:18,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.7476, 0.1693, 0.0831]), new_distribution = tensor([0.7483, 0.1688, 0.0828])
2024-12-05 15:34:18,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.7483, 0.1688, 0.0828]), new_distribution = tensor([0.7490, 0.1684, 0.0826])
2024-12-05 15:34:18,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.7490, 0.1684, 0.0826]), new_distribution = tensor([0.7497, 0.1679, 0.0824])
2024-12-05 15:34:18,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.7497, 0.1679, 0.0824]), new_distribution = tensor([0.7504, 0.1674, 0.0821])
2024-12-05 15:34:18,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.7504, 0.1674, 0.0821]), new_distribution = tensor([0.7511, 0.1670, 0.0819])
2024-12-05 15:34:18,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.7511, 0.1670, 0.0819]), new_distribution = tensor([0.7518, 0.1665, 0.0817])
2024-12-05 15:34:18,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.7518, 0.1665, 0.0817]), new_distribution = tensor([0.7525, 0.1661, 0.0814])
2024-12-05 15:34:18,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.7525, 0.1661, 0.0814]), new_distribution = tensor([0.7532, 0.1656, 0.0812])
2024-12-05 15:34:18,556 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.7532, 0.1656, 0.0812]), new_distribution = tensor([0.7539, 0.1652, 0.0809])
2024-12-05 15:34:18,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.7539, 0.1652, 0.0809]), new_distribution = tensor([0.7546, 0.1647, 0.0807])
2024-12-05 15:34:18,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.7546, 0.1647, 0.0807]), new_distribution = tensor([0.7553, 0.1642, 0.0805])
2024-12-05 15:34:18,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.7553, 0.1642, 0.0805]), new_distribution = tensor([0.7560, 0.1638, 0.0802])
2024-12-05 15:34:18,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.7560, 0.1638, 0.0802]), new_distribution = tensor([0.7567, 0.1633, 0.0800])
2024-12-05 15:34:18,827 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.7567, 0.1633, 0.0800]), new_distribution = tensor([0.7573, 0.1629, 0.0798])
2024-12-05 15:34:18,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.7573, 0.1629, 0.0798]), new_distribution = tensor([0.7580, 0.1624, 0.0795])
2024-12-05 15:34:18,936 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.7580, 0.1624, 0.0795]), new_distribution = tensor([0.7587, 0.1620, 0.0793])
2024-12-05 15:34:18,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.7587, 0.1620, 0.0793]), new_distribution = tensor([0.7594, 0.1615, 0.0791])
2024-12-05 15:34:19,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.7594, 0.1615, 0.0791]), new_distribution = tensor([0.7601, 0.1611, 0.0788])
2024-12-05 15:34:19,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.7601, 0.1611, 0.0788]), new_distribution = tensor([0.7608, 0.1606, 0.0786])
2024-12-05 15:34:19,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.7608, 0.1606, 0.0786]), new_distribution = tensor([0.7614, 0.1602, 0.0784])
2024-12-05 15:34:19,208 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.7614, 0.1602, 0.0784]), new_distribution = tensor([0.7621, 0.1597, 0.0782])
2024-12-05 15:34:19,262 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.7621, 0.1597, 0.0782]), new_distribution = tensor([0.7628, 0.1593, 0.0779])
2024-12-05 15:34:19,316 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.7628, 0.1593, 0.0779]), new_distribution = tensor([0.7635, 0.1588, 0.0777])
2024-12-05 15:34:19,370 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.7635, 0.1588, 0.0777]), new_distribution = tensor([0.7641, 0.1584, 0.0775])
2024-12-05 15:34:19,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.7641, 0.1584, 0.0775]), new_distribution = tensor([0.7648, 0.1579, 0.0773])
2024-12-05 15:34:19,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.7648, 0.1579, 0.0773]), new_distribution = tensor([0.7655, 0.1575, 0.0770])
2024-12-05 15:34:19,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.7655, 0.1575, 0.0770]), new_distribution = tensor([0.7661, 0.1571, 0.0768])
2024-12-05 15:34:19,588 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.7661, 0.1571, 0.0768]), new_distribution = tensor([0.7668, 0.1566, 0.0766])
2024-12-05 15:34:19,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.7668, 0.1566, 0.0766]), new_distribution = tensor([0.7675, 0.1562, 0.0764])
2024-12-05 15:34:19,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.7675, 0.1562, 0.0764]), new_distribution = tensor([0.7681, 0.1557, 0.0761])
2024-12-05 15:34:19,751 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.7681, 0.1557, 0.0761]), new_distribution = tensor([0.7688, 0.1553, 0.0759])
2024-12-05 15:34:19,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.7688, 0.1553, 0.0759]), new_distribution = tensor([0.7695, 0.1549, 0.0757])
2024-12-05 15:34:19,860 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.7695, 0.1549, 0.0757]), new_distribution = tensor([0.7701, 0.1544, 0.0755])
2024-12-05 15:34:19,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.7701, 0.1544, 0.0755]), new_distribution = tensor([0.7708, 0.1540, 0.0753])
2024-12-05 15:34:19,968 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.7708, 0.1540, 0.0753]), new_distribution = tensor([0.7714, 0.1535, 0.0750])
2024-12-05 15:34:20,022 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.7714, 0.1535, 0.0750]), new_distribution = tensor([0.7721, 0.1531, 0.0748])
2024-12-05 15:34:20,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:20,355 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:20,409 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:20,463 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:20,517 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:20,572 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:20,626 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:20,680 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:20,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:20,789 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:20,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:20,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:20,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,007 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,061 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,115 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,169 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,223 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,277 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,331 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,385 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,439 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,493 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,818 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,872 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,926 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:21,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,410 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,464 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,518 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,572 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,626 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,680 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,734 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,841 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,895 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:22,949 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,003 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,057 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,111 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,165 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,436 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,490 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,544 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,598 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,706 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,760 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,814 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:23,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,138 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,192 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,300 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,408 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,624 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,678 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:24,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,001 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,486 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,540 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,647 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:34:25,910 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.1000, 0.3000, 0.6000]), new_distribution = tensor([0.1003, 0.3005, 0.5992])
2024-12-05 15:34:25,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.1003, 0.3005, 0.5992]), new_distribution = tensor([0.1006, 0.3009, 0.5984])
2024-12-05 15:34:26,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.1006, 0.3009, 0.5984]), new_distribution = tensor([0.1010, 0.3014, 0.5976])
2024-12-05 15:34:26,074 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.1010, 0.3014, 0.5976]), new_distribution = tensor([0.1013, 0.3019, 0.5968])
2024-12-05 15:34:26,128 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.1013, 0.3019, 0.5968]), new_distribution = tensor([0.1016, 0.3024, 0.5960])
2024-12-05 15:34:26,182 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.1016, 0.3024, 0.5960]), new_distribution = tensor([0.1019, 0.3028, 0.5952])
2024-12-05 15:34:26,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.1019, 0.3028, 0.5952]), new_distribution = tensor([0.1022, 0.3033, 0.5944])
2024-12-05 15:34:26,289 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.1022, 0.3033, 0.5944]), new_distribution = tensor([0.1026, 0.3038, 0.5936])
2024-12-05 15:34:26,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.1026, 0.3038, 0.5936]), new_distribution = tensor([0.1029, 0.3043, 0.5928])
2024-12-05 15:34:26,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.1029, 0.3043, 0.5928]), new_distribution = tensor([0.1032, 0.3047, 0.5920])
2024-12-05 15:34:26,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.1032, 0.3047, 0.5920]), new_distribution = tensor([0.1036, 0.3052, 0.5913])
2024-12-05 15:34:26,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.1036, 0.3052, 0.5913]), new_distribution = tensor([0.1039, 0.3057, 0.5905])
2024-12-05 15:34:26,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.1039, 0.3057, 0.5905]), new_distribution = tensor([0.1042, 0.3061, 0.5897])
2024-12-05 15:34:26,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.1042, 0.3061, 0.5897]), new_distribution = tensor([0.1045, 0.3066, 0.5889])
2024-12-05 15:34:26,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.1045, 0.3066, 0.5889]), new_distribution = tensor([0.1049, 0.3071, 0.5881])
2024-12-05 15:34:26,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.1049, 0.3071, 0.5881]), new_distribution = tensor([0.1052, 0.3075, 0.5872])
2024-12-05 15:34:26,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.1052, 0.3075, 0.5872]), new_distribution = tensor([0.1055, 0.3080, 0.5864])
2024-12-05 15:34:26,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.1055, 0.3080, 0.5864]), new_distribution = tensor([0.1059, 0.3085, 0.5856])
2024-12-05 15:34:26,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.1059, 0.3085, 0.5856]), new_distribution = tensor([0.1062, 0.3089, 0.5848])
2024-12-05 15:34:26,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.1062, 0.3089, 0.5848]), new_distribution = tensor([0.1066, 0.3094, 0.5840])
2024-12-05 15:34:26,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.1066, 0.3094, 0.5840]), new_distribution = tensor([0.1069, 0.3099, 0.5832])
2024-12-05 15:34:27,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.1069, 0.3099, 0.5832]), new_distribution = tensor([0.1072, 0.3103, 0.5824])
2024-12-05 15:34:27,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.1072, 0.3103, 0.5824]), new_distribution = tensor([0.1076, 0.3108, 0.5816])
2024-12-05 15:34:27,156 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.1076, 0.3108, 0.5816]), new_distribution = tensor([0.1079, 0.3113, 0.5808])
2024-12-05 15:34:27,210 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.1079, 0.3113, 0.5808]), new_distribution = tensor([0.1083, 0.3117, 0.5800])
2024-12-05 15:34:27,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.1083, 0.3117, 0.5800]), new_distribution = tensor([0.1086, 0.3122, 0.5792])
2024-12-05 15:34:27,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.1086, 0.3122, 0.5792]), new_distribution = tensor([0.1089, 0.3127, 0.5784])
2024-12-05 15:34:27,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.1089, 0.3127, 0.5784]), new_distribution = tensor([0.1093, 0.3131, 0.5776])
2024-12-05 15:34:27,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.1093, 0.3131, 0.5776]), new_distribution = tensor([0.1096, 0.3136, 0.5768])
2024-12-05 15:34:27,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.1096, 0.3136, 0.5768]), new_distribution = tensor([0.1100, 0.3140, 0.5760])
2024-12-05 15:34:27,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.1100, 0.3140, 0.5760]), new_distribution = tensor([0.1103, 0.3145, 0.5752])
2024-12-05 15:34:27,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.1103, 0.3145, 0.5752]), new_distribution = tensor([0.1107, 0.3150, 0.5744])
2024-12-05 15:34:27,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.1107, 0.3150, 0.5744]), new_distribution = tensor([0.1110, 0.3154, 0.5735])
2024-12-05 15:34:27,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.1110, 0.3154, 0.5735]), new_distribution = tensor([0.1114, 0.3159, 0.5727])
2024-12-05 15:34:27,749 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.1114, 0.3159, 0.5727]), new_distribution = tensor([0.1117, 0.3163, 0.5719])
2024-12-05 15:34:27,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.1117, 0.3163, 0.5719]), new_distribution = tensor([0.1121, 0.3168, 0.5711])
2024-12-05 15:34:27,857 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.1121, 0.3168, 0.5711]), new_distribution = tensor([0.1124, 0.3173, 0.5703])
2024-12-05 15:34:27,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.1124, 0.3173, 0.5703]), new_distribution = tensor([0.1128, 0.3177, 0.5695])
2024-12-05 15:34:27,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.1128, 0.3177, 0.5695]), new_distribution = tensor([0.1132, 0.3182, 0.5687])
2024-12-05 15:34:28,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.1132, 0.3182, 0.5687]), new_distribution = tensor([0.1135, 0.3186, 0.5679])
2024-12-05 15:34:28,072 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.1135, 0.3186, 0.5679]), new_distribution = tensor([0.1139, 0.3191, 0.5670])
2024-12-05 15:34:28,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.1139, 0.3191, 0.5670]), new_distribution = tensor([0.1142, 0.3195, 0.5662])
2024-12-05 15:34:28,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.1142, 0.3195, 0.5662]), new_distribution = tensor([0.1146, 0.3200, 0.5654])
2024-12-05 15:34:28,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.1146, 0.3200, 0.5654]), new_distribution = tensor([0.1150, 0.3205, 0.5646])
2024-12-05 15:34:28,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.1150, 0.3205, 0.5646]), new_distribution = tensor([0.1153, 0.3209, 0.5638])
2024-12-05 15:34:28,342 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.1153, 0.3209, 0.5638]), new_distribution = tensor([0.1157, 0.3214, 0.5630])
2024-12-05 15:34:28,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.1157, 0.3214, 0.5630]), new_distribution = tensor([0.1160, 0.3218, 0.5621])
2024-12-05 15:34:28,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.1160, 0.3218, 0.5621]), new_distribution = tensor([0.1164, 0.3223, 0.5613])
2024-12-05 15:34:28,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.1164, 0.3223, 0.5613]), new_distribution = tensor([0.1168, 0.3227, 0.5605])
2024-12-05 15:34:28,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.1168, 0.3227, 0.5605]), new_distribution = tensor([0.1172, 0.3232, 0.5597])
2024-12-05 15:34:28,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.1172, 0.3232, 0.5597]), new_distribution = tensor([0.1175, 0.3236, 0.5589])
2024-12-05 15:34:28,666 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.1175, 0.3236, 0.5589]), new_distribution = tensor([0.1179, 0.3241, 0.5580])
2024-12-05 15:34:28,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.1179, 0.3241, 0.5580]), new_distribution = tensor([0.1183, 0.3245, 0.5572])
2024-12-05 15:34:28,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.1183, 0.3245, 0.5572]), new_distribution = tensor([0.1186, 0.3250, 0.5564])
2024-12-05 15:34:28,827 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.1186, 0.3250, 0.5564]), new_distribution = tensor([0.1190, 0.3254, 0.5556])
2024-12-05 15:34:28,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.1190, 0.3254, 0.5556]), new_distribution = tensor([0.1194, 0.3259, 0.5548])
2024-12-05 15:34:28,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.1194, 0.3259, 0.5548]), new_distribution = tensor([0.1198, 0.3263, 0.5539])
2024-12-05 15:34:28,988 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.1198, 0.3263, 0.5539]), new_distribution = tensor([0.1201, 0.3267, 0.5531])
2024-12-05 15:34:29,042 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.1201, 0.3267, 0.5531]), new_distribution = tensor([0.1205, 0.3272, 0.5523])
2024-12-05 15:34:29,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.1205, 0.3272, 0.5523]), new_distribution = tensor([0.1209, 0.3276, 0.5515])
2024-12-05 15:34:29,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.1209, 0.3276, 0.5515]), new_distribution = tensor([0.1213, 0.3281, 0.5506])
2024-12-05 15:34:29,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.1213, 0.3281, 0.5506]), new_distribution = tensor([0.1217, 0.3285, 0.5498])
2024-12-05 15:34:29,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.1217, 0.3285, 0.5498]), new_distribution = tensor([0.1220, 0.3290, 0.5490])
2024-12-05 15:34:29,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.1220, 0.3290, 0.5490]), new_distribution = tensor([0.1224, 0.3294, 0.5482])
2024-12-05 15:34:29,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.1224, 0.3294, 0.5482]), new_distribution = tensor([0.1228, 0.3298, 0.5474])
2024-12-05 15:34:29,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.1228, 0.3298, 0.5474]), new_distribution = tensor([0.1232, 0.3303, 0.5465])
2024-12-05 15:34:29,472 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.1232, 0.3303, 0.5465]), new_distribution = tensor([0.1236, 0.3307, 0.5457])
2024-12-05 15:34:29,526 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.1236, 0.3307, 0.5457]), new_distribution = tensor([0.1240, 0.3311, 0.5449])
2024-12-05 15:34:29,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.1240, 0.3311, 0.5449]), new_distribution = tensor([0.1244, 0.3316, 0.5440])
2024-12-05 15:34:29,634 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.1244, 0.3316, 0.5440]), new_distribution = tensor([0.1248, 0.3320, 0.5432])
2024-12-05 15:34:29,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.1248, 0.3320, 0.5432]), new_distribution = tensor([0.1251, 0.3325, 0.5424])
2024-12-05 15:34:29,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.1251, 0.3325, 0.5424]), new_distribution = tensor([0.1255, 0.3329, 0.5416])
2024-12-05 15:34:29,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.1255, 0.3329, 0.5416]), new_distribution = tensor([0.1259, 0.3333, 0.5407])
2024-12-05 15:34:29,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.1259, 0.3333, 0.5407]), new_distribution = tensor([0.1263, 0.3338, 0.5399])
2024-12-05 15:34:29,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.1263, 0.3338, 0.5399]), new_distribution = tensor([0.1267, 0.3342, 0.5391])
2024-12-05 15:34:29,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.1267, 0.3342, 0.5391]), new_distribution = tensor([0.1271, 0.3346, 0.5383])
2024-12-05 15:34:30,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.1271, 0.3346, 0.5383]), new_distribution = tensor([0.1275, 0.3350, 0.5374])
2024-12-05 15:34:30,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.1275, 0.3350, 0.5374]), new_distribution = tensor([0.1279, 0.3355, 0.5366])
2024-12-05 15:34:30,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.1279, 0.3355, 0.5366]), new_distribution = tensor([0.1283, 0.3359, 0.5358])
2024-12-05 15:34:30,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.1283, 0.3359, 0.5358]), new_distribution = tensor([0.1287, 0.3363, 0.5349])
2024-12-05 15:34:30,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.1287, 0.3363, 0.5349]), new_distribution = tensor([0.1291, 0.3368, 0.5341])
2024-12-05 15:34:30,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.1291, 0.3368, 0.5341]), new_distribution = tensor([0.1295, 0.3372, 0.5333])
2024-12-05 15:34:30,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.1295, 0.3372, 0.5333]), new_distribution = tensor([0.1299, 0.3376, 0.5324])
2024-12-05 15:34:30,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.1299, 0.3376, 0.5324]), new_distribution = tensor([0.1303, 0.3380, 0.5316])
2024-12-05 15:34:30,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.1303, 0.3380, 0.5316]), new_distribution = tensor([0.1308, 0.3385, 0.5308])
2024-12-05 15:34:30,494 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.1308, 0.3385, 0.5308]), new_distribution = tensor([0.1312, 0.3389, 0.5300])
2024-12-05 15:34:30,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.1312, 0.3389, 0.5300]), new_distribution = tensor([0.1316, 0.3393, 0.5291])
2024-12-05 15:34:30,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.1316, 0.3393, 0.5291]), new_distribution = tensor([0.1320, 0.3397, 0.5283])
2024-12-05 15:34:30,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.1320, 0.3397, 0.5283]), new_distribution = tensor([0.1324, 0.3401, 0.5275])
2024-12-05 15:34:30,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.1324, 0.3401, 0.5275]), new_distribution = tensor([0.1328, 0.3406, 0.5266])
2024-12-05 15:34:30,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.1328, 0.3406, 0.5266]), new_distribution = tensor([0.1332, 0.3410, 0.5258])
2024-12-05 15:34:30,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.1332, 0.3410, 0.5258]), new_distribution = tensor([0.1336, 0.3414, 0.5250])
2024-12-05 15:34:30,871 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.1336, 0.3414, 0.5250]), new_distribution = tensor([0.1341, 0.3418, 0.5241])
2024-12-05 15:34:30,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.1341, 0.3418, 0.5241]), new_distribution = tensor([0.1345, 0.3422, 0.5233])
2024-12-05 15:34:30,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.1345, 0.3422, 0.5233]), new_distribution = tensor([0.1349, 0.3426, 0.5225])
2024-12-05 15:34:31,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.1349, 0.3426, 0.5225]), new_distribution = tensor([0.1353, 0.3431, 0.5216])
2024-12-05 15:34:31,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.1353, 0.3431, 0.5216]), new_distribution = tensor([0.1357, 0.3435, 0.5208])
2024-12-05 15:34:31,140 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.1357, 0.3435, 0.5208]), new_distribution = tensor([0.1362, 0.3439, 0.5200])
2024-12-05 15:34:31,194 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.1362, 0.3439, 0.5200]), new_distribution = tensor([0.1366, 0.3443, 0.5191])
2024-12-05 15:34:31,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.1366, 0.3443, 0.5191]), new_distribution = tensor([0.1370, 0.3447, 0.5183])
2024-12-05 15:36:09,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.5375, 0.2791, 0.1834]), new_distribution = tensor([0.5384, 0.2787, 0.1829])
2024-12-05 15:36:09,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.5384, 0.2787, 0.1829]), new_distribution = tensor([0.5394, 0.2783, 0.1824])
2024-12-05 15:36:09,219 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.5394, 0.2783, 0.1824]), new_distribution = tensor([0.5403, 0.2778, 0.1819])
2024-12-05 15:36:09,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.5403, 0.2778, 0.1819]), new_distribution = tensor([0.5412, 0.2774, 0.1814])
2024-12-05 15:36:09,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.5412, 0.2774, 0.1814]), new_distribution = tensor([0.5421, 0.2769, 0.1809])
2024-12-05 15:36:09,456 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.5421, 0.2769, 0.1809]), new_distribution = tensor([0.5431, 0.2765, 0.1804])
2024-12-05 15:36:09,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.5431, 0.2765, 0.1804]), new_distribution = tensor([0.5440, 0.2761, 0.1800])
2024-12-05 15:36:09,614 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.5440, 0.2761, 0.1800]), new_distribution = tensor([0.5449, 0.2756, 0.1795])
2024-12-05 15:36:09,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.5449, 0.2756, 0.1795]), new_distribution = tensor([0.5458, 0.2752, 0.1790])
2024-12-05 15:36:09,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.5458, 0.2752, 0.1790]), new_distribution = tensor([0.5467, 0.2748, 0.1785])
2024-12-05 15:36:09,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.5467, 0.2748, 0.1785]), new_distribution = tensor([0.5477, 0.2743, 0.1780])
2024-12-05 15:36:09,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.5477, 0.2743, 0.1780]), new_distribution = tensor([0.5486, 0.2739, 0.1775])
2024-12-05 15:36:10,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.5486, 0.2739, 0.1775]), new_distribution = tensor([0.5495, 0.2734, 0.1771])
2024-12-05 15:36:10,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.5495, 0.2734, 0.1771]), new_distribution = tensor([0.5504, 0.2730, 0.1766])
2024-12-05 15:36:10,165 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.5504, 0.2730, 0.1766]), new_distribution = tensor([0.5513, 0.2725, 0.1761])
2024-12-05 15:36:10,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.5513, 0.2725, 0.1761]), new_distribution = tensor([0.5523, 0.2721, 0.1756])
2024-12-05 15:36:10,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.5523, 0.2721, 0.1756]), new_distribution = tensor([0.5532, 0.2717, 0.1752])
2024-12-05 15:36:10,402 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.5532, 0.2717, 0.1752]), new_distribution = tensor([0.5541, 0.2712, 0.1747])
2024-12-05 15:36:10,481 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.5541, 0.2712, 0.1747]), new_distribution = tensor([0.5550, 0.2708, 0.1742])
2024-12-05 15:36:10,590 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.5550, 0.2708, 0.1742]), new_distribution = tensor([0.5559, 0.2703, 0.1738])
2024-12-05 15:36:10,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.5559, 0.2703, 0.1738]), new_distribution = tensor([0.5568, 0.2699, 0.1733])
2024-12-05 15:36:10,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.5568, 0.2699, 0.1733]), new_distribution = tensor([0.5578, 0.2694, 0.1728])
2024-12-05 15:36:10,906 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.5578, 0.2694, 0.1728]), new_distribution = tensor([0.5587, 0.2690, 0.1724])
2024-12-05 15:36:11,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.5587, 0.2690, 0.1724]), new_distribution = tensor([0.5596, 0.2685, 0.1719])
2024-12-05 15:36:11,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.5596, 0.2685, 0.1719]), new_distribution = tensor([0.5605, 0.2681, 0.1714])
2024-12-05 15:36:11,223 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.5605, 0.2681, 0.1714]), new_distribution = tensor([0.5614, 0.2676, 0.1710])
2024-12-05 15:36:11,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.5614, 0.2676, 0.1710]), new_distribution = tensor([0.5623, 0.2672, 0.1705])
2024-12-05 15:36:11,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.5623, 0.2672, 0.1705]), new_distribution = tensor([0.5632, 0.2667, 0.1700])
2024-12-05 15:36:11,544 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.5632, 0.2667, 0.1700]), new_distribution = tensor([0.5642, 0.2663, 0.1696])
2024-12-05 15:36:11,650 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.5642, 0.2663, 0.1696]), new_distribution = tensor([0.5651, 0.2658, 0.1691])
2024-12-05 15:36:11,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.5651, 0.2658, 0.1691]), new_distribution = tensor([0.5660, 0.2654, 0.1687])
2024-12-05 15:36:11,861 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.5660, 0.2654, 0.1687]), new_distribution = tensor([0.5669, 0.2649, 0.1682])
2024-12-05 15:36:11,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.5669, 0.2649, 0.1682]), new_distribution = tensor([0.5678, 0.2645, 0.1677])
2024-12-05 15:36:12,072 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.5678, 0.2645, 0.1677]), new_distribution = tensor([0.5687, 0.2640, 0.1673])
2024-12-05 15:36:12,174 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.5687, 0.2640, 0.1673]), new_distribution = tensor([0.5696, 0.2635, 0.1668])
2024-12-05 15:36:12,272 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.5696, 0.2635, 0.1668]), new_distribution = tensor([0.5705, 0.2631, 0.1664])
2024-12-05 15:36:12,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.5705, 0.2631, 0.1664]), new_distribution = tensor([0.5715, 0.2626, 0.1659])
2024-12-05 15:36:12,452 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.5715, 0.2626, 0.1659]), new_distribution = tensor([0.5724, 0.2622, 0.1655])
2024-12-05 15:36:12,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.5724, 0.2622, 0.1655]), new_distribution = tensor([0.5733, 0.2617, 0.1650])
2024-12-05 15:36:12,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.5733, 0.2617, 0.1650]), new_distribution = tensor([0.5742, 0.2612, 0.1646])
2024-12-05 15:36:12,686 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.5742, 0.2612, 0.1646]), new_distribution = tensor([0.5751, 0.2608, 0.1641])
2024-12-05 15:36:12,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.5751, 0.2608, 0.1641]), new_distribution = tensor([0.5760, 0.2603, 0.1637])
2024-12-05 15:36:12,822 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.5760, 0.2603, 0.1637]), new_distribution = tensor([0.5769, 0.2599, 0.1632])
2024-12-05 15:36:12,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.5769, 0.2599, 0.1632]), new_distribution = tensor([0.5778, 0.2594, 0.1628])
2024-12-05 15:36:12,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.5778, 0.2594, 0.1628]), new_distribution = tensor([0.5787, 0.2589, 0.1623])
2024-12-05 15:36:13,009 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.5787, 0.2589, 0.1623]), new_distribution = tensor([0.5796, 0.2585, 0.1619])
2024-12-05 15:36:13,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.5796, 0.2585, 0.1619]), new_distribution = tensor([0.5805, 0.2580, 0.1615])
2024-12-05 15:36:13,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.5805, 0.2580, 0.1615]), new_distribution = tensor([0.5814, 0.2576, 0.1610])
2024-12-05 15:36:13,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.5814, 0.2576, 0.1610]), new_distribution = tensor([0.5823, 0.2571, 0.1606])
2024-12-05 15:36:13,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.5823, 0.2571, 0.1606]), new_distribution = tensor([0.5832, 0.2566, 0.1601])
2024-12-05 15:36:13,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.5832, 0.2566, 0.1601]), new_distribution = tensor([0.5841, 0.2562, 0.1597])
2024-12-05 15:36:13,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.5841, 0.2562, 0.1597]), new_distribution = tensor([0.5850, 0.2557, 0.1593])
2024-12-05 15:36:13,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.5850, 0.2557, 0.1593]), new_distribution = tensor([0.5859, 0.2552, 0.1588])
2024-12-05 15:36:13,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.5859, 0.2552, 0.1588]), new_distribution = tensor([0.5868, 0.2548, 0.1584])
2024-12-05 15:36:13,494 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.5868, 0.2548, 0.1584]), new_distribution = tensor([0.5877, 0.2543, 0.1580])
2024-12-05 15:36:13,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.5877, 0.2543, 0.1580]), new_distribution = tensor([0.5886, 0.2538, 0.1575])
2024-12-05 15:36:13,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.5886, 0.2538, 0.1575]), new_distribution = tensor([0.5895, 0.2534, 0.1571])
2024-12-05 15:36:13,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.5895, 0.2534, 0.1571]), new_distribution = tensor([0.5904, 0.2529, 0.1567])
2024-12-05 15:36:13,709 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.5904, 0.2529, 0.1567]), new_distribution = tensor([0.5913, 0.2524, 0.1562])
2024-12-05 15:36:13,763 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.5913, 0.2524, 0.1562]), new_distribution = tensor([0.5922, 0.2520, 0.1558])
2024-12-05 15:36:13,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.5922, 0.2520, 0.1558]), new_distribution = tensor([0.5931, 0.2515, 0.1554])
2024-12-05 15:36:13,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.5931, 0.2515, 0.1554]), new_distribution = tensor([0.5940, 0.2510, 0.1550])
2024-12-05 15:36:13,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.5940, 0.2510, 0.1550]), new_distribution = tensor([0.5949, 0.2505, 0.1545])
2024-12-05 15:36:13,978 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.5949, 0.2505, 0.1545]), new_distribution = tensor([0.5958, 0.2501, 0.1541])
2024-12-05 15:36:14,031 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.5958, 0.2501, 0.1541]), new_distribution = tensor([0.5967, 0.2496, 0.1537])
2024-12-05 15:36:14,085 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.5967, 0.2496, 0.1537]), new_distribution = tensor([0.5976, 0.2491, 0.1533])
2024-12-05 15:36:14,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.5976, 0.2491, 0.1533]), new_distribution = tensor([0.5985, 0.2487, 0.1528])
2024-12-05 15:36:14,193 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.5985, 0.2487, 0.1528]), new_distribution = tensor([0.5994, 0.2482, 0.1524])
2024-12-05 15:36:14,247 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.5994, 0.2482, 0.1524]), new_distribution = tensor([0.6003, 0.2477, 0.1520])
2024-12-05 15:36:14,300 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.6003, 0.2477, 0.1520]), new_distribution = tensor([0.6012, 0.2472, 0.1516])
2024-12-05 15:36:14,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.6012, 0.2472, 0.1516]), new_distribution = tensor([0.6021, 0.2468, 0.1512])
2024-12-05 15:36:14,408 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.6021, 0.2468, 0.1512]), new_distribution = tensor([0.6029, 0.2463, 0.1507])
2024-12-05 15:36:14,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.6029, 0.2463, 0.1507]), new_distribution = tensor([0.6038, 0.2458, 0.1503])
2024-12-05 15:36:14,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.6038, 0.2458, 0.1503]), new_distribution = tensor([0.6047, 0.2454, 0.1499])
2024-12-05 15:36:14,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.6047, 0.2454, 0.1499]), new_distribution = tensor([0.6056, 0.2449, 0.1495])
2024-12-05 15:36:14,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.6056, 0.2449, 0.1495]), new_distribution = tensor([0.6065, 0.2444, 0.1491])
2024-12-05 15:36:14,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.6065, 0.2444, 0.1491]), new_distribution = tensor([0.6074, 0.2439, 0.1487])
2024-12-05 15:36:14,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.6074, 0.2439, 0.1487]), new_distribution = tensor([0.6083, 0.2435, 0.1483])
2024-12-05 15:36:14,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.6083, 0.2435, 0.1483]), new_distribution = tensor([0.6092, 0.2430, 0.1479])
2024-12-05 15:36:14,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.6092, 0.2430, 0.1479]), new_distribution = tensor([0.6100, 0.2425, 0.1475])
2024-12-05 15:36:14,891 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.6100, 0.2425, 0.1475]), new_distribution = tensor([0.6109, 0.2420, 0.1470])
2024-12-05 15:36:14,945 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.6109, 0.2420, 0.1470]), new_distribution = tensor([0.6118, 0.2416, 0.1466])
2024-12-05 15:36:14,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.6118, 0.2416, 0.1466]), new_distribution = tensor([0.6127, 0.2411, 0.1462])
2024-12-05 15:36:15,053 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.6127, 0.2411, 0.1462]), new_distribution = tensor([0.6136, 0.2406, 0.1458])
2024-12-05 15:36:15,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.6136, 0.2406, 0.1458]), new_distribution = tensor([0.6144, 0.2401, 0.1454])
2024-12-05 15:36:15,161 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.6144, 0.2401, 0.1454]), new_distribution = tensor([0.6153, 0.2396, 0.1450])
2024-12-05 15:36:15,214 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.6153, 0.2396, 0.1450]), new_distribution = tensor([0.6162, 0.2392, 0.1446])
2024-12-05 15:36:15,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.6162, 0.2392, 0.1446]), new_distribution = tensor([0.6171, 0.2387, 0.1442])
2024-12-05 15:36:15,322 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.6171, 0.2387, 0.1442]), new_distribution = tensor([0.6180, 0.2382, 0.1438])
2024-12-05 15:36:15,376 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.6180, 0.2382, 0.1438]), new_distribution = tensor([0.6188, 0.2377, 0.1434])
2024-12-05 15:36:15,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.6188, 0.2377, 0.1434]), new_distribution = tensor([0.6197, 0.2373, 0.1430])
2024-12-05 15:36:15,483 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.6197, 0.2373, 0.1430]), new_distribution = tensor([0.6206, 0.2368, 0.1426])
2024-12-05 15:36:15,537 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.6206, 0.2368, 0.1426]), new_distribution = tensor([0.6215, 0.2363, 0.1422])
2024-12-05 15:36:15,590 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.6215, 0.2363, 0.1422]), new_distribution = tensor([0.6223, 0.2358, 0.1418])
2024-12-05 15:36:15,644 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.6223, 0.2358, 0.1418]), new_distribution = tensor([0.6232, 0.2353, 0.1414])
2024-12-05 15:36:15,698 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.6232, 0.2353, 0.1414]), new_distribution = tensor([0.6241, 0.2349, 0.1411])
2024-12-05 15:36:15,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.6241, 0.2349, 0.1411]), new_distribution = tensor([0.6249, 0.2344, 0.1407])
2024-12-05 15:36:15,806 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.6249, 0.2344, 0.1407]), new_distribution = tensor([0.6258, 0.2339, 0.1403])
2024-12-05 15:36:15,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.6258, 0.2339, 0.1403]), new_distribution = tensor([0.6267, 0.2334, 0.1399])
2024-12-05 15:36:15,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.6267, 0.2334, 0.1399]), new_distribution = tensor([0.6276, 0.2330, 0.1395])
2024-12-05 15:36:15,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([0.6276, 0.2330, 0.1395]), new_distribution = tensor([0.6284, 0.2325, 0.1391])
2024-12-05 15:36:16,022 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([0.6284, 0.2325, 0.1391]), new_distribution = tensor([0.6293, 0.2320, 0.1387])
2024-12-05 15:36:16,076 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([0.6293, 0.2320, 0.1387]), new_distribution = tensor([0.6302, 0.2315, 0.1383])
2024-12-05 15:36:16,130 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([0.6302, 0.2315, 0.1383]), new_distribution = tensor([0.6310, 0.2310, 0.1380])
2024-12-05 15:36:16,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([0.6310, 0.2310, 0.1380]), new_distribution = tensor([0.6319, 0.2306, 0.1376])
2024-12-05 15:36:16,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([0.6319, 0.2306, 0.1376]), new_distribution = tensor([0.6327, 0.2301, 0.1372])
2024-12-05 15:36:16,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([0.6327, 0.2301, 0.1372]), new_distribution = tensor([0.6336, 0.2296, 0.1368])
2024-12-05 15:36:16,345 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([0.6336, 0.2296, 0.1368]), new_distribution = tensor([0.6345, 0.2291, 0.1364])
2024-12-05 15:36:16,399 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([0.6345, 0.2291, 0.1364]), new_distribution = tensor([0.6353, 0.2286, 0.1360])
2024-12-05 15:36:16,453 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([0.6353, 0.2286, 0.1360]), new_distribution = tensor([0.6362, 0.2281, 0.1357])
2024-12-05 15:36:16,506 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([0.6362, 0.2281, 0.1357]), new_distribution = tensor([0.6370, 0.2277, 0.1353])
2024-12-05 15:36:16,560 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([0.6370, 0.2277, 0.1353]), new_distribution = tensor([0.6379, 0.2272, 0.1349])
2024-12-05 15:36:16,614 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([0.6379, 0.2272, 0.1349]), new_distribution = tensor([0.6388, 0.2267, 0.1345])
2024-12-05 15:36:16,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([0.6388, 0.2267, 0.1345]), new_distribution = tensor([0.6396, 0.2262, 0.1342])
2024-12-05 15:36:16,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([0.6396, 0.2262, 0.1342]), new_distribution = tensor([0.6405, 0.2257, 0.1338])
2024-12-05 15:36:16,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([0.6405, 0.2257, 0.1338]), new_distribution = tensor([0.6413, 0.2253, 0.1334])
2024-12-05 15:36:16,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([0.6413, 0.2253, 0.1334]), new_distribution = tensor([0.6422, 0.2248, 0.1330])
2024-12-05 15:36:16,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([0.6422, 0.2248, 0.1330]), new_distribution = tensor([0.6430, 0.2243, 0.1327])
2024-12-05 15:36:16,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([0.6430, 0.2243, 0.1327]), new_distribution = tensor([0.6439, 0.2238, 0.1323])
2024-12-05 15:36:16,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([0.6439, 0.2238, 0.1323]), new_distribution = tensor([0.6447, 0.2233, 0.1319])
2024-12-05 15:36:17,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([0.6447, 0.2233, 0.1319]), new_distribution = tensor([0.6456, 0.2229, 0.1316])
2024-12-05 15:36:17,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([0.6456, 0.2229, 0.1316]), new_distribution = tensor([0.6464, 0.2224, 0.1312])
2024-12-05 15:36:17,152 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([0.6464, 0.2224, 0.1312]), new_distribution = tensor([0.6473, 0.2219, 0.1308])
2024-12-05 15:36:17,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([0.6473, 0.2219, 0.1308]), new_distribution = tensor([0.6481, 0.2214, 0.1305])
2024-12-05 15:36:17,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([0.6481, 0.2214, 0.1305]), new_distribution = tensor([0.6490, 0.2209, 0.1301])
2024-12-05 15:36:17,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([0.6490, 0.2209, 0.1301]), new_distribution = tensor([0.6498, 0.2205, 0.1297])
2024-12-05 15:36:17,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([0.6498, 0.2205, 0.1297]), new_distribution = tensor([0.6507, 0.2200, 0.1294])
2024-12-05 15:36:17,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([0.6507, 0.2200, 0.1294]), new_distribution = tensor([0.6515, 0.2195, 0.1290])
2024-12-05 15:36:17,480 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([0.6515, 0.2195, 0.1290]), new_distribution = tensor([0.6523, 0.2190, 0.1286])
2024-12-05 15:36:17,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([0.6523, 0.2190, 0.1286]), new_distribution = tensor([0.6532, 0.2185, 0.1283])
2024-12-05 15:36:17,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([0.6532, 0.2185, 0.1283]), new_distribution = tensor([0.6540, 0.2181, 0.1279])
2024-12-05 15:36:17,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([0.6540, 0.2181, 0.1279]), new_distribution = tensor([0.6549, 0.2176, 0.1276])
2024-12-05 15:36:17,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([0.6549, 0.2176, 0.1276]), new_distribution = tensor([0.6557, 0.2171, 0.1272])
2024-12-05 15:36:17,749 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([0.6557, 0.2171, 0.1272]), new_distribution = tensor([0.6565, 0.2166, 0.1268])
2024-12-05 15:36:17,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([0.6565, 0.2166, 0.1268]), new_distribution = tensor([0.6574, 0.2161, 0.1265])
2024-12-05 15:36:17,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([0.6574, 0.2161, 0.1265]), new_distribution = tensor([0.6582, 0.2157, 0.1261])
2024-12-05 15:36:17,910 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([0.6582, 0.2157, 0.1261]), new_distribution = tensor([0.6591, 0.2152, 0.1258])
2024-12-05 15:36:17,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([0.6591, 0.2152, 0.1258]), new_distribution = tensor([0.6599, 0.2147, 0.1254])
2024-12-05 15:36:18,019 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([0.6599, 0.2147, 0.1254]), new_distribution = tensor([0.6607, 0.2142, 0.1251])
2024-12-05 15:36:18,072 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([0.6607, 0.2142, 0.1251]), new_distribution = tensor([0.6615, 0.2137, 0.1247])
2024-12-05 15:36:18,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([0.6615, 0.2137, 0.1247]), new_distribution = tensor([0.6624, 0.2133, 0.1244])
2024-12-05 15:36:18,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([0.6624, 0.2133, 0.1244]), new_distribution = tensor([0.6632, 0.2128, 0.1240])
2024-12-05 15:36:18,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([0.6632, 0.2128, 0.1240]), new_distribution = tensor([0.6640, 0.2123, 0.1237])
2024-12-05 15:36:18,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([0.6640, 0.2123, 0.1237]), new_distribution = tensor([0.6649, 0.2118, 0.1233])
2024-12-05 15:36:18,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([0.6649, 0.2118, 0.1233]), new_distribution = tensor([0.6657, 0.2113, 0.1230])
2024-12-05 15:36:18,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([0.6657, 0.2113, 0.1230]), new_distribution = tensor([0.6665, 0.2109, 0.1226])
2024-12-05 15:36:18,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([0.6665, 0.2109, 0.1226]), new_distribution = tensor([0.6673, 0.2104, 0.1223])
2024-12-05 15:36:18,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([0.6673, 0.2104, 0.1223]), new_distribution = tensor([0.6682, 0.2099, 0.1219])
2024-12-05 15:36:18,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([0.6682, 0.2099, 0.1219]), new_distribution = tensor([0.6690, 0.2094, 0.1216])
2024-12-05 15:36:18,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([0.6690, 0.2094, 0.1216]), new_distribution = tensor([0.6698, 0.2089, 0.1213])
2024-12-05 15:36:18,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([0.6698, 0.2089, 0.1213]), new_distribution = tensor([0.6706, 0.2085, 0.1209])
2024-12-05 15:36:18,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([0.6706, 0.2085, 0.1209]), new_distribution = tensor([0.6714, 0.2080, 0.1206])
2024-12-05 15:36:18,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([0.6714, 0.2080, 0.1206]), new_distribution = tensor([0.6723, 0.2075, 0.1202])
2024-12-05 15:36:18,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([0.6723, 0.2075, 0.1202]), new_distribution = tensor([0.6731, 0.2070, 0.1199])
2024-12-05 15:36:18,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([0.6731, 0.2070, 0.1199]), new_distribution = tensor([0.6739, 0.2066, 0.1196])
2024-12-05 15:36:18,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([0.6739, 0.2066, 0.1196]), new_distribution = tensor([0.6747, 0.2061, 0.1192])
2024-12-05 15:36:18,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([0.6747, 0.2061, 0.1192]), new_distribution = tensor([0.6755, 0.2056, 0.1189])
2024-12-05 15:36:19,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([0.6755, 0.2056, 0.1189]), new_distribution = tensor([0.6763, 0.2051, 0.1185])
2024-12-05 15:36:19,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([0.6763, 0.2051, 0.1185]), new_distribution = tensor([0.6771, 0.2046, 0.1182])
2024-12-05 15:36:19,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([0.6771, 0.2046, 0.1182]), new_distribution = tensor([0.6780, 0.2042, 0.1179])
2024-12-05 15:36:19,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([0.6780, 0.2042, 0.1179]), new_distribution = tensor([0.6788, 0.2037, 0.1175])
2024-12-05 15:36:19,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([0.6788, 0.2037, 0.1175]), new_distribution = tensor([0.6796, 0.2032, 0.1172])
2024-12-05 15:36:19,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([0.6796, 0.2032, 0.1172]), new_distribution = tensor([0.6804, 0.2027, 0.1169])
2024-12-05 15:36:19,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([0.6804, 0.2027, 0.1169]), new_distribution = tensor([0.6812, 0.2023, 0.1166])
2024-12-05 15:36:19,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([0.6812, 0.2023, 0.1166]), new_distribution = tensor([0.6820, 0.2018, 0.1162])
2024-12-05 15:36:19,477 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([0.6820, 0.2018, 0.1162]), new_distribution = tensor([0.6828, 0.2013, 0.1159])
2024-12-05 15:36:19,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([0.6828, 0.2013, 0.1159]), new_distribution = tensor([0.6836, 0.2008, 0.1156])
2024-12-05 15:36:19,584 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([0.6836, 0.2008, 0.1156]), new_distribution = tensor([0.6844, 0.2004, 0.1152])
2024-12-05 15:36:19,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([0.6844, 0.2004, 0.1152]), new_distribution = tensor([0.6852, 0.1999, 0.1149])
2024-12-05 15:36:19,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([0.6852, 0.1999, 0.1149]), new_distribution = tensor([0.6860, 0.1994, 0.1146])
2024-12-05 15:36:19,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([0.6860, 0.1994, 0.1146]), new_distribution = tensor([0.6868, 0.1989, 0.1143])
2024-12-05 15:36:19,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([0.6868, 0.1989, 0.1143]), new_distribution = tensor([0.6876, 0.1985, 0.1139])
2024-12-05 15:36:19,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([0.6876, 0.1985, 0.1139]), new_distribution = tensor([0.6884, 0.1980, 0.1136])
2024-12-05 15:36:19,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([0.6884, 0.1980, 0.1136]), new_distribution = tensor([0.6892, 0.1975, 0.1133])
2024-12-05 15:36:19,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([0.6892, 0.1975, 0.1133]), new_distribution = tensor([0.6900, 0.1970, 0.1130])
2024-12-05 15:36:20,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([0.6900, 0.1970, 0.1130]), new_distribution = tensor([0.6908, 0.1966, 0.1127])
2024-12-05 15:36:20,069 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([0.6908, 0.1966, 0.1127]), new_distribution = tensor([0.6916, 0.1961, 0.1123])
2024-12-05 15:36:20,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([0.6916, 0.1961, 0.1123]), new_distribution = tensor([0.6924, 0.1956, 0.1120])
2024-12-05 15:36:20,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([0.6924, 0.1956, 0.1120]), new_distribution = tensor([0.6931, 0.1952, 0.1117])
2024-12-05 15:36:20,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([0.6931, 0.1952, 0.1117]), new_distribution = tensor([0.6939, 0.1947, 0.1114])
2024-12-05 15:36:20,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([0.6939, 0.1947, 0.1114]), new_distribution = tensor([0.6947, 0.1942, 0.1111])
2024-12-05 15:36:20,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([0.6947, 0.1942, 0.1111]), new_distribution = tensor([0.6955, 0.1937, 0.1108])
2024-12-05 15:36:20,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([0.6955, 0.1937, 0.1108]), new_distribution = tensor([0.6963, 0.1933, 0.1104])
2024-12-05 15:36:20,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([0.6963, 0.1933, 0.1104]), new_distribution = tensor([0.6971, 0.1928, 0.1101])
2024-12-05 15:36:20,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([0.6971, 0.1928, 0.1101]), new_distribution = tensor([0.6979, 0.1923, 0.1098])
2024-12-05 15:36:20,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([0.6979, 0.1923, 0.1098]), new_distribution = tensor([0.6986, 0.1919, 0.1095])
2024-12-05 15:36:20,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([0.6986, 0.1919, 0.1095]), new_distribution = tensor([0.6994, 0.1914, 0.1092])
2024-12-05 15:36:20,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([0.6994, 0.1914, 0.1092]), new_distribution = tensor([0.7002, 0.1909, 0.1089])
2024-12-05 15:36:20,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([0.7002, 0.1909, 0.1089]), new_distribution = tensor([0.7010, 0.1905, 0.1086])
2024-12-05 15:36:20,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([0.7010, 0.1905, 0.1086]), new_distribution = tensor([0.7017, 0.1900, 0.1083])
2024-12-05 15:36:20,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([0.7017, 0.1900, 0.1083]), new_distribution = tensor([0.7025, 0.1895, 0.1080])
2024-12-05 15:36:20,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([0.7025, 0.1895, 0.1080]), new_distribution = tensor([0.7033, 0.1891, 0.1076])
2024-12-05 15:36:20,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([0.7033, 0.1891, 0.1076]), new_distribution = tensor([0.7041, 0.1886, 0.1073])
2024-12-05 15:36:20,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([0.7041, 0.1886, 0.1073]), new_distribution = tensor([0.7048, 0.1881, 0.1070])
2024-12-05 15:36:21,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([0.7048, 0.1881, 0.1070]), new_distribution = tensor([0.7056, 0.1877, 0.1067])
2024-12-05 15:36:21,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([0.7056, 0.1877, 0.1067]), new_distribution = tensor([0.7064, 0.1872, 0.1064])
2024-12-05 15:36:21,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([0.7064, 0.1872, 0.1064]), new_distribution = tensor([0.7071, 0.1867, 0.1061])
2024-12-05 15:36:21,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([0.7071, 0.1867, 0.1061]), new_distribution = tensor([0.7079, 0.1863, 0.1058])
2024-12-05 15:36:21,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([0.7079, 0.1863, 0.1058]), new_distribution = tensor([0.7087, 0.1858, 0.1055])
2024-12-05 15:36:21,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([0.7087, 0.1858, 0.1055]), new_distribution = tensor([0.7094, 0.1853, 0.1052])
2024-12-05 15:36:21,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([0.7094, 0.1853, 0.1052]), new_distribution = tensor([0.7102, 0.1849, 0.1049])
2024-12-05 15:36:21,418 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([0.7102, 0.1849, 0.1049]), new_distribution = tensor([0.7110, 0.1844, 0.1046])
2024-12-05 15:36:21,472 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([0.7110, 0.1844, 0.1046]), new_distribution = tensor([0.7117, 0.1840, 0.1043])
2024-12-05 15:36:21,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([0.7117, 0.1840, 0.1043]), new_distribution = tensor([0.7125, 0.1835, 0.1040])
2024-12-05 15:36:21,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([0.7125, 0.1835, 0.1040]), new_distribution = tensor([0.7132, 0.1830, 0.1037])
2024-12-05 15:36:21,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([0.7132, 0.1830, 0.1037]), new_distribution = tensor([0.7140, 0.1826, 0.1034])
2024-12-05 15:36:21,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([0.7140, 0.1826, 0.1034]), new_distribution = tensor([0.7148, 0.1821, 0.1031])
2024-12-05 15:36:21,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([0.7148, 0.1821, 0.1031]), new_distribution = tensor([0.7155, 0.1816, 0.1028])
2024-12-05 15:36:21,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([0.7155, 0.1816, 0.1028]), new_distribution = tensor([0.7163, 0.1812, 0.1026])
2024-12-05 15:36:21,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([0.7163, 0.1812, 0.1026]), new_distribution = tensor([0.7170, 0.1807, 0.1023])
2024-12-05 15:36:21,902 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([0.7170, 0.1807, 0.1023]), new_distribution = tensor([0.7178, 0.1803, 0.1020])
2024-12-05 15:36:21,956 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([0.7178, 0.1803, 0.1020]), new_distribution = tensor([0.7185, 0.1798, 0.1017])
2024-12-05 15:36:22,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([0.7185, 0.1798, 0.1017]), new_distribution = tensor([0.7193, 0.1793, 0.1014])
2024-12-05 15:36:22,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([0.7193, 0.1793, 0.1014]), new_distribution = tensor([0.7200, 0.1789, 0.1011])
2024-12-05 15:36:22,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([0.7200, 0.1789, 0.1011]), new_distribution = tensor([0.7208, 0.1784, 0.1008])
2024-12-05 15:36:22,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([0.7208, 0.1784, 0.1008]), new_distribution = tensor([0.7215, 0.1780, 0.1005])
2024-12-05 15:36:22,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([0.7215, 0.1780, 0.1005]), new_distribution = tensor([0.7222, 0.1775, 0.1002])
2024-12-05 15:36:22,278 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([0.7222, 0.1775, 0.1002]), new_distribution = tensor([0.7230, 0.1771, 0.0999])
2024-12-05 15:36:22,332 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([0.7230, 0.1771, 0.0999]), new_distribution = tensor([0.7237, 0.1766, 0.0997])
2024-12-05 15:36:22,386 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([0.7237, 0.1766, 0.0997]), new_distribution = tensor([0.7245, 0.1762, 0.0994])
2024-12-05 15:36:22,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([0.7245, 0.1762, 0.0994]), new_distribution = tensor([0.7252, 0.1757, 0.0991])
2024-12-05 15:36:22,494 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([0.7252, 0.1757, 0.0991]), new_distribution = tensor([0.7259, 0.1752, 0.0988])
2024-12-05 15:36:22,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([0.7259, 0.1752, 0.0988]), new_distribution = tensor([0.7267, 0.1748, 0.0985])
2024-12-05 15:36:22,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([0.7267, 0.1748, 0.0985]), new_distribution = tensor([0.7274, 0.1743, 0.0982])
2024-12-05 15:36:22,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([0.7274, 0.1743, 0.0982]), new_distribution = tensor([0.7282, 0.1739, 0.0980])
2024-12-05 15:36:22,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([0.7282, 0.1739, 0.0980]), new_distribution = tensor([0.7289, 0.1734, 0.0977])
2024-12-05 15:36:22,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([0.7289, 0.1734, 0.0977]), new_distribution = tensor([0.7296, 0.1730, 0.0974])
2024-12-05 15:36:22,818 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([0.7296, 0.1730, 0.0974]), new_distribution = tensor([0.7303, 0.1725, 0.0971])
2024-12-05 15:36:22,872 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([0.7303, 0.1725, 0.0971]), new_distribution = tensor([0.7311, 0.1721, 0.0968])
2024-12-05 15:36:22,926 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([0.7311, 0.1721, 0.0968]), new_distribution = tensor([0.7318, 0.1716, 0.0966])
2024-12-05 15:36:22,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([0.7318, 0.1716, 0.0966]), new_distribution = tensor([0.7325, 0.1712, 0.0963])
2024-12-05 15:36:23,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([0.7325, 0.1712, 0.0963]), new_distribution = tensor([0.7332, 0.1707, 0.0960])
2024-12-05 15:36:23,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([0.7332, 0.1707, 0.0960]), new_distribution = tensor([0.7340, 0.1703, 0.0957])
2024-12-05 15:36:23,144 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([0.7340, 0.1703, 0.0957]), new_distribution = tensor([0.7347, 0.1698, 0.0955])
2024-12-05 15:36:23,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([0.7347, 0.1698, 0.0955]), new_distribution = tensor([0.7354, 0.1694, 0.0952])
2024-12-05 15:36:23,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([0.7354, 0.1694, 0.0952]), new_distribution = tensor([0.7361, 0.1689, 0.0949])
2024-12-05 15:36:23,305 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([0.7361, 0.1689, 0.0949]), new_distribution = tensor([0.7369, 0.1685, 0.0947])
2024-12-05 15:36:23,359 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([0.7369, 0.1685, 0.0947]), new_distribution = tensor([0.7376, 0.1680, 0.0944])
2024-12-05 15:36:23,413 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([0.7376, 0.1680, 0.0944]), new_distribution = tensor([0.7383, 0.1676, 0.0941])
2024-12-05 15:36:23,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([0.7383, 0.1676, 0.0941]), new_distribution = tensor([0.7390, 0.1672, 0.0938])
2024-12-05 15:36:23,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([0.7390, 0.1672, 0.0938]), new_distribution = tensor([0.7397, 0.1667, 0.0936])
2024-12-05 15:36:23,574 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([0.7397, 0.1667, 0.0936]), new_distribution = tensor([0.7404, 0.1663, 0.0933])
2024-12-05 15:36:23,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([0.7404, 0.1663, 0.0933]), new_distribution = tensor([0.7411, 0.1658, 0.0930])
2024-12-05 15:36:23,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([0.7411, 0.1658, 0.0930]), new_distribution = tensor([0.7418, 0.1654, 0.0928])
2024-12-05 15:36:23,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([0.7418, 0.1654, 0.0928]), new_distribution = tensor([0.7426, 0.1649, 0.0925])
2024-12-05 15:36:23,789 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([0.7426, 0.1649, 0.0925]), new_distribution = tensor([0.7433, 0.1645, 0.0922])
2024-12-05 15:36:23,843 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([0.7433, 0.1645, 0.0922]), new_distribution = tensor([0.7440, 0.1641, 0.0920])
2024-12-05 15:36:23,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([0.7440, 0.1641, 0.0920]), new_distribution = tensor([0.7447, 0.1636, 0.0917])
2024-12-05 15:36:23,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([0.7447, 0.1636, 0.0917]), new_distribution = tensor([0.7454, 0.1632, 0.0914])
2024-12-05 15:36:24,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([0.7454, 0.1632, 0.0914]), new_distribution = tensor([0.7461, 0.1627, 0.0912])
2024-12-05 15:36:24,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([0.7461, 0.1627, 0.0912]), new_distribution = tensor([0.7468, 0.1623, 0.0909])
2024-12-05 15:36:24,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([0.7468, 0.1623, 0.0909]), new_distribution = tensor([0.7475, 0.1619, 0.0907])
2024-12-05 15:36:24,166 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([0.7475, 0.1619, 0.0907]), new_distribution = tensor([0.7482, 0.1614, 0.0904])
2024-12-05 15:36:24,219 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([0.7482, 0.1614, 0.0904]), new_distribution = tensor([0.7489, 0.1610, 0.0901])
2024-12-05 15:36:24,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([0.7489, 0.1610, 0.0901]), new_distribution = tensor([0.7496, 0.1606, 0.0899])
2024-12-05 15:36:24,327 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([0.7496, 0.1606, 0.0899]), new_distribution = tensor([0.7503, 0.1601, 0.0896])
2024-12-05 15:36:24,381 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([0.7503, 0.1601, 0.0896]), new_distribution = tensor([0.7509, 0.1597, 0.0894])
2024-12-05 15:36:24,435 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([0.7509, 0.1597, 0.0894]), new_distribution = tensor([0.7516, 0.1593, 0.0891])
2024-12-05 15:36:24,489 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([0.7516, 0.1593, 0.0891]), new_distribution = tensor([0.7523, 0.1588, 0.0889])
2024-12-05 15:36:24,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([0.7523, 0.1588, 0.0889]), new_distribution = tensor([0.7530, 0.1584, 0.0886])
2024-12-05 15:36:24,597 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([0.7530, 0.1584, 0.0886]), new_distribution = tensor([0.7537, 0.1580, 0.0883])
2024-12-05 15:36:24,651 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([0.7537, 0.1580, 0.0883]), new_distribution = tensor([0.7544, 0.1575, 0.0881])
2024-12-05 15:36:24,705 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([0.7544, 0.1575, 0.0881]), new_distribution = tensor([0.7551, 0.1571, 0.0878])
2024-12-05 15:36:24,758 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([0.7551, 0.1571, 0.0878]), new_distribution = tensor([0.7558, 0.1567, 0.0876])
2024-12-05 15:36:24,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([0.7558, 0.1567, 0.0876]), new_distribution = tensor([0.7564, 0.1562, 0.0873])
2024-12-05 15:36:24,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([0.7564, 0.1562, 0.0873]), new_distribution = tensor([0.7571, 0.1558, 0.0871])
2024-12-05 15:36:24,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([0.7571, 0.1558, 0.0871]), new_distribution = tensor([0.7578, 0.1554, 0.0868])
2024-12-05 15:36:24,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([0.7578, 0.1554, 0.0868]), new_distribution = tensor([0.7585, 0.1549, 0.0866])
2024-12-05 15:36:25,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([0.7585, 0.1549, 0.0866]), new_distribution = tensor([0.7592, 0.1545, 0.0863])
2024-12-05 15:36:25,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([0.7592, 0.1545, 0.0863]), new_distribution = tensor([0.7598, 0.1541, 0.0861])
2024-12-05 15:36:25,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([0.7598, 0.1541, 0.0861]), new_distribution = tensor([0.7605, 0.1537, 0.0858])
2024-12-05 15:36:25,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([0.7605, 0.1537, 0.0858]), new_distribution = tensor([0.7612, 0.1532, 0.0856])
2024-12-05 15:36:25,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([0.7612, 0.1532, 0.0856]), new_distribution = tensor([0.7618, 0.1528, 0.0853])
2024-12-05 15:36:25,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([0.7618, 0.1528, 0.0853]), new_distribution = tensor([0.7625, 0.1524, 0.0851])
2024-12-05 15:36:25,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([0.7625, 0.1524, 0.0851]), new_distribution = tensor([0.7632, 0.1520, 0.0848])
2024-12-05 15:36:25,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([0.7632, 0.1520, 0.0848]), new_distribution = tensor([0.7639, 0.1515, 0.0846])
2024-12-05 15:36:25,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([0.7639, 0.1515, 0.0846]), new_distribution = tensor([0.7645, 0.1511, 0.0844])
2024-12-05 15:36:25,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([0.7645, 0.1511, 0.0844]), new_distribution = tensor([0.7652, 0.1507, 0.0841])
2024-12-05 15:36:25,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([0.7652, 0.1507, 0.0841]), new_distribution = tensor([0.7658, 0.1503, 0.0839])
2024-12-05 15:36:25,621 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([0.7658, 0.1503, 0.0839]), new_distribution = tensor([0.7665, 0.1499, 0.0836])
2024-12-05 15:36:25,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([0.7665, 0.1499, 0.0836]), new_distribution = tensor([0.7672, 0.1494, 0.0834])
2024-12-05 15:36:25,729 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([0.7672, 0.1494, 0.0834]), new_distribution = tensor([0.7678, 0.1490, 0.0831])
2024-12-05 15:36:25,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([0.7678, 0.1490, 0.0831]), new_distribution = tensor([0.7685, 0.1486, 0.0829])
2024-12-05 15:36:25,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([0.7685, 0.1486, 0.0829]), new_distribution = tensor([0.7691, 0.1482, 0.0827])
2024-12-05 15:36:25,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([0.7691, 0.1482, 0.0827]), new_distribution = tensor([0.7698, 0.1478, 0.0824])
2024-12-05 15:36:25,943 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([0.7698, 0.1478, 0.0824]), new_distribution = tensor([0.7705, 0.1474, 0.0822])
2024-12-05 15:36:25,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([0.7705, 0.1474, 0.0822]), new_distribution = tensor([0.7711, 0.1469, 0.0820])
2024-12-05 15:36:26,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([0.7711, 0.1469, 0.0820]), new_distribution = tensor([0.7718, 0.1465, 0.0817])
2024-12-05 15:36:26,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([0.7718, 0.1465, 0.0817]), new_distribution = tensor([0.7724, 0.1461, 0.0815])
2024-12-05 15:36:26,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([0.7724, 0.1461, 0.0815]), new_distribution = tensor([0.7731, 0.1457, 0.0812])
2024-12-05 15:36:26,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([0.7731, 0.1457, 0.0812]), new_distribution = tensor([0.7737, 0.1453, 0.0810])
2024-12-05 15:36:26,266 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([0.7737, 0.1453, 0.0810]), new_distribution = tensor([0.7744, 0.1449, 0.0808])
2024-12-05 15:36:26,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([0.7744, 0.1449, 0.0808]), new_distribution = tensor([0.7750, 0.1445, 0.0805])
2024-12-05 15:36:26,374 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([0.7750, 0.1445, 0.0805]), new_distribution = tensor([0.7756, 0.1440, 0.0803])
2024-12-05 15:36:26,427 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([0.7756, 0.1440, 0.0803]), new_distribution = tensor([0.7763, 0.1436, 0.0801])
2024-12-05 15:36:26,481 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([0.7763, 0.1436, 0.0801]), new_distribution = tensor([0.7769, 0.1432, 0.0799])
2024-12-05 15:36:26,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([0.7769, 0.1432, 0.0799]), new_distribution = tensor([0.7776, 0.1428, 0.0796])
2024-12-05 15:36:26,589 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([0.7776, 0.1428, 0.0796]), new_distribution = tensor([0.7782, 0.1424, 0.0794])
2024-12-05 15:36:26,643 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([0.7782, 0.1424, 0.0794]), new_distribution = tensor([0.7788, 0.1420, 0.0792])
2024-12-05 15:36:26,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([0.7788, 0.1420, 0.0792]), new_distribution = tensor([0.7795, 0.1416, 0.0789])
2024-12-05 15:36:27,077 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.7000, 0.2000, 0.1000]), new_distribution = tensor([0.7008, 0.1995, 0.0997])
2024-12-05 15:36:27,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.7008, 0.1995, 0.0997]), new_distribution = tensor([0.7016, 0.1990, 0.0994])
2024-12-05 15:36:27,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.7016, 0.1990, 0.0994]), new_distribution = tensor([0.7023, 0.1985, 0.0991])
2024-12-05 15:36:27,398 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.7023, 0.1985, 0.0991]), new_distribution = tensor([0.7031, 0.1980, 0.0989])
2024-12-05 15:36:27,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.7031, 0.1980, 0.0989]), new_distribution = tensor([0.7039, 0.1975, 0.0986])
2024-12-05 15:36:27,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.7039, 0.1975, 0.0986]), new_distribution = tensor([0.7047, 0.1970, 0.0983])
2024-12-05 15:36:27,713 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.7047, 0.1970, 0.0983]), new_distribution = tensor([0.7055, 0.1965, 0.0980])
2024-12-05 15:36:27,818 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.7055, 0.1965, 0.0980]), new_distribution = tensor([0.7062, 0.1960, 0.0977])
2024-12-05 15:36:27,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.7062, 0.1960, 0.0977]), new_distribution = tensor([0.7070, 0.1956, 0.0974])
2024-12-05 15:36:28,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.7070, 0.1956, 0.0974]), new_distribution = tensor([0.7078, 0.1951, 0.0972])
2024-12-05 15:36:28,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.7078, 0.1951, 0.0972]), new_distribution = tensor([0.7086, 0.1946, 0.0969])
2024-12-05 15:36:28,237 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.7086, 0.1946, 0.0969]), new_distribution = tensor([0.7093, 0.1941, 0.0966])
2024-12-05 15:36:28,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.7093, 0.1941, 0.0966]), new_distribution = tensor([0.7101, 0.1936, 0.0963])
2024-12-05 15:36:28,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.7101, 0.1936, 0.0963]), new_distribution = tensor([0.7109, 0.1931, 0.0960])
2024-12-05 15:36:28,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.7109, 0.1931, 0.0960]), new_distribution = tensor([0.7116, 0.1926, 0.0958])
2024-12-05 15:36:28,644 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.7116, 0.1926, 0.0958]), new_distribution = tensor([0.7124, 0.1921, 0.0955])
2024-12-05 15:36:28,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.7124, 0.1921, 0.0955]), new_distribution = tensor([0.7132, 0.1916, 0.0952])
2024-12-05 15:36:28,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.7132, 0.1916, 0.0952]), new_distribution = tensor([0.7139, 0.1911, 0.0949])
2024-12-05 15:36:28,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.7139, 0.1911, 0.0949]), new_distribution = tensor([0.7147, 0.1907, 0.0947])
2024-12-05 15:36:28,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.7147, 0.1907, 0.0947]), new_distribution = tensor([0.7154, 0.1902, 0.0944])
2024-12-05 15:36:29,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.7154, 0.1902, 0.0944]), new_distribution = tensor([0.7162, 0.1897, 0.0941])
2024-12-05 15:36:29,121 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.7162, 0.1897, 0.0941]), new_distribution = tensor([0.7170, 0.1892, 0.0938])
2024-12-05 15:36:29,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.7170, 0.1892, 0.0938]), new_distribution = tensor([0.7177, 0.1887, 0.0936])
2024-12-05 15:36:29,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.7177, 0.1887, 0.0936]), new_distribution = tensor([0.7185, 0.1882, 0.0933])
2024-12-05 15:36:29,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.7185, 0.1882, 0.0933]), new_distribution = tensor([0.7192, 0.1877, 0.0930])
2024-12-05 15:36:29,367 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.7192, 0.1877, 0.0930]), new_distribution = tensor([0.7200, 0.1873, 0.0928])
2024-12-05 15:36:29,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.7200, 0.1873, 0.0928]), new_distribution = tensor([0.7207, 0.1868, 0.0925])
2024-12-05 15:36:29,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.7207, 0.1868, 0.0925]), new_distribution = tensor([0.7215, 0.1863, 0.0922])
2024-12-05 15:36:29,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.7215, 0.1863, 0.0922]), new_distribution = tensor([0.7222, 0.1858, 0.0920])
2024-12-05 15:36:29,584 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.7222, 0.1858, 0.0920]), new_distribution = tensor([0.7230, 0.1853, 0.0917])
2024-12-05 15:36:29,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.7230, 0.1853, 0.0917]), new_distribution = tensor([0.7237, 0.1848, 0.0914])
2024-12-05 15:36:29,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.7237, 0.1848, 0.0914]), new_distribution = tensor([0.7245, 0.1844, 0.0912])
2024-12-05 15:36:29,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.7245, 0.1844, 0.0912]), new_distribution = tensor([0.7252, 0.1839, 0.0909])
2024-12-05 15:36:29,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.7252, 0.1839, 0.0909]), new_distribution = tensor([0.7260, 0.1834, 0.0906])
2024-12-05 15:36:29,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.7260, 0.1834, 0.0906]), new_distribution = tensor([0.7267, 0.1829, 0.0904])
2024-12-05 15:36:29,907 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.7267, 0.1829, 0.0904]), new_distribution = tensor([0.7274, 0.1824, 0.0901])
2024-12-05 15:36:29,961 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.7274, 0.1824, 0.0901]), new_distribution = tensor([0.7282, 0.1820, 0.0899])
2024-12-05 15:36:30,015 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.7282, 0.1820, 0.0899]), new_distribution = tensor([0.7289, 0.1815, 0.0896])
2024-12-05 15:36:30,069 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.7289, 0.1815, 0.0896]), new_distribution = tensor([0.7296, 0.1810, 0.0893])
2024-12-05 15:36:30,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.7296, 0.1810, 0.0893]), new_distribution = tensor([0.7304, 0.1805, 0.0891])
2024-12-05 15:36:30,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.7304, 0.1805, 0.0891]), new_distribution = tensor([0.7311, 0.1801, 0.0888])
2024-12-05 15:36:30,230 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.7311, 0.1801, 0.0888]), new_distribution = tensor([0.7318, 0.1796, 0.0886])
2024-12-05 15:36:30,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.7318, 0.1796, 0.0886]), new_distribution = tensor([0.7326, 0.1791, 0.0883])
2024-12-05 15:36:30,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.7326, 0.1791, 0.0883]), new_distribution = tensor([0.7333, 0.1786, 0.0881])
2024-12-05 15:36:30,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.7333, 0.1786, 0.0881]), new_distribution = tensor([0.7340, 0.1782, 0.0878])
2024-12-05 15:36:30,446 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.7340, 0.1782, 0.0878]), new_distribution = tensor([0.7348, 0.1777, 0.0875])
2024-12-05 15:36:30,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.7348, 0.1777, 0.0875]), new_distribution = tensor([0.7355, 0.1772, 0.0873])
2024-12-05 15:36:30,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.7355, 0.1772, 0.0873]), new_distribution = tensor([0.7362, 0.1767, 0.0870])
2024-12-05 15:36:30,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.7362, 0.1767, 0.0870]), new_distribution = tensor([0.7369, 0.1763, 0.0868])
2024-12-05 15:36:30,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.7369, 0.1763, 0.0868]), new_distribution = tensor([0.7377, 0.1758, 0.0865])
2024-12-05 15:36:30,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.7377, 0.1758, 0.0865]), new_distribution = tensor([0.7384, 0.1753, 0.0863])
2024-12-05 15:36:30,770 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.7384, 0.1753, 0.0863]), new_distribution = tensor([0.7391, 0.1749, 0.0860])
2024-12-05 15:36:30,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.7391, 0.1749, 0.0860]), new_distribution = tensor([0.7398, 0.1744, 0.0858])
2024-12-05 15:36:30,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.7398, 0.1744, 0.0858]), new_distribution = tensor([0.7405, 0.1739, 0.0855])
2024-12-05 15:36:30,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.7405, 0.1739, 0.0855]), new_distribution = tensor([0.7413, 0.1735, 0.0853])
2024-12-05 15:36:30,985 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.7413, 0.1735, 0.0853]), new_distribution = tensor([0.7420, 0.1730, 0.0850])
2024-12-05 15:36:31,039 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.7420, 0.1730, 0.0850]), new_distribution = tensor([0.7427, 0.1725, 0.0848])
2024-12-05 15:36:31,093 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.7427, 0.1725, 0.0848]), new_distribution = tensor([0.7434, 0.1721, 0.0845])
2024-12-05 15:36:31,147 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.7434, 0.1721, 0.0845]), new_distribution = tensor([0.7441, 0.1716, 0.0843])
2024-12-05 15:36:31,201 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.7441, 0.1716, 0.0843]), new_distribution = tensor([0.7448, 0.1711, 0.0841])
2024-12-05 15:36:31,255 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.7448, 0.1711, 0.0841]), new_distribution = tensor([0.7455, 0.1707, 0.0838])
2024-12-05 15:36:31,309 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.7455, 0.1707, 0.0838]), new_distribution = tensor([0.7462, 0.1702, 0.0836])
2024-12-05 15:36:31,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.7462, 0.1702, 0.0836]), new_distribution = tensor([0.7469, 0.1697, 0.0833])
2024-12-05 15:36:31,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.7469, 0.1697, 0.0833]), new_distribution = tensor([0.7476, 0.1693, 0.0831])
2024-12-05 15:36:31,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.7476, 0.1693, 0.0831]), new_distribution = tensor([0.7483, 0.1688, 0.0828])
2024-12-05 15:36:31,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.7483, 0.1688, 0.0828]), new_distribution = tensor([0.7490, 0.1684, 0.0826])
2024-12-05 15:36:31,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.7490, 0.1684, 0.0826]), new_distribution = tensor([0.7497, 0.1679, 0.0824])
2024-12-05 15:36:31,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.7497, 0.1679, 0.0824]), new_distribution = tensor([0.7504, 0.1674, 0.0821])
2024-12-05 15:36:31,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.7504, 0.1674, 0.0821]), new_distribution = tensor([0.7511, 0.1670, 0.0819])
2024-12-05 15:36:31,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.7511, 0.1670, 0.0819]), new_distribution = tensor([0.7518, 0.1665, 0.0817])
2024-12-05 15:36:31,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.7518, 0.1665, 0.0817]), new_distribution = tensor([0.7525, 0.1661, 0.0814])
2024-12-05 15:36:31,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.7525, 0.1661, 0.0814]), new_distribution = tensor([0.7532, 0.1656, 0.0812])
2024-12-05 15:36:31,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.7532, 0.1656, 0.0812]), new_distribution = tensor([0.7539, 0.1652, 0.0809])
2024-12-05 15:36:31,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.7539, 0.1652, 0.0809]), new_distribution = tensor([0.7546, 0.1647, 0.0807])
2024-12-05 15:36:32,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.7546, 0.1647, 0.0807]), new_distribution = tensor([0.7553, 0.1642, 0.0805])
2024-12-05 15:36:32,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.7553, 0.1642, 0.0805]), new_distribution = tensor([0.7560, 0.1638, 0.0802])
2024-12-05 15:36:32,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.7560, 0.1638, 0.0802]), new_distribution = tensor([0.7567, 0.1633, 0.0800])
2024-12-05 15:36:32,174 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.7567, 0.1633, 0.0800]), new_distribution = tensor([0.7573, 0.1629, 0.0798])
2024-12-05 15:36:32,228 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.7573, 0.1629, 0.0798]), new_distribution = tensor([0.7580, 0.1624, 0.0795])
2024-12-05 15:36:32,282 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.7580, 0.1624, 0.0795]), new_distribution = tensor([0.7587, 0.1620, 0.0793])
2024-12-05 15:36:32,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.7587, 0.1620, 0.0793]), new_distribution = tensor([0.7594, 0.1615, 0.0791])
2024-12-05 15:36:32,390 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.7594, 0.1615, 0.0791]), new_distribution = tensor([0.7601, 0.1611, 0.0788])
2024-12-05 15:36:32,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.7601, 0.1611, 0.0788]), new_distribution = tensor([0.7608, 0.1606, 0.0786])
2024-12-05 15:36:32,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.7608, 0.1606, 0.0786]), new_distribution = tensor([0.7614, 0.1602, 0.0784])
2024-12-05 15:36:32,552 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.7614, 0.1602, 0.0784]), new_distribution = tensor([0.7621, 0.1597, 0.0782])
2024-12-05 15:36:32,606 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.7621, 0.1597, 0.0782]), new_distribution = tensor([0.7628, 0.1593, 0.0779])
2024-12-05 15:36:32,660 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.7628, 0.1593, 0.0779]), new_distribution = tensor([0.7635, 0.1588, 0.0777])
2024-12-05 15:36:32,714 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.7635, 0.1588, 0.0777]), new_distribution = tensor([0.7641, 0.1584, 0.0775])
2024-12-05 15:36:32,768 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.7641, 0.1584, 0.0775]), new_distribution = tensor([0.7648, 0.1579, 0.0773])
2024-12-05 15:36:32,822 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.7648, 0.1579, 0.0773]), new_distribution = tensor([0.7655, 0.1575, 0.0770])
2024-12-05 15:36:32,876 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.7655, 0.1575, 0.0770]), new_distribution = tensor([0.7661, 0.1571, 0.0768])
2024-12-05 15:36:32,930 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.7661, 0.1571, 0.0768]), new_distribution = tensor([0.7668, 0.1566, 0.0766])
2024-12-05 15:36:32,984 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.7668, 0.1566, 0.0766]), new_distribution = tensor([0.7675, 0.1562, 0.0764])
2024-12-05 15:36:33,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.7675, 0.1562, 0.0764]), new_distribution = tensor([0.7681, 0.1557, 0.0761])
2024-12-05 15:36:33,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.7681, 0.1557, 0.0761]), new_distribution = tensor([0.7688, 0.1553, 0.0759])
2024-12-05 15:36:33,146 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.7688, 0.1553, 0.0759]), new_distribution = tensor([0.7695, 0.1549, 0.0757])
2024-12-05 15:36:33,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.7695, 0.1549, 0.0757]), new_distribution = tensor([0.7701, 0.1544, 0.0755])
2024-12-05 15:36:33,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.7701, 0.1544, 0.0755]), new_distribution = tensor([0.7708, 0.1540, 0.0753])
2024-12-05 15:36:33,307 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.7708, 0.1540, 0.0753]), new_distribution = tensor([0.7714, 0.1535, 0.0750])
2024-12-05 15:36:33,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.7714, 0.1535, 0.0750]), new_distribution = tensor([0.7721, 0.1531, 0.0748])
2024-12-05 15:36:33,421 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([0.7721, 0.1531, 0.0748]), new_distribution = tensor([0.7727, 0.1527, 0.0746])
2024-12-05 15:36:33,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([0.7727, 0.1527, 0.0746]), new_distribution = tensor([0.7734, 0.1522, 0.0744])
2024-12-05 15:36:33,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([0.7734, 0.1522, 0.0744]), new_distribution = tensor([0.7740, 0.1518, 0.0742])
2024-12-05 15:36:33,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([0.7740, 0.1518, 0.0742]), new_distribution = tensor([0.7747, 0.1514, 0.0739])
2024-12-05 15:36:33,636 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([0.7747, 0.1514, 0.0739]), new_distribution = tensor([0.7753, 0.1509, 0.0737])
2024-12-05 15:36:33,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([0.7753, 0.1509, 0.0737]), new_distribution = tensor([0.7760, 0.1505, 0.0735])
2024-12-05 15:36:33,743 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([0.7760, 0.1505, 0.0735]), new_distribution = tensor([0.7766, 0.1501, 0.0733])
2024-12-05 15:36:33,797 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([0.7766, 0.1501, 0.0733]), new_distribution = tensor([0.7773, 0.1496, 0.0731])
2024-12-05 15:36:33,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([0.7773, 0.1496, 0.0731]), new_distribution = tensor([0.7779, 0.1492, 0.0729])
2024-12-05 15:36:33,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([0.7779, 0.1492, 0.0729]), new_distribution = tensor([0.7786, 0.1488, 0.0727])
2024-12-05 15:36:33,959 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([0.7786, 0.1488, 0.0727]), new_distribution = tensor([0.7792, 0.1483, 0.0725])
2024-12-05 15:36:34,013 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([0.7792, 0.1483, 0.0725]), new_distribution = tensor([0.7798, 0.1479, 0.0722])
2024-12-05 15:36:34,067 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([0.7798, 0.1479, 0.0722]), new_distribution = tensor([0.7805, 0.1475, 0.0720])
2024-12-05 15:36:34,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([0.7805, 0.1475, 0.0720]), new_distribution = tensor([0.7811, 0.1471, 0.0718])
2024-12-05 15:36:34,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([0.7811, 0.1471, 0.0718]), new_distribution = tensor([0.7818, 0.1466, 0.0716])
2024-12-05 15:36:34,232 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([0.7818, 0.1466, 0.0716]), new_distribution = tensor([0.7824, 0.1462, 0.0714])
2024-12-05 15:36:34,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([0.7824, 0.1462, 0.0714]), new_distribution = tensor([0.7830, 0.1458, 0.0712])
2024-12-05 15:36:34,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([0.7830, 0.1458, 0.0712]), new_distribution = tensor([0.7837, 0.1454, 0.0710])
2024-12-05 15:36:34,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([0.7837, 0.1454, 0.0710]), new_distribution = tensor([0.7843, 0.1449, 0.0708])
2024-12-05 15:36:34,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([0.7843, 0.1449, 0.0708]), new_distribution = tensor([0.7849, 0.1445, 0.0706])
2024-12-05 15:36:34,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([0.7849, 0.1445, 0.0706]), new_distribution = tensor([0.7855, 0.1441, 0.0704])
2024-12-05 15:36:34,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([0.7855, 0.1441, 0.0704]), new_distribution = tensor([0.7862, 0.1437, 0.0702])
2024-12-05 15:36:34,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([0.7862, 0.1437, 0.0702]), new_distribution = tensor([0.7868, 0.1433, 0.0700])
2024-12-05 15:36:34,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([0.7868, 0.1433, 0.0700]), new_distribution = tensor([0.7874, 0.1428, 0.0698])
2024-12-05 15:36:34,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([0.7874, 0.1428, 0.0698]), new_distribution = tensor([0.7880, 0.1424, 0.0695])
2024-12-05 15:36:34,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([0.7880, 0.1424, 0.0695]), new_distribution = tensor([0.7887, 0.1420, 0.0693])
2024-12-05 15:36:34,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([0.7887, 0.1420, 0.0693]), new_distribution = tensor([0.7893, 0.1416, 0.0691])
2024-12-05 15:36:34,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([0.7893, 0.1416, 0.0691]), new_distribution = tensor([0.7899, 0.1412, 0.0689])
2024-12-05 15:36:34,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([0.7899, 0.1412, 0.0689]), new_distribution = tensor([0.7905, 0.1408, 0.0687])
2024-12-05 15:36:34,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([0.7905, 0.1408, 0.0687]), new_distribution = tensor([0.7911, 0.1403, 0.0685])
2024-12-05 15:36:35,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([0.7911, 0.1403, 0.0685]), new_distribution = tensor([0.7917, 0.1399, 0.0683])
2024-12-05 15:36:35,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([0.7917, 0.1399, 0.0683]), new_distribution = tensor([0.7923, 0.1395, 0.0681])
2024-12-05 15:36:35,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([0.7923, 0.1395, 0.0681]), new_distribution = tensor([0.7930, 0.1391, 0.0679])
2024-12-05 15:36:35,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([0.7930, 0.1391, 0.0679]), new_distribution = tensor([0.7936, 0.1387, 0.0677])
2024-12-05 15:36:35,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([0.7936, 0.1387, 0.0677]), new_distribution = tensor([0.7942, 0.1383, 0.0675])
2024-12-05 15:36:35,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([0.7942, 0.1383, 0.0675]), new_distribution = tensor([0.7948, 0.1379, 0.0673])
2024-12-05 15:36:35,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([0.7948, 0.1379, 0.0673]), new_distribution = tensor([0.7954, 0.1375, 0.0671])
2024-12-05 15:36:35,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([0.7954, 0.1375, 0.0671]), new_distribution = tensor([0.7960, 0.1371, 0.0670])
2024-12-05 15:36:35,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([0.7960, 0.1371, 0.0670]), new_distribution = tensor([0.7966, 0.1366, 0.0668])
2024-12-05 15:36:35,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([0.7966, 0.1366, 0.0668]), new_distribution = tensor([0.7972, 0.1362, 0.0666])
2024-12-05 15:36:35,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([0.7972, 0.1362, 0.0666]), new_distribution = tensor([0.7978, 0.1358, 0.0664])
2024-12-05 15:36:35,636 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([0.7978, 0.1358, 0.0664]), new_distribution = tensor([0.7984, 0.1354, 0.0662])
2024-12-05 15:36:35,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([0.7984, 0.1354, 0.0662]), new_distribution = tensor([0.7990, 0.1350, 0.0660])
2024-12-05 15:36:35,744 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([0.7990, 0.1350, 0.0660]), new_distribution = tensor([0.7996, 0.1346, 0.0658])
2024-12-05 15:36:35,798 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([0.7996, 0.1346, 0.0658]), new_distribution = tensor([0.8002, 0.1342, 0.0656])
2024-12-05 15:36:35,852 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([0.8002, 0.1342, 0.0656]), new_distribution = tensor([0.8008, 0.1338, 0.0654])
2024-12-05 15:36:35,906 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([0.8008, 0.1338, 0.0654]), new_distribution = tensor([0.8014, 0.1334, 0.0652])
2024-12-05 15:36:35,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([0.8014, 0.1334, 0.0652]), new_distribution = tensor([0.8020, 0.1330, 0.0650])
2024-12-05 15:36:36,013 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([0.8020, 0.1330, 0.0650]), new_distribution = tensor([0.8026, 0.1326, 0.0648])
2024-12-05 15:36:36,067 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([0.8026, 0.1326, 0.0648]), new_distribution = tensor([0.8031, 0.1322, 0.0646])
2024-12-05 15:36:36,121 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([0.8031, 0.1322, 0.0646]), new_distribution = tensor([0.8037, 0.1318, 0.0644])
2024-12-05 15:36:36,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([0.8037, 0.1318, 0.0644]), new_distribution = tensor([0.8043, 0.1314, 0.0643])
2024-12-05 15:36:36,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([0.8043, 0.1314, 0.0643]), new_distribution = tensor([0.8049, 0.1310, 0.0641])
2024-12-05 15:36:36,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([0.8049, 0.1310, 0.0641]), new_distribution = tensor([0.8055, 0.1306, 0.0639])
2024-12-05 15:36:36,337 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([0.8055, 0.1306, 0.0639]), new_distribution = tensor([0.8061, 0.1302, 0.0637])
2024-12-05 15:36:36,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([0.8061, 0.1302, 0.0637]), new_distribution = tensor([0.8066, 0.1298, 0.0635])
2024-12-05 15:36:36,445 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([0.8066, 0.1298, 0.0635]), new_distribution = tensor([0.8072, 0.1295, 0.0633])
2024-12-05 15:36:36,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([0.8072, 0.1295, 0.0633]), new_distribution = tensor([0.8078, 0.1291, 0.0631])
2024-12-05 15:36:36,553 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([0.8078, 0.1291, 0.0631]), new_distribution = tensor([0.8084, 0.1287, 0.0630])
2024-12-05 15:36:36,607 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([0.8084, 0.1287, 0.0630]), new_distribution = tensor([0.8089, 0.1283, 0.0628])
2024-12-05 15:36:36,660 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([0.8089, 0.1283, 0.0628]), new_distribution = tensor([0.8095, 0.1279, 0.0626])
2024-12-05 15:36:36,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([0.8095, 0.1279, 0.0626]), new_distribution = tensor([0.8101, 0.1275, 0.0624])
2024-12-05 15:36:36,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([0.8101, 0.1275, 0.0624]), new_distribution = tensor([0.8107, 0.1271, 0.0622])
2024-12-05 15:36:36,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([0.8107, 0.1271, 0.0622]), new_distribution = tensor([0.8112, 0.1267, 0.0620])
2024-12-05 15:36:36,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([0.8112, 0.1267, 0.0620]), new_distribution = tensor([0.8118, 0.1263, 0.0619])
2024-12-05 15:36:36,930 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([0.8118, 0.1263, 0.0619]), new_distribution = tensor([0.8124, 0.1260, 0.0617])
2024-12-05 15:36:36,984 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([0.8124, 0.1260, 0.0617]), new_distribution = tensor([0.8129, 0.1256, 0.0615])
2024-12-05 15:36:37,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([0.8129, 0.1256, 0.0615]), new_distribution = tensor([0.8135, 0.1252, 0.0613])
2024-12-05 15:36:37,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([0.8135, 0.1252, 0.0613]), new_distribution = tensor([0.8141, 0.1248, 0.0611])
2024-12-05 15:36:37,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([0.8141, 0.1248, 0.0611]), new_distribution = tensor([0.8146, 0.1244, 0.0610])
2024-12-05 15:36:37,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([0.8146, 0.1244, 0.0610]), new_distribution = tensor([0.8152, 0.1240, 0.0608])
2024-12-05 15:36:37,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([0.8152, 0.1240, 0.0608]), new_distribution = tensor([0.8157, 0.1237, 0.0606])
2024-12-05 15:36:37,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([0.8157, 0.1237, 0.0606]), new_distribution = tensor([0.8163, 0.1233, 0.0604])
2024-12-05 15:36:37,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([0.8163, 0.1233, 0.0604]), new_distribution = tensor([0.8169, 0.1229, 0.0602])
2024-12-05 15:36:37,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([0.8169, 0.1229, 0.0602]), new_distribution = tensor([0.8174, 0.1225, 0.0601])
2024-12-05 15:36:37,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([0.8174, 0.1225, 0.0601]), new_distribution = tensor([0.8180, 0.1222, 0.0599])
2024-12-05 15:36:37,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([0.8180, 0.1222, 0.0599]), new_distribution = tensor([0.8185, 0.1218, 0.0597])
2024-12-05 15:36:37,581 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([0.8185, 0.1218, 0.0597]), new_distribution = tensor([0.8191, 0.1214, 0.0595])
2024-12-05 15:36:37,635 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([0.8191, 0.1214, 0.0595]), new_distribution = tensor([0.8196, 0.1210, 0.0594])
2024-12-05 15:36:37,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([0.8196, 0.1210, 0.0594]), new_distribution = tensor([0.8202, 0.1206, 0.0592])
2024-12-05 15:36:37,742 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([0.8202, 0.1206, 0.0592]), new_distribution = tensor([0.8207, 0.1203, 0.0590])
2024-12-05 15:36:37,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([0.8207, 0.1203, 0.0590]), new_distribution = tensor([0.8213, 0.1199, 0.0588])
2024-12-05 15:36:37,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([0.8213, 0.1199, 0.0588]), new_distribution = tensor([0.8218, 0.1195, 0.0587])
2024-12-05 15:36:37,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([0.8218, 0.1195, 0.0587]), new_distribution = tensor([0.8223, 0.1192, 0.0585])
2024-12-05 15:36:37,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([0.8223, 0.1192, 0.0585]), new_distribution = tensor([0.8229, 0.1188, 0.0583])
2024-12-05 15:36:38,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([0.8229, 0.1188, 0.0583]), new_distribution = tensor([0.8234, 0.1184, 0.0582])
2024-12-05 15:36:38,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([0.8234, 0.1184, 0.0582]), new_distribution = tensor([0.8240, 0.1181, 0.0580])
2024-12-05 15:36:38,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([0.8240, 0.1181, 0.0580]), new_distribution = tensor([0.8245, 0.1177, 0.0578])
2024-12-05 15:36:38,174 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([0.8245, 0.1177, 0.0578]), new_distribution = tensor([0.8250, 0.1173, 0.0576])
2024-12-05 15:36:38,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([0.8250, 0.1173, 0.0576]), new_distribution = tensor([0.8256, 0.1170, 0.0575])
2024-12-05 15:36:38,281 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([0.8256, 0.1170, 0.0575]), new_distribution = tensor([0.8261, 0.1166, 0.0573])
2024-12-05 15:36:38,335 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([0.8261, 0.1166, 0.0573]), new_distribution = tensor([0.8266, 0.1162, 0.0571])
2024-12-05 15:36:38,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([0.8266, 0.1162, 0.0571]), new_distribution = tensor([0.8272, 0.1159, 0.0570])
2024-12-05 15:36:38,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([0.8272, 0.1159, 0.0570]), new_distribution = tensor([0.8277, 0.1155, 0.0568])
2024-12-05 15:36:38,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([0.8277, 0.1155, 0.0568]), new_distribution = tensor([0.8282, 0.1151, 0.0566])
2024-12-05 15:36:38,551 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([0.8282, 0.1151, 0.0566]), new_distribution = tensor([0.8287, 0.1148, 0.0565])
2024-12-05 15:36:38,604 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([0.8287, 0.1148, 0.0565]), new_distribution = tensor([0.8293, 0.1144, 0.0563])
2024-12-05 15:36:38,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([0.8293, 0.1144, 0.0563]), new_distribution = tensor([0.8298, 0.1141, 0.0561])
2024-12-05 15:36:38,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([0.8298, 0.1141, 0.0561]), new_distribution = tensor([0.8303, 0.1137, 0.0560])
2024-12-05 15:36:38,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([0.8303, 0.1137, 0.0560]), new_distribution = tensor([0.8308, 0.1133, 0.0558])
2024-12-05 15:36:38,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([0.8308, 0.1133, 0.0558]), new_distribution = tensor([0.8314, 0.1130, 0.0556])
2024-12-05 15:36:38,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([0.8314, 0.1130, 0.0556]), new_distribution = tensor([0.8319, 0.1126, 0.0555])
2024-12-05 15:36:38,928 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([0.8319, 0.1126, 0.0555]), new_distribution = tensor([0.8324, 0.1123, 0.0553])
2024-12-05 15:36:38,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([0.8324, 0.1123, 0.0553]), new_distribution = tensor([0.8329, 0.1119, 0.0552])
2024-12-05 15:36:39,036 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([0.8329, 0.1119, 0.0552]), new_distribution = tensor([0.8334, 0.1116, 0.0550])
2024-12-05 15:36:39,090 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([0.8334, 0.1116, 0.0550]), new_distribution = tensor([0.8339, 0.1112, 0.0548])
2024-12-05 15:36:39,144 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([0.8339, 0.1112, 0.0548]), new_distribution = tensor([0.8345, 0.1109, 0.0547])
2024-12-05 15:36:39,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([0.8345, 0.1109, 0.0547]), new_distribution = tensor([0.8350, 0.1105, 0.0545])
2024-12-05 15:36:39,252 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([0.8350, 0.1105, 0.0545]), new_distribution = tensor([0.8355, 0.1102, 0.0544])
2024-12-05 15:36:39,306 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([0.8355, 0.1102, 0.0544]), new_distribution = tensor([0.8360, 0.1098, 0.0542])
2024-12-05 15:36:39,360 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([0.8360, 0.1098, 0.0542]), new_distribution = tensor([0.8365, 0.1095, 0.0540])
2024-12-05 15:36:39,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([0.8365, 0.1095, 0.0540]), new_distribution = tensor([0.8370, 0.1091, 0.0539])
2024-12-05 15:36:39,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([0.8370, 0.1091, 0.0539]), new_distribution = tensor([0.8375, 0.1088, 0.0537])
2024-12-05 15:36:39,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([0.8375, 0.1088, 0.0537]), new_distribution = tensor([0.8380, 0.1084, 0.0536])
2024-12-05 15:36:39,575 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([0.8380, 0.1084, 0.0536]), new_distribution = tensor([0.8385, 0.1081, 0.0534])
2024-12-05 15:36:39,629 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([0.8385, 0.1081, 0.0534]), new_distribution = tensor([0.8390, 0.1077, 0.0532])
2024-12-05 15:36:39,683 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([0.8390, 0.1077, 0.0532]), new_distribution = tensor([0.8395, 0.1074, 0.0531])
2024-12-05 15:36:39,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([0.8395, 0.1074, 0.0531]), new_distribution = tensor([0.8400, 0.1071, 0.0529])
2024-12-05 15:36:39,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([0.8400, 0.1071, 0.0529]), new_distribution = tensor([0.8405, 0.1067, 0.0528])
2024-12-05 15:36:39,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([0.8405, 0.1067, 0.0528]), new_distribution = tensor([0.8410, 0.1064, 0.0526])
2024-12-05 15:36:39,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([0.8410, 0.1064, 0.0526]), new_distribution = tensor([0.8415, 0.1060, 0.0525])
2024-12-05 15:36:39,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([0.8415, 0.1060, 0.0525]), new_distribution = tensor([0.8420, 0.1057, 0.0523])
2024-12-05 15:36:40,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([0.8420, 0.1057, 0.0523]), new_distribution = tensor([0.8425, 0.1054, 0.0522])
2024-12-05 15:36:40,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([0.8425, 0.1054, 0.0522]), new_distribution = tensor([0.8430, 0.1050, 0.0520])
2024-12-05 15:36:40,114 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([0.8430, 0.1050, 0.0520]), new_distribution = tensor([0.8435, 0.1047, 0.0519])
2024-12-05 15:36:40,168 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([0.8435, 0.1047, 0.0519]), new_distribution = tensor([0.8440, 0.1043, 0.0517])
2024-12-05 15:36:40,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([0.8440, 0.1043, 0.0517]), new_distribution = tensor([0.8444, 0.1040, 0.0516])
2024-12-05 15:36:40,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([0.8444, 0.1040, 0.0516]), new_distribution = tensor([0.8449, 0.1037, 0.0514])
2024-12-05 15:36:40,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([0.8449, 0.1037, 0.0514]), new_distribution = tensor([0.8454, 0.1033, 0.0512])
2024-12-05 15:36:40,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([0.8454, 0.1033, 0.0512]), new_distribution = tensor([0.8459, 0.1030, 0.0511])
2024-12-05 15:36:40,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([0.8459, 0.1030, 0.0511]), new_distribution = tensor([0.8464, 0.1027, 0.0509])
2024-12-05 15:36:40,492 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([0.8464, 0.1027, 0.0509]), new_distribution = tensor([0.8469, 0.1023, 0.0508])
2024-12-05 15:36:40,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([0.8469, 0.1023, 0.0508]), new_distribution = tensor([0.8473, 0.1020, 0.0506])
2024-12-05 15:36:40,599 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([0.8473, 0.1020, 0.0506]), new_distribution = tensor([0.8478, 0.1017, 0.0505])
2024-12-05 15:36:40,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([0.8478, 0.1017, 0.0505]), new_distribution = tensor([0.8483, 0.1014, 0.0503])
2024-12-05 15:36:40,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([0.8483, 0.1014, 0.0503]), new_distribution = tensor([0.8488, 0.1010, 0.0502])
2024-12-05 15:36:40,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([0.8488, 0.1010, 0.0502]), new_distribution = tensor([0.8492, 0.1007, 0.0501])
2024-12-05 15:36:40,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([0.8492, 0.1007, 0.0501]), new_distribution = tensor([0.8497, 0.1004, 0.0499])
2024-12-05 15:36:40,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([0.8497, 0.1004, 0.0499]), new_distribution = tensor([0.8502, 0.1001, 0.0498])
2024-12-05 15:36:40,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([0.8502, 0.1001, 0.0498]), new_distribution = tensor([0.8507, 0.0997, 0.0496])
2024-12-05 15:36:40,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([0.8507, 0.0997, 0.0496]), new_distribution = tensor([0.8511, 0.0994, 0.0495])
2024-12-05 15:36:41,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([0.8511, 0.0994, 0.0495]), new_distribution = tensor([0.8516, 0.0991, 0.0493])
2024-12-05 15:36:41,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([0.8516, 0.0991, 0.0493]), new_distribution = tensor([0.8521, 0.0988, 0.0492])
2024-12-05 15:36:41,138 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([0.8521, 0.0988, 0.0492]), new_distribution = tensor([0.8525, 0.0984, 0.0490])
2024-12-05 15:36:41,192 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([0.8525, 0.0984, 0.0490]), new_distribution = tensor([0.8530, 0.0981, 0.0489])
2024-12-05 15:36:41,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([0.8530, 0.0981, 0.0489]), new_distribution = tensor([0.8535, 0.0978, 0.0487])
2024-12-05 15:36:41,300 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([0.8535, 0.0978, 0.0487]), new_distribution = tensor([0.8539, 0.0975, 0.0486])
2024-12-05 15:36:41,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([0.8539, 0.0975, 0.0486]), new_distribution = tensor([0.8544, 0.0972, 0.0485])
2024-12-05 15:36:41,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([0.8544, 0.0972, 0.0485]), new_distribution = tensor([0.8548, 0.0968, 0.0483])
2024-12-05 15:36:41,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([0.8548, 0.0968, 0.0483]), new_distribution = tensor([0.8553, 0.0965, 0.0482])
2024-12-05 15:36:41,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([0.8553, 0.0965, 0.0482]), new_distribution = tensor([0.8558, 0.0962, 0.0480])
2024-12-05 15:36:41,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([0.8558, 0.0962, 0.0480]), new_distribution = tensor([0.8562, 0.0959, 0.0479])
2024-12-05 15:36:41,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([0.8562, 0.0959, 0.0479]), new_distribution = tensor([0.8567, 0.0956, 0.0477])
2024-12-05 15:36:41,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([0.8567, 0.0956, 0.0477]), new_distribution = tensor([0.8571, 0.0953, 0.0476])
2024-12-05 15:36:41,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([0.8571, 0.0953, 0.0476]), new_distribution = tensor([0.8576, 0.0950, 0.0475])
2024-12-05 15:36:41,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([0.8576, 0.0950, 0.0475]), new_distribution = tensor([0.8580, 0.0946, 0.0473])
2024-12-05 15:36:41,838 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([0.8580, 0.0946, 0.0473]), new_distribution = tensor([0.8585, 0.0943, 0.0472])
2024-12-05 15:36:41,892 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([0.8585, 0.0943, 0.0472]), new_distribution = tensor([0.8589, 0.0940, 0.0470])
2024-12-05 15:36:41,946 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([0.8589, 0.0940, 0.0470]), new_distribution = tensor([0.8594, 0.0937, 0.0469])
2024-12-05 15:36:42,000 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([0.8594, 0.0937, 0.0469]), new_distribution = tensor([0.8598, 0.0934, 0.0468])
2024-12-05 15:36:42,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([0.8598, 0.0934, 0.0468]), new_distribution = tensor([0.8603, 0.0931, 0.0466])
2024-12-05 15:36:42,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([0.8603, 0.0931, 0.0466]), new_distribution = tensor([0.8607, 0.0928, 0.0465])
2024-12-05 15:36:42,162 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([0.8607, 0.0928, 0.0465]), new_distribution = tensor([0.8611, 0.0925, 0.0464])
2024-12-05 15:36:42,216 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([0.8611, 0.0925, 0.0464]), new_distribution = tensor([0.8616, 0.0922, 0.0462])
2024-12-05 15:36:42,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([0.8616, 0.0922, 0.0462]), new_distribution = tensor([0.8620, 0.0919, 0.0461])
2024-12-05 15:36:42,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([0.8620, 0.0919, 0.0461]), new_distribution = tensor([0.8625, 0.0916, 0.0460])
2024-12-05 15:36:42,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([0.8625, 0.0916, 0.0460]), new_distribution = tensor([0.8629, 0.0913, 0.0458])
2024-12-05 15:36:42,431 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([0.8629, 0.0913, 0.0458]), new_distribution = tensor([0.8633, 0.0910, 0.0457])
2024-12-05 15:36:42,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([0.8633, 0.0910, 0.0457]), new_distribution = tensor([0.8638, 0.0907, 0.0455])
2024-12-05 15:36:42,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([0.8638, 0.0907, 0.0455]), new_distribution = tensor([0.8642, 0.0904, 0.0454])
2024-12-05 15:36:42,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([0.8642, 0.0904, 0.0454]), new_distribution = tensor([0.8646, 0.0901, 0.0453])
2024-12-05 15:36:42,647 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([0.8646, 0.0901, 0.0453]), new_distribution = tensor([0.8651, 0.0898, 0.0451])
2024-12-05 15:36:42,701 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([0.8651, 0.0898, 0.0451]), new_distribution = tensor([0.8655, 0.0895, 0.0450])
2024-12-05 15:36:42,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([0.8655, 0.0895, 0.0450]), new_distribution = tensor([0.8659, 0.0892, 0.0449])
2024-12-05 15:36:42,809 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([0.8659, 0.0892, 0.0449]), new_distribution = tensor([0.8664, 0.0889, 0.0447])
2024-12-05 15:36:42,863 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([0.8664, 0.0889, 0.0447]), new_distribution = tensor([0.8668, 0.0886, 0.0446])
2024-12-05 15:36:42,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([0.8668, 0.0886, 0.0446]), new_distribution = tensor([0.8672, 0.0883, 0.0445])
2024-12-05 15:36:42,971 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([0.8672, 0.0883, 0.0445]), new_distribution = tensor([0.8676, 0.0880, 0.0444])
2024-12-05 15:36:43,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([0.8676, 0.0880, 0.0444]), new_distribution = tensor([0.8681, 0.0877, 0.0442])
2024-12-05 15:36:43,080 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([0.8681, 0.0877, 0.0442]), new_distribution = tensor([0.8685, 0.0874, 0.0441])
2024-12-05 15:36:43,134 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([0.8685, 0.0874, 0.0441]), new_distribution = tensor([0.8689, 0.0871, 0.0440])
2024-12-05 15:36:43,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([0.8689, 0.0871, 0.0440]), new_distribution = tensor([0.8693, 0.0868, 0.0438])
2024-12-05 15:36:43,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([0.8693, 0.0868, 0.0438]), new_distribution = tensor([0.8698, 0.0865, 0.0437])
2024-12-05 15:36:43,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([0.8698, 0.0865, 0.0437]), new_distribution = tensor([0.8702, 0.0863, 0.0436])
2024-12-05 15:36:43,350 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([0.8702, 0.0863, 0.0436]), new_distribution = tensor([0.8706, 0.0860, 0.0434])
2024-12-05 15:36:43,404 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([0.8706, 0.0860, 0.0434]), new_distribution = tensor([0.8710, 0.0857, 0.0433])
2024-12-05 15:36:43,458 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([0.8710, 0.0857, 0.0433]), new_distribution = tensor([0.8714, 0.0854, 0.0432])
2024-12-05 15:36:43,512 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([0.8714, 0.0854, 0.0432]), new_distribution = tensor([0.8718, 0.0851, 0.0431])
2024-12-05 15:36:43,566 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([0.8718, 0.0851, 0.0431]), new_distribution = tensor([0.8722, 0.0848, 0.0429])
2024-12-05 15:36:43,620 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([0.8722, 0.0848, 0.0429]), new_distribution = tensor([0.8727, 0.0845, 0.0428])
2024-12-05 15:36:43,678 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([0.8727, 0.0845, 0.0428]), new_distribution = tensor([0.8731, 0.0843, 0.0427])
2024-12-05 15:36:43,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([0.8731, 0.0843, 0.0427]), new_distribution = tensor([0.8735, 0.0840, 0.0426])
2024-12-05 15:36:43,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([0.8735, 0.0840, 0.0426]), new_distribution = tensor([0.8739, 0.0837, 0.0424])
2024-12-05 15:36:43,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([0.8739, 0.0837, 0.0424]), new_distribution = tensor([0.8743, 0.0834, 0.0423])
2024-12-05 15:36:43,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([0.8743, 0.0834, 0.0423]), new_distribution = tensor([0.8747, 0.0831, 0.0422])
2024-12-05 15:36:43,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([0.8747, 0.0831, 0.0422]), new_distribution = tensor([0.8751, 0.0828, 0.0421])
2024-12-05 15:36:44,001 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([0.8751, 0.0828, 0.0421]), new_distribution = tensor([0.8755, 0.0826, 0.0419])
2024-12-05 15:36:44,055 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([0.8755, 0.0826, 0.0419]), new_distribution = tensor([0.8759, 0.0823, 0.0418])
2024-12-05 15:36:44,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([0.8759, 0.0823, 0.0418]), new_distribution = tensor([0.8763, 0.0820, 0.0417])
2024-12-05 15:36:44,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([0.8763, 0.0820, 0.0417]), new_distribution = tensor([0.8767, 0.0817, 0.0416])
2024-12-05 15:36:44,435 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:44,490 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:44,544 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:44,598 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:44,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:44,706 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:44,760 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:44,814 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:44,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:44,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:44,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,029 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,083 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,137 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,621 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,728 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:45,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:46,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:46,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:46,214 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:46,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:46,423 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:46,529 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:46,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:46,738 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:46,843 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:46,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:47,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:47,157 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:47,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:47,367 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:47,472 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:47,575 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:47,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:47,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:47,862 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:47,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,029 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,106 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,247 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,374 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,434 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:48,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,138 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,192 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,568 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,621 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,729 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,889 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,943 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:49,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,211 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,319 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,480 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,694 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,802 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,855 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:50,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,232 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,930 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:51,984 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,146 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,307 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,629 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,683 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:52,951 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,005 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,436 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,489 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,597 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,651 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,705 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,759 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,867 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:53,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,243 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,297 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,405 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,512 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,620 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,728 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:54,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,106 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,214 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,322 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,376 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,484 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,538 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,646 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,754 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,861 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,915 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:55,969 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,023 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,077 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,131 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,185 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,239 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,509 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,562 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,670 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,725 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,779 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,832 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,886 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,940 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:56,994 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,161 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,327 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,381 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,435 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,489 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,597 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,651 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,705 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,759 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:57,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,405 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,625 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:58,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,002 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,055 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,110 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,486 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,540 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,594 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,809 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,863 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:36:59,971 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,133 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,240 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,295 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,349 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,403 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,511 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,673 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,835 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,889 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,943 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:00,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:01,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:01,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:01,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:01,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:01,266 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:01,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:01,374 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:01,428 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:01,482 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:01,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:01,589 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:37:01,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.1000, 0.3000, 0.6000]), new_distribution = tensor([0.1003, 0.3005, 0.5992])
2024-12-05 15:37:01,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.1003, 0.3005, 0.5992]), new_distribution = tensor([0.1006, 0.3009, 0.5984])
2024-12-05 15:37:01,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.1006, 0.3009, 0.5984]), new_distribution = tensor([0.1010, 0.3014, 0.5976])
2024-12-05 15:37:02,031 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.1010, 0.3014, 0.5976]), new_distribution = tensor([0.1013, 0.3019, 0.5968])
2024-12-05 15:37:02,085 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.1013, 0.3019, 0.5968]), new_distribution = tensor([0.1016, 0.3024, 0.5960])
2024-12-05 15:37:02,138 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.1016, 0.3024, 0.5960]), new_distribution = tensor([0.1019, 0.3028, 0.5952])
2024-12-05 15:37:02,192 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.1019, 0.3028, 0.5952]), new_distribution = tensor([0.1022, 0.3033, 0.5944])
2024-12-05 15:37:02,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.1022, 0.3033, 0.5944]), new_distribution = tensor([0.1026, 0.3038, 0.5936])
2024-12-05 15:37:02,300 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.1026, 0.3038, 0.5936]), new_distribution = tensor([0.1029, 0.3043, 0.5928])
2024-12-05 15:37:02,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.1029, 0.3043, 0.5928]), new_distribution = tensor([0.1032, 0.3047, 0.5920])
2024-12-05 15:37:02,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.1032, 0.3047, 0.5920]), new_distribution = tensor([0.1036, 0.3052, 0.5913])
2024-12-05 15:37:02,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.1036, 0.3052, 0.5913]), new_distribution = tensor([0.1039, 0.3057, 0.5905])
2024-12-05 15:37:02,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.1039, 0.3057, 0.5905]), new_distribution = tensor([0.1042, 0.3061, 0.5897])
2024-12-05 15:37:02,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.1042, 0.3061, 0.5897]), new_distribution = tensor([0.1045, 0.3066, 0.5889])
2024-12-05 15:37:02,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.1045, 0.3066, 0.5889]), new_distribution = tensor([0.1049, 0.3071, 0.5881])
2024-12-05 15:37:02,678 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.1049, 0.3071, 0.5881]), new_distribution = tensor([0.1052, 0.3075, 0.5872])
2024-12-05 15:37:02,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.1052, 0.3075, 0.5872]), new_distribution = tensor([0.1055, 0.3080, 0.5864])
2024-12-05 15:37:02,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.1055, 0.3080, 0.5864]), new_distribution = tensor([0.1059, 0.3085, 0.5856])
2024-12-05 15:37:02,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.1059, 0.3085, 0.5856]), new_distribution = tensor([0.1062, 0.3089, 0.5848])
2024-12-05 15:37:02,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.1062, 0.3089, 0.5848]), new_distribution = tensor([0.1066, 0.3094, 0.5840])
2024-12-05 15:37:02,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.1066, 0.3094, 0.5840]), new_distribution = tensor([0.1069, 0.3099, 0.5832])
2024-12-05 15:37:03,001 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.1069, 0.3099, 0.5832]), new_distribution = tensor([0.1072, 0.3103, 0.5824])
2024-12-05 15:37:03,055 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.1072, 0.3103, 0.5824]), new_distribution = tensor([0.1076, 0.3108, 0.5816])
2024-12-05 15:37:03,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.1076, 0.3108, 0.5816]), new_distribution = tensor([0.1079, 0.3113, 0.5808])
2024-12-05 15:37:03,162 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.1079, 0.3113, 0.5808]), new_distribution = tensor([0.1083, 0.3117, 0.5800])
2024-12-05 15:37:03,216 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.1083, 0.3117, 0.5800]), new_distribution = tensor([0.1086, 0.3122, 0.5792])
2024-12-05 15:37:03,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.1086, 0.3122, 0.5792]), new_distribution = tensor([0.1089, 0.3127, 0.5784])
2024-12-05 15:37:03,324 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.1089, 0.3127, 0.5784]), new_distribution = tensor([0.1093, 0.3131, 0.5776])
2024-12-05 15:37:03,378 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.1093, 0.3131, 0.5776]), new_distribution = tensor([0.1096, 0.3136, 0.5768])
2024-12-05 15:37:03,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.1096, 0.3136, 0.5768]), new_distribution = tensor([0.1100, 0.3140, 0.5760])
2024-12-05 15:37:03,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.1100, 0.3140, 0.5760]), new_distribution = tensor([0.1103, 0.3145, 0.5752])
2024-12-05 15:37:03,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.1103, 0.3145, 0.5752]), new_distribution = tensor([0.1107, 0.3150, 0.5744])
2024-12-05 15:37:03,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.1107, 0.3150, 0.5744]), new_distribution = tensor([0.1110, 0.3154, 0.5735])
2024-12-05 15:37:03,646 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.1110, 0.3154, 0.5735]), new_distribution = tensor([0.1114, 0.3159, 0.5727])
2024-12-05 15:37:03,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.1114, 0.3159, 0.5727]), new_distribution = tensor([0.1117, 0.3163, 0.5719])
2024-12-05 15:37:03,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.1117, 0.3163, 0.5719]), new_distribution = tensor([0.1121, 0.3168, 0.5711])
2024-12-05 15:37:03,810 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.1121, 0.3168, 0.5711]), new_distribution = tensor([0.1124, 0.3173, 0.5703])
2024-12-05 15:37:03,864 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.1124, 0.3173, 0.5703]), new_distribution = tensor([0.1128, 0.3177, 0.5695])
2024-12-05 15:37:03,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.1128, 0.3177, 0.5695]), new_distribution = tensor([0.1132, 0.3182, 0.5687])
2024-12-05 15:37:03,971 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.1132, 0.3182, 0.5687]), new_distribution = tensor([0.1135, 0.3186, 0.5679])
2024-12-05 15:37:04,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.1135, 0.3186, 0.5679]), new_distribution = tensor([0.1139, 0.3191, 0.5670])
2024-12-05 15:37:04,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.1139, 0.3191, 0.5670]), new_distribution = tensor([0.1142, 0.3195, 0.5662])
2024-12-05 15:37:04,133 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.1142, 0.3195, 0.5662]), new_distribution = tensor([0.1146, 0.3200, 0.5654])
2024-12-05 15:37:04,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.1146, 0.3200, 0.5654]), new_distribution = tensor([0.1150, 0.3205, 0.5646])
2024-12-05 15:37:04,240 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.1150, 0.3205, 0.5646]), new_distribution = tensor([0.1153, 0.3209, 0.5638])
2024-12-05 15:37:04,294 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.1153, 0.3209, 0.5638]), new_distribution = tensor([0.1157, 0.3214, 0.5630])
2024-12-05 15:37:04,348 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.1157, 0.3214, 0.5630]), new_distribution = tensor([0.1160, 0.3218, 0.5621])
2024-12-05 15:37:04,402 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.1160, 0.3218, 0.5621]), new_distribution = tensor([0.1164, 0.3223, 0.5613])
2024-12-05 15:37:04,456 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.1164, 0.3223, 0.5613]), new_distribution = tensor([0.1168, 0.3227, 0.5605])
2024-12-05 15:37:04,510 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.1168, 0.3227, 0.5605]), new_distribution = tensor([0.1172, 0.3232, 0.5597])
2024-12-05 15:37:04,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.1172, 0.3232, 0.5597]), new_distribution = tensor([0.1175, 0.3236, 0.5589])
2024-12-05 15:37:04,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.1175, 0.3236, 0.5589]), new_distribution = tensor([0.1179, 0.3241, 0.5580])
2024-12-05 15:37:04,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.1179, 0.3241, 0.5580]), new_distribution = tensor([0.1183, 0.3245, 0.5572])
2024-12-05 15:37:04,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.1183, 0.3245, 0.5572]), new_distribution = tensor([0.1186, 0.3250, 0.5564])
2024-12-05 15:37:04,780 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.1186, 0.3250, 0.5564]), new_distribution = tensor([0.1190, 0.3254, 0.5556])
2024-12-05 15:37:04,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.1190, 0.3254, 0.5556]), new_distribution = tensor([0.1194, 0.3259, 0.5548])
2024-12-05 15:37:04,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.1194, 0.3259, 0.5548]), new_distribution = tensor([0.1198, 0.3263, 0.5539])
2024-12-05 15:37:04,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.1198, 0.3263, 0.5539]), new_distribution = tensor([0.1201, 0.3267, 0.5531])
2024-12-05 15:37:04,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.1201, 0.3267, 0.5531]), new_distribution = tensor([0.1205, 0.3272, 0.5523])
2024-12-05 15:37:05,049 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.1205, 0.3272, 0.5523]), new_distribution = tensor([0.1209, 0.3276, 0.5515])
2024-12-05 15:37:05,103 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.1209, 0.3276, 0.5515]), new_distribution = tensor([0.1213, 0.3281, 0.5506])
2024-12-05 15:37:05,156 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.1213, 0.3281, 0.5506]), new_distribution = tensor([0.1217, 0.3285, 0.5498])
2024-12-05 15:37:05,210 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.1217, 0.3285, 0.5498]), new_distribution = tensor([0.1220, 0.3290, 0.5490])
2024-12-05 15:37:05,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.1220, 0.3290, 0.5490]), new_distribution = tensor([0.1224, 0.3294, 0.5482])
2024-12-05 15:37:05,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.1224, 0.3294, 0.5482]), new_distribution = tensor([0.1228, 0.3298, 0.5474])
2024-12-05 15:37:05,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.1228, 0.3298, 0.5474]), new_distribution = tensor([0.1232, 0.3303, 0.5465])
2024-12-05 15:37:05,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.1232, 0.3303, 0.5465]), new_distribution = tensor([0.1236, 0.3307, 0.5457])
2024-12-05 15:37:05,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.1236, 0.3307, 0.5457]), new_distribution = tensor([0.1240, 0.3311, 0.5449])
2024-12-05 15:37:05,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.1240, 0.3311, 0.5449]), new_distribution = tensor([0.1244, 0.3316, 0.5440])
2024-12-05 15:37:05,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.1244, 0.3316, 0.5440]), new_distribution = tensor([0.1248, 0.3320, 0.5432])
2024-12-05 15:37:05,640 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.1248, 0.3320, 0.5432]), new_distribution = tensor([0.1251, 0.3325, 0.5424])
2024-12-05 15:37:05,694 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.1251, 0.3325, 0.5424]), new_distribution = tensor([0.1255, 0.3329, 0.5416])
2024-12-05 15:37:05,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.1255, 0.3329, 0.5416]), new_distribution = tensor([0.1259, 0.3333, 0.5407])
2024-12-05 15:37:05,802 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.1259, 0.3333, 0.5407]), new_distribution = tensor([0.1263, 0.3338, 0.5399])
2024-12-05 15:37:05,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.1263, 0.3338, 0.5399]), new_distribution = tensor([0.1267, 0.3342, 0.5391])
2024-12-05 15:37:05,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.1267, 0.3342, 0.5391]), new_distribution = tensor([0.1271, 0.3346, 0.5383])
2024-12-05 15:37:05,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.1271, 0.3346, 0.5383]), new_distribution = tensor([0.1275, 0.3350, 0.5374])
2024-12-05 15:37:06,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.1275, 0.3350, 0.5374]), new_distribution = tensor([0.1279, 0.3355, 0.5366])
2024-12-05 15:37:06,072 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.1279, 0.3355, 0.5366]), new_distribution = tensor([0.1283, 0.3359, 0.5358])
2024-12-05 15:37:06,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.1283, 0.3359, 0.5358]), new_distribution = tensor([0.1287, 0.3363, 0.5349])
2024-12-05 15:37:06,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.1287, 0.3363, 0.5349]), new_distribution = tensor([0.1291, 0.3368, 0.5341])
2024-12-05 15:37:06,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.1291, 0.3368, 0.5341]), new_distribution = tensor([0.1295, 0.3372, 0.5333])
2024-12-05 15:37:06,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.1295, 0.3372, 0.5333]), new_distribution = tensor([0.1299, 0.3376, 0.5324])
2024-12-05 15:37:06,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.1299, 0.3376, 0.5324]), new_distribution = tensor([0.1303, 0.3380, 0.5316])
2024-12-05 15:37:06,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.1303, 0.3380, 0.5316]), new_distribution = tensor([0.1308, 0.3385, 0.5308])
2024-12-05 15:37:06,448 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.1308, 0.3385, 0.5308]), new_distribution = tensor([0.1312, 0.3389, 0.5300])
2024-12-05 15:37:06,502 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.1312, 0.3389, 0.5300]), new_distribution = tensor([0.1316, 0.3393, 0.5291])
2024-12-05 15:37:06,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.1316, 0.3393, 0.5291]), new_distribution = tensor([0.1320, 0.3397, 0.5283])
2024-12-05 15:37:06,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.1320, 0.3397, 0.5283]), new_distribution = tensor([0.1324, 0.3401, 0.5275])
2024-12-05 15:37:06,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.1324, 0.3401, 0.5275]), new_distribution = tensor([0.1328, 0.3406, 0.5266])
2024-12-05 15:37:06,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.1328, 0.3406, 0.5266]), new_distribution = tensor([0.1332, 0.3410, 0.5258])
2024-12-05 15:37:06,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.1332, 0.3410, 0.5258]), new_distribution = tensor([0.1336, 0.3414, 0.5250])
2024-12-05 15:37:06,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.1336, 0.3414, 0.5250]), new_distribution = tensor([0.1341, 0.3418, 0.5241])
2024-12-05 15:37:06,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.1341, 0.3418, 0.5241]), new_distribution = tensor([0.1345, 0.3422, 0.5233])
2024-12-05 15:37:06,936 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.1345, 0.3422, 0.5233]), new_distribution = tensor([0.1349, 0.3426, 0.5225])
2024-12-05 15:37:06,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.1349, 0.3426, 0.5225]), new_distribution = tensor([0.1353, 0.3431, 0.5216])
2024-12-05 15:37:07,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.1353, 0.3431, 0.5216]), new_distribution = tensor([0.1357, 0.3435, 0.5208])
2024-12-05 15:37:07,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.1357, 0.3435, 0.5208]), new_distribution = tensor([0.1362, 0.3439, 0.5200])
2024-12-05 15:37:07,152 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.1362, 0.3439, 0.5200]), new_distribution = tensor([0.1366, 0.3443, 0.5191])
2024-12-05 15:37:07,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.1366, 0.3443, 0.5191]), new_distribution = tensor([0.1370, 0.3447, 0.5183])
2024-12-05 15:37:07,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([0.1370, 0.3447, 0.5183]), new_distribution = tensor([0.1374, 0.3451, 0.5174])
2024-12-05 15:37:07,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([0.1374, 0.3451, 0.5174]), new_distribution = tensor([0.1379, 0.3455, 0.5166])
2024-12-05 15:37:07,371 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([0.1379, 0.3455, 0.5166]), new_distribution = tensor([0.1383, 0.3459, 0.5158])
2024-12-05 15:37:07,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([0.1383, 0.3459, 0.5158]), new_distribution = tensor([0.1387, 0.3463, 0.5149])
2024-12-05 15:37:07,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([0.1387, 0.3463, 0.5149]), new_distribution = tensor([0.1392, 0.3467, 0.5141])
2024-12-05 15:37:07,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([0.1392, 0.3467, 0.5141]), new_distribution = tensor([0.1396, 0.3471, 0.5133])
2024-12-05 15:37:07,586 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([0.1396, 0.3471, 0.5133]), new_distribution = tensor([0.1400, 0.3475, 0.5124])
2024-12-05 15:37:07,640 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([0.1400, 0.3475, 0.5124]), new_distribution = tensor([0.1405, 0.3479, 0.5116])
2024-12-05 15:37:07,694 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([0.1405, 0.3479, 0.5116]), new_distribution = tensor([0.1409, 0.3483, 0.5108])
2024-12-05 15:37:07,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([0.1409, 0.3483, 0.5108]), new_distribution = tensor([0.1413, 0.3487, 0.5099])
2024-12-05 15:37:07,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([0.1413, 0.3487, 0.5099]), new_distribution = tensor([0.1418, 0.3491, 0.5091])
2024-12-05 15:37:07,855 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([0.1418, 0.3491, 0.5091]), new_distribution = tensor([0.1422, 0.3495, 0.5082])
2024-12-05 15:37:07,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([0.1422, 0.3495, 0.5082]), new_distribution = tensor([0.1427, 0.3499, 0.5074])
2024-12-05 15:37:07,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([0.1427, 0.3499, 0.5074]), new_distribution = tensor([0.1431, 0.3503, 0.5066])
2024-12-05 15:37:08,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([0.1431, 0.3503, 0.5066]), new_distribution = tensor([0.1435, 0.3507, 0.5057])
2024-12-05 15:37:08,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([0.1435, 0.3507, 0.5057]), new_distribution = tensor([0.1440, 0.3511, 0.5049])
2024-12-05 15:37:08,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([0.1440, 0.3511, 0.5049]), new_distribution = tensor([0.1444, 0.3515, 0.5041])
2024-12-05 15:37:08,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([0.1444, 0.3515, 0.5041]), new_distribution = tensor([0.1449, 0.3519, 0.5032])
2024-12-05 15:37:08,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([0.1449, 0.3519, 0.5032]), new_distribution = tensor([0.1453, 0.3523, 0.5024])
2024-12-05 15:37:08,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([0.1453, 0.3523, 0.5024]), new_distribution = tensor([0.1458, 0.3527, 0.5015])
2024-12-05 15:37:08,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([0.1458, 0.3527, 0.5015]), new_distribution = tensor([0.1462, 0.3531, 0.5007])
2024-12-05 15:37:08,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([0.1462, 0.3531, 0.5007]), new_distribution = tensor([0.1467, 0.3534, 0.4999])
2024-12-05 15:37:08,448 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([0.1467, 0.3534, 0.4999]), new_distribution = tensor([0.1471, 0.3538, 0.4990])
2024-12-05 15:37:08,502 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([0.1471, 0.3538, 0.4990]), new_distribution = tensor([0.1476, 0.3542, 0.4982])
2024-12-05 15:37:08,556 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([0.1476, 0.3542, 0.4982]), new_distribution = tensor([0.1481, 0.3546, 0.4974])
2024-12-05 15:37:08,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([0.1481, 0.3546, 0.4974]), new_distribution = tensor([0.1485, 0.3550, 0.4965])
2024-12-05 15:37:08,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([0.1485, 0.3550, 0.4965]), new_distribution = tensor([0.1490, 0.3554, 0.4957])
2024-12-05 15:37:08,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([0.1490, 0.3554, 0.4957]), new_distribution = tensor([0.1494, 0.3557, 0.4948])
2024-12-05 15:37:08,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([0.1494, 0.3557, 0.4948]), new_distribution = tensor([0.1499, 0.3561, 0.4940])
2024-12-05 15:37:08,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([0.1499, 0.3561, 0.4940]), new_distribution = tensor([0.1504, 0.3565, 0.4932])
2024-12-05 15:37:08,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([0.1504, 0.3565, 0.4932]), new_distribution = tensor([0.1508, 0.3569, 0.4923])
2024-12-05 15:37:08,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([0.1508, 0.3569, 0.4923]), new_distribution = tensor([0.1513, 0.3572, 0.4915])
2024-12-05 15:37:08,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([0.1513, 0.3572, 0.4915]), new_distribution = tensor([0.1517, 0.3576, 0.4906])
2024-12-05 15:37:09,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([0.1517, 0.3576, 0.4906]), new_distribution = tensor([0.1522, 0.3580, 0.4898])
2024-12-05 15:37:09,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([0.1522, 0.3580, 0.4898]), new_distribution = tensor([0.1527, 0.3584, 0.4890])
2024-12-05 15:37:09,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([0.1527, 0.3584, 0.4890]), new_distribution = tensor([0.1532, 0.3587, 0.4881])
2024-12-05 15:37:09,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([0.1532, 0.3587, 0.4881]), new_distribution = tensor([0.1536, 0.3591, 0.4873])
2024-12-05 15:37:09,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([0.1536, 0.3591, 0.4873]), new_distribution = tensor([0.1541, 0.3595, 0.4864])
2024-12-05 15:37:09,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([0.1541, 0.3595, 0.4864]), new_distribution = tensor([0.1546, 0.3598, 0.4856])
2024-12-05 15:37:09,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([0.1546, 0.3598, 0.4856]), new_distribution = tensor([0.1550, 0.3602, 0.4848])
2024-12-05 15:37:09,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([0.1550, 0.3602, 0.4848]), new_distribution = tensor([0.1555, 0.3605, 0.4839])
2024-12-05 15:37:09,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([0.1555, 0.3605, 0.4839]), new_distribution = tensor([0.1560, 0.3609, 0.4831])
2024-12-05 15:37:09,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([0.1560, 0.3609, 0.4831]), new_distribution = tensor([0.1565, 0.3613, 0.4823])
2024-12-05 15:37:09,578 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([0.1565, 0.3613, 0.4823]), new_distribution = tensor([0.1570, 0.3616, 0.4814])
2024-12-05 15:37:09,632 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([0.1570, 0.3616, 0.4814]), new_distribution = tensor([0.1574, 0.3620, 0.4806])
2024-12-05 15:37:09,686 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([0.1574, 0.3620, 0.4806]), new_distribution = tensor([0.1579, 0.3623, 0.4797])
2024-12-05 15:37:09,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([0.1579, 0.3623, 0.4797]), new_distribution = tensor([0.1584, 0.3627, 0.4789])
2024-12-05 15:37:09,794 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([0.1584, 0.3627, 0.4789]), new_distribution = tensor([0.1589, 0.3631, 0.4781])
2024-12-05 15:37:09,847 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([0.1589, 0.3631, 0.4781]), new_distribution = tensor([0.1594, 0.3634, 0.4772])
2024-12-05 15:37:09,901 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([0.1594, 0.3634, 0.4772]), new_distribution = tensor([0.1599, 0.3638, 0.4764])
2024-12-05 15:37:09,955 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([0.1599, 0.3638, 0.4764]), new_distribution = tensor([0.1604, 0.3641, 0.4755])
2024-12-05 15:37:10,009 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([0.1604, 0.3641, 0.4755]), new_distribution = tensor([0.1608, 0.3645, 0.4747])
2024-12-05 15:37:10,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([0.1608, 0.3645, 0.4747]), new_distribution = tensor([0.1613, 0.3648, 0.4739])
2024-12-05 15:37:10,116 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([0.1613, 0.3648, 0.4739]), new_distribution = tensor([0.1618, 0.3651, 0.4730])
2024-12-05 15:37:10,170 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([0.1618, 0.3651, 0.4730]), new_distribution = tensor([0.1623, 0.3655, 0.4722])
2024-12-05 15:37:10,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([0.1623, 0.3655, 0.4722]), new_distribution = tensor([0.1628, 0.3658, 0.4713])
2024-12-05 15:37:10,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([0.1628, 0.3658, 0.4713]), new_distribution = tensor([0.1633, 0.3662, 0.4705])
2024-12-05 15:37:10,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([0.1633, 0.3662, 0.4705]), new_distribution = tensor([0.1638, 0.3665, 0.4697])
2024-12-05 15:37:10,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([0.1638, 0.3665, 0.4697]), new_distribution = tensor([0.1643, 0.3669, 0.4688])
2024-12-05 15:37:10,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([0.1643, 0.3669, 0.4688]), new_distribution = tensor([0.1648, 0.3672, 0.4680])
2024-12-05 15:37:10,494 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([0.1648, 0.3672, 0.4680]), new_distribution = tensor([0.1653, 0.3675, 0.4671])
2024-12-05 15:37:10,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([0.1653, 0.3675, 0.4671]), new_distribution = tensor([0.1658, 0.3679, 0.4663])
2024-12-05 15:37:10,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([0.1658, 0.3679, 0.4663]), new_distribution = tensor([0.1663, 0.3682, 0.4655])
2024-12-05 15:37:10,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([0.1663, 0.3682, 0.4655]), new_distribution = tensor([0.1668, 0.3685, 0.4646])
2024-12-05 15:37:10,709 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([0.1668, 0.3685, 0.4646]), new_distribution = tensor([0.1673, 0.3689, 0.4638])
2024-12-05 15:37:10,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([0.1673, 0.3689, 0.4638]), new_distribution = tensor([0.1679, 0.3692, 0.4630])
2024-12-05 15:37:10,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([0.1679, 0.3692, 0.4630]), new_distribution = tensor([0.1684, 0.3695, 0.4621])
2024-12-05 15:37:10,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([0.1684, 0.3695, 0.4621]), new_distribution = tensor([0.1689, 0.3698, 0.4613])
2024-12-05 15:37:10,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([0.1689, 0.3698, 0.4613]), new_distribution = tensor([0.1694, 0.3702, 0.4604])
2024-12-05 15:37:10,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([0.1694, 0.3702, 0.4604]), new_distribution = tensor([0.1699, 0.3705, 0.4596])
2024-12-05 15:37:11,031 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([0.1699, 0.3705, 0.4596]), new_distribution = tensor([0.1704, 0.3708, 0.4588])
2024-12-05 15:37:11,085 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([0.1704, 0.3708, 0.4588]), new_distribution = tensor([0.1709, 0.3711, 0.4579])
2024-12-05 15:37:11,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([0.1709, 0.3711, 0.4579]), new_distribution = tensor([0.1715, 0.3714, 0.4571])
2024-12-05 15:37:11,192 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([0.1715, 0.3714, 0.4571]), new_distribution = tensor([0.1720, 0.3718, 0.4563])
2024-12-05 15:37:11,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([0.1720, 0.3718, 0.4563]), new_distribution = tensor([0.1725, 0.3721, 0.4554])
2024-12-05 15:37:11,300 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([0.1725, 0.3721, 0.4554]), new_distribution = tensor([0.1730, 0.3724, 0.4546])
2024-12-05 15:37:11,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([0.1730, 0.3724, 0.4546]), new_distribution = tensor([0.1735, 0.3727, 0.4538])
2024-12-05 15:37:11,408 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([0.1735, 0.3727, 0.4538]), new_distribution = tensor([0.1741, 0.3730, 0.4529])
2024-12-05 15:37:11,463 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([0.1741, 0.3730, 0.4529]), new_distribution = tensor([0.1746, 0.3733, 0.4521])
2024-12-05 15:37:11,517 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([0.1746, 0.3733, 0.4521]), new_distribution = tensor([0.1751, 0.3736, 0.4512])
2024-12-05 15:37:11,571 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([0.1751, 0.3736, 0.4512]), new_distribution = tensor([0.1756, 0.3739, 0.4504])
2024-12-05 15:37:11,625 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([0.1756, 0.3739, 0.4504]), new_distribution = tensor([0.1762, 0.3742, 0.4496])
2024-12-05 15:37:11,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([0.1762, 0.3742, 0.4496]), new_distribution = tensor([0.1767, 0.3746, 0.4487])
2024-12-05 15:37:11,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([0.1767, 0.3746, 0.4487]), new_distribution = tensor([0.1772, 0.3749, 0.4479])
2024-12-05 15:37:11,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([0.1772, 0.3749, 0.4479]), new_distribution = tensor([0.1778, 0.3752, 0.4471])
2024-12-05 15:37:11,841 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([0.1778, 0.3752, 0.4471]), new_distribution = tensor([0.1783, 0.3755, 0.4462])
2024-12-05 15:37:11,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([0.1783, 0.3755, 0.4462]), new_distribution = tensor([0.1788, 0.3758, 0.4454])
2024-12-05 15:37:11,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([0.1788, 0.3758, 0.4454]), new_distribution = tensor([0.1794, 0.3760, 0.4446])
2024-12-05 15:37:12,002 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([0.1794, 0.3760, 0.4446]), new_distribution = tensor([0.1799, 0.3763, 0.4437])
2024-12-05 15:37:12,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([0.1799, 0.3763, 0.4437]), new_distribution = tensor([0.1805, 0.3766, 0.4429])
2024-12-05 15:37:12,110 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([0.1805, 0.3766, 0.4429]), new_distribution = tensor([0.1810, 0.3769, 0.4421])
2024-12-05 15:37:12,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([0.1810, 0.3769, 0.4421]), new_distribution = tensor([0.1816, 0.3772, 0.4412])
2024-12-05 15:37:12,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([0.1816, 0.3772, 0.4412]), new_distribution = tensor([0.1821, 0.3775, 0.4404])
2024-12-05 15:37:12,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([0.1821, 0.3775, 0.4404]), new_distribution = tensor([0.1826, 0.3778, 0.4396])
2024-12-05 15:37:12,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([0.1826, 0.3778, 0.4396]), new_distribution = tensor([0.1832, 0.3781, 0.4387])
2024-12-05 15:37:12,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([0.1832, 0.3781, 0.4387]), new_distribution = tensor([0.1837, 0.3784, 0.4379])
2024-12-05 15:37:12,435 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([0.1837, 0.3784, 0.4379]), new_distribution = tensor([0.1843, 0.3786, 0.4371])
2024-12-05 15:37:12,489 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([0.1843, 0.3786, 0.4371]), new_distribution = tensor([0.1848, 0.3789, 0.4362])
2024-12-05 15:37:12,542 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([0.1848, 0.3789, 0.4362]), new_distribution = tensor([0.1854, 0.3792, 0.4354])
2024-12-05 15:37:12,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([0.1854, 0.3792, 0.4354]), new_distribution = tensor([0.1859, 0.3795, 0.4346])
2024-12-05 15:37:12,650 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([0.1859, 0.3795, 0.4346]), new_distribution = tensor([0.1865, 0.3797, 0.4338])
2024-12-05 15:37:12,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([0.1865, 0.3797, 0.4338]), new_distribution = tensor([0.1871, 0.3800, 0.4329])
2024-12-05 15:37:12,758 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([0.1871, 0.3800, 0.4329]), new_distribution = tensor([0.1876, 0.3803, 0.4321])
2024-12-05 15:37:12,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([0.1876, 0.3803, 0.4321]), new_distribution = tensor([0.1882, 0.3806, 0.4313])
2024-12-05 15:37:12,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([0.1882, 0.3806, 0.4313]), new_distribution = tensor([0.1887, 0.3808, 0.4304])
2024-12-05 15:37:12,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([0.1887, 0.3808, 0.4304]), new_distribution = tensor([0.1893, 0.3811, 0.4296])
2024-12-05 15:37:12,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([0.1893, 0.3811, 0.4296]), new_distribution = tensor([0.1899, 0.3814, 0.4288])
2024-12-05 15:37:13,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([0.1899, 0.3814, 0.4288]), new_distribution = tensor([0.1904, 0.3816, 0.4279])
2024-12-05 15:37:13,081 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([0.1904, 0.3816, 0.4279]), new_distribution = tensor([0.1910, 0.3819, 0.4271])
2024-12-05 15:37:13,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([0.1910, 0.3819, 0.4271]), new_distribution = tensor([0.1916, 0.3821, 0.4263])
2024-12-05 15:37:13,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([0.1916, 0.3821, 0.4263]), new_distribution = tensor([0.1921, 0.3824, 0.4255])
2024-12-05 15:37:13,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([0.1921, 0.3824, 0.4255]), new_distribution = tensor([0.1927, 0.3827, 0.4246])
2024-12-05 15:37:13,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([0.1927, 0.3827, 0.4246]), new_distribution = tensor([0.1933, 0.3829, 0.4238])
2024-12-05 15:37:13,349 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([0.1933, 0.3829, 0.4238]), new_distribution = tensor([0.1939, 0.3832, 0.4230])
2024-12-05 15:37:13,403 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([0.1939, 0.3832, 0.4230]), new_distribution = tensor([0.1944, 0.3834, 0.4222])
2024-12-05 15:37:13,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([0.1944, 0.3834, 0.4222]), new_distribution = tensor([0.1950, 0.3837, 0.4213])
2024-12-05 15:37:13,511 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([0.1950, 0.3837, 0.4213]), new_distribution = tensor([0.1956, 0.3839, 0.4205])
2024-12-05 15:37:13,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([0.1956, 0.3839, 0.4205]), new_distribution = tensor([0.1962, 0.3842, 0.4197])
2024-12-05 15:37:13,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([0.1962, 0.3842, 0.4197]), new_distribution = tensor([0.1967, 0.3844, 0.4189])
2024-12-05 15:37:13,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([0.1967, 0.3844, 0.4189]), new_distribution = tensor([0.1973, 0.3846, 0.4180])
2024-12-05 15:37:13,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([0.1973, 0.3846, 0.4180]), new_distribution = tensor([0.1979, 0.3849, 0.4172])
2024-12-05 15:37:13,779 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([0.1979, 0.3849, 0.4172]), new_distribution = tensor([0.1985, 0.3851, 0.4164])
2024-12-05 15:37:13,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([0.1985, 0.3851, 0.4164]), new_distribution = tensor([0.1991, 0.3854, 0.4156])
2024-12-05 15:37:13,888 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([0.1991, 0.3854, 0.4156]), new_distribution = tensor([0.1997, 0.3856, 0.4147])
2024-12-05 15:37:13,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([0.1997, 0.3856, 0.4147]), new_distribution = tensor([0.2003, 0.3858, 0.4139])
2024-12-05 15:37:13,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([0.2003, 0.3858, 0.4139]), new_distribution = tensor([0.2008, 0.3860, 0.4131])
2024-12-05 15:37:14,049 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([0.2008, 0.3860, 0.4131]), new_distribution = tensor([0.2014, 0.3863, 0.4123])
2024-12-05 15:37:14,103 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([0.2014, 0.3863, 0.4123]), new_distribution = tensor([0.2020, 0.3865, 0.4115])
2024-12-05 15:37:14,156 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([0.2020, 0.3865, 0.4115]), new_distribution = tensor([0.2026, 0.3867, 0.4106])
2024-12-05 15:37:14,210 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([0.2026, 0.3867, 0.4106]), new_distribution = tensor([0.2032, 0.3870, 0.4098])
2024-12-05 15:37:14,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([0.2032, 0.3870, 0.4098]), new_distribution = tensor([0.2038, 0.3872, 0.4090])
2024-12-05 15:37:14,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([0.2038, 0.3872, 0.4090]), new_distribution = tensor([0.2044, 0.3874, 0.4082])
2024-12-05 15:37:14,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([0.2044, 0.3874, 0.4082]), new_distribution = tensor([0.2050, 0.3876, 0.4074])
2024-12-05 15:37:14,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([0.2050, 0.3876, 0.4074]), new_distribution = tensor([0.2056, 0.3878, 0.4065])
2024-12-05 15:37:14,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([0.2056, 0.3878, 0.4065]), new_distribution = tensor([0.2062, 0.3880, 0.4057])
2024-12-05 15:37:14,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([0.2062, 0.3880, 0.4057]), new_distribution = tensor([0.2068, 0.3883, 0.4049])
2024-12-05 15:37:14,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([0.2068, 0.3883, 0.4049]), new_distribution = tensor([0.2074, 0.3885, 0.4041])
2024-12-05 15:37:14,640 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([0.2074, 0.3885, 0.4041]), new_distribution = tensor([0.2080, 0.3887, 0.4033])
2024-12-05 15:37:14,694 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([0.2080, 0.3887, 0.4033]), new_distribution = tensor([0.2086, 0.3889, 0.4025])
2024-12-05 15:37:14,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([0.2086, 0.3889, 0.4025]), new_distribution = tensor([0.2093, 0.3891, 0.4017])
2024-12-05 15:37:14,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([0.2093, 0.3891, 0.4017]), new_distribution = tensor([0.2099, 0.3893, 0.4008])
2024-12-05 15:37:14,855 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([0.2099, 0.3893, 0.4008]), new_distribution = tensor([0.2105, 0.3895, 0.4000])
2024-12-05 15:37:14,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([0.2105, 0.3895, 0.4000]), new_distribution = tensor([0.2111, 0.3897, 0.3992])
2024-12-05 15:37:14,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([0.2111, 0.3897, 0.3992]), new_distribution = tensor([0.2117, 0.3899, 0.3984])
2024-12-05 15:37:15,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([0.2117, 0.3899, 0.3984]), new_distribution = tensor([0.2123, 0.3901, 0.3976])
2024-12-05 15:37:15,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([0.2123, 0.3901, 0.3976]), new_distribution = tensor([0.2129, 0.3903, 0.3968])
2024-12-05 15:37:15,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([0.2129, 0.3903, 0.3968]), new_distribution = tensor([0.2136, 0.3905, 0.3960])
2024-12-05 15:37:15,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([0.2136, 0.3905, 0.3960]), new_distribution = tensor([0.2142, 0.3907, 0.3952])
2024-12-05 15:37:15,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([0.2142, 0.3907, 0.3952]), new_distribution = tensor([0.2148, 0.3909, 0.3943])
2024-12-05 15:37:15,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([0.2148, 0.3909, 0.3943]), new_distribution = tensor([0.2154, 0.3910, 0.3935])
2024-12-05 15:37:15,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([0.2154, 0.3910, 0.3935]), new_distribution = tensor([0.2161, 0.3912, 0.3927])
2024-12-05 15:37:15,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([0.2161, 0.3912, 0.3927]), new_distribution = tensor([0.2167, 0.3914, 0.3919])
2024-12-05 15:37:15,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([0.2167, 0.3914, 0.3919]), new_distribution = tensor([0.2173, 0.3916, 0.3911])
2024-12-05 15:37:15,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([0.2173, 0.3916, 0.3911]), new_distribution = tensor([0.2179, 0.3918, 0.3903])
2024-12-05 15:37:15,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([0.2179, 0.3918, 0.3903]), new_distribution = tensor([0.2186, 0.3919, 0.3895])
2024-12-05 15:37:15,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([0.2186, 0.3919, 0.3895]), new_distribution = tensor([0.2192, 0.3921, 0.3887])
2024-12-05 15:37:15,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([0.2192, 0.3921, 0.3887]), new_distribution = tensor([0.2198, 0.3923, 0.3879])
2024-12-05 15:37:15,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([0.2198, 0.3923, 0.3879]), new_distribution = tensor([0.2205, 0.3925, 0.3871])
2024-12-05 15:37:15,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([0.2205, 0.3925, 0.3871]), new_distribution = tensor([0.2211, 0.3926, 0.3863])
2024-12-05 15:37:15,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([0.2211, 0.3926, 0.3863]), new_distribution = tensor([0.2217, 0.3928, 0.3855])
2024-12-05 15:37:15,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([0.2217, 0.3928, 0.3855]), new_distribution = tensor([0.2224, 0.3930, 0.3847])
2024-12-05 15:37:15,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([0.2224, 0.3930, 0.3847]), new_distribution = tensor([0.2230, 0.3931, 0.3839])
2024-12-05 15:37:15,985 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([0.2230, 0.3931, 0.3839]), new_distribution = tensor([0.2237, 0.3933, 0.3831])
2024-12-05 15:37:16,039 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([0.2237, 0.3933, 0.3831]), new_distribution = tensor([0.2243, 0.3934, 0.3823])
2024-12-05 15:37:16,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([0.2243, 0.3934, 0.3823]), new_distribution = tensor([0.2249, 0.3936, 0.3815])
2024-12-05 15:37:16,146 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([0.2249, 0.3936, 0.3815]), new_distribution = tensor([0.2256, 0.3938, 0.3807])
2024-12-05 15:37:16,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([0.2256, 0.3938, 0.3807]), new_distribution = tensor([0.2262, 0.3939, 0.3799])
2024-12-05 15:37:16,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([0.2262, 0.3939, 0.3799]), new_distribution = tensor([0.2269, 0.3941, 0.3791])
2024-12-05 15:37:16,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([0.2269, 0.3941, 0.3791]), new_distribution = tensor([0.2275, 0.3942, 0.3783])
2024-12-05 15:37:16,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([0.2275, 0.3942, 0.3783]), new_distribution = tensor([0.2282, 0.3943, 0.3775])
2024-12-05 15:37:16,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([0.2282, 0.3943, 0.3775]), new_distribution = tensor([0.2288, 0.3945, 0.3767])
2024-12-05 15:37:16,469 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([0.2288, 0.3945, 0.3767]), new_distribution = tensor([0.2295, 0.3946, 0.3759])
2024-12-05 15:37:16,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([0.2295, 0.3946, 0.3759]), new_distribution = tensor([0.2302, 0.3948, 0.3751])
2024-12-05 15:37:16,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([0.2302, 0.3948, 0.3751]), new_distribution = tensor([0.2308, 0.3949, 0.3743])
2024-12-05 15:37:16,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([0.2308, 0.3949, 0.3743]), new_distribution = tensor([0.2315, 0.3951, 0.3735])
2024-12-05 15:37:16,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([0.2315, 0.3951, 0.3735]), new_distribution = tensor([0.2321, 0.3952, 0.3727])
2024-12-05 15:37:16,739 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([0.2321, 0.3952, 0.3727]), new_distribution = tensor([0.2328, 0.3953, 0.3719])
2024-12-05 15:37:16,792 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([0.2328, 0.3953, 0.3719]), new_distribution = tensor([0.2335, 0.3954, 0.3711])
2024-12-05 15:37:16,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([0.2335, 0.3954, 0.3711]), new_distribution = tensor([0.2341, 0.3956, 0.3703])
2024-12-05 15:37:16,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([0.2341, 0.3956, 0.3703]), new_distribution = tensor([0.2348, 0.3957, 0.3695])
2024-12-05 15:37:16,953 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([0.2348, 0.3957, 0.3695]), new_distribution = tensor([0.2355, 0.3958, 0.3687])
2024-12-05 15:37:17,007 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([0.2355, 0.3958, 0.3687]), new_distribution = tensor([0.2361, 0.3960, 0.3679])
2024-12-05 15:37:17,061 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([0.2361, 0.3960, 0.3679]), new_distribution = tensor([0.2368, 0.3961, 0.3671])
2024-12-05 15:37:17,115 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([0.2368, 0.3961, 0.3671]), new_distribution = tensor([0.2375, 0.3962, 0.3664])
2024-12-05 15:37:17,169 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([0.2375, 0.3962, 0.3664]), new_distribution = tensor([0.2381, 0.3963, 0.3656])
2024-12-05 15:37:17,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([0.2381, 0.3963, 0.3656]), new_distribution = tensor([0.2388, 0.3964, 0.3648])
2024-12-05 15:37:17,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([0.2388, 0.3964, 0.3648]), new_distribution = tensor([0.2395, 0.3965, 0.3640])
2024-12-05 15:37:17,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([0.2395, 0.3965, 0.3640]), new_distribution = tensor([0.2402, 0.3966, 0.3632])
2024-12-05 15:37:17,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([0.2402, 0.3966, 0.3632]), new_distribution = tensor([0.2408, 0.3967, 0.3624])
2024-12-05 15:37:17,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([0.2408, 0.3967, 0.3624]), new_distribution = tensor([0.2415, 0.3969, 0.3616])
2024-12-05 15:37:17,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([0.2415, 0.3969, 0.3616]), new_distribution = tensor([0.2422, 0.3970, 0.3608])
2024-12-05 15:37:17,549 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([0.2422, 0.3970, 0.3608]), new_distribution = tensor([0.2429, 0.3971, 0.3601])
2024-12-05 15:37:17,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([0.2429, 0.3971, 0.3601]), new_distribution = tensor([0.2436, 0.3972, 0.3593])
2024-12-05 15:37:17,657 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([0.2436, 0.3972, 0.3593]), new_distribution = tensor([0.2442, 0.3973, 0.3585])
2024-12-05 15:37:17,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([0.2442, 0.3973, 0.3585]), new_distribution = tensor([0.2449, 0.3973, 0.3577])
2024-12-05 15:37:17,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([0.2449, 0.3973, 0.3577]), new_distribution = tensor([0.2456, 0.3974, 0.3569])
2024-12-05 15:37:17,818 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([0.2456, 0.3974, 0.3569]), new_distribution = tensor([0.2463, 0.3975, 0.3562])
2024-12-05 15:37:17,872 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([0.2463, 0.3975, 0.3562]), new_distribution = tensor([0.2470, 0.3976, 0.3554])
2024-12-05 15:37:17,926 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([0.2470, 0.3976, 0.3554]), new_distribution = tensor([0.2477, 0.3977, 0.3546])
2024-12-05 15:37:17,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([0.2477, 0.3977, 0.3546]), new_distribution = tensor([0.2484, 0.3978, 0.3538])
2024-12-05 15:38:01,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.7795, 0.1416, 0.0789]), new_distribution = tensor([0.7801, 0.1412, 0.0787])
2024-12-05 15:38:01,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.7801, 0.1412, 0.0787]), new_distribution = tensor([0.7807, 0.1408, 0.0785])
2024-12-05 15:38:01,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.7807, 0.1408, 0.0785]), new_distribution = tensor([0.7814, 0.1404, 0.0782])
2024-12-05 15:38:01,598 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.7814, 0.1404, 0.0782]), new_distribution = tensor([0.7820, 0.1400, 0.0780])
2024-12-05 15:38:01,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.7820, 0.1400, 0.0780]), new_distribution = tensor([0.7826, 0.1396, 0.0778])
2024-12-05 15:38:01,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.7826, 0.1396, 0.0778]), new_distribution = tensor([0.7833, 0.1392, 0.0776])
2024-12-05 15:38:01,834 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.7833, 0.1392, 0.0776]), new_distribution = tensor([0.7839, 0.1388, 0.0773])
2024-12-05 15:38:01,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.7839, 0.1388, 0.0773]), new_distribution = tensor([0.7845, 0.1384, 0.0771])
2024-12-05 15:38:01,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.7845, 0.1384, 0.0771]), new_distribution = tensor([0.7851, 0.1380, 0.0769])
2024-12-05 15:38:02,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.7851, 0.1380, 0.0769]), new_distribution = tensor([0.7858, 0.1376, 0.0767])
2024-12-05 15:38:02,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.7858, 0.1376, 0.0767]), new_distribution = tensor([0.7864, 0.1372, 0.0765])
2024-12-05 15:38:02,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.7864, 0.1372, 0.0765]), new_distribution = tensor([0.7870, 0.1368, 0.0762])
2024-12-05 15:38:02,309 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.7870, 0.1368, 0.0762]), new_distribution = tensor([0.7876, 0.1364, 0.0760])
2024-12-05 15:38:02,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.7876, 0.1364, 0.0760]), new_distribution = tensor([0.7882, 0.1360, 0.0758])
2024-12-05 15:38:02,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.7882, 0.1360, 0.0758]), new_distribution = tensor([0.7888, 0.1356, 0.0756])
2024-12-05 15:38:02,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.7888, 0.1356, 0.0756]), new_distribution = tensor([0.7895, 0.1352, 0.0754])
2024-12-05 15:38:02,624 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.7895, 0.1352, 0.0754]), new_distribution = tensor([0.7901, 0.1348, 0.0751])
2024-12-05 15:38:02,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.7901, 0.1348, 0.0751]), new_distribution = tensor([0.7907, 0.1344, 0.0749])
2024-12-05 15:38:02,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.7907, 0.1344, 0.0749]), new_distribution = tensor([0.7913, 0.1340, 0.0747])
2024-12-05 15:38:02,860 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.7913, 0.1340, 0.0747]), new_distribution = tensor([0.7919, 0.1336, 0.0745])
2024-12-05 15:38:02,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.7919, 0.1336, 0.0745]), new_distribution = tensor([0.7925, 0.1332, 0.0743])
2024-12-05 15:38:03,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.7925, 0.1332, 0.0743]), new_distribution = tensor([0.7931, 0.1328, 0.0741])
2024-12-05 15:38:03,096 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.7931, 0.1328, 0.0741]), new_distribution = tensor([0.7937, 0.1324, 0.0738])
2024-12-05 15:38:03,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.7937, 0.1324, 0.0738]), new_distribution = tensor([0.7943, 0.1320, 0.0736])
2024-12-05 15:38:03,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.7943, 0.1320, 0.0736]), new_distribution = tensor([0.7949, 0.1317, 0.0734])
2024-12-05 15:38:03,332 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.7949, 0.1317, 0.0734]), new_distribution = tensor([0.7955, 0.1313, 0.0732])
2024-12-05 15:38:03,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.7955, 0.1313, 0.0732]), new_distribution = tensor([0.7961, 0.1309, 0.0730])
2024-12-05 15:38:03,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.7961, 0.1309, 0.0730]), new_distribution = tensor([0.7967, 0.1305, 0.0728])
2024-12-05 15:38:03,560 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.7967, 0.1305, 0.0728]), new_distribution = tensor([0.7973, 0.1301, 0.0726])
2024-12-05 15:38:03,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.7973, 0.1301, 0.0726]), new_distribution = tensor([0.7979, 0.1297, 0.0724])
2024-12-05 15:38:03,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.7979, 0.1297, 0.0724]), new_distribution = tensor([0.7985, 0.1293, 0.0721])
2024-12-05 15:38:03,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.7985, 0.1293, 0.0721]), new_distribution = tensor([0.7991, 0.1290, 0.0719])
2024-12-05 15:38:03,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.7991, 0.1290, 0.0719]), new_distribution = tensor([0.7997, 0.1286, 0.0717])
2024-12-05 15:38:03,871 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.7997, 0.1286, 0.0717]), new_distribution = tensor([0.8003, 0.1282, 0.0715])
2024-12-05 15:38:03,926 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.8003, 0.1282, 0.0715]), new_distribution = tensor([0.8009, 0.1278, 0.0713])
2024-12-05 15:38:03,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.8009, 0.1278, 0.0713]), new_distribution = tensor([0.8015, 0.1274, 0.0711])
2024-12-05 15:38:04,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.8015, 0.1274, 0.0711]), new_distribution = tensor([0.8020, 0.1271, 0.0709])
2024-12-05 15:38:04,088 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.8020, 0.1271, 0.0709]), new_distribution = tensor([0.8026, 0.1267, 0.0707])
2024-12-05 15:38:04,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.8026, 0.1267, 0.0707]), new_distribution = tensor([0.8032, 0.1263, 0.0705])
2024-12-05 15:38:04,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.8032, 0.1263, 0.0705]), new_distribution = tensor([0.8038, 0.1259, 0.0703])
2024-12-05 15:38:04,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.8038, 0.1259, 0.0703]), new_distribution = tensor([0.8044, 0.1255, 0.0701])
2024-12-05 15:38:04,303 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.8044, 0.1255, 0.0701]), new_distribution = tensor([0.8050, 0.1252, 0.0699])
2024-12-05 15:38:04,357 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.8050, 0.1252, 0.0699]), new_distribution = tensor([0.8055, 0.1248, 0.0697])
2024-12-05 15:38:04,410 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.8055, 0.1248, 0.0697]), new_distribution = tensor([0.8061, 0.1244, 0.0695])
2024-12-05 15:38:04,464 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.8061, 0.1244, 0.0695]), new_distribution = tensor([0.8067, 0.1240, 0.0693])
2024-12-05 15:38:04,518 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.8067, 0.1240, 0.0693]), new_distribution = tensor([0.8073, 0.1237, 0.0691])
2024-12-05 15:38:04,572 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.8073, 0.1237, 0.0691]), new_distribution = tensor([0.8078, 0.1233, 0.0689])
2024-12-05 15:38:04,626 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.8078, 0.1233, 0.0689]), new_distribution = tensor([0.8084, 0.1229, 0.0687])
2024-12-05 15:38:04,680 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.8084, 0.1229, 0.0687]), new_distribution = tensor([0.8090, 0.1226, 0.0685])
2024-12-05 15:38:04,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.8090, 0.1226, 0.0685]), new_distribution = tensor([0.8095, 0.1222, 0.0683])
2024-12-05 15:38:04,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.8095, 0.1222, 0.0683]), new_distribution = tensor([0.8101, 0.1218, 0.0681])
2024-12-05 15:38:04,841 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.8101, 0.1218, 0.0681]), new_distribution = tensor([0.8107, 0.1214, 0.0679])
2024-12-05 15:38:04,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.8107, 0.1214, 0.0679]), new_distribution = tensor([0.8112, 0.1211, 0.0677])
2024-12-05 15:38:04,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.8112, 0.1211, 0.0677]), new_distribution = tensor([0.8118, 0.1207, 0.0675])
2024-12-05 15:38:05,002 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.8118, 0.1207, 0.0675]), new_distribution = tensor([0.8124, 0.1203, 0.0673])
2024-12-05 15:38:05,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.8124, 0.1203, 0.0673]), new_distribution = tensor([0.8129, 0.1200, 0.0671])
2024-12-05 15:38:05,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.8129, 0.1200, 0.0671]), new_distribution = tensor([0.8135, 0.1196, 0.0669])
2024-12-05 15:38:05,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.8135, 0.1196, 0.0669]), new_distribution = tensor([0.8140, 0.1193, 0.0667])
2024-12-05 15:38:05,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.8140, 0.1193, 0.0667]), new_distribution = tensor([0.8146, 0.1189, 0.0665])
2024-12-05 15:38:05,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.8146, 0.1189, 0.0665]), new_distribution = tensor([0.8152, 0.1185, 0.0663])
2024-12-05 15:38:05,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.8152, 0.1185, 0.0663]), new_distribution = tensor([0.8157, 0.1182, 0.0661])
2024-12-05 15:38:05,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.8157, 0.1182, 0.0661]), new_distribution = tensor([0.8163, 0.1178, 0.0659])
2024-12-05 15:38:05,436 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.8163, 0.1178, 0.0659]), new_distribution = tensor([0.8168, 0.1174, 0.0657])
2024-12-05 15:38:05,490 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.8168, 0.1174, 0.0657]), new_distribution = tensor([0.8174, 0.1171, 0.0655])
2024-12-05 15:38:05,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.8174, 0.1171, 0.0655]), new_distribution = tensor([0.8179, 0.1167, 0.0654])
2024-12-05 15:38:05,597 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.8179, 0.1167, 0.0654]), new_distribution = tensor([0.8185, 0.1164, 0.0652])
2024-12-05 15:38:05,651 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.8185, 0.1164, 0.0652]), new_distribution = tensor([0.8190, 0.1160, 0.0650])
2024-12-05 15:38:05,705 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.8190, 0.1160, 0.0650]), new_distribution = tensor([0.8196, 0.1157, 0.0648])
2024-12-05 15:38:05,759 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.8196, 0.1157, 0.0648]), new_distribution = tensor([0.8201, 0.1153, 0.0646])
2024-12-05 15:38:05,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.8201, 0.1153, 0.0646]), new_distribution = tensor([0.8206, 0.1149, 0.0644])
2024-12-05 15:38:05,867 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.8206, 0.1149, 0.0644]), new_distribution = tensor([0.8212, 0.1146, 0.0642])
2024-12-05 15:38:05,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.8212, 0.1146, 0.0642]), new_distribution = tensor([0.8217, 0.1142, 0.0640])
2024-12-05 15:38:05,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.8217, 0.1142, 0.0640]), new_distribution = tensor([0.8223, 0.1139, 0.0638])
2024-12-05 15:38:06,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.8223, 0.1139, 0.0638]), new_distribution = tensor([0.8228, 0.1135, 0.0637])
2024-12-05 15:38:06,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.8228, 0.1135, 0.0637]), new_distribution = tensor([0.8233, 0.1132, 0.0635])
2024-12-05 15:38:06,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.8233, 0.1132, 0.0635]), new_distribution = tensor([0.8239, 0.1128, 0.0633])
2024-12-05 15:38:06,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.8239, 0.1128, 0.0633]), new_distribution = tensor([0.8244, 0.1125, 0.0631])
2024-12-05 15:38:06,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.8244, 0.1125, 0.0631]), new_distribution = tensor([0.8249, 0.1121, 0.0629])
2024-12-05 15:38:06,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.8249, 0.1121, 0.0629]), new_distribution = tensor([0.8255, 0.1118, 0.0627])
2024-12-05 15:38:06,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.8255, 0.1118, 0.0627]), new_distribution = tensor([0.8260, 0.1114, 0.0626])
2024-12-05 15:38:06,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.8260, 0.1114, 0.0626]), new_distribution = tensor([0.8265, 0.1111, 0.0624])
2024-12-05 15:38:06,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.8265, 0.1111, 0.0624]), new_distribution = tensor([0.8271, 0.1108, 0.0622])
2024-12-05 15:38:06,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.8271, 0.1108, 0.0622]), new_distribution = tensor([0.8276, 0.1104, 0.0620])
2024-12-05 15:38:06,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.8276, 0.1104, 0.0620]), new_distribution = tensor([0.8281, 0.1101, 0.0618])
2024-12-05 15:38:06,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.8281, 0.1101, 0.0618]), new_distribution = tensor([0.8286, 0.1097, 0.0616])
2024-12-05 15:38:06,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.8286, 0.1097, 0.0616]), new_distribution = tensor([0.8292, 0.1094, 0.0615])
2024-12-05 15:38:06,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.8292, 0.1094, 0.0615]), new_distribution = tensor([0.8297, 0.1090, 0.0613])
2024-12-05 15:38:06,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.8297, 0.1090, 0.0613]), new_distribution = tensor([0.8302, 0.1087, 0.0611])
2024-12-05 15:38:06,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.8302, 0.1087, 0.0611]), new_distribution = tensor([0.8307, 0.1084, 0.0609])
2024-12-05 15:38:06,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.8307, 0.1084, 0.0609]), new_distribution = tensor([0.8312, 0.1080, 0.0608])
2024-12-05 15:38:06,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.8312, 0.1080, 0.0608]), new_distribution = tensor([0.8317, 0.1077, 0.0606])
2024-12-05 15:38:07,001 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.8317, 0.1077, 0.0606]), new_distribution = tensor([0.8323, 0.1073, 0.0604])
2024-12-05 15:38:07,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.8323, 0.1073, 0.0604]), new_distribution = tensor([0.8328, 0.1070, 0.0602])
2024-12-05 15:38:07,110 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.8328, 0.1070, 0.0602]), new_distribution = tensor([0.8333, 0.1067, 0.0600])
2024-12-05 15:38:07,166 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.8333, 0.1067, 0.0600]), new_distribution = tensor([0.8338, 0.1063, 0.0599])
2024-12-05 15:38:07,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.8338, 0.1063, 0.0599]), new_distribution = tensor([0.8343, 0.1060, 0.0597])
2024-12-05 15:38:07,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.8343, 0.1060, 0.0597]), new_distribution = tensor([0.8348, 0.1057, 0.0595])
2024-12-05 15:38:07,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.8348, 0.1057, 0.0595]), new_distribution = tensor([0.8353, 0.1053, 0.0594])
2024-12-05 15:38:07,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.8353, 0.1053, 0.0594]), new_distribution = tensor([0.8358, 0.1050, 0.0592])
2024-12-05 15:38:07,435 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.8358, 0.1050, 0.0592]), new_distribution = tensor([0.8363, 0.1047, 0.0590])
2024-12-05 15:38:07,489 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([0.8363, 0.1047, 0.0590]), new_distribution = tensor([0.8368, 0.1043, 0.0588])
2024-12-05 15:38:07,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([0.8368, 0.1043, 0.0588]), new_distribution = tensor([0.8373, 0.1040, 0.0587])
2024-12-05 15:38:07,597 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([0.8373, 0.1040, 0.0587]), new_distribution = tensor([0.8378, 0.1037, 0.0585])
2024-12-05 15:38:07,650 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([0.8378, 0.1037, 0.0585]), new_distribution = tensor([0.8383, 0.1034, 0.0583])
2024-12-05 15:38:07,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([0.8383, 0.1034, 0.0583]), new_distribution = tensor([0.8388, 0.1030, 0.0582])
2024-12-05 15:38:07,758 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([0.8388, 0.1030, 0.0582]), new_distribution = tensor([0.8393, 0.1027, 0.0580])
2024-12-05 15:38:07,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([0.8393, 0.1027, 0.0580]), new_distribution = tensor([0.8398, 0.1024, 0.0578])
2024-12-05 15:38:07,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([0.8398, 0.1024, 0.0578]), new_distribution = tensor([0.8403, 0.1020, 0.0576])
2024-12-05 15:38:07,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([0.8403, 0.1020, 0.0576]), new_distribution = tensor([0.8408, 0.1017, 0.0575])
2024-12-05 15:38:07,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([0.8408, 0.1017, 0.0575]), new_distribution = tensor([0.8413, 0.1014, 0.0573])
2024-12-05 15:38:08,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([0.8413, 0.1014, 0.0573]), new_distribution = tensor([0.8418, 0.1011, 0.0571])
2024-12-05 15:38:08,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([0.8418, 0.1011, 0.0571]), new_distribution = tensor([0.8423, 0.1008, 0.0570])
2024-12-05 15:38:08,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([0.8423, 0.1008, 0.0570]), new_distribution = tensor([0.8428, 0.1004, 0.0568])
2024-12-05 15:38:08,189 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([0.8428, 0.1004, 0.0568]), new_distribution = tensor([0.8432, 0.1001, 0.0566])
2024-12-05 15:38:08,243 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([0.8432, 0.1001, 0.0566]), new_distribution = tensor([0.8437, 0.0998, 0.0565])
2024-12-05 15:38:08,297 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([0.8437, 0.0998, 0.0565]), new_distribution = tensor([0.8442, 0.0995, 0.0563])
2024-12-05 15:38:08,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([0.8442, 0.0995, 0.0563]), new_distribution = tensor([0.8447, 0.0992, 0.0561])
2024-12-05 15:38:08,405 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([0.8447, 0.0992, 0.0561]), new_distribution = tensor([0.8452, 0.0988, 0.0560])
2024-12-05 15:38:08,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([0.8452, 0.0988, 0.0560]), new_distribution = tensor([0.8457, 0.0985, 0.0558])
2024-12-05 15:38:08,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([0.8457, 0.0985, 0.0558]), new_distribution = tensor([0.8461, 0.0982, 0.0557])
2024-12-05 15:38:08,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([0.8461, 0.0982, 0.0557]), new_distribution = tensor([0.8466, 0.0979, 0.0555])
2024-12-05 15:38:08,621 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([0.8466, 0.0979, 0.0555]), new_distribution = tensor([0.8471, 0.0976, 0.0553])
2024-12-05 15:38:08,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([0.8471, 0.0976, 0.0553]), new_distribution = tensor([0.8476, 0.0973, 0.0552])
2024-12-05 15:38:08,729 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([0.8476, 0.0973, 0.0552]), new_distribution = tensor([0.8480, 0.0970, 0.0550])
2024-12-05 15:38:08,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([0.8480, 0.0970, 0.0550]), new_distribution = tensor([0.8485, 0.0966, 0.0548])
2024-12-05 15:38:08,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([0.8485, 0.0966, 0.0548]), new_distribution = tensor([0.8490, 0.0963, 0.0547])
2024-12-05 15:38:08,891 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([0.8490, 0.0963, 0.0547]), new_distribution = tensor([0.8495, 0.0960, 0.0545])
2024-12-05 15:38:08,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([0.8495, 0.0960, 0.0545]), new_distribution = tensor([0.8499, 0.0957, 0.0544])
2024-12-05 15:38:08,998 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([0.8499, 0.0957, 0.0544]), new_distribution = tensor([0.8504, 0.0954, 0.0542])
2024-12-05 15:38:09,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([0.8504, 0.0954, 0.0542]), new_distribution = tensor([0.8509, 0.0951, 0.0540])
2024-12-05 15:38:09,106 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([0.8509, 0.0951, 0.0540]), new_distribution = tensor([0.8513, 0.0948, 0.0539])
2024-12-05 15:38:09,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([0.8513, 0.0948, 0.0539]), new_distribution = tensor([0.8518, 0.0945, 0.0537])
2024-12-05 15:38:09,214 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([0.8518, 0.0945, 0.0537]), new_distribution = tensor([0.8523, 0.0942, 0.0536])
2024-12-05 15:38:09,267 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([0.8523, 0.0942, 0.0536]), new_distribution = tensor([0.8527, 0.0939, 0.0534])
2024-12-05 15:38:09,321 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([0.8527, 0.0939, 0.0534]), new_distribution = tensor([0.8532, 0.0936, 0.0533])
2024-12-05 15:38:09,375 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([0.8532, 0.0936, 0.0533]), new_distribution = tensor([0.8536, 0.0933, 0.0531])
2024-12-05 15:38:09,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([0.8536, 0.0933, 0.0531]), new_distribution = tensor([0.8541, 0.0930, 0.0530])
2024-12-05 15:38:09,483 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([0.8541, 0.0930, 0.0530]), new_distribution = tensor([0.8545, 0.0927, 0.0528])
2024-12-05 15:38:09,537 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([0.8545, 0.0927, 0.0528]), new_distribution = tensor([0.8550, 0.0924, 0.0526])
2024-12-05 15:38:09,590 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([0.8550, 0.0924, 0.0526]), new_distribution = tensor([0.8555, 0.0921, 0.0525])
2024-12-05 15:38:09,644 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([0.8555, 0.0921, 0.0525]), new_distribution = tensor([0.8559, 0.0918, 0.0523])
2024-12-05 15:38:09,698 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([0.8559, 0.0918, 0.0523]), new_distribution = tensor([0.8564, 0.0915, 0.0522])
2024-12-05 15:38:09,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([0.8564, 0.0915, 0.0522]), new_distribution = tensor([0.8568, 0.0912, 0.0520])
2024-12-05 15:38:09,806 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([0.8568, 0.0912, 0.0520]), new_distribution = tensor([0.8573, 0.0909, 0.0519])
2024-12-05 15:38:09,860 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([0.8573, 0.0909, 0.0519]), new_distribution = tensor([0.8577, 0.0906, 0.0517])
2024-12-05 15:38:09,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([0.8577, 0.0906, 0.0517]), new_distribution = tensor([0.8582, 0.0903, 0.0516])
2024-12-05 15:38:09,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([0.8582, 0.0903, 0.0516]), new_distribution = tensor([0.8586, 0.0900, 0.0514])
2024-12-05 15:38:10,021 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([0.8586, 0.0900, 0.0514]), new_distribution = tensor([0.8591, 0.0897, 0.0513])
2024-12-05 15:38:10,075 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([0.8591, 0.0897, 0.0513]), new_distribution = tensor([0.8595, 0.0894, 0.0511])
2024-12-05 15:38:10,128 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([0.8595, 0.0894, 0.0511]), new_distribution = tensor([0.8599, 0.0891, 0.0510])
2024-12-05 15:38:10,182 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([0.8599, 0.0891, 0.0510]), new_distribution = tensor([0.8604, 0.0888, 0.0508])
2024-12-05 15:38:10,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([0.8604, 0.0888, 0.0508]), new_distribution = tensor([0.8608, 0.0885, 0.0507])
2024-12-05 15:38:10,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([0.8608, 0.0885, 0.0507]), new_distribution = tensor([0.8613, 0.0882, 0.0505])
2024-12-05 15:38:10,344 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([0.8613, 0.0882, 0.0505]), new_distribution = tensor([0.8617, 0.0879, 0.0504])
2024-12-05 15:38:10,398 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([0.8617, 0.0879, 0.0504]), new_distribution = tensor([0.8621, 0.0876, 0.0502])
2024-12-05 15:38:10,452 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([0.8621, 0.0876, 0.0502]), new_distribution = tensor([0.8626, 0.0873, 0.0501])
2024-12-05 15:38:10,506 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([0.8626, 0.0873, 0.0501]), new_distribution = tensor([0.8630, 0.0871, 0.0499])
2024-12-05 15:38:10,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([0.8630, 0.0871, 0.0499]), new_distribution = tensor([0.8634, 0.0868, 0.0498])
2024-12-05 15:38:10,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([0.8634, 0.0868, 0.0498]), new_distribution = tensor([0.8639, 0.0865, 0.0496])
2024-12-05 15:38:10,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([0.8639, 0.0865, 0.0496]), new_distribution = tensor([0.8643, 0.0862, 0.0495])
2024-12-05 15:38:10,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([0.8643, 0.0862, 0.0495]), new_distribution = tensor([0.8647, 0.0859, 0.0494])
2024-12-05 15:38:10,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([0.8647, 0.0859, 0.0494]), new_distribution = tensor([0.8652, 0.0856, 0.0492])
2024-12-05 15:38:10,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([0.8652, 0.0856, 0.0492]), new_distribution = tensor([0.8656, 0.0854, 0.0491])
2024-12-05 15:38:10,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([0.8656, 0.0854, 0.0491]), new_distribution = tensor([0.8660, 0.0851, 0.0489])
2024-12-05 15:38:10,936 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([0.8660, 0.0851, 0.0489]), new_distribution = tensor([0.8664, 0.0848, 0.0488])
2024-12-05 15:38:10,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([0.8664, 0.0848, 0.0488]), new_distribution = tensor([0.8669, 0.0845, 0.0486])
2024-12-05 15:38:11,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([0.8669, 0.0845, 0.0486]), new_distribution = tensor([0.8673, 0.0842, 0.0485])
2024-12-05 15:38:11,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([0.8673, 0.0842, 0.0485]), new_distribution = tensor([0.8677, 0.0839, 0.0483])
2024-12-05 15:38:11,152 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([0.8677, 0.0839, 0.0483]), new_distribution = tensor([0.8681, 0.0837, 0.0482])
2024-12-05 15:38:11,206 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([0.8681, 0.0837, 0.0482]), new_distribution = tensor([0.8685, 0.0834, 0.0481])
2024-12-05 15:38:11,260 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([0.8685, 0.0834, 0.0481]), new_distribution = tensor([0.8690, 0.0831, 0.0479])
2024-12-05 15:38:11,314 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([0.8690, 0.0831, 0.0479]), new_distribution = tensor([0.8694, 0.0828, 0.0478])
2024-12-05 15:38:11,368 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([0.8694, 0.0828, 0.0478]), new_distribution = tensor([0.8698, 0.0826, 0.0476])
2024-12-05 15:38:11,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([0.8698, 0.0826, 0.0476]), new_distribution = tensor([0.8702, 0.0823, 0.0475])
2024-12-05 15:38:11,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([0.8702, 0.0823, 0.0475]), new_distribution = tensor([0.8706, 0.0820, 0.0474])
2024-12-05 15:38:11,529 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([0.8706, 0.0820, 0.0474]), new_distribution = tensor([0.8710, 0.0817, 0.0472])
2024-12-05 15:38:11,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([0.8710, 0.0817, 0.0472]), new_distribution = tensor([0.8714, 0.0815, 0.0471])
2024-12-05 15:38:11,637 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([0.8714, 0.0815, 0.0471]), new_distribution = tensor([0.8719, 0.0812, 0.0470])
2024-12-05 15:38:11,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([0.8719, 0.0812, 0.0470]), new_distribution = tensor([0.8723, 0.0809, 0.0468])
2024-12-05 15:38:11,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([0.8723, 0.0809, 0.0468]), new_distribution = tensor([0.8727, 0.0807, 0.0467])
2024-12-05 15:38:11,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([0.8727, 0.0807, 0.0467]), new_distribution = tensor([0.8731, 0.0804, 0.0465])
2024-12-05 15:38:11,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([0.8731, 0.0804, 0.0465]), new_distribution = tensor([0.8735, 0.0801, 0.0464])
2024-12-05 15:38:11,907 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([0.8735, 0.0801, 0.0464]), new_distribution = tensor([0.8739, 0.0799, 0.0463])
2024-12-05 15:38:11,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([0.8739, 0.0799, 0.0463]), new_distribution = tensor([0.8743, 0.0796, 0.0461])
2024-12-05 15:38:12,021 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([0.8743, 0.0796, 0.0461]), new_distribution = tensor([0.8747, 0.0793, 0.0460])
2024-12-05 15:38:12,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([0.8747, 0.0793, 0.0460]), new_distribution = tensor([0.8751, 0.0791, 0.0459])
2024-12-05 15:38:12,213 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([0.8751, 0.0791, 0.0459]), new_distribution = tensor([0.8755, 0.0788, 0.0457])
2024-12-05 15:38:12,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([0.8755, 0.0788, 0.0457]), new_distribution = tensor([0.8759, 0.0785, 0.0456])
2024-12-05 15:38:12,420 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([0.8759, 0.0785, 0.0456]), new_distribution = tensor([0.8763, 0.0783, 0.0455])
2024-12-05 15:38:12,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([0.8763, 0.0783, 0.0455]), new_distribution = tensor([0.8767, 0.0780, 0.0453])
2024-12-05 15:38:12,630 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([0.8767, 0.0780, 0.0453]), new_distribution = tensor([0.8771, 0.0777, 0.0452])
2024-12-05 15:38:12,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([0.8771, 0.0777, 0.0452]), new_distribution = tensor([0.8775, 0.0775, 0.0451])
2024-12-05 15:38:12,841 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([0.8775, 0.0775, 0.0451]), new_distribution = tensor([0.8779, 0.0772, 0.0449])
2024-12-05 15:38:12,946 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([0.8779, 0.0772, 0.0449]), new_distribution = tensor([0.8783, 0.0770, 0.0448])
2024-12-05 15:38:13,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([0.8783, 0.0770, 0.0448]), new_distribution = tensor([0.8786, 0.0767, 0.0447])
2024-12-05 15:38:13,156 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([0.8786, 0.0767, 0.0447]), new_distribution = tensor([0.8790, 0.0764, 0.0445])
2024-12-05 15:38:13,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([0.8790, 0.0764, 0.0445]), new_distribution = tensor([0.8794, 0.0762, 0.0444])
2024-12-05 15:38:13,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([0.8794, 0.0762, 0.0444]), new_distribution = tensor([0.8798, 0.0759, 0.0443])
2024-12-05 15:38:13,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([0.8798, 0.0759, 0.0443]), new_distribution = tensor([0.8802, 0.0757, 0.0441])
2024-12-05 15:38:13,575 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([0.8802, 0.0757, 0.0441]), new_distribution = tensor([0.8806, 0.0754, 0.0440])
2024-12-05 15:38:13,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([0.8806, 0.0754, 0.0440]), new_distribution = tensor([0.8810, 0.0751, 0.0439])
2024-12-05 15:38:13,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([0.8810, 0.0751, 0.0439]), new_distribution = tensor([0.8814, 0.0749, 0.0438])
2024-12-05 15:38:13,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([0.8814, 0.0749, 0.0438]), new_distribution = tensor([0.8817, 0.0746, 0.0436])
2024-12-05 15:38:13,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([0.8817, 0.0746, 0.0436]), new_distribution = tensor([0.8821, 0.0744, 0.0435])
2024-12-05 15:38:14,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([0.8821, 0.0744, 0.0435]), new_distribution = tensor([0.8825, 0.0741, 0.0434])
2024-12-05 15:38:14,111 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([0.8825, 0.0741, 0.0434]), new_distribution = tensor([0.8829, 0.0739, 0.0432])
2024-12-05 15:38:14,185 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([0.8829, 0.0739, 0.0432]), new_distribution = tensor([0.8833, 0.0736, 0.0431])
2024-12-05 15:38:14,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([0.8833, 0.0736, 0.0431]), new_distribution = tensor([0.8836, 0.0734, 0.0430])
2024-12-05 15:38:14,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([0.8836, 0.0734, 0.0430]), new_distribution = tensor([0.8840, 0.0731, 0.0429])
2024-12-05 15:38:14,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([0.8840, 0.0731, 0.0429]), new_distribution = tensor([0.8844, 0.0729, 0.0427])
2024-12-05 15:38:14,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([0.8844, 0.0729, 0.0427]), new_distribution = tensor([0.8848, 0.0726, 0.0426])
2024-12-05 15:38:14,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([0.8848, 0.0726, 0.0426]), new_distribution = tensor([0.8851, 0.0724, 0.0425])
2024-12-05 15:38:14,556 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([0.8851, 0.0724, 0.0425]), new_distribution = tensor([0.8855, 0.0721, 0.0424])
2024-12-05 15:38:14,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([0.8855, 0.0721, 0.0424]), new_distribution = tensor([0.8859, 0.0719, 0.0422])
2024-12-05 15:38:14,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([0.8859, 0.0719, 0.0422]), new_distribution = tensor([0.8862, 0.0717, 0.0421])
2024-12-05 15:38:14,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([0.8862, 0.0717, 0.0421]), new_distribution = tensor([0.8866, 0.0714, 0.0420])
2024-12-05 15:38:14,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([0.8866, 0.0714, 0.0420]), new_distribution = tensor([0.8870, 0.0712, 0.0419])
2024-12-05 15:38:14,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([0.8870, 0.0712, 0.0419]), new_distribution = tensor([0.8873, 0.0709, 0.0417])
2024-12-05 15:38:14,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([0.8873, 0.0709, 0.0417]), new_distribution = tensor([0.8877, 0.0707, 0.0416])
2024-12-05 15:38:14,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([0.8877, 0.0707, 0.0416]), new_distribution = tensor([0.8881, 0.0704, 0.0415])
2024-12-05 15:38:14,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([0.8881, 0.0704, 0.0415]), new_distribution = tensor([0.8884, 0.0702, 0.0414])
2024-12-05 15:38:15,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([0.8884, 0.0702, 0.0414]), new_distribution = tensor([0.8888, 0.0700, 0.0413])
2024-12-05 15:38:15,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([0.8888, 0.0700, 0.0413]), new_distribution = tensor([0.8891, 0.0697, 0.0411])
2024-12-05 15:38:15,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([0.8891, 0.0697, 0.0411]), new_distribution = tensor([0.8895, 0.0695, 0.0410])
2024-12-05 15:38:15,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([0.8895, 0.0695, 0.0410]), new_distribution = tensor([0.8899, 0.0692, 0.0409])
2024-12-05 15:38:15,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([0.8899, 0.0692, 0.0409]), new_distribution = tensor([0.8902, 0.0690, 0.0408])
2024-12-05 15:38:15,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([0.8902, 0.0690, 0.0408]), new_distribution = tensor([0.8906, 0.0688, 0.0406])
2024-12-05 15:38:15,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([0.8906, 0.0688, 0.0406]), new_distribution = tensor([0.8909, 0.0685, 0.0405])
2024-12-05 15:38:15,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([0.8909, 0.0685, 0.0405]), new_distribution = tensor([0.8913, 0.0683, 0.0404])
2024-12-05 15:38:15,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([0.8913, 0.0683, 0.0404]), new_distribution = tensor([0.8916, 0.0681, 0.0403])
2024-12-05 15:38:15,526 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([0.8916, 0.0681, 0.0403]), new_distribution = tensor([0.8920, 0.0678, 0.0402])
2024-12-05 15:38:15,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([0.8920, 0.0678, 0.0402]), new_distribution = tensor([0.8923, 0.0676, 0.0401])
2024-12-05 15:38:15,634 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([0.8923, 0.0676, 0.0401]), new_distribution = tensor([0.8927, 0.0674, 0.0399])
2024-12-05 15:38:15,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([0.8927, 0.0674, 0.0399]), new_distribution = tensor([0.8930, 0.0671, 0.0398])
2024-12-05 15:38:15,742 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([0.8930, 0.0671, 0.0398]), new_distribution = tensor([0.8934, 0.0669, 0.0397])
2024-12-05 15:38:15,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([0.8934, 0.0669, 0.0397]), new_distribution = tensor([0.8937, 0.0667, 0.0396])
2024-12-05 15:38:15,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([0.8937, 0.0667, 0.0396]), new_distribution = tensor([0.8941, 0.0664, 0.0395])
2024-12-05 15:38:15,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([0.8941, 0.0664, 0.0395]), new_distribution = tensor([0.8944, 0.0662, 0.0394])
2024-12-05 15:38:15,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([0.8944, 0.0662, 0.0394]), new_distribution = tensor([0.8948, 0.0660, 0.0392])
2024-12-05 15:38:16,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([0.8948, 0.0660, 0.0392]), new_distribution = tensor([0.8951, 0.0658, 0.0391])
2024-12-05 15:38:16,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([0.8951, 0.0658, 0.0391]), new_distribution = tensor([0.8955, 0.0655, 0.0390])
2024-12-05 15:38:16,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([0.8955, 0.0655, 0.0390]), new_distribution = tensor([0.8958, 0.0653, 0.0389])
2024-12-05 15:38:16,174 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([0.8958, 0.0653, 0.0389]), new_distribution = tensor([0.8961, 0.0651, 0.0388])
2024-12-05 15:38:16,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([0.8961, 0.0651, 0.0388]), new_distribution = tensor([0.8965, 0.0648, 0.0387])
2024-12-05 15:38:16,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([0.8965, 0.0648, 0.0387]), new_distribution = tensor([0.8968, 0.0646, 0.0386])
2024-12-05 15:38:16,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([0.8968, 0.0646, 0.0386]), new_distribution = tensor([0.8972, 0.0644, 0.0384])
2024-12-05 15:38:16,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([0.8972, 0.0644, 0.0384]), new_distribution = tensor([0.8975, 0.0642, 0.0383])
2024-12-05 15:38:16,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([0.8975, 0.0642, 0.0383]), new_distribution = tensor([0.8978, 0.0640, 0.0382])
2024-12-05 15:38:16,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([0.8978, 0.0640, 0.0382]), new_distribution = tensor([0.8982, 0.0637, 0.0381])
2024-12-05 15:38:16,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([0.8982, 0.0637, 0.0381]), new_distribution = tensor([0.8985, 0.0635, 0.0380])
2024-12-05 15:38:16,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([0.8985, 0.0635, 0.0380]), new_distribution = tensor([0.8988, 0.0633, 0.0379])
2024-12-05 15:38:16,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([0.8988, 0.0633, 0.0379]), new_distribution = tensor([0.8992, 0.0631, 0.0378])
2024-12-05 15:38:16,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([0.8992, 0.0631, 0.0378]), new_distribution = tensor([0.8995, 0.0629, 0.0377])
2024-12-05 15:38:16,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([0.8995, 0.0629, 0.0377]), new_distribution = tensor([0.8998, 0.0626, 0.0375])
2024-12-05 15:38:16,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([0.8998, 0.0626, 0.0375]), new_distribution = tensor([0.9002, 0.0624, 0.0374])
2024-12-05 15:38:16,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([0.9002, 0.0624, 0.0374]), new_distribution = tensor([0.9005, 0.0622, 0.0373])
2024-12-05 15:38:16,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([0.9005, 0.0622, 0.0373]), new_distribution = tensor([0.9008, 0.0620, 0.0372])
2024-12-05 15:38:16,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([0.9008, 0.0620, 0.0372]), new_distribution = tensor([0.9011, 0.0618, 0.0371])
2024-12-05 15:38:17,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([0.9011, 0.0618, 0.0371]), new_distribution = tensor([0.9015, 0.0616, 0.0370])
2024-12-05 15:38:17,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([0.9015, 0.0616, 0.0370]), new_distribution = tensor([0.9018, 0.0613, 0.0369])
2024-12-05 15:38:17,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([0.9018, 0.0613, 0.0369]), new_distribution = tensor([0.9021, 0.0611, 0.0368])
2024-12-05 15:38:17,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([0.9021, 0.0611, 0.0368]), new_distribution = tensor([0.9024, 0.0609, 0.0367])
2024-12-05 15:38:17,260 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([0.9024, 0.0609, 0.0367]), new_distribution = tensor([0.9027, 0.0607, 0.0366])
2024-12-05 15:38:17,314 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([0.9027, 0.0607, 0.0366]), new_distribution = tensor([0.9031, 0.0605, 0.0365])
2024-12-05 15:38:17,368 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([0.9031, 0.0605, 0.0365]), new_distribution = tensor([0.9034, 0.0603, 0.0363])
2024-12-05 15:38:17,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([0.9034, 0.0603, 0.0363]), new_distribution = tensor([0.9037, 0.0601, 0.0362])
2024-12-05 15:38:17,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([0.9037, 0.0601, 0.0362]), new_distribution = tensor([0.9040, 0.0599, 0.0361])
2024-12-05 15:38:17,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([0.9040, 0.0599, 0.0361]), new_distribution = tensor([0.9043, 0.0596, 0.0360])
2024-12-05 15:38:17,584 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([0.9043, 0.0596, 0.0360]), new_distribution = tensor([0.9047, 0.0594, 0.0359])
2024-12-05 15:38:17,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([0.9047, 0.0594, 0.0359]), new_distribution = tensor([0.9050, 0.0592, 0.0358])
2024-12-05 15:38:17,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([0.9050, 0.0592, 0.0358]), new_distribution = tensor([0.9053, 0.0590, 0.0357])
2024-12-05 15:38:17,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([0.9053, 0.0590, 0.0357]), new_distribution = tensor([0.9056, 0.0588, 0.0356])
2024-12-05 15:38:17,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([0.9056, 0.0588, 0.0356]), new_distribution = tensor([0.9059, 0.0586, 0.0355])
2024-12-05 15:38:17,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([0.9059, 0.0586, 0.0355]), new_distribution = tensor([0.9062, 0.0584, 0.0354])
2024-12-05 15:38:17,907 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([0.9062, 0.0584, 0.0354]), new_distribution = tensor([0.9065, 0.0582, 0.0353])
2024-12-05 15:38:17,961 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([0.9065, 0.0582, 0.0353]), new_distribution = tensor([0.9068, 0.0580, 0.0352])
2024-12-05 15:38:18,015 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([0.9068, 0.0580, 0.0352]), new_distribution = tensor([0.9071, 0.0578, 0.0351])
2024-12-05 15:38:18,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([0.9071, 0.0578, 0.0351]), new_distribution = tensor([0.9074, 0.0576, 0.0350])
2024-12-05 15:38:18,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([0.9074, 0.0576, 0.0350]), new_distribution = tensor([0.9077, 0.0574, 0.0349])
2024-12-05 15:38:18,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([0.9077, 0.0574, 0.0349]), new_distribution = tensor([0.9081, 0.0572, 0.0348])
2024-12-05 15:38:18,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([0.9081, 0.0572, 0.0348]), new_distribution = tensor([0.9084, 0.0570, 0.0347])
2024-12-05 15:38:18,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([0.9084, 0.0570, 0.0347]), new_distribution = tensor([0.9087, 0.0568, 0.0346])
2024-12-05 15:38:18,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([0.9087, 0.0568, 0.0346]), new_distribution = tensor([0.9090, 0.0566, 0.0345])
2024-12-05 15:38:18,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([0.9090, 0.0566, 0.0345]), new_distribution = tensor([0.9093, 0.0564, 0.0344])
2024-12-05 15:38:18,448 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([0.9093, 0.0564, 0.0344]), new_distribution = tensor([0.9096, 0.0562, 0.0343])
2024-12-05 15:38:18,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([0.9096, 0.0562, 0.0343]), new_distribution = tensor([0.9099, 0.0560, 0.0342])
2024-12-05 15:38:18,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([0.9099, 0.0560, 0.0342]), new_distribution = tensor([0.9102, 0.0558, 0.0341])
2024-12-05 15:38:18,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([0.9102, 0.0558, 0.0341]), new_distribution = tensor([0.9105, 0.0556, 0.0340])
2024-12-05 15:38:18,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([0.9105, 0.0556, 0.0340]), new_distribution = tensor([0.9108, 0.0554, 0.0339])
2024-12-05 15:38:18,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([0.9108, 0.0554, 0.0339]), new_distribution = tensor([0.9110, 0.0552, 0.0338])
2024-12-05 15:38:18,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([0.9110, 0.0552, 0.0338]), new_distribution = tensor([0.9113, 0.0550, 0.0337])
2024-12-05 15:38:18,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([0.9113, 0.0550, 0.0337]), new_distribution = tensor([0.9116, 0.0548, 0.0336])
2024-12-05 15:38:18,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([0.9116, 0.0548, 0.0336]), new_distribution = tensor([0.9119, 0.0546, 0.0335])
2024-12-05 15:38:18,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([0.9119, 0.0546, 0.0335]), new_distribution = tensor([0.9122, 0.0544, 0.0334])
2024-12-05 15:38:18,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([0.9122, 0.0544, 0.0334]), new_distribution = tensor([0.9125, 0.0542, 0.0333])
2024-12-05 15:38:19,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([0.9125, 0.0542, 0.0333]), new_distribution = tensor([0.9128, 0.0540, 0.0332])
2024-12-05 15:38:19,096 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([0.9128, 0.0540, 0.0332]), new_distribution = tensor([0.9131, 0.0538, 0.0331])
2024-12-05 15:38:19,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([0.9131, 0.0538, 0.0331]), new_distribution = tensor([0.9134, 0.0536, 0.0330])
2024-12-05 15:38:19,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([0.9134, 0.0536, 0.0330]), new_distribution = tensor([0.9137, 0.0535, 0.0329])
2024-12-05 15:38:19,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([0.9137, 0.0535, 0.0329]), new_distribution = tensor([0.9140, 0.0533, 0.0328])
2024-12-05 15:38:19,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 300: ref_distribution = tensor([0.9140, 0.0533, 0.0328]), new_distribution = tensor([0.9142, 0.0531, 0.0327])
2024-12-05 15:38:19,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 301: ref_distribution = tensor([0.9142, 0.0531, 0.0327]), new_distribution = tensor([0.9145, 0.0529, 0.0326])
2024-12-05 15:38:19,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 302: ref_distribution = tensor([0.9145, 0.0529, 0.0326]), new_distribution = tensor([0.9148, 0.0527, 0.0325])
2024-12-05 15:38:19,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 303: ref_distribution = tensor([0.9148, 0.0527, 0.0325]), new_distribution = tensor([0.9151, 0.0525, 0.0324])
2024-12-05 15:38:19,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 304: ref_distribution = tensor([0.9151, 0.0525, 0.0324]), new_distribution = tensor([0.9154, 0.0523, 0.0323])
2024-12-05 15:38:19,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 305: ref_distribution = tensor([0.9154, 0.0523, 0.0323]), new_distribution = tensor([0.9157, 0.0521, 0.0322])
2024-12-05 15:38:19,636 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 306: ref_distribution = tensor([0.9157, 0.0521, 0.0322]), new_distribution = tensor([0.9159, 0.0520, 0.0321])
2024-12-05 15:38:19,690 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 307: ref_distribution = tensor([0.9159, 0.0520, 0.0321]), new_distribution = tensor([0.9162, 0.0518, 0.0320])
2024-12-05 15:38:19,744 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 308: ref_distribution = tensor([0.9162, 0.0518, 0.0320]), new_distribution = tensor([0.9165, 0.0516, 0.0319])
2024-12-05 15:38:19,798 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 309: ref_distribution = tensor([0.9165, 0.0516, 0.0319]), new_distribution = tensor([0.9168, 0.0514, 0.0318])
2024-12-05 15:38:19,852 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 310: ref_distribution = tensor([0.9168, 0.0514, 0.0318]), new_distribution = tensor([0.9171, 0.0512, 0.0317])
2024-12-05 15:38:19,906 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 311: ref_distribution = tensor([0.9171, 0.0512, 0.0317]), new_distribution = tensor([0.9173, 0.0510, 0.0316])
2024-12-05 15:38:19,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 312: ref_distribution = tensor([0.9173, 0.0510, 0.0316]), new_distribution = tensor([0.9176, 0.0509, 0.0315])
2024-12-05 15:38:20,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 313: ref_distribution = tensor([0.9176, 0.0509, 0.0315]), new_distribution = tensor([0.9179, 0.0507, 0.0314])
2024-12-05 15:38:20,068 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 314: ref_distribution = tensor([0.9179, 0.0507, 0.0314]), new_distribution = tensor([0.9182, 0.0505, 0.0314])
2024-12-05 15:38:20,121 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 315: ref_distribution = tensor([0.9182, 0.0505, 0.0314]), new_distribution = tensor([0.9184, 0.0503, 0.0313])
2024-12-05 15:38:20,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 316: ref_distribution = tensor([0.9184, 0.0503, 0.0313]), new_distribution = tensor([0.9187, 0.0501, 0.0312])
2024-12-05 15:38:20,230 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 317: ref_distribution = tensor([0.9187, 0.0501, 0.0312]), new_distribution = tensor([0.9190, 0.0500, 0.0311])
2024-12-05 15:38:20,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 318: ref_distribution = tensor([0.9190, 0.0500, 0.0311]), new_distribution = tensor([0.9192, 0.0498, 0.0310])
2024-12-05 15:38:20,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 319: ref_distribution = tensor([0.9192, 0.0498, 0.0310]), new_distribution = tensor([0.9195, 0.0496, 0.0309])
2024-12-05 15:38:20,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 320: ref_distribution = tensor([0.9195, 0.0496, 0.0309]), new_distribution = tensor([0.9198, 0.0494, 0.0308])
2024-12-05 15:38:20,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 321: ref_distribution = tensor([0.9198, 0.0494, 0.0308]), new_distribution = tensor([0.9200, 0.0492, 0.0307])
2024-12-05 15:38:20,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 322: ref_distribution = tensor([0.9200, 0.0492, 0.0307]), new_distribution = tensor([0.9203, 0.0491, 0.0306])
2024-12-05 15:38:20,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 323: ref_distribution = tensor([0.9203, 0.0491, 0.0306]), new_distribution = tensor([0.9206, 0.0489, 0.0305])
2024-12-05 15:38:20,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 324: ref_distribution = tensor([0.9206, 0.0489, 0.0305]), new_distribution = tensor([0.9208, 0.0487, 0.0304])
2024-12-05 15:38:20,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 325: ref_distribution = tensor([0.9208, 0.0487, 0.0304]), new_distribution = tensor([0.9211, 0.0485, 0.0304])
2024-12-05 15:38:20,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 326: ref_distribution = tensor([0.9211, 0.0485, 0.0304]), new_distribution = tensor([0.9214, 0.0484, 0.0303])
2024-12-05 15:38:20,770 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 327: ref_distribution = tensor([0.9214, 0.0484, 0.0303]), new_distribution = tensor([0.9216, 0.0482, 0.0302])
2024-12-05 15:38:20,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 328: ref_distribution = tensor([0.9216, 0.0482, 0.0302]), new_distribution = tensor([0.9219, 0.0480, 0.0301])
2024-12-05 15:38:20,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 329: ref_distribution = tensor([0.9219, 0.0480, 0.0301]), new_distribution = tensor([0.9222, 0.0478, 0.0300])
2024-12-05 15:38:20,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 330: ref_distribution = tensor([0.9222, 0.0478, 0.0300]), new_distribution = tensor([0.9224, 0.0477, 0.0299])
2024-12-05 15:38:20,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 331: ref_distribution = tensor([0.9224, 0.0477, 0.0299]), new_distribution = tensor([0.9227, 0.0475, 0.0298])
2024-12-05 15:38:21,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 332: ref_distribution = tensor([0.9227, 0.0475, 0.0298]), new_distribution = tensor([0.9229, 0.0473, 0.0297])
2024-12-05 15:38:21,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 333: ref_distribution = tensor([0.9229, 0.0473, 0.0297]), new_distribution = tensor([0.9232, 0.0472, 0.0296])
2024-12-05 15:38:21,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 334: ref_distribution = tensor([0.9232, 0.0472, 0.0296]), new_distribution = tensor([0.9235, 0.0470, 0.0296])
2024-12-05 15:38:21,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 335: ref_distribution = tensor([0.9235, 0.0470, 0.0296]), new_distribution = tensor([0.9237, 0.0468, 0.0295])
2024-12-05 15:38:21,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 336: ref_distribution = tensor([0.9237, 0.0468, 0.0295]), new_distribution = tensor([0.9240, 0.0467, 0.0294])
2024-12-05 15:38:21,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 337: ref_distribution = tensor([0.9240, 0.0467, 0.0294]), new_distribution = tensor([0.9242, 0.0465, 0.0293])
2024-12-05 15:38:21,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 338: ref_distribution = tensor([0.9242, 0.0465, 0.0293]), new_distribution = tensor([0.9245, 0.0463, 0.0292])
2024-12-05 15:38:21,418 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 339: ref_distribution = tensor([0.9245, 0.0463, 0.0292]), new_distribution = tensor([0.9247, 0.0462, 0.0291])
2024-12-05 15:38:21,472 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 340: ref_distribution = tensor([0.9247, 0.0462, 0.0291]), new_distribution = tensor([0.9250, 0.0460, 0.0290])
2024-12-05 15:38:21,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 341: ref_distribution = tensor([0.9250, 0.0460, 0.0290]), new_distribution = tensor([0.9252, 0.0458, 0.0289])
2024-12-05 15:38:21,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 342: ref_distribution = tensor([0.9252, 0.0458, 0.0289]), new_distribution = tensor([0.9255, 0.0457, 0.0289])
2024-12-05 15:38:21,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 343: ref_distribution = tensor([0.9255, 0.0457, 0.0289]), new_distribution = tensor([0.9257, 0.0455, 0.0288])
2024-12-05 15:38:21,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 344: ref_distribution = tensor([0.9257, 0.0455, 0.0288]), new_distribution = tensor([0.9260, 0.0453, 0.0287])
2024-12-05 15:38:21,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 345: ref_distribution = tensor([0.9260, 0.0453, 0.0287]), new_distribution = tensor([0.9262, 0.0452, 0.0286])
2024-12-05 15:38:21,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 346: ref_distribution = tensor([0.9262, 0.0452, 0.0286]), new_distribution = tensor([0.9265, 0.0450, 0.0285])
2024-12-05 15:38:21,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 347: ref_distribution = tensor([0.9265, 0.0450, 0.0285]), new_distribution = tensor([0.9267, 0.0448, 0.0284])
2024-12-05 15:38:21,902 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 348: ref_distribution = tensor([0.9267, 0.0448, 0.0284]), new_distribution = tensor([0.9270, 0.0447, 0.0284])
2024-12-05 15:38:21,956 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 349: ref_distribution = tensor([0.9270, 0.0447, 0.0284]), new_distribution = tensor([0.9272, 0.0445, 0.0283])
2024-12-05 15:38:22,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 350: ref_distribution = tensor([0.9272, 0.0445, 0.0283]), new_distribution = tensor([0.9275, 0.0444, 0.0282])
2024-12-05 15:38:22,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 351: ref_distribution = tensor([0.9275, 0.0444, 0.0282]), new_distribution = tensor([0.9277, 0.0442, 0.0281])
2024-12-05 15:38:22,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 352: ref_distribution = tensor([0.9277, 0.0442, 0.0281]), new_distribution = tensor([0.9279, 0.0440, 0.0280])
2024-12-05 15:38:22,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 353: ref_distribution = tensor([0.9279, 0.0440, 0.0280]), new_distribution = tensor([0.9282, 0.0439, 0.0279])
2024-12-05 15:38:22,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 354: ref_distribution = tensor([0.9282, 0.0439, 0.0279]), new_distribution = tensor([0.9284, 0.0437, 0.0279])
2024-12-05 15:38:22,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 355: ref_distribution = tensor([0.9284, 0.0437, 0.0279]), new_distribution = tensor([0.9287, 0.0436, 0.0278])
2024-12-05 15:38:22,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 356: ref_distribution = tensor([0.9287, 0.0436, 0.0278]), new_distribution = tensor([0.9289, 0.0434, 0.0277])
2024-12-05 15:38:22,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 357: ref_distribution = tensor([0.9289, 0.0434, 0.0277]), new_distribution = tensor([0.9291, 0.0432, 0.0276])
2024-12-05 15:38:22,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 358: ref_distribution = tensor([0.9291, 0.0432, 0.0276]), new_distribution = tensor([0.9294, 0.0431, 0.0275])
2024-12-05 15:38:22,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 359: ref_distribution = tensor([0.9294, 0.0431, 0.0275]), new_distribution = tensor([0.9296, 0.0429, 0.0274])
2024-12-05 15:38:22,550 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 360: ref_distribution = tensor([0.9296, 0.0429, 0.0274]), new_distribution = tensor([0.9299, 0.0428, 0.0274])
2024-12-05 15:38:22,604 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 361: ref_distribution = tensor([0.9299, 0.0428, 0.0274]), new_distribution = tensor([0.9301, 0.0426, 0.0273])
2024-12-05 15:38:22,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 362: ref_distribution = tensor([0.9301, 0.0426, 0.0273]), new_distribution = tensor([0.9303, 0.0425, 0.0272])
2024-12-05 15:38:22,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 363: ref_distribution = tensor([0.9303, 0.0425, 0.0272]), new_distribution = tensor([0.9306, 0.0423, 0.0271])
2024-12-05 15:38:22,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 364: ref_distribution = tensor([0.9306, 0.0423, 0.0271]), new_distribution = tensor([0.9308, 0.0422, 0.0270])
2024-12-05 15:38:22,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 365: ref_distribution = tensor([0.9308, 0.0422, 0.0270]), new_distribution = tensor([0.9310, 0.0420, 0.0270])
2024-12-05 15:38:22,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 366: ref_distribution = tensor([0.9310, 0.0420, 0.0270]), new_distribution = tensor([0.9313, 0.0418, 0.0269])
2024-12-05 15:38:22,928 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 367: ref_distribution = tensor([0.9313, 0.0418, 0.0269]), new_distribution = tensor([0.9315, 0.0417, 0.0268])
2024-12-05 15:38:22,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 368: ref_distribution = tensor([0.9315, 0.0417, 0.0268]), new_distribution = tensor([0.9317, 0.0415, 0.0267])
2024-12-05 15:38:23,036 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 369: ref_distribution = tensor([0.9317, 0.0415, 0.0267]), new_distribution = tensor([0.9320, 0.0414, 0.0266])
2024-12-05 15:38:23,090 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 370: ref_distribution = tensor([0.9320, 0.0414, 0.0266]), new_distribution = tensor([0.9322, 0.0412, 0.0266])
2024-12-05 15:38:23,144 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 371: ref_distribution = tensor([0.9322, 0.0412, 0.0266]), new_distribution = tensor([0.9324, 0.0411, 0.0265])
2024-12-05 15:38:23,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 372: ref_distribution = tensor([0.9324, 0.0411, 0.0265]), new_distribution = tensor([0.9326, 0.0409, 0.0264])
2024-12-05 15:38:23,252 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 373: ref_distribution = tensor([0.9326, 0.0409, 0.0264]), new_distribution = tensor([0.9329, 0.0408, 0.0263])
2024-12-05 15:38:23,306 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 374: ref_distribution = tensor([0.9329, 0.0408, 0.0263]), new_distribution = tensor([0.9331, 0.0406, 0.0263])
2024-12-05 15:38:23,360 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 375: ref_distribution = tensor([0.9331, 0.0406, 0.0263]), new_distribution = tensor([0.9333, 0.0405, 0.0262])
2024-12-05 15:38:23,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 376: ref_distribution = tensor([0.9333, 0.0405, 0.0262]), new_distribution = tensor([0.9335, 0.0404, 0.0261])
2024-12-05 15:38:23,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 377: ref_distribution = tensor([0.9335, 0.0404, 0.0261]), new_distribution = tensor([0.9338, 0.0402, 0.0260])
2024-12-05 15:38:23,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 378: ref_distribution = tensor([0.9338, 0.0402, 0.0260]), new_distribution = tensor([0.9340, 0.0401, 0.0259])
2024-12-05 15:38:23,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 379: ref_distribution = tensor([0.9340, 0.0401, 0.0259]), new_distribution = tensor([0.9342, 0.0399, 0.0259])
2024-12-05 15:38:23,630 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 380: ref_distribution = tensor([0.9342, 0.0399, 0.0259]), new_distribution = tensor([0.9344, 0.0398, 0.0258])
2024-12-05 15:38:23,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 381: ref_distribution = tensor([0.9344, 0.0398, 0.0258]), new_distribution = tensor([0.9347, 0.0396, 0.0257])
2024-12-05 15:38:23,738 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 382: ref_distribution = tensor([0.9347, 0.0396, 0.0257]), new_distribution = tensor([0.9349, 0.0395, 0.0256])
2024-12-05 15:38:23,792 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 383: ref_distribution = tensor([0.9349, 0.0395, 0.0256]), new_distribution = tensor([0.9351, 0.0393, 0.0256])
2024-12-05 15:38:23,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 384: ref_distribution = tensor([0.9351, 0.0393, 0.0256]), new_distribution = tensor([0.9353, 0.0392, 0.0255])
2024-12-05 15:38:23,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 385: ref_distribution = tensor([0.9353, 0.0392, 0.0255]), new_distribution = tensor([0.9355, 0.0390, 0.0254])
2024-12-05 15:38:23,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 386: ref_distribution = tensor([0.9355, 0.0390, 0.0254]), new_distribution = tensor([0.9358, 0.0389, 0.0253])
2024-12-05 15:38:24,007 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 387: ref_distribution = tensor([0.9358, 0.0389, 0.0253]), new_distribution = tensor([0.9360, 0.0388, 0.0253])
2024-12-05 15:38:24,061 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 388: ref_distribution = tensor([0.9360, 0.0388, 0.0253]), new_distribution = tensor([0.9362, 0.0386, 0.0252])
2024-12-05 15:38:24,115 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 389: ref_distribution = tensor([0.9362, 0.0386, 0.0252]), new_distribution = tensor([0.9364, 0.0385, 0.0251])
2024-12-05 15:38:24,169 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 390: ref_distribution = tensor([0.9364, 0.0385, 0.0251]), new_distribution = tensor([0.9366, 0.0383, 0.0250])
2024-12-05 15:38:24,223 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 391: ref_distribution = tensor([0.9366, 0.0383, 0.0250]), new_distribution = tensor([0.9368, 0.0382, 0.0250])
2024-12-05 15:38:24,277 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 392: ref_distribution = tensor([0.9368, 0.0382, 0.0250]), new_distribution = tensor([0.9371, 0.0381, 0.0249])
2024-12-05 15:38:24,331 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 393: ref_distribution = tensor([0.9371, 0.0381, 0.0249]), new_distribution = tensor([0.9373, 0.0379, 0.0248])
2024-12-05 15:38:24,385 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 394: ref_distribution = tensor([0.9373, 0.0379, 0.0248]), new_distribution = tensor([0.9375, 0.0378, 0.0247])
2024-12-05 15:38:24,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 395: ref_distribution = tensor([0.9375, 0.0378, 0.0247]), new_distribution = tensor([0.9377, 0.0376, 0.0247])
2024-12-05 15:38:24,492 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 396: ref_distribution = tensor([0.9377, 0.0376, 0.0247]), new_distribution = tensor([0.9379, 0.0375, 0.0246])
2024-12-05 15:38:24,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 397: ref_distribution = tensor([0.9379, 0.0375, 0.0246]), new_distribution = tensor([0.9381, 0.0374, 0.0245])
2024-12-05 15:38:24,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 398: ref_distribution = tensor([0.9381, 0.0374, 0.0245]), new_distribution = tensor([0.9383, 0.0372, 0.0245])
2024-12-05 15:38:24,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 399: ref_distribution = tensor([0.9383, 0.0372, 0.0245]), new_distribution = tensor([0.9385, 0.0371, 0.0244])
2024-12-05 15:38:24,709 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 400: ref_distribution = tensor([0.9385, 0.0371, 0.0244]), new_distribution = tensor([0.9387, 0.0369, 0.0243])
2024-12-05 15:38:24,763 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 401: ref_distribution = tensor([0.9387, 0.0369, 0.0243]), new_distribution = tensor([0.9389, 0.0368, 0.0242])
2024-12-05 15:38:24,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 402: ref_distribution = tensor([0.9389, 0.0368, 0.0242]), new_distribution = tensor([0.9392, 0.0367, 0.0242])
2024-12-05 15:38:24,871 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 403: ref_distribution = tensor([0.9392, 0.0367, 0.0242]), new_distribution = tensor([0.9394, 0.0365, 0.0241])
2024-12-05 15:38:24,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 404: ref_distribution = tensor([0.9394, 0.0365, 0.0241]), new_distribution = tensor([0.9396, 0.0364, 0.0240])
2024-12-05 15:38:24,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 405: ref_distribution = tensor([0.9396, 0.0364, 0.0240]), new_distribution = tensor([0.9398, 0.0363, 0.0240])
2024-12-05 15:38:25,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 406: ref_distribution = tensor([0.9398, 0.0363, 0.0240]), new_distribution = tensor([0.9400, 0.0361, 0.0239])
2024-12-05 15:38:25,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 407: ref_distribution = tensor([0.9400, 0.0361, 0.0239]), new_distribution = tensor([0.9402, 0.0360, 0.0238])
2024-12-05 15:38:25,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 408: ref_distribution = tensor([0.9402, 0.0360, 0.0238]), new_distribution = tensor([0.9404, 0.0359, 0.0237])
2024-12-05 15:38:25,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 409: ref_distribution = tensor([0.9404, 0.0359, 0.0237]), new_distribution = tensor([0.9406, 0.0357, 0.0237])
2024-12-05 15:38:25,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 410: ref_distribution = tensor([0.9406, 0.0357, 0.0237]), new_distribution = tensor([0.9408, 0.0356, 0.0236])
2024-12-05 15:38:25,304 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 411: ref_distribution = tensor([0.9408, 0.0356, 0.0236]), new_distribution = tensor([0.9410, 0.0355, 0.0235])
2024-12-05 15:38:25,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 412: ref_distribution = tensor([0.9410, 0.0355, 0.0235]), new_distribution = tensor([0.9412, 0.0354, 0.0235])
2024-12-05 15:38:25,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 413: ref_distribution = tensor([0.9412, 0.0354, 0.0235]), new_distribution = tensor([0.9414, 0.0352, 0.0234])
2024-12-05 15:38:25,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 414: ref_distribution = tensor([0.9414, 0.0352, 0.0234]), new_distribution = tensor([0.9416, 0.0351, 0.0233])
2024-12-05 15:38:25,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 415: ref_distribution = tensor([0.9416, 0.0351, 0.0233]), new_distribution = tensor([0.9418, 0.0350, 0.0233])
2024-12-05 15:38:25,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 416: ref_distribution = tensor([0.9418, 0.0350, 0.0233]), new_distribution = tensor([0.9420, 0.0348, 0.0232])
2024-12-05 15:38:25,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 417: ref_distribution = tensor([0.9420, 0.0348, 0.0232]), new_distribution = tensor([0.9422, 0.0347, 0.0231])
2024-12-05 15:38:25,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 418: ref_distribution = tensor([0.9422, 0.0347, 0.0231]), new_distribution = tensor([0.9424, 0.0346, 0.0230])
2024-12-05 15:38:25,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 419: ref_distribution = tensor([0.9424, 0.0346, 0.0230]), new_distribution = tensor([0.9426, 0.0344, 0.0230])
2024-12-05 15:38:25,789 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 420: ref_distribution = tensor([0.9426, 0.0344, 0.0230]), new_distribution = tensor([0.9428, 0.0343, 0.0229])
2024-12-05 15:38:25,843 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 421: ref_distribution = tensor([0.9428, 0.0343, 0.0229]), new_distribution = tensor([0.9430, 0.0342, 0.0228])
2024-12-05 15:38:25,897 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 422: ref_distribution = tensor([0.9430, 0.0342, 0.0228]), new_distribution = tensor([0.9432, 0.0341, 0.0228])
2024-12-05 15:38:25,951 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 423: ref_distribution = tensor([0.9432, 0.0341, 0.0228]), new_distribution = tensor([0.9434, 0.0339, 0.0227])
2024-12-05 15:38:26,005 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 424: ref_distribution = tensor([0.9434, 0.0339, 0.0227]), new_distribution = tensor([0.9435, 0.0338, 0.0226])
2024-12-05 15:38:26,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 425: ref_distribution = tensor([0.9435, 0.0338, 0.0226]), new_distribution = tensor([0.9437, 0.0337, 0.0226])
2024-12-05 15:38:26,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 426: ref_distribution = tensor([0.9437, 0.0337, 0.0226]), new_distribution = tensor([0.9439, 0.0336, 0.0225])
2024-12-05 15:38:26,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 427: ref_distribution = tensor([0.9439, 0.0336, 0.0225]), new_distribution = tensor([0.9441, 0.0334, 0.0224])
2024-12-05 15:38:26,221 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 428: ref_distribution = tensor([0.9441, 0.0334, 0.0224]), new_distribution = tensor([0.9443, 0.0333, 0.0224])
2024-12-05 15:38:26,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 429: ref_distribution = tensor([0.9443, 0.0333, 0.0224]), new_distribution = tensor([0.9445, 0.0332, 0.0223])
2024-12-05 15:38:26,329 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 430: ref_distribution = tensor([0.9445, 0.0332, 0.0223]), new_distribution = tensor([0.9447, 0.0331, 0.0222])
2024-12-05 15:38:26,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 431: ref_distribution = tensor([0.9447, 0.0331, 0.0222]), new_distribution = tensor([0.9449, 0.0329, 0.0222])
2024-12-05 15:38:26,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 432: ref_distribution = tensor([0.9449, 0.0329, 0.0222]), new_distribution = tensor([0.9451, 0.0328, 0.0221])
2024-12-05 15:38:26,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 433: ref_distribution = tensor([0.9451, 0.0328, 0.0221]), new_distribution = tensor([0.9453, 0.0327, 0.0220])
2024-12-05 15:38:26,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 434: ref_distribution = tensor([0.9453, 0.0327, 0.0220]), new_distribution = tensor([0.9454, 0.0326, 0.0220])
2024-12-05 15:38:26,599 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 435: ref_distribution = tensor([0.9454, 0.0326, 0.0220]), new_distribution = tensor([0.9456, 0.0325, 0.0219])
2024-12-05 15:38:26,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 436: ref_distribution = tensor([0.9456, 0.0325, 0.0219]), new_distribution = tensor([0.9458, 0.0323, 0.0218])
2024-12-05 15:38:26,708 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 437: ref_distribution = tensor([0.9458, 0.0323, 0.0218]), new_distribution = tensor([0.9460, 0.0322, 0.0218])
2024-12-05 15:38:26,763 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 438: ref_distribution = tensor([0.9460, 0.0322, 0.0218]), new_distribution = tensor([0.9462, 0.0321, 0.0217])
2024-12-05 15:38:26,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 439: ref_distribution = tensor([0.9462, 0.0321, 0.0217]), new_distribution = tensor([0.9464, 0.0320, 0.0217])
2024-12-05 15:38:26,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 440: ref_distribution = tensor([0.9464, 0.0320, 0.0217]), new_distribution = tensor([0.9465, 0.0319, 0.0216])
2024-12-05 15:38:26,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 441: ref_distribution = tensor([0.9465, 0.0319, 0.0216]), new_distribution = tensor([0.9467, 0.0317, 0.0215])
2024-12-05 15:38:26,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 442: ref_distribution = tensor([0.9467, 0.0317, 0.0215]), new_distribution = tensor([0.9469, 0.0316, 0.0215])
2024-12-05 15:38:27,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 443: ref_distribution = tensor([0.9469, 0.0316, 0.0215]), new_distribution = tensor([0.9471, 0.0315, 0.0214])
2024-12-05 15:38:27,088 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 444: ref_distribution = tensor([0.9471, 0.0315, 0.0214]), new_distribution = tensor([0.9473, 0.0314, 0.0213])
2024-12-05 15:38:27,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 445: ref_distribution = tensor([0.9473, 0.0314, 0.0213]), new_distribution = tensor([0.9474, 0.0313, 0.0213])
2024-12-05 15:38:27,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 446: ref_distribution = tensor([0.9474, 0.0313, 0.0213]), new_distribution = tensor([0.9476, 0.0312, 0.0212])
2024-12-05 15:38:27,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 447: ref_distribution = tensor([0.9476, 0.0312, 0.0212]), new_distribution = tensor([0.9478, 0.0310, 0.0211])
2024-12-05 15:38:27,309 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 448: ref_distribution = tensor([0.9478, 0.0310, 0.0211]), new_distribution = tensor([0.9480, 0.0309, 0.0211])
2024-12-05 15:38:27,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 449: ref_distribution = tensor([0.9480, 0.0309, 0.0211]), new_distribution = tensor([0.9482, 0.0308, 0.0210])
2024-12-05 15:38:27,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 450: ref_distribution = tensor([0.9482, 0.0308, 0.0210]), new_distribution = tensor([0.9483, 0.0307, 0.0210])
2024-12-05 15:38:27,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 451: ref_distribution = tensor([0.9483, 0.0307, 0.0210]), new_distribution = tensor([0.9485, 0.0306, 0.0209])
2024-12-05 15:38:27,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 452: ref_distribution = tensor([0.9485, 0.0306, 0.0209]), new_distribution = tensor([0.9487, 0.0305, 0.0208])
2024-12-05 15:38:27,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 453: ref_distribution = tensor([0.9487, 0.0305, 0.0208]), new_distribution = tensor([0.9489, 0.0304, 0.0208])
2024-12-05 15:38:27,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 454: ref_distribution = tensor([0.9489, 0.0304, 0.0208]), new_distribution = tensor([0.9490, 0.0302, 0.0207])
2024-12-05 15:38:27,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 455: ref_distribution = tensor([0.9490, 0.0302, 0.0207]), new_distribution = tensor([0.9492, 0.0301, 0.0207])
2024-12-05 15:38:27,743 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 456: ref_distribution = tensor([0.9492, 0.0301, 0.0207]), new_distribution = tensor([0.9494, 0.0300, 0.0206])
2024-12-05 15:38:27,797 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 457: ref_distribution = tensor([0.9494, 0.0300, 0.0206]), new_distribution = tensor([0.9496, 0.0299, 0.0205])
2024-12-05 15:38:27,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 458: ref_distribution = tensor([0.9496, 0.0299, 0.0205]), new_distribution = tensor([0.9497, 0.0298, 0.0205])
2024-12-05 15:38:27,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 459: ref_distribution = tensor([0.9497, 0.0298, 0.0205]), new_distribution = tensor([0.9499, 0.0297, 0.0204])
2024-12-05 15:38:27,959 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 460: ref_distribution = tensor([0.9499, 0.0297, 0.0204]), new_distribution = tensor([0.9501, 0.0296, 0.0203])
2024-12-05 15:38:28,013 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 461: ref_distribution = tensor([0.9501, 0.0296, 0.0203]), new_distribution = tensor([0.9502, 0.0295, 0.0203])
2024-12-05 15:38:28,067 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 462: ref_distribution = tensor([0.9502, 0.0295, 0.0203]), new_distribution = tensor([0.9504, 0.0294, 0.0202])
2024-12-05 15:38:28,121 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 463: ref_distribution = tensor([0.9504, 0.0294, 0.0202]), new_distribution = tensor([0.9506, 0.0292, 0.0202])
2024-12-05 15:38:28,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 464: ref_distribution = tensor([0.9506, 0.0292, 0.0202]), new_distribution = tensor([0.9508, 0.0291, 0.0201])
2024-12-05 15:38:28,230 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 465: ref_distribution = tensor([0.9508, 0.0291, 0.0201]), new_distribution = tensor([0.9509, 0.0290, 0.0200])
2024-12-05 15:38:28,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 466: ref_distribution = tensor([0.9509, 0.0290, 0.0200]), new_distribution = tensor([0.9511, 0.0289, 0.0200])
2024-12-05 15:38:28,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 467: ref_distribution = tensor([0.9511, 0.0289, 0.0200]), new_distribution = tensor([0.9513, 0.0288, 0.0199])
2024-12-05 15:38:28,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 468: ref_distribution = tensor([0.9513, 0.0288, 0.0199]), new_distribution = tensor([0.9514, 0.0287, 0.0199])
2024-12-05 15:38:28,446 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 469: ref_distribution = tensor([0.9514, 0.0287, 0.0199]), new_distribution = tensor([0.9516, 0.0286, 0.0198])
2024-12-05 15:38:28,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 470: ref_distribution = tensor([0.9516, 0.0286, 0.0198]), new_distribution = tensor([0.9518, 0.0285, 0.0198])
2024-12-05 15:38:28,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 471: ref_distribution = tensor([0.9518, 0.0285, 0.0198]), new_distribution = tensor([0.9519, 0.0284, 0.0197])
2024-12-05 15:38:28,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 472: ref_distribution = tensor([0.9519, 0.0284, 0.0197]), new_distribution = tensor([0.9521, 0.0283, 0.0196])
2024-12-05 15:38:28,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 473: ref_distribution = tensor([0.9521, 0.0283, 0.0196]), new_distribution = tensor([0.9523, 0.0282, 0.0196])
2024-12-05 15:38:28,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 474: ref_distribution = tensor([0.9523, 0.0282, 0.0196]), new_distribution = tensor([0.9524, 0.0281, 0.0195])
2024-12-05 15:38:28,770 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 475: ref_distribution = tensor([0.9524, 0.0281, 0.0195]), new_distribution = tensor([0.9526, 0.0280, 0.0195])
2024-12-05 15:38:28,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 476: ref_distribution = tensor([0.9526, 0.0280, 0.0195]), new_distribution = tensor([0.9527, 0.0279, 0.0194])
2024-12-05 15:38:28,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 477: ref_distribution = tensor([0.9527, 0.0279, 0.0194]), new_distribution = tensor([0.9529, 0.0278, 0.0193])
2024-12-05 15:38:28,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 478: ref_distribution = tensor([0.9529, 0.0278, 0.0193]), new_distribution = tensor([0.9531, 0.0276, 0.0193])
2024-12-05 15:38:28,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 479: ref_distribution = tensor([0.9531, 0.0276, 0.0193]), new_distribution = tensor([0.9532, 0.0275, 0.0192])
2024-12-05 15:38:29,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 480: ref_distribution = tensor([0.9532, 0.0275, 0.0192]), new_distribution = tensor([0.9534, 0.0274, 0.0192])
2024-12-05 15:38:29,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 481: ref_distribution = tensor([0.9534, 0.0274, 0.0192]), new_distribution = tensor([0.9535, 0.0273, 0.0191])
2024-12-05 15:38:29,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 482: ref_distribution = tensor([0.9535, 0.0273, 0.0191]), new_distribution = tensor([0.9537, 0.0272, 0.0191])
2024-12-05 15:38:29,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 483: ref_distribution = tensor([0.9537, 0.0272, 0.0191]), new_distribution = tensor([0.9539, 0.0271, 0.0190])
2024-12-05 15:38:29,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 484: ref_distribution = tensor([0.9539, 0.0271, 0.0190]), new_distribution = tensor([0.9540, 0.0270, 0.0189])
2024-12-05 15:38:29,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 485: ref_distribution = tensor([0.9540, 0.0270, 0.0189]), new_distribution = tensor([0.9542, 0.0269, 0.0189])
2024-12-05 15:38:29,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 486: ref_distribution = tensor([0.9542, 0.0269, 0.0189]), new_distribution = tensor([0.9543, 0.0268, 0.0188])
2024-12-05 15:38:29,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 487: ref_distribution = tensor([0.9543, 0.0268, 0.0188]), new_distribution = tensor([0.9545, 0.0267, 0.0188])
2024-12-05 15:38:29,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 488: ref_distribution = tensor([0.9545, 0.0267, 0.0188]), new_distribution = tensor([0.9547, 0.0266, 0.0187])
2024-12-05 15:38:29,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 489: ref_distribution = tensor([0.9547, 0.0266, 0.0187]), new_distribution = tensor([0.9548, 0.0265, 0.0187])
2024-12-05 15:38:29,581 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 490: ref_distribution = tensor([0.9548, 0.0265, 0.0187]), new_distribution = tensor([0.9550, 0.0264, 0.0186])
2024-12-05 15:38:29,635 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 491: ref_distribution = tensor([0.9550, 0.0264, 0.0186]), new_distribution = tensor([0.9551, 0.0263, 0.0186])
2024-12-05 15:38:29,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 492: ref_distribution = tensor([0.9551, 0.0263, 0.0186]), new_distribution = tensor([0.9553, 0.0262, 0.0185])
2024-12-05 15:38:29,742 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 493: ref_distribution = tensor([0.9553, 0.0262, 0.0185]), new_distribution = tensor([0.9554, 0.0261, 0.0184])
2024-12-05 15:38:29,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 494: ref_distribution = tensor([0.9554, 0.0261, 0.0184]), new_distribution = tensor([0.9556, 0.0260, 0.0184])
2024-12-05 15:38:29,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 495: ref_distribution = tensor([0.9556, 0.0260, 0.0184]), new_distribution = tensor([0.9557, 0.0259, 0.0183])
2024-12-05 15:38:29,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 496: ref_distribution = tensor([0.9557, 0.0259, 0.0183]), new_distribution = tensor([0.9559, 0.0258, 0.0183])
2024-12-05 15:38:29,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 497: ref_distribution = tensor([0.9559, 0.0258, 0.0183]), new_distribution = tensor([0.9560, 0.0257, 0.0182])
2024-12-05 15:38:30,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 498: ref_distribution = tensor([0.9560, 0.0257, 0.0182]), new_distribution = tensor([0.9562, 0.0256, 0.0182])
2024-12-05 15:38:30,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 499: ref_distribution = tensor([0.9562, 0.0256, 0.0182]), new_distribution = tensor([0.9563, 0.0255, 0.0181])
2024-12-05 15:38:30,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.7000, 0.2000, 0.1000]), new_distribution = tensor([0.7008, 0.1995, 0.0997])
2024-12-05 15:38:30,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.7008, 0.1995, 0.0997]), new_distribution = tensor([0.7016, 0.1990, 0.0994])
2024-12-05 15:38:30,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.7016, 0.1990, 0.0994]), new_distribution = tensor([0.7023, 0.1985, 0.0991])
2024-12-05 15:38:30,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.7023, 0.1985, 0.0991]), new_distribution = tensor([0.7031, 0.1980, 0.0989])
2024-12-05 15:38:30,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.7031, 0.1980, 0.0989]), new_distribution = tensor([0.7039, 0.1975, 0.0986])
2024-12-05 15:38:30,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.7039, 0.1975, 0.0986]), new_distribution = tensor([0.7047, 0.1970, 0.0983])
2024-12-05 15:38:30,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.7047, 0.1970, 0.0983]), new_distribution = tensor([0.7055, 0.1965, 0.0980])
2024-12-05 15:38:30,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.7055, 0.1965, 0.0980]), new_distribution = tensor([0.7062, 0.1960, 0.0977])
2024-12-05 15:38:30,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.7062, 0.1960, 0.0977]), new_distribution = tensor([0.7070, 0.1956, 0.0974])
2024-12-05 15:38:30,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.7070, 0.1956, 0.0974]), new_distribution = tensor([0.7078, 0.1951, 0.0972])
2024-12-05 15:38:30,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.7078, 0.1951, 0.0972]), new_distribution = tensor([0.7086, 0.1946, 0.0969])
2024-12-05 15:38:30,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.7086, 0.1946, 0.0969]), new_distribution = tensor([0.7093, 0.1941, 0.0966])
2024-12-05 15:38:30,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.7093, 0.1941, 0.0966]), new_distribution = tensor([0.7101, 0.1936, 0.0963])
2024-12-05 15:38:31,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.7101, 0.1936, 0.0963]), new_distribution = tensor([0.7109, 0.1931, 0.0960])
2024-12-05 15:38:31,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.7109, 0.1931, 0.0960]), new_distribution = tensor([0.7116, 0.1926, 0.0958])
2024-12-05 15:38:31,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.7116, 0.1926, 0.0958]), new_distribution = tensor([0.7124, 0.1921, 0.0955])
2024-12-05 15:38:31,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.7124, 0.1921, 0.0955]), new_distribution = tensor([0.7132, 0.1916, 0.0952])
2024-12-05 15:38:31,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.7132, 0.1916, 0.0952]), new_distribution = tensor([0.7139, 0.1911, 0.0949])
2024-12-05 15:38:31,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.7139, 0.1911, 0.0949]), new_distribution = tensor([0.7147, 0.1907, 0.0947])
2024-12-05 15:38:31,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.7147, 0.1907, 0.0947]), new_distribution = tensor([0.7154, 0.1902, 0.0944])
2024-12-05 15:38:31,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.7154, 0.1902, 0.0944]), new_distribution = tensor([0.7162, 0.1897, 0.0941])
2024-12-05 15:38:31,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.7162, 0.1897, 0.0941]), new_distribution = tensor([0.7170, 0.1892, 0.0938])
2024-12-05 15:38:31,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.7170, 0.1892, 0.0938]), new_distribution = tensor([0.7177, 0.1887, 0.0936])
2024-12-05 15:38:31,581 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.7177, 0.1887, 0.0936]), new_distribution = tensor([0.7185, 0.1882, 0.0933])
2024-12-05 15:38:31,635 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.7185, 0.1882, 0.0933]), new_distribution = tensor([0.7192, 0.1877, 0.0930])
2024-12-05 15:38:31,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.7192, 0.1877, 0.0930]), new_distribution = tensor([0.7200, 0.1873, 0.0928])
2024-12-05 15:38:31,743 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.7200, 0.1873, 0.0928]), new_distribution = tensor([0.7207, 0.1868, 0.0925])
2024-12-05 15:38:31,797 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.7207, 0.1868, 0.0925]), new_distribution = tensor([0.7215, 0.1863, 0.0922])
2024-12-05 15:38:31,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.7215, 0.1863, 0.0922]), new_distribution = tensor([0.7222, 0.1858, 0.0920])
2024-12-05 15:38:31,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.7222, 0.1858, 0.0920]), new_distribution = tensor([0.7230, 0.1853, 0.0917])
2024-12-05 15:38:31,959 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.7230, 0.1853, 0.0917]), new_distribution = tensor([0.7237, 0.1848, 0.0914])
2024-12-05 15:38:32,013 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.7237, 0.1848, 0.0914]), new_distribution = tensor([0.7245, 0.1844, 0.0912])
2024-12-05 15:38:32,067 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.7245, 0.1844, 0.0912]), new_distribution = tensor([0.7252, 0.1839, 0.0909])
2024-12-05 15:38:32,121 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.7252, 0.1839, 0.0909]), new_distribution = tensor([0.7260, 0.1834, 0.0906])
2024-12-05 15:38:32,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.7260, 0.1834, 0.0906]), new_distribution = tensor([0.7267, 0.1829, 0.0904])
2024-12-05 15:38:32,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.7267, 0.1829, 0.0904]), new_distribution = tensor([0.7274, 0.1824, 0.0901])
2024-12-05 15:38:32,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.7274, 0.1824, 0.0901]), new_distribution = tensor([0.7282, 0.1820, 0.0899])
2024-12-05 15:38:32,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.7282, 0.1820, 0.0899]), new_distribution = tensor([0.7289, 0.1815, 0.0896])
2024-12-05 15:38:32,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.7289, 0.1815, 0.0896]), new_distribution = tensor([0.7296, 0.1810, 0.0893])
2024-12-05 15:38:32,446 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.7296, 0.1810, 0.0893]), new_distribution = tensor([0.7304, 0.1805, 0.0891])
2024-12-05 15:38:32,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.7304, 0.1805, 0.0891]), new_distribution = tensor([0.7311, 0.1801, 0.0888])
2024-12-05 15:38:32,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.7311, 0.1801, 0.0888]), new_distribution = tensor([0.7318, 0.1796, 0.0886])
2024-12-05 15:38:32,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.7318, 0.1796, 0.0886]), new_distribution = tensor([0.7326, 0.1791, 0.0883])
2024-12-05 15:38:32,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.7326, 0.1791, 0.0883]), new_distribution = tensor([0.7333, 0.1786, 0.0881])
2024-12-05 15:38:32,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.7333, 0.1786, 0.0881]), new_distribution = tensor([0.7340, 0.1782, 0.0878])
2024-12-05 15:38:32,770 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.7340, 0.1782, 0.0878]), new_distribution = tensor([0.7348, 0.1777, 0.0875])
2024-12-05 15:38:32,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.7348, 0.1777, 0.0875]), new_distribution = tensor([0.7355, 0.1772, 0.0873])
2024-12-05 15:38:32,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.7355, 0.1772, 0.0873]), new_distribution = tensor([0.7362, 0.1767, 0.0870])
2024-12-05 15:38:32,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.7362, 0.1767, 0.0870]), new_distribution = tensor([0.7369, 0.1763, 0.0868])
2024-12-05 15:38:32,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.7369, 0.1763, 0.0868]), new_distribution = tensor([0.7377, 0.1758, 0.0865])
2024-12-05 15:38:33,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.7377, 0.1758, 0.0865]), new_distribution = tensor([0.7384, 0.1753, 0.0863])
2024-12-05 15:38:33,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.7384, 0.1753, 0.0863]), new_distribution = tensor([0.7391, 0.1749, 0.0860])
2024-12-05 15:38:33,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.7391, 0.1749, 0.0860]), new_distribution = tensor([0.7398, 0.1744, 0.0858])
2024-12-05 15:38:33,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.7398, 0.1744, 0.0858]), new_distribution = tensor([0.7405, 0.1739, 0.0855])
2024-12-05 15:38:33,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.7405, 0.1739, 0.0855]), new_distribution = tensor([0.7413, 0.1735, 0.0853])
2024-12-05 15:38:33,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.7413, 0.1735, 0.0853]), new_distribution = tensor([0.7420, 0.1730, 0.0850])
2024-12-05 15:38:33,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.7420, 0.1730, 0.0850]), new_distribution = tensor([0.7427, 0.1725, 0.0848])
2024-12-05 15:38:33,418 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.7427, 0.1725, 0.0848]), new_distribution = tensor([0.7434, 0.1721, 0.0845])
2024-12-05 15:38:33,472 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.7434, 0.1721, 0.0845]), new_distribution = tensor([0.7441, 0.1716, 0.0843])
2024-12-05 15:38:33,526 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.7441, 0.1716, 0.0843]), new_distribution = tensor([0.7448, 0.1711, 0.0841])
2024-12-05 15:38:33,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.7448, 0.1711, 0.0841]), new_distribution = tensor([0.7455, 0.1707, 0.0838])
2024-12-05 15:38:33,634 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.7455, 0.1707, 0.0838]), new_distribution = tensor([0.7462, 0.1702, 0.0836])
2024-12-05 15:38:33,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.7462, 0.1702, 0.0836]), new_distribution = tensor([0.7469, 0.1697, 0.0833])
2024-12-05 15:38:33,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.7469, 0.1697, 0.0833]), new_distribution = tensor([0.7476, 0.1693, 0.0831])
2024-12-05 15:38:33,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.7476, 0.1693, 0.0831]), new_distribution = tensor([0.7483, 0.1688, 0.0828])
2024-12-05 15:38:33,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.7483, 0.1688, 0.0828]), new_distribution = tensor([0.7490, 0.1684, 0.0826])
2024-12-05 15:38:33,907 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.7490, 0.1684, 0.0826]), new_distribution = tensor([0.7497, 0.1679, 0.0824])
2024-12-05 15:38:33,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.7497, 0.1679, 0.0824]), new_distribution = tensor([0.7504, 0.1674, 0.0821])
2024-12-05 15:38:34,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.7504, 0.1674, 0.0821]), new_distribution = tensor([0.7511, 0.1670, 0.0819])
2024-12-05 15:38:34,068 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.7511, 0.1670, 0.0819]), new_distribution = tensor([0.7518, 0.1665, 0.0817])
2024-12-05 15:38:34,122 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.7518, 0.1665, 0.0817]), new_distribution = tensor([0.7525, 0.1661, 0.0814])
2024-12-05 15:38:34,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.7525, 0.1661, 0.0814]), new_distribution = tensor([0.7532, 0.1656, 0.0812])
2024-12-05 15:38:34,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.7532, 0.1656, 0.0812]), new_distribution = tensor([0.7539, 0.1652, 0.0809])
2024-12-05 15:38:34,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.7539, 0.1652, 0.0809]), new_distribution = tensor([0.7546, 0.1647, 0.0807])
2024-12-05 15:38:34,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.7546, 0.1647, 0.0807]), new_distribution = tensor([0.7553, 0.1642, 0.0805])
2024-12-05 15:38:34,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.7553, 0.1642, 0.0805]), new_distribution = tensor([0.7560, 0.1638, 0.0802])
2024-12-05 15:38:34,446 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.7560, 0.1638, 0.0802]), new_distribution = tensor([0.7567, 0.1633, 0.0800])
2024-12-05 15:38:34,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.7567, 0.1633, 0.0800]), new_distribution = tensor([0.7573, 0.1629, 0.0798])
2024-12-05 15:38:34,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.7573, 0.1629, 0.0798]), new_distribution = tensor([0.7580, 0.1624, 0.0795])
2024-12-05 15:38:34,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.7580, 0.1624, 0.0795]), new_distribution = tensor([0.7587, 0.1620, 0.0793])
2024-12-05 15:38:34,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.7587, 0.1620, 0.0793]), new_distribution = tensor([0.7594, 0.1615, 0.0791])
2024-12-05 15:38:34,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.7594, 0.1615, 0.0791]), new_distribution = tensor([0.7601, 0.1611, 0.0788])
2024-12-05 15:38:34,770 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.7601, 0.1611, 0.0788]), new_distribution = tensor([0.7608, 0.1606, 0.0786])
2024-12-05 15:38:34,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.7608, 0.1606, 0.0786]), new_distribution = tensor([0.7614, 0.1602, 0.0784])
2024-12-05 15:38:34,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.7614, 0.1602, 0.0784]), new_distribution = tensor([0.7621, 0.1597, 0.0782])
2024-12-05 15:38:34,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.7621, 0.1597, 0.0782]), new_distribution = tensor([0.7628, 0.1593, 0.0779])
2024-12-05 15:38:34,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.7628, 0.1593, 0.0779]), new_distribution = tensor([0.7635, 0.1588, 0.0777])
2024-12-05 15:38:35,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.7635, 0.1588, 0.0777]), new_distribution = tensor([0.7641, 0.1584, 0.0775])
2024-12-05 15:38:35,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.7641, 0.1584, 0.0775]), new_distribution = tensor([0.7648, 0.1579, 0.0773])
2024-12-05 15:38:35,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.7648, 0.1579, 0.0773]), new_distribution = tensor([0.7655, 0.1575, 0.0770])
2024-12-05 15:38:35,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.7655, 0.1575, 0.0770]), new_distribution = tensor([0.7661, 0.1571, 0.0768])
2024-12-05 15:38:35,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.7661, 0.1571, 0.0768]), new_distribution = tensor([0.7668, 0.1566, 0.0766])
2024-12-05 15:38:35,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.7668, 0.1566, 0.0766]), new_distribution = tensor([0.7675, 0.1562, 0.0764])
2024-12-05 15:38:35,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.7675, 0.1562, 0.0764]), new_distribution = tensor([0.7681, 0.1557, 0.0761])
2024-12-05 15:38:35,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.7681, 0.1557, 0.0761]), new_distribution = tensor([0.7688, 0.1553, 0.0759])
2024-12-05 15:38:35,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.7688, 0.1553, 0.0759]), new_distribution = tensor([0.7695, 0.1549, 0.0757])
2024-12-05 15:38:35,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.7695, 0.1549, 0.0757]), new_distribution = tensor([0.7701, 0.1544, 0.0755])
2024-12-05 15:38:35,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.7701, 0.1544, 0.0755]), new_distribution = tensor([0.7708, 0.1540, 0.0753])
2024-12-05 15:38:35,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.7708, 0.1540, 0.0753]), new_distribution = tensor([0.7714, 0.1535, 0.0750])
2024-12-05 15:38:35,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.7714, 0.1535, 0.0750]), new_distribution = tensor([0.7721, 0.1531, 0.0748])
2024-12-05 15:38:35,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([0.7721, 0.1531, 0.0748]), new_distribution = tensor([0.7727, 0.1527, 0.0746])
2024-12-05 15:38:35,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([0.7727, 0.1527, 0.0746]), new_distribution = tensor([0.7734, 0.1522, 0.0744])
2024-12-05 15:38:35,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([0.7734, 0.1522, 0.0744]), new_distribution = tensor([0.7740, 0.1518, 0.0742])
2024-12-05 15:38:35,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([0.7740, 0.1518, 0.0742]), new_distribution = tensor([0.7747, 0.1514, 0.0739])
2024-12-05 15:38:35,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([0.7747, 0.1514, 0.0739]), new_distribution = tensor([0.7753, 0.1509, 0.0737])
2024-12-05 15:38:36,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([0.7753, 0.1509, 0.0737]), new_distribution = tensor([0.7760, 0.1505, 0.0735])
2024-12-05 15:38:36,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([0.7760, 0.1505, 0.0735]), new_distribution = tensor([0.7766, 0.1501, 0.0733])
2024-12-05 15:38:36,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([0.7766, 0.1501, 0.0733]), new_distribution = tensor([0.7773, 0.1496, 0.0731])
2024-12-05 15:38:36,173 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([0.7773, 0.1496, 0.0731]), new_distribution = tensor([0.7779, 0.1492, 0.0729])
2024-12-05 15:38:36,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([0.7779, 0.1492, 0.0729]), new_distribution = tensor([0.7786, 0.1488, 0.0727])
2024-12-05 15:38:36,281 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([0.7786, 0.1488, 0.0727]), new_distribution = tensor([0.7792, 0.1483, 0.0725])
2024-12-05 15:38:36,335 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([0.7792, 0.1483, 0.0725]), new_distribution = tensor([0.7798, 0.1479, 0.0722])
2024-12-05 15:38:36,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([0.7798, 0.1479, 0.0722]), new_distribution = tensor([0.7805, 0.1475, 0.0720])
2024-12-05 15:38:36,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([0.7805, 0.1475, 0.0720]), new_distribution = tensor([0.7811, 0.1471, 0.0718])
2024-12-05 15:38:36,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([0.7811, 0.1471, 0.0718]), new_distribution = tensor([0.7818, 0.1466, 0.0716])
2024-12-05 15:38:36,550 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([0.7818, 0.1466, 0.0716]), new_distribution = tensor([0.7824, 0.1462, 0.0714])
2024-12-05 15:38:36,604 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([0.7824, 0.1462, 0.0714]), new_distribution = tensor([0.7830, 0.1458, 0.0712])
2024-12-05 15:38:36,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([0.7830, 0.1458, 0.0712]), new_distribution = tensor([0.7837, 0.1454, 0.0710])
2024-12-05 15:38:36,713 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([0.7837, 0.1454, 0.0710]), new_distribution = tensor([0.7843, 0.1449, 0.0708])
2024-12-05 15:38:36,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([0.7843, 0.1449, 0.0708]), new_distribution = tensor([0.7849, 0.1445, 0.0706])
2024-12-05 15:38:36,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([0.7849, 0.1445, 0.0706]), new_distribution = tensor([0.7855, 0.1441, 0.0704])
2024-12-05 15:38:36,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([0.7855, 0.1441, 0.0704]), new_distribution = tensor([0.7862, 0.1437, 0.0702])
2024-12-05 15:38:36,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([0.7862, 0.1437, 0.0702]), new_distribution = tensor([0.7868, 0.1433, 0.0700])
2024-12-05 15:38:36,983 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([0.7868, 0.1433, 0.0700]), new_distribution = tensor([0.7874, 0.1428, 0.0698])
2024-12-05 15:38:37,036 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([0.7874, 0.1428, 0.0698]), new_distribution = tensor([0.7880, 0.1424, 0.0695])
2024-12-05 15:38:37,091 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([0.7880, 0.1424, 0.0695]), new_distribution = tensor([0.7887, 0.1420, 0.0693])
2024-12-05 15:38:37,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([0.7887, 0.1420, 0.0693]), new_distribution = tensor([0.7893, 0.1416, 0.0691])
2024-12-05 15:38:37,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([0.7893, 0.1416, 0.0691]), new_distribution = tensor([0.7899, 0.1412, 0.0689])
2024-12-05 15:38:37,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([0.7899, 0.1412, 0.0689]), new_distribution = tensor([0.7905, 0.1408, 0.0687])
2024-12-05 15:38:37,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([0.7905, 0.1408, 0.0687]), new_distribution = tensor([0.7911, 0.1403, 0.0685])
2024-12-05 15:38:37,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([0.7911, 0.1403, 0.0685]), new_distribution = tensor([0.7917, 0.1399, 0.0683])
2024-12-05 15:38:37,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([0.7917, 0.1399, 0.0683]), new_distribution = tensor([0.7923, 0.1395, 0.0681])
2024-12-05 15:38:37,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([0.7923, 0.1395, 0.0681]), new_distribution = tensor([0.7930, 0.1391, 0.0679])
2024-12-05 15:38:37,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([0.7930, 0.1391, 0.0679]), new_distribution = tensor([0.7936, 0.1387, 0.0677])
2024-12-05 15:38:37,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([0.7936, 0.1387, 0.0677]), new_distribution = tensor([0.7942, 0.1383, 0.0675])
2024-12-05 15:38:37,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([0.7942, 0.1383, 0.0675]), new_distribution = tensor([0.7948, 0.1379, 0.0673])
2024-12-05 15:38:37,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([0.7948, 0.1379, 0.0673]), new_distribution = tensor([0.7954, 0.1375, 0.0671])
2024-12-05 15:38:37,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([0.7954, 0.1375, 0.0671]), new_distribution = tensor([0.7960, 0.1371, 0.0670])
2024-12-05 15:38:37,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([0.7960, 0.1371, 0.0670]), new_distribution = tensor([0.7966, 0.1366, 0.0668])
2024-12-05 15:38:37,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([0.7966, 0.1366, 0.0668]), new_distribution = tensor([0.7972, 0.1362, 0.0666])
2024-12-05 15:38:37,902 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([0.7972, 0.1362, 0.0666]), new_distribution = tensor([0.7978, 0.1358, 0.0664])
2024-12-05 15:38:37,956 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([0.7978, 0.1358, 0.0664]), new_distribution = tensor([0.7984, 0.1354, 0.0662])
2024-12-05 15:38:38,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([0.7984, 0.1354, 0.0662]), new_distribution = tensor([0.7990, 0.1350, 0.0660])
2024-12-05 15:38:38,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([0.7990, 0.1350, 0.0660]), new_distribution = tensor([0.7996, 0.1346, 0.0658])
2024-12-05 15:38:38,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([0.7996, 0.1346, 0.0658]), new_distribution = tensor([0.8002, 0.1342, 0.0656])
2024-12-05 15:38:38,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([0.8002, 0.1342, 0.0656]), new_distribution = tensor([0.8008, 0.1338, 0.0654])
2024-12-05 15:38:38,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([0.8008, 0.1338, 0.0654]), new_distribution = tensor([0.8014, 0.1334, 0.0652])
2024-12-05 15:38:38,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([0.8014, 0.1334, 0.0652]), new_distribution = tensor([0.8020, 0.1330, 0.0650])
2024-12-05 15:38:38,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([0.8020, 0.1330, 0.0650]), new_distribution = tensor([0.8026, 0.1326, 0.0648])
2024-12-05 15:38:38,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([0.8026, 0.1326, 0.0648]), new_distribution = tensor([0.8031, 0.1322, 0.0646])
2024-12-05 15:38:38,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([0.8031, 0.1322, 0.0646]), new_distribution = tensor([0.8037, 0.1318, 0.0644])
2024-12-05 15:38:38,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([0.8037, 0.1318, 0.0644]), new_distribution = tensor([0.8043, 0.1314, 0.0643])
2024-12-05 15:38:38,549 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([0.8043, 0.1314, 0.0643]), new_distribution = tensor([0.8049, 0.1310, 0.0641])
2024-12-05 15:38:38,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([0.8049, 0.1310, 0.0641]), new_distribution = tensor([0.8055, 0.1306, 0.0639])
2024-12-05 15:38:38,657 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([0.8055, 0.1306, 0.0639]), new_distribution = tensor([0.8061, 0.1302, 0.0637])
2024-12-05 15:38:38,711 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([0.8061, 0.1302, 0.0637]), new_distribution = tensor([0.8066, 0.1298, 0.0635])
2024-12-05 15:38:38,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([0.8066, 0.1298, 0.0635]), new_distribution = tensor([0.8072, 0.1295, 0.0633])
2024-12-05 15:38:38,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([0.8072, 0.1295, 0.0633]), new_distribution = tensor([0.8078, 0.1291, 0.0631])
2024-12-05 15:38:38,873 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([0.8078, 0.1291, 0.0631]), new_distribution = tensor([0.8084, 0.1287, 0.0630])
2024-12-05 15:38:38,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([0.8084, 0.1287, 0.0630]), new_distribution = tensor([0.8089, 0.1283, 0.0628])
2024-12-05 15:38:38,981 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([0.8089, 0.1283, 0.0628]), new_distribution = tensor([0.8095, 0.1279, 0.0626])
2024-12-05 15:38:39,035 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([0.8095, 0.1279, 0.0626]), new_distribution = tensor([0.8101, 0.1275, 0.0624])
2024-12-05 15:38:39,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([0.8101, 0.1275, 0.0624]), new_distribution = tensor([0.8107, 0.1271, 0.0622])
2024-12-05 15:38:39,143 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([0.8107, 0.1271, 0.0622]), new_distribution = tensor([0.8112, 0.1267, 0.0620])
2024-12-05 15:38:39,197 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([0.8112, 0.1267, 0.0620]), new_distribution = tensor([0.8118, 0.1263, 0.0619])
2024-12-05 15:38:39,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([0.8118, 0.1263, 0.0619]), new_distribution = tensor([0.8124, 0.1260, 0.0617])
2024-12-05 15:38:39,305 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([0.8124, 0.1260, 0.0617]), new_distribution = tensor([0.8129, 0.1256, 0.0615])
2024-12-05 15:38:39,359 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([0.8129, 0.1256, 0.0615]), new_distribution = tensor([0.8135, 0.1252, 0.0613])
2024-12-05 15:38:39,413 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([0.8135, 0.1252, 0.0613]), new_distribution = tensor([0.8141, 0.1248, 0.0611])
2024-12-05 15:38:39,467 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([0.8141, 0.1248, 0.0611]), new_distribution = tensor([0.8146, 0.1244, 0.0610])
2024-12-05 15:38:39,521 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([0.8146, 0.1244, 0.0610]), new_distribution = tensor([0.8152, 0.1240, 0.0608])
2024-12-05 15:38:39,575 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([0.8152, 0.1240, 0.0608]), new_distribution = tensor([0.8157, 0.1237, 0.0606])
2024-12-05 15:38:39,629 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([0.8157, 0.1237, 0.0606]), new_distribution = tensor([0.8163, 0.1233, 0.0604])
2024-12-05 15:38:39,683 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([0.8163, 0.1233, 0.0604]), new_distribution = tensor([0.8169, 0.1229, 0.0602])
2024-12-05 15:38:39,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([0.8169, 0.1229, 0.0602]), new_distribution = tensor([0.8174, 0.1225, 0.0601])
2024-12-05 15:38:39,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([0.8174, 0.1225, 0.0601]), new_distribution = tensor([0.8180, 0.1222, 0.0599])
2024-12-05 15:38:39,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([0.8180, 0.1222, 0.0599]), new_distribution = tensor([0.8185, 0.1218, 0.0597])
2024-12-05 15:38:39,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([0.8185, 0.1218, 0.0597]), new_distribution = tensor([0.8191, 0.1214, 0.0595])
2024-12-05 15:38:39,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([0.8191, 0.1214, 0.0595]), new_distribution = tensor([0.8196, 0.1210, 0.0594])
2024-12-05 15:38:40,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([0.8196, 0.1210, 0.0594]), new_distribution = tensor([0.8202, 0.1206, 0.0592])
2024-12-05 15:38:40,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([0.8202, 0.1206, 0.0592]), new_distribution = tensor([0.8207, 0.1203, 0.0590])
2024-12-05 15:38:40,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([0.8207, 0.1203, 0.0590]), new_distribution = tensor([0.8213, 0.1199, 0.0588])
2024-12-05 15:38:40,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([0.8213, 0.1199, 0.0588]), new_distribution = tensor([0.8218, 0.1195, 0.0587])
2024-12-05 15:38:40,221 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([0.8218, 0.1195, 0.0587]), new_distribution = tensor([0.8223, 0.1192, 0.0585])
2024-12-05 15:38:40,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([0.8223, 0.1192, 0.0585]), new_distribution = tensor([0.8229, 0.1188, 0.0583])
2024-12-05 15:38:40,329 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([0.8229, 0.1188, 0.0583]), new_distribution = tensor([0.8234, 0.1184, 0.0582])
2024-12-05 15:38:40,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([0.8234, 0.1184, 0.0582]), new_distribution = tensor([0.8240, 0.1181, 0.0580])
2024-12-05 15:38:40,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([0.8240, 0.1181, 0.0580]), new_distribution = tensor([0.8245, 0.1177, 0.0578])
2024-12-05 15:38:40,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([0.8245, 0.1177, 0.0578]), new_distribution = tensor([0.8250, 0.1173, 0.0576])
2024-12-05 15:38:40,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([0.8250, 0.1173, 0.0576]), new_distribution = tensor([0.8256, 0.1170, 0.0575])
2024-12-05 15:38:40,599 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([0.8256, 0.1170, 0.0575]), new_distribution = tensor([0.8261, 0.1166, 0.0573])
2024-12-05 15:38:40,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([0.8261, 0.1166, 0.0573]), new_distribution = tensor([0.8266, 0.1162, 0.0571])
2024-12-05 15:38:40,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([0.8266, 0.1162, 0.0571]), new_distribution = tensor([0.8272, 0.1159, 0.0570])
2024-12-05 15:38:40,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([0.8272, 0.1159, 0.0570]), new_distribution = tensor([0.8277, 0.1155, 0.0568])
2024-12-05 15:38:40,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([0.8277, 0.1155, 0.0568]), new_distribution = tensor([0.8282, 0.1151, 0.0566])
2024-12-05 15:38:40,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([0.8282, 0.1151, 0.0566]), new_distribution = tensor([0.8287, 0.1148, 0.0565])
2024-12-05 15:38:40,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([0.8287, 0.1148, 0.0565]), new_distribution = tensor([0.8293, 0.1144, 0.0563])
2024-12-05 15:38:40,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([0.8293, 0.1144, 0.0563]), new_distribution = tensor([0.8298, 0.1141, 0.0561])
2024-12-05 15:38:41,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([0.8298, 0.1141, 0.0561]), new_distribution = tensor([0.8303, 0.1137, 0.0560])
2024-12-05 15:38:41,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([0.8303, 0.1137, 0.0560]), new_distribution = tensor([0.8308, 0.1133, 0.0558])
2024-12-05 15:38:41,138 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([0.8308, 0.1133, 0.0558]), new_distribution = tensor([0.8314, 0.1130, 0.0556])
2024-12-05 15:38:41,192 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([0.8314, 0.1130, 0.0556]), new_distribution = tensor([0.8319, 0.1126, 0.0555])
2024-12-05 15:38:41,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([0.8319, 0.1126, 0.0555]), new_distribution = tensor([0.8324, 0.1123, 0.0553])
2024-12-05 15:38:41,300 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([0.8324, 0.1123, 0.0553]), new_distribution = tensor([0.8329, 0.1119, 0.0552])
2024-12-05 15:38:41,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([0.8329, 0.1119, 0.0552]), new_distribution = tensor([0.8334, 0.1116, 0.0550])
2024-12-05 15:38:41,408 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([0.8334, 0.1116, 0.0550]), new_distribution = tensor([0.8339, 0.1112, 0.0548])
2024-12-05 15:38:41,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([0.8339, 0.1112, 0.0548]), new_distribution = tensor([0.8345, 0.1109, 0.0547])
2024-12-05 15:38:41,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([0.8345, 0.1109, 0.0547]), new_distribution = tensor([0.8350, 0.1105, 0.0545])
2024-12-05 15:38:41,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([0.8350, 0.1105, 0.0545]), new_distribution = tensor([0.8355, 0.1102, 0.0544])
2024-12-05 15:38:41,624 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([0.8355, 0.1102, 0.0544]), new_distribution = tensor([0.8360, 0.1098, 0.0542])
2024-12-05 15:38:41,678 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([0.8360, 0.1098, 0.0542]), new_distribution = tensor([0.8365, 0.1095, 0.0540])
2024-12-05 15:38:41,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([0.8365, 0.1095, 0.0540]), new_distribution = tensor([0.8370, 0.1091, 0.0539])
2024-12-05 15:38:41,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([0.8370, 0.1091, 0.0539]), new_distribution = tensor([0.8375, 0.1088, 0.0537])
2024-12-05 15:38:41,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([0.8375, 0.1088, 0.0537]), new_distribution = tensor([0.8380, 0.1084, 0.0536])
2024-12-05 15:38:41,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([0.8380, 0.1084, 0.0536]), new_distribution = tensor([0.8385, 0.1081, 0.0534])
2024-12-05 15:38:41,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([0.8385, 0.1081, 0.0534]), new_distribution = tensor([0.8390, 0.1077, 0.0532])
2024-12-05 15:38:42,002 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([0.8390, 0.1077, 0.0532]), new_distribution = tensor([0.8395, 0.1074, 0.0531])
2024-12-05 15:38:42,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([0.8395, 0.1074, 0.0531]), new_distribution = tensor([0.8400, 0.1071, 0.0529])
2024-12-05 15:38:42,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([0.8400, 0.1071, 0.0529]), new_distribution = tensor([0.8405, 0.1067, 0.0528])
2024-12-05 15:38:42,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([0.8405, 0.1067, 0.0528]), new_distribution = tensor([0.8410, 0.1064, 0.0526])
2024-12-05 15:38:42,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([0.8410, 0.1064, 0.0526]), new_distribution = tensor([0.8415, 0.1060, 0.0525])
2024-12-05 15:38:42,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([0.8415, 0.1060, 0.0525]), new_distribution = tensor([0.8420, 0.1057, 0.0523])
2024-12-05 15:38:42,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([0.8420, 0.1057, 0.0523]), new_distribution = tensor([0.8425, 0.1054, 0.0522])
2024-12-05 15:38:42,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([0.8425, 0.1054, 0.0522]), new_distribution = tensor([0.8430, 0.1050, 0.0520])
2024-12-05 15:38:42,433 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([0.8430, 0.1050, 0.0520]), new_distribution = tensor([0.8435, 0.1047, 0.0519])
2024-12-05 15:38:42,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([0.8435, 0.1047, 0.0519]), new_distribution = tensor([0.8440, 0.1043, 0.0517])
2024-12-05 15:38:42,541 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([0.8440, 0.1043, 0.0517]), new_distribution = tensor([0.8444, 0.1040, 0.0516])
2024-12-05 15:38:42,595 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([0.8444, 0.1040, 0.0516]), new_distribution = tensor([0.8449, 0.1037, 0.0514])
2024-12-05 15:38:42,649 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([0.8449, 0.1037, 0.0514]), new_distribution = tensor([0.8454, 0.1033, 0.0512])
2024-12-05 15:38:42,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([0.8454, 0.1033, 0.0512]), new_distribution = tensor([0.8459, 0.1030, 0.0511])
2024-12-05 15:38:42,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([0.8459, 0.1030, 0.0511]), new_distribution = tensor([0.8464, 0.1027, 0.0509])
2024-12-05 15:38:42,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([0.8464, 0.1027, 0.0509]), new_distribution = tensor([0.8469, 0.1023, 0.0508])
2024-12-05 15:38:42,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([0.8469, 0.1023, 0.0508]), new_distribution = tensor([0.8473, 0.1020, 0.0506])
2024-12-05 15:38:42,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([0.8473, 0.1020, 0.0506]), new_distribution = tensor([0.8478, 0.1017, 0.0505])
2024-12-05 15:38:42,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([0.8478, 0.1017, 0.0505]), new_distribution = tensor([0.8483, 0.1014, 0.0503])
2024-12-05 15:38:43,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([0.8483, 0.1014, 0.0503]), new_distribution = tensor([0.8488, 0.1010, 0.0502])
2024-12-05 15:38:43,081 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([0.8488, 0.1010, 0.0502]), new_distribution = tensor([0.8492, 0.1007, 0.0501])
2024-12-05 15:38:43,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([0.8492, 0.1007, 0.0501]), new_distribution = tensor([0.8497, 0.1004, 0.0499])
2024-12-05 15:38:43,189 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([0.8497, 0.1004, 0.0499]), new_distribution = tensor([0.8502, 0.1001, 0.0498])
2024-12-05 15:38:43,243 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([0.8502, 0.1001, 0.0498]), new_distribution = tensor([0.8507, 0.0997, 0.0496])
2024-12-05 15:38:43,297 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([0.8507, 0.0997, 0.0496]), new_distribution = tensor([0.8511, 0.0994, 0.0495])
2024-12-05 15:38:43,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([0.8511, 0.0994, 0.0495]), new_distribution = tensor([0.8516, 0.0991, 0.0493])
2024-12-05 15:38:43,404 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([0.8516, 0.0991, 0.0493]), new_distribution = tensor([0.8521, 0.0988, 0.0492])
2024-12-05 15:38:43,458 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([0.8521, 0.0988, 0.0492]), new_distribution = tensor([0.8525, 0.0984, 0.0490])
2024-12-05 15:38:43,512 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([0.8525, 0.0984, 0.0490]), new_distribution = tensor([0.8530, 0.0981, 0.0489])
2024-12-05 15:38:43,566 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([0.8530, 0.0981, 0.0489]), new_distribution = tensor([0.8535, 0.0978, 0.0487])
2024-12-05 15:38:43,620 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([0.8535, 0.0978, 0.0487]), new_distribution = tensor([0.8539, 0.0975, 0.0486])
2024-12-05 15:38:43,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([0.8539, 0.0975, 0.0486]), new_distribution = tensor([0.8544, 0.0972, 0.0485])
2024-12-05 15:38:43,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([0.8544, 0.0972, 0.0485]), new_distribution = tensor([0.8548, 0.0968, 0.0483])
2024-12-05 15:38:43,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([0.8548, 0.0968, 0.0483]), new_distribution = tensor([0.8553, 0.0965, 0.0482])
2024-12-05 15:38:43,835 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([0.8553, 0.0965, 0.0482]), new_distribution = tensor([0.8558, 0.0962, 0.0480])
2024-12-05 15:38:43,889 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([0.8558, 0.0962, 0.0480]), new_distribution = tensor([0.8562, 0.0959, 0.0479])
2024-12-05 15:38:43,943 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([0.8562, 0.0959, 0.0479]), new_distribution = tensor([0.8567, 0.0956, 0.0477])
2024-12-05 15:38:43,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([0.8567, 0.0956, 0.0477]), new_distribution = tensor([0.8571, 0.0953, 0.0476])
2024-12-05 15:38:44,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([0.8571, 0.0953, 0.0476]), new_distribution = tensor([0.8576, 0.0950, 0.0475])
2024-12-05 15:38:44,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([0.8576, 0.0950, 0.0475]), new_distribution = tensor([0.8580, 0.0946, 0.0473])
2024-12-05 15:38:44,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([0.8580, 0.0946, 0.0473]), new_distribution = tensor([0.8585, 0.0943, 0.0472])
2024-12-05 15:38:44,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([0.8585, 0.0943, 0.0472]), new_distribution = tensor([0.8589, 0.0940, 0.0470])
2024-12-05 15:38:44,266 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([0.8589, 0.0940, 0.0470]), new_distribution = tensor([0.8594, 0.0937, 0.0469])
2024-12-05 15:38:44,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([0.8594, 0.0937, 0.0469]), new_distribution = tensor([0.8598, 0.0934, 0.0468])
2024-12-05 15:38:44,374 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([0.8598, 0.0934, 0.0468]), new_distribution = tensor([0.8603, 0.0931, 0.0466])
2024-12-05 15:38:44,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([0.8603, 0.0931, 0.0466]), new_distribution = tensor([0.8607, 0.0928, 0.0465])
2024-12-05 15:38:44,483 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([0.8607, 0.0928, 0.0465]), new_distribution = tensor([0.8611, 0.0925, 0.0464])
2024-12-05 15:38:44,537 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([0.8611, 0.0925, 0.0464]), new_distribution = tensor([0.8616, 0.0922, 0.0462])
2024-12-05 15:38:44,591 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([0.8616, 0.0922, 0.0462]), new_distribution = tensor([0.8620, 0.0919, 0.0461])
2024-12-05 15:38:44,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([0.8620, 0.0919, 0.0461]), new_distribution = tensor([0.8625, 0.0916, 0.0460])
2024-12-05 15:38:44,699 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([0.8625, 0.0916, 0.0460]), new_distribution = tensor([0.8629, 0.0913, 0.0458])
2024-12-05 15:38:44,753 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([0.8629, 0.0913, 0.0458]), new_distribution = tensor([0.8633, 0.0910, 0.0457])
2024-12-05 15:38:44,807 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([0.8633, 0.0910, 0.0457]), new_distribution = tensor([0.8638, 0.0907, 0.0455])
2024-12-05 15:38:44,861 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([0.8638, 0.0907, 0.0455]), new_distribution = tensor([0.8642, 0.0904, 0.0454])
2024-12-05 15:38:44,915 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([0.8642, 0.0904, 0.0454]), new_distribution = tensor([0.8646, 0.0901, 0.0453])
2024-12-05 15:38:44,968 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([0.8646, 0.0901, 0.0453]), new_distribution = tensor([0.8651, 0.0898, 0.0451])
2024-12-05 15:38:45,022 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([0.8651, 0.0898, 0.0451]), new_distribution = tensor([0.8655, 0.0895, 0.0450])
2024-12-05 15:38:45,077 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([0.8655, 0.0895, 0.0450]), new_distribution = tensor([0.8659, 0.0892, 0.0449])
2024-12-05 15:38:45,130 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([0.8659, 0.0892, 0.0449]), new_distribution = tensor([0.8664, 0.0889, 0.0447])
2024-12-05 15:38:45,185 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([0.8664, 0.0889, 0.0447]), new_distribution = tensor([0.8668, 0.0886, 0.0446])
2024-12-05 15:38:45,239 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([0.8668, 0.0886, 0.0446]), new_distribution = tensor([0.8672, 0.0883, 0.0445])
2024-12-05 15:38:45,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([0.8672, 0.0883, 0.0445]), new_distribution = tensor([0.8676, 0.0880, 0.0444])
2024-12-05 15:38:45,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([0.8676, 0.0880, 0.0444]), new_distribution = tensor([0.8681, 0.0877, 0.0442])
2024-12-05 15:38:45,400 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([0.8681, 0.0877, 0.0442]), new_distribution = tensor([0.8685, 0.0874, 0.0441])
2024-12-05 15:38:45,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([0.8685, 0.0874, 0.0441]), new_distribution = tensor([0.8689, 0.0871, 0.0440])
2024-12-05 15:38:45,509 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([0.8689, 0.0871, 0.0440]), new_distribution = tensor([0.8693, 0.0868, 0.0438])
2024-12-05 15:38:45,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([0.8693, 0.0868, 0.0438]), new_distribution = tensor([0.8698, 0.0865, 0.0437])
2024-12-05 15:38:45,617 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([0.8698, 0.0865, 0.0437]), new_distribution = tensor([0.8702, 0.0863, 0.0436])
2024-12-05 15:38:45,671 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([0.8702, 0.0863, 0.0436]), new_distribution = tensor([0.8706, 0.0860, 0.0434])
2024-12-05 15:38:45,725 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([0.8706, 0.0860, 0.0434]), new_distribution = tensor([0.8710, 0.0857, 0.0433])
2024-12-05 15:38:45,779 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([0.8710, 0.0857, 0.0433]), new_distribution = tensor([0.8714, 0.0854, 0.0432])
2024-12-05 15:38:45,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([0.8714, 0.0854, 0.0432]), new_distribution = tensor([0.8718, 0.0851, 0.0431])
2024-12-05 15:38:45,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([0.8718, 0.0851, 0.0431]), new_distribution = tensor([0.8722, 0.0848, 0.0429])
2024-12-05 15:38:45,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([0.8722, 0.0848, 0.0429]), new_distribution = tensor([0.8727, 0.0845, 0.0428])
2024-12-05 15:38:45,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([0.8727, 0.0845, 0.0428]), new_distribution = tensor([0.8731, 0.0843, 0.0427])
2024-12-05 15:38:46,049 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([0.8731, 0.0843, 0.0427]), new_distribution = tensor([0.8735, 0.0840, 0.0426])
2024-12-05 15:38:46,103 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([0.8735, 0.0840, 0.0426]), new_distribution = tensor([0.8739, 0.0837, 0.0424])
2024-12-05 15:38:46,157 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([0.8739, 0.0837, 0.0424]), new_distribution = tensor([0.8743, 0.0834, 0.0423])
2024-12-05 15:38:46,211 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([0.8743, 0.0834, 0.0423]), new_distribution = tensor([0.8747, 0.0831, 0.0422])
2024-12-05 15:38:46,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([0.8747, 0.0831, 0.0422]), new_distribution = tensor([0.8751, 0.0828, 0.0421])
2024-12-05 15:38:46,319 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([0.8751, 0.0828, 0.0421]), new_distribution = tensor([0.8755, 0.0826, 0.0419])
2024-12-05 15:38:46,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([0.8755, 0.0826, 0.0419]), new_distribution = tensor([0.8759, 0.0823, 0.0418])
2024-12-05 15:38:46,427 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([0.8759, 0.0823, 0.0418]), new_distribution = tensor([0.8763, 0.0820, 0.0417])
2024-12-05 15:38:46,480 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([0.8763, 0.0820, 0.0417]), new_distribution = tensor([0.8767, 0.0817, 0.0416])
2024-12-05 15:38:46,534 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 300: ref_distribution = tensor([0.8767, 0.0817, 0.0416]), new_distribution = tensor([0.8771, 0.0815, 0.0414])
2024-12-05 15:38:46,588 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 301: ref_distribution = tensor([0.8771, 0.0815, 0.0414]), new_distribution = tensor([0.8775, 0.0812, 0.0413])
2024-12-05 15:38:46,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 302: ref_distribution = tensor([0.8775, 0.0812, 0.0413]), new_distribution = tensor([0.8779, 0.0809, 0.0412])
2024-12-05 15:38:46,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 303: ref_distribution = tensor([0.8779, 0.0809, 0.0412]), new_distribution = tensor([0.8783, 0.0806, 0.0411])
2024-12-05 15:38:46,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 304: ref_distribution = tensor([0.8783, 0.0806, 0.0411]), new_distribution = tensor([0.8787, 0.0804, 0.0410])
2024-12-05 15:38:46,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 305: ref_distribution = tensor([0.8787, 0.0804, 0.0410]), new_distribution = tensor([0.8791, 0.0801, 0.0408])
2024-12-05 15:38:46,858 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 306: ref_distribution = tensor([0.8791, 0.0801, 0.0408]), new_distribution = tensor([0.8795, 0.0798, 0.0407])
2024-12-05 15:38:46,912 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 307: ref_distribution = tensor([0.8795, 0.0798, 0.0407]), new_distribution = tensor([0.8799, 0.0796, 0.0406])
2024-12-05 15:38:46,966 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 308: ref_distribution = tensor([0.8799, 0.0796, 0.0406]), new_distribution = tensor([0.8802, 0.0793, 0.0405])
2024-12-05 15:38:47,020 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 309: ref_distribution = tensor([0.8802, 0.0793, 0.0405]), new_distribution = tensor([0.8806, 0.0790, 0.0404])
2024-12-05 15:38:47,074 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 310: ref_distribution = tensor([0.8806, 0.0790, 0.0404]), new_distribution = tensor([0.8810, 0.0787, 0.0402])
2024-12-05 15:38:47,131 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 311: ref_distribution = tensor([0.8810, 0.0787, 0.0402]), new_distribution = tensor([0.8814, 0.0785, 0.0401])
2024-12-05 15:38:47,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 312: ref_distribution = tensor([0.8814, 0.0785, 0.0401]), new_distribution = tensor([0.8818, 0.0782, 0.0400])
2024-12-05 15:38:47,241 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 313: ref_distribution = tensor([0.8818, 0.0782, 0.0400]), new_distribution = tensor([0.8822, 0.0779, 0.0399])
2024-12-05 15:38:47,295 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 314: ref_distribution = tensor([0.8822, 0.0779, 0.0399]), new_distribution = tensor([0.8826, 0.0777, 0.0398])
2024-12-05 15:38:47,349 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 315: ref_distribution = tensor([0.8826, 0.0777, 0.0398]), new_distribution = tensor([0.8829, 0.0774, 0.0396])
2024-12-05 15:38:47,403 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 316: ref_distribution = tensor([0.8829, 0.0774, 0.0396]), new_distribution = tensor([0.8833, 0.0772, 0.0395])
2024-12-05 15:38:47,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 317: ref_distribution = tensor([0.8833, 0.0772, 0.0395]), new_distribution = tensor([0.8837, 0.0769, 0.0394])
2024-12-05 15:38:47,511 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 318: ref_distribution = tensor([0.8837, 0.0769, 0.0394]), new_distribution = tensor([0.8841, 0.0766, 0.0393])
2024-12-05 15:38:47,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 319: ref_distribution = tensor([0.8841, 0.0766, 0.0393]), new_distribution = tensor([0.8845, 0.0764, 0.0392])
2024-12-05 15:38:47,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 320: ref_distribution = tensor([0.8845, 0.0764, 0.0392]), new_distribution = tensor([0.8848, 0.0761, 0.0391])
2024-12-05 15:38:47,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 321: ref_distribution = tensor([0.8848, 0.0761, 0.0391]), new_distribution = tensor([0.8852, 0.0758, 0.0389])
2024-12-05 15:38:47,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 322: ref_distribution = tensor([0.8852, 0.0758, 0.0389]), new_distribution = tensor([0.8856, 0.0756, 0.0388])
2024-12-05 15:38:47,780 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 323: ref_distribution = tensor([0.8856, 0.0756, 0.0388]), new_distribution = tensor([0.8860, 0.0753, 0.0387])
2024-12-05 15:38:47,834 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 324: ref_distribution = tensor([0.8860, 0.0753, 0.0387]), new_distribution = tensor([0.8863, 0.0751, 0.0386])
2024-12-05 15:38:47,888 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 325: ref_distribution = tensor([0.8863, 0.0751, 0.0386]), new_distribution = tensor([0.8867, 0.0748, 0.0385])
2024-12-05 15:38:47,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 326: ref_distribution = tensor([0.8867, 0.0748, 0.0385]), new_distribution = tensor([0.8871, 0.0746, 0.0384])
2024-12-05 15:38:47,996 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 327: ref_distribution = tensor([0.8871, 0.0746, 0.0384]), new_distribution = tensor([0.8874, 0.0743, 0.0383])
2024-12-05 15:38:48,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 328: ref_distribution = tensor([0.8874, 0.0743, 0.0383]), new_distribution = tensor([0.8878, 0.0741, 0.0381])
2024-12-05 15:38:48,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 329: ref_distribution = tensor([0.8878, 0.0741, 0.0381]), new_distribution = tensor([0.8882, 0.0738, 0.0380])
2024-12-05 15:38:48,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 330: ref_distribution = tensor([0.8882, 0.0738, 0.0380]), new_distribution = tensor([0.8885, 0.0735, 0.0379])
2024-12-05 15:38:48,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 331: ref_distribution = tensor([0.8885, 0.0735, 0.0379]), new_distribution = tensor([0.8889, 0.0733, 0.0378])
2024-12-05 15:38:48,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 332: ref_distribution = tensor([0.8889, 0.0733, 0.0378]), new_distribution = tensor([0.8893, 0.0730, 0.0377])
2024-12-05 15:38:48,319 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 333: ref_distribution = tensor([0.8893, 0.0730, 0.0377]), new_distribution = tensor([0.8896, 0.0728, 0.0376])
2024-12-05 15:38:48,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 334: ref_distribution = tensor([0.8896, 0.0728, 0.0376]), new_distribution = tensor([0.8900, 0.0725, 0.0375])
2024-12-05 15:38:48,427 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 335: ref_distribution = tensor([0.8900, 0.0725, 0.0375]), new_distribution = tensor([0.8903, 0.0723, 0.0374])
2024-12-05 15:38:48,481 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 336: ref_distribution = tensor([0.8903, 0.0723, 0.0374]), new_distribution = tensor([0.8907, 0.0720, 0.0373])
2024-12-05 15:38:48,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 337: ref_distribution = tensor([0.8907, 0.0720, 0.0373]), new_distribution = tensor([0.8911, 0.0718, 0.0371])
2024-12-05 15:38:48,589 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 338: ref_distribution = tensor([0.8911, 0.0718, 0.0371]), new_distribution = tensor([0.8914, 0.0715, 0.0370])
2024-12-05 15:38:48,643 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 339: ref_distribution = tensor([0.8914, 0.0715, 0.0370]), new_distribution = tensor([0.8918, 0.0713, 0.0369])
2024-12-05 15:38:48,697 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 340: ref_distribution = tensor([0.8918, 0.0713, 0.0369]), new_distribution = tensor([0.8921, 0.0711, 0.0368])
2024-12-05 15:38:48,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 341: ref_distribution = tensor([0.8921, 0.0711, 0.0368]), new_distribution = tensor([0.8925, 0.0708, 0.0367])
2024-12-05 15:38:48,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 342: ref_distribution = tensor([0.8925, 0.0708, 0.0367]), new_distribution = tensor([0.8928, 0.0706, 0.0366])
2024-12-05 15:38:48,858 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 343: ref_distribution = tensor([0.8928, 0.0706, 0.0366]), new_distribution = tensor([0.8932, 0.0703, 0.0365])
2024-12-05 15:38:48,912 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 344: ref_distribution = tensor([0.8932, 0.0703, 0.0365]), new_distribution = tensor([0.8935, 0.0701, 0.0364])
2024-12-05 15:38:48,966 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 345: ref_distribution = tensor([0.8935, 0.0701, 0.0364]), new_distribution = tensor([0.8939, 0.0698, 0.0363])
2024-12-05 15:38:49,020 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 346: ref_distribution = tensor([0.8939, 0.0698, 0.0363]), new_distribution = tensor([0.8942, 0.0696, 0.0362])
2024-12-05 15:38:49,074 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 347: ref_distribution = tensor([0.8942, 0.0696, 0.0362]), new_distribution = tensor([0.8946, 0.0694, 0.0361])
2024-12-05 15:38:49,128 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 348: ref_distribution = tensor([0.8946, 0.0694, 0.0361]), new_distribution = tensor([0.8949, 0.0691, 0.0360])
2024-12-05 15:38:49,182 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 349: ref_distribution = tensor([0.8949, 0.0691, 0.0360]), new_distribution = tensor([0.8953, 0.0689, 0.0359])
2024-12-05 15:38:49,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 350: ref_distribution = tensor([0.8953, 0.0689, 0.0359]), new_distribution = tensor([0.8956, 0.0686, 0.0357])
2024-12-05 15:38:49,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 351: ref_distribution = tensor([0.8956, 0.0686, 0.0357]), new_distribution = tensor([0.8960, 0.0684, 0.0356])
2024-12-05 15:38:49,344 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 352: ref_distribution = tensor([0.8960, 0.0684, 0.0356]), new_distribution = tensor([0.8963, 0.0682, 0.0355])
2024-12-05 15:38:49,398 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 353: ref_distribution = tensor([0.8963, 0.0682, 0.0355]), new_distribution = tensor([0.8967, 0.0679, 0.0354])
2024-12-05 15:38:49,452 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 354: ref_distribution = tensor([0.8967, 0.0679, 0.0354]), new_distribution = tensor([0.8970, 0.0677, 0.0353])
2024-12-05 15:38:49,506 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 355: ref_distribution = tensor([0.8970, 0.0677, 0.0353]), new_distribution = tensor([0.8973, 0.0674, 0.0352])
2024-12-05 15:38:49,560 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 356: ref_distribution = tensor([0.8973, 0.0674, 0.0352]), new_distribution = tensor([0.8977, 0.0672, 0.0351])
2024-12-05 15:38:49,614 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 357: ref_distribution = tensor([0.8977, 0.0672, 0.0351]), new_distribution = tensor([0.8980, 0.0670, 0.0350])
2024-12-05 15:38:49,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 358: ref_distribution = tensor([0.8980, 0.0670, 0.0350]), new_distribution = tensor([0.8983, 0.0667, 0.0349])
2024-12-05 15:38:49,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 359: ref_distribution = tensor([0.8983, 0.0667, 0.0349]), new_distribution = tensor([0.8987, 0.0665, 0.0348])
2024-12-05 15:38:49,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 360: ref_distribution = tensor([0.8987, 0.0665, 0.0348]), new_distribution = tensor([0.8990, 0.0663, 0.0347])
2024-12-05 15:38:49,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 361: ref_distribution = tensor([0.8990, 0.0663, 0.0347]), new_distribution = tensor([0.8993, 0.0661, 0.0346])
2024-12-05 15:38:49,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 362: ref_distribution = tensor([0.8993, 0.0661, 0.0346]), new_distribution = tensor([0.8997, 0.0658, 0.0345])
2024-12-05 15:38:49,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 363: ref_distribution = tensor([0.8997, 0.0658, 0.0345]), new_distribution = tensor([0.9000, 0.0656, 0.0344])
2024-12-05 15:38:49,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 364: ref_distribution = tensor([0.9000, 0.0656, 0.0344]), new_distribution = tensor([0.9003, 0.0654, 0.0343])
2024-12-05 15:38:50,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 365: ref_distribution = tensor([0.9003, 0.0654, 0.0343]), new_distribution = tensor([0.9007, 0.0651, 0.0342])
2024-12-05 15:38:50,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 366: ref_distribution = tensor([0.9007, 0.0651, 0.0342]), new_distribution = tensor([0.9010, 0.0649, 0.0341])
2024-12-05 15:38:50,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 367: ref_distribution = tensor([0.9010, 0.0649, 0.0341]), new_distribution = tensor([0.9013, 0.0647, 0.0340])
2024-12-05 15:38:50,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 368: ref_distribution = tensor([0.9013, 0.0647, 0.0340]), new_distribution = tensor([0.9017, 0.0645, 0.0339])
2024-12-05 15:38:50,260 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 369: ref_distribution = tensor([0.9017, 0.0645, 0.0339]), new_distribution = tensor([0.9020, 0.0642, 0.0338])
2024-12-05 15:38:50,314 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 370: ref_distribution = tensor([0.9020, 0.0642, 0.0338]), new_distribution = tensor([0.9023, 0.0640, 0.0337])
2024-12-05 15:38:50,368 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 371: ref_distribution = tensor([0.9023, 0.0640, 0.0337]), new_distribution = tensor([0.9026, 0.0638, 0.0336])
2024-12-05 15:38:50,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 372: ref_distribution = tensor([0.9026, 0.0638, 0.0336]), new_distribution = tensor([0.9030, 0.0636, 0.0335])
2024-12-05 15:38:50,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 373: ref_distribution = tensor([0.9030, 0.0636, 0.0335]), new_distribution = tensor([0.9033, 0.0633, 0.0334])
2024-12-05 15:38:50,529 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 374: ref_distribution = tensor([0.9033, 0.0633, 0.0334]), new_distribution = tensor([0.9036, 0.0631, 0.0333])
2024-12-05 15:38:50,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 375: ref_distribution = tensor([0.9036, 0.0631, 0.0333]), new_distribution = tensor([0.9039, 0.0629, 0.0332])
2024-12-05 15:38:50,637 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 376: ref_distribution = tensor([0.9039, 0.0629, 0.0332]), new_distribution = tensor([0.9042, 0.0627, 0.0331])
2024-12-05 15:38:50,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 377: ref_distribution = tensor([0.9042, 0.0627, 0.0331]), new_distribution = tensor([0.9045, 0.0625, 0.0330])
2024-12-05 15:38:50,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 378: ref_distribution = tensor([0.9045, 0.0625, 0.0330]), new_distribution = tensor([0.9049, 0.0622, 0.0329])
2024-12-05 15:38:50,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 379: ref_distribution = tensor([0.9049, 0.0622, 0.0329]), new_distribution = tensor([0.9052, 0.0620, 0.0328])
2024-12-05 15:38:50,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 380: ref_distribution = tensor([0.9052, 0.0620, 0.0328]), new_distribution = tensor([0.9055, 0.0618, 0.0327])
2024-12-05 15:38:50,906 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 381: ref_distribution = tensor([0.9055, 0.0618, 0.0327]), new_distribution = tensor([0.9058, 0.0616, 0.0326])
2024-12-05 15:38:50,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 382: ref_distribution = tensor([0.9058, 0.0616, 0.0326]), new_distribution = tensor([0.9061, 0.0614, 0.0325])
2024-12-05 15:38:51,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 383: ref_distribution = tensor([0.9061, 0.0614, 0.0325]), new_distribution = tensor([0.9064, 0.0611, 0.0324])
2024-12-05 15:38:51,068 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 384: ref_distribution = tensor([0.9064, 0.0611, 0.0324]), new_distribution = tensor([0.9067, 0.0609, 0.0323])
2024-12-05 15:38:51,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 385: ref_distribution = tensor([0.9067, 0.0609, 0.0323]), new_distribution = tensor([0.9071, 0.0607, 0.0322])
2024-12-05 15:38:51,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 386: ref_distribution = tensor([0.9071, 0.0607, 0.0322]), new_distribution = tensor([0.9074, 0.0605, 0.0321])
2024-12-05 15:38:51,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 387: ref_distribution = tensor([0.9074, 0.0605, 0.0321]), new_distribution = tensor([0.9077, 0.0603, 0.0320])
2024-12-05 15:38:51,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 388: ref_distribution = tensor([0.9077, 0.0603, 0.0320]), new_distribution = tensor([0.9080, 0.0601, 0.0319])
2024-12-05 15:38:51,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 389: ref_distribution = tensor([0.9080, 0.0601, 0.0319]), new_distribution = tensor([0.9083, 0.0599, 0.0318])
2024-12-05 15:38:51,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 390: ref_distribution = tensor([0.9083, 0.0599, 0.0318]), new_distribution = tensor([0.9086, 0.0597, 0.0318])
2024-12-05 15:38:51,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 391: ref_distribution = tensor([0.9086, 0.0597, 0.0318]), new_distribution = tensor([0.9089, 0.0594, 0.0317])
2024-12-05 15:38:51,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 392: ref_distribution = tensor([0.9089, 0.0594, 0.0317]), new_distribution = tensor([0.9092, 0.0592, 0.0316])
2024-12-05 15:38:51,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 393: ref_distribution = tensor([0.9092, 0.0592, 0.0316]), new_distribution = tensor([0.9095, 0.0590, 0.0315])
2024-12-05 15:38:51,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 394: ref_distribution = tensor([0.9095, 0.0590, 0.0315]), new_distribution = tensor([0.9098, 0.0588, 0.0314])
2024-12-05 15:38:51,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 395: ref_distribution = tensor([0.9098, 0.0588, 0.0314]), new_distribution = tensor([0.9101, 0.0586, 0.0313])
2024-12-05 15:38:51,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 396: ref_distribution = tensor([0.9101, 0.0586, 0.0313]), new_distribution = tensor([0.9104, 0.0584, 0.0312])
2024-12-05 15:38:51,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 397: ref_distribution = tensor([0.9104, 0.0584, 0.0312]), new_distribution = tensor([0.9107, 0.0582, 0.0311])
2024-12-05 15:38:51,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 398: ref_distribution = tensor([0.9107, 0.0582, 0.0311]), new_distribution = tensor([0.9110, 0.0580, 0.0310])
2024-12-05 15:38:51,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 399: ref_distribution = tensor([0.9110, 0.0580, 0.0310]), new_distribution = tensor([0.9113, 0.0578, 0.0309])
2024-12-05 15:38:51,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 400: ref_distribution = tensor([0.9113, 0.0578, 0.0309]), new_distribution = tensor([0.9116, 0.0576, 0.0308])
2024-12-05 15:38:51,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 401: ref_distribution = tensor([0.9116, 0.0576, 0.0308]), new_distribution = tensor([0.9119, 0.0574, 0.0307])
2024-12-05 15:38:52,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 402: ref_distribution = tensor([0.9119, 0.0574, 0.0307]), new_distribution = tensor([0.9122, 0.0572, 0.0306])
2024-12-05 15:38:52,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 403: ref_distribution = tensor([0.9122, 0.0572, 0.0306]), new_distribution = tensor([0.9125, 0.0570, 0.0306])
2024-12-05 15:38:52,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 404: ref_distribution = tensor([0.9125, 0.0570, 0.0306]), new_distribution = tensor([0.9128, 0.0568, 0.0305])
2024-12-05 15:38:52,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 405: ref_distribution = tensor([0.9128, 0.0568, 0.0305]), new_distribution = tensor([0.9131, 0.0566, 0.0304])
2024-12-05 15:38:52,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 406: ref_distribution = tensor([0.9131, 0.0566, 0.0304]), new_distribution = tensor([0.9134, 0.0564, 0.0303])
2024-12-05 15:38:52,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 407: ref_distribution = tensor([0.9134, 0.0564, 0.0303]), new_distribution = tensor([0.9136, 0.0562, 0.0302])
2024-12-05 15:38:52,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 408: ref_distribution = tensor([0.9136, 0.0562, 0.0302]), new_distribution = tensor([0.9139, 0.0560, 0.0301])
2024-12-05 15:38:52,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 409: ref_distribution = tensor([0.9139, 0.0560, 0.0301]), new_distribution = tensor([0.9142, 0.0558, 0.0300])
2024-12-05 15:38:52,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 410: ref_distribution = tensor([0.9142, 0.0558, 0.0300]), new_distribution = tensor([0.9145, 0.0556, 0.0299])
2024-12-05 15:38:52,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 411: ref_distribution = tensor([0.9145, 0.0556, 0.0299]), new_distribution = tensor([0.9148, 0.0554, 0.0298])
2024-12-05 15:38:52,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 412: ref_distribution = tensor([0.9148, 0.0554, 0.0298]), new_distribution = tensor([0.9151, 0.0552, 0.0297])
2024-12-05 15:38:52,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 413: ref_distribution = tensor([0.9151, 0.0552, 0.0297]), new_distribution = tensor([0.9154, 0.0550, 0.0297])
2024-12-05 15:38:52,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 414: ref_distribution = tensor([0.9154, 0.0550, 0.0297]), new_distribution = tensor([0.9157, 0.0548, 0.0296])
2024-12-05 15:38:52,742 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 415: ref_distribution = tensor([0.9157, 0.0548, 0.0296]), new_distribution = tensor([0.9159, 0.0546, 0.0295])
2024-12-05 15:38:52,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 416: ref_distribution = tensor([0.9159, 0.0546, 0.0295]), new_distribution = tensor([0.9162, 0.0544, 0.0294])
2024-12-05 15:38:52,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 417: ref_distribution = tensor([0.9162, 0.0544, 0.0294]), new_distribution = tensor([0.9165, 0.0542, 0.0293])
2024-12-05 15:38:52,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 418: ref_distribution = tensor([0.9165, 0.0542, 0.0293]), new_distribution = tensor([0.9168, 0.0540, 0.0292])
2024-12-05 15:38:52,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 419: ref_distribution = tensor([0.9168, 0.0540, 0.0292]), new_distribution = tensor([0.9171, 0.0538, 0.0291])
2024-12-05 15:38:53,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 420: ref_distribution = tensor([0.9171, 0.0538, 0.0291]), new_distribution = tensor([0.9173, 0.0536, 0.0291])
2024-12-05 15:38:53,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 421: ref_distribution = tensor([0.9173, 0.0536, 0.0291]), new_distribution = tensor([0.9176, 0.0534, 0.0290])
2024-12-05 15:38:53,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 422: ref_distribution = tensor([0.9176, 0.0534, 0.0290]), new_distribution = tensor([0.9179, 0.0532, 0.0289])
2024-12-05 15:38:53,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 423: ref_distribution = tensor([0.9179, 0.0532, 0.0289]), new_distribution = tensor([0.9182, 0.0530, 0.0288])
2024-12-05 15:38:53,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 424: ref_distribution = tensor([0.9182, 0.0530, 0.0288]), new_distribution = tensor([0.9184, 0.0528, 0.0287])
2024-12-05 15:38:53,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 425: ref_distribution = tensor([0.9184, 0.0528, 0.0287]), new_distribution = tensor([0.9187, 0.0527, 0.0286])
2024-12-05 15:38:53,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 426: ref_distribution = tensor([0.9187, 0.0527, 0.0286]), new_distribution = tensor([0.9190, 0.0525, 0.0285])
2024-12-05 15:38:53,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 427: ref_distribution = tensor([0.9190, 0.0525, 0.0285]), new_distribution = tensor([0.9193, 0.0523, 0.0285])
2024-12-05 15:38:53,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 428: ref_distribution = tensor([0.9193, 0.0523, 0.0285]), new_distribution = tensor([0.9195, 0.0521, 0.0284])
2024-12-05 15:38:53,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 429: ref_distribution = tensor([0.9195, 0.0521, 0.0284]), new_distribution = tensor([0.9198, 0.0519, 0.0283])
2024-12-05 15:38:53,549 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 430: ref_distribution = tensor([0.9198, 0.0519, 0.0283]), new_distribution = tensor([0.9201, 0.0517, 0.0282])
2024-12-05 15:38:53,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 431: ref_distribution = tensor([0.9201, 0.0517, 0.0282]), new_distribution = tensor([0.9203, 0.0515, 0.0281])
2024-12-05 15:38:53,657 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 432: ref_distribution = tensor([0.9203, 0.0515, 0.0281]), new_distribution = tensor([0.9206, 0.0514, 0.0280])
2024-12-05 15:38:53,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 433: ref_distribution = tensor([0.9206, 0.0514, 0.0280]), new_distribution = tensor([0.9209, 0.0512, 0.0280])
2024-12-05 15:38:53,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 434: ref_distribution = tensor([0.9209, 0.0512, 0.0280]), new_distribution = tensor([0.9211, 0.0510, 0.0279])
2024-12-05 15:38:53,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 435: ref_distribution = tensor([0.9211, 0.0510, 0.0279]), new_distribution = tensor([0.9214, 0.0508, 0.0278])
2024-12-05 15:38:53,873 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 436: ref_distribution = tensor([0.9214, 0.0508, 0.0278]), new_distribution = tensor([0.9217, 0.0506, 0.0277])
2024-12-05 15:38:53,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 437: ref_distribution = tensor([0.9217, 0.0506, 0.0277]), new_distribution = tensor([0.9219, 0.0504, 0.0276])
2024-12-05 15:38:53,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 438: ref_distribution = tensor([0.9219, 0.0504, 0.0276]), new_distribution = tensor([0.9222, 0.0503, 0.0275])
2024-12-05 15:38:54,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 439: ref_distribution = tensor([0.9222, 0.0503, 0.0275]), new_distribution = tensor([0.9225, 0.0501, 0.0275])
2024-12-05 15:38:54,088 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 440: ref_distribution = tensor([0.9225, 0.0501, 0.0275]), new_distribution = tensor([0.9227, 0.0499, 0.0274])
2024-12-05 15:38:54,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 441: ref_distribution = tensor([0.9227, 0.0499, 0.0274]), new_distribution = tensor([0.9230, 0.0497, 0.0273])
2024-12-05 15:38:54,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 442: ref_distribution = tensor([0.9230, 0.0497, 0.0273]), new_distribution = tensor([0.9232, 0.0495, 0.0272])
2024-12-05 15:38:54,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 443: ref_distribution = tensor([0.9232, 0.0495, 0.0272]), new_distribution = tensor([0.9235, 0.0494, 0.0271])
2024-12-05 15:38:54,304 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 444: ref_distribution = tensor([0.9235, 0.0494, 0.0271]), new_distribution = tensor([0.9238, 0.0492, 0.0271])
2024-12-05 15:38:54,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 445: ref_distribution = tensor([0.9238, 0.0492, 0.0271]), new_distribution = tensor([0.9240, 0.0490, 0.0270])
2024-12-05 15:38:54,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 446: ref_distribution = tensor([0.9240, 0.0490, 0.0270]), new_distribution = tensor([0.9243, 0.0488, 0.0269])
2024-12-05 15:38:54,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 447: ref_distribution = tensor([0.9243, 0.0488, 0.0269]), new_distribution = tensor([0.9245, 0.0486, 0.0268])
2024-12-05 15:38:54,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 448: ref_distribution = tensor([0.9245, 0.0486, 0.0268]), new_distribution = tensor([0.9248, 0.0485, 0.0267])
2024-12-05 15:38:54,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 449: ref_distribution = tensor([0.9248, 0.0485, 0.0267]), new_distribution = tensor([0.9250, 0.0483, 0.0267])
2024-12-05 15:38:54,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 450: ref_distribution = tensor([0.9250, 0.0483, 0.0267]), new_distribution = tensor([0.9253, 0.0481, 0.0266])
2024-12-05 15:38:54,729 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 451: ref_distribution = tensor([0.9253, 0.0481, 0.0266]), new_distribution = tensor([0.9256, 0.0479, 0.0265])
2024-12-05 15:38:54,834 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 452: ref_distribution = tensor([0.9256, 0.0479, 0.0265]), new_distribution = tensor([0.9258, 0.0478, 0.0264])
2024-12-05 15:38:54,939 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 453: ref_distribution = tensor([0.9258, 0.0478, 0.0264]), new_distribution = tensor([0.9261, 0.0476, 0.0263])
2024-12-05 15:38:55,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 454: ref_distribution = tensor([0.9261, 0.0476, 0.0263]), new_distribution = tensor([0.9263, 0.0474, 0.0263])
2024-12-05 15:38:55,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 455: ref_distribution = tensor([0.9263, 0.0474, 0.0263]), new_distribution = tensor([0.9266, 0.0473, 0.0262])
2024-12-05 15:38:55,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 456: ref_distribution = tensor([0.9266, 0.0473, 0.0262]), new_distribution = tensor([0.9268, 0.0471, 0.0261])
2024-12-05 15:38:55,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 457: ref_distribution = tensor([0.9268, 0.0471, 0.0261]), new_distribution = tensor([0.9271, 0.0469, 0.0260])
2024-12-05 15:38:55,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 458: ref_distribution = tensor([0.9271, 0.0469, 0.0260]), new_distribution = tensor([0.9273, 0.0467, 0.0260])
2024-12-05 15:38:55,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 459: ref_distribution = tensor([0.9273, 0.0467, 0.0260]), new_distribution = tensor([0.9275, 0.0466, 0.0259])
2024-12-05 15:38:55,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 460: ref_distribution = tensor([0.9275, 0.0466, 0.0259]), new_distribution = tensor([0.9278, 0.0464, 0.0258])
2024-12-05 15:38:55,780 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 461: ref_distribution = tensor([0.9278, 0.0464, 0.0258]), new_distribution = tensor([0.9280, 0.0462, 0.0257])
2024-12-05 15:38:55,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 462: ref_distribution = tensor([0.9280, 0.0462, 0.0257]), new_distribution = tensor([0.9283, 0.0461, 0.0256])
2024-12-05 15:38:55,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 463: ref_distribution = tensor([0.9283, 0.0461, 0.0256]), new_distribution = tensor([0.9285, 0.0459, 0.0256])
2024-12-05 15:38:56,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 464: ref_distribution = tensor([0.9285, 0.0459, 0.0256]), new_distribution = tensor([0.9288, 0.0457, 0.0255])
2024-12-05 15:38:56,199 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 465: ref_distribution = tensor([0.9288, 0.0457, 0.0255]), new_distribution = tensor([0.9290, 0.0456, 0.0254])
2024-12-05 15:38:56,300 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 466: ref_distribution = tensor([0.9290, 0.0456, 0.0254]), new_distribution = tensor([0.9292, 0.0454, 0.0253])
2024-12-05 15:38:56,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 467: ref_distribution = tensor([0.9292, 0.0454, 0.0253]), new_distribution = tensor([0.9295, 0.0452, 0.0253])
2024-12-05 15:38:56,489 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 468: ref_distribution = tensor([0.9295, 0.0452, 0.0253]), new_distribution = tensor([0.9297, 0.0451, 0.0252])
2024-12-05 15:38:56,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 469: ref_distribution = tensor([0.9297, 0.0451, 0.0252]), new_distribution = tensor([0.9300, 0.0449, 0.0251])
2024-12-05 15:38:56,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 470: ref_distribution = tensor([0.9300, 0.0449, 0.0251]), new_distribution = tensor([0.9302, 0.0448, 0.0250])
2024-12-05 15:38:56,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 471: ref_distribution = tensor([0.9302, 0.0448, 0.0250]), new_distribution = tensor([0.9304, 0.0446, 0.0250])
2024-12-05 15:38:56,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 472: ref_distribution = tensor([0.9304, 0.0446, 0.0250]), new_distribution = tensor([0.9307, 0.0444, 0.0249])
2024-12-05 15:38:56,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 473: ref_distribution = tensor([0.9307, 0.0444, 0.0249]), new_distribution = tensor([0.9309, 0.0443, 0.0248])
2024-12-05 15:38:56,943 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 474: ref_distribution = tensor([0.9309, 0.0443, 0.0248]), new_distribution = tensor([0.9311, 0.0441, 0.0247])
2024-12-05 15:38:57,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 475: ref_distribution = tensor([0.9311, 0.0441, 0.0247]), new_distribution = tensor([0.9314, 0.0439, 0.0247])
2024-12-05 15:38:57,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 476: ref_distribution = tensor([0.9314, 0.0439, 0.0247]), new_distribution = tensor([0.9316, 0.0438, 0.0246])
2024-12-05 15:38:57,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 477: ref_distribution = tensor([0.9316, 0.0438, 0.0246]), new_distribution = tensor([0.9318, 0.0436, 0.0245])
2024-12-05 15:38:57,181 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 478: ref_distribution = tensor([0.9318, 0.0436, 0.0245]), new_distribution = tensor([0.9321, 0.0435, 0.0245])
2024-12-05 15:38:57,235 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 479: ref_distribution = tensor([0.9321, 0.0435, 0.0245]), new_distribution = tensor([0.9323, 0.0433, 0.0244])
2024-12-05 15:38:57,289 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 480: ref_distribution = tensor([0.9323, 0.0433, 0.0244]), new_distribution = tensor([0.9325, 0.0431, 0.0243])
2024-12-05 15:38:57,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 481: ref_distribution = tensor([0.9325, 0.0431, 0.0243]), new_distribution = tensor([0.9328, 0.0430, 0.0242])
2024-12-05 15:38:57,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 482: ref_distribution = tensor([0.9328, 0.0430, 0.0242]), new_distribution = tensor([0.9330, 0.0428, 0.0242])
2024-12-05 15:38:57,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 483: ref_distribution = tensor([0.9330, 0.0428, 0.0242]), new_distribution = tensor([0.9332, 0.0427, 0.0241])
2024-12-05 15:38:57,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 484: ref_distribution = tensor([0.9332, 0.0427, 0.0241]), new_distribution = tensor([0.9335, 0.0425, 0.0240])
2024-12-05 15:38:57,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 485: ref_distribution = tensor([0.9335, 0.0425, 0.0240]), new_distribution = tensor([0.9337, 0.0424, 0.0240])
2024-12-05 15:38:57,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 486: ref_distribution = tensor([0.9337, 0.0424, 0.0240]), new_distribution = tensor([0.9339, 0.0422, 0.0239])
2024-12-05 15:38:57,666 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 487: ref_distribution = tensor([0.9339, 0.0422, 0.0239]), new_distribution = tensor([0.9341, 0.0421, 0.0238])
2024-12-05 15:38:57,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 488: ref_distribution = tensor([0.9341, 0.0421, 0.0238]), new_distribution = tensor([0.9344, 0.0419, 0.0237])
2024-12-05 15:38:57,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 489: ref_distribution = tensor([0.9344, 0.0419, 0.0237]), new_distribution = tensor([0.9346, 0.0417, 0.0237])
2024-12-05 15:38:57,827 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 490: ref_distribution = tensor([0.9346, 0.0417, 0.0237]), new_distribution = tensor([0.9348, 0.0416, 0.0236])
2024-12-05 15:38:57,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 491: ref_distribution = tensor([0.9348, 0.0416, 0.0236]), new_distribution = tensor([0.9350, 0.0414, 0.0235])
2024-12-05 15:38:57,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 492: ref_distribution = tensor([0.9350, 0.0414, 0.0235]), new_distribution = tensor([0.9352, 0.0413, 0.0235])
2024-12-05 15:38:57,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 493: ref_distribution = tensor([0.9352, 0.0413, 0.0235]), new_distribution = tensor([0.9355, 0.0411, 0.0234])
2024-12-05 15:38:58,043 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 494: ref_distribution = tensor([0.9355, 0.0411, 0.0234]), new_distribution = tensor([0.9357, 0.0410, 0.0233])
2024-12-05 15:38:58,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 495: ref_distribution = tensor([0.9357, 0.0410, 0.0233]), new_distribution = tensor([0.9359, 0.0408, 0.0233])
2024-12-05 15:38:58,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 496: ref_distribution = tensor([0.9359, 0.0408, 0.0233]), new_distribution = tensor([0.9361, 0.0407, 0.0232])
2024-12-05 15:38:58,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 497: ref_distribution = tensor([0.9361, 0.0407, 0.0232]), new_distribution = tensor([0.9363, 0.0405, 0.0231])
2024-12-05 15:38:58,262 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 498: ref_distribution = tensor([0.9363, 0.0405, 0.0231]), new_distribution = tensor([0.9366, 0.0404, 0.0230])
2024-12-05 15:38:58,316 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 499: ref_distribution = tensor([0.9366, 0.0404, 0.0230]), new_distribution = tensor([0.9368, 0.0402, 0.0230])
2024-12-05 15:38:58,588 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:58,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:58,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:58,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:58,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:58,857 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:58,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:58,965 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,019 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,073 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,127 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,181 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,235 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,342 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,560 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,614 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,884 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:38:59,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,046 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,100 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,423 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,477 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,531 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,585 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,639 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,855 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:00,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,232 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,448 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,502 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,556 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:01,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,418 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:02,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,119 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,173 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,281 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,335 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,551 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,605 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:03,983 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,146 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,307 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,469 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,630 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,738 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,792 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,899 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:04,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,007 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,061 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,115 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,168 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,599 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:05,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,031 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,085 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,192 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,300 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,408 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:06,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,002 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,111 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,168 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,492 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:07,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,138 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,192 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,300 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,408 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:08,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,000 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,162 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,216 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,378 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,431 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,647 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,701 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,809 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,863 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,916 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:09,970 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,024 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,078 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,240 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,509 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,617 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,671 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,724 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,779 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,940 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:10,994 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,048 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,102 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,156 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,210 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,480 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,534 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,802 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,910 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:11,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,395 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,502 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,556 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,718 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,772 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,826 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:12,988 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,042 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,096 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,581 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,634 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,742 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:13,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,119 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,173 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,281 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,335 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,442 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,550 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,604 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,711 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 300: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 301: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,873 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 302: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,926 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 303: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:14,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 304: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 305: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,088 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 306: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 307: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 308: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 309: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,304 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 310: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 311: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 312: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 313: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 314: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 315: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 316: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,680 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 317: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,734 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 318: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,788 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 319: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,842 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 320: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 321: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:15,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 322: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 323: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 324: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 325: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,165 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 326: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,219 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 327: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 328: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,327 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 329: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,381 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 330: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,434 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 331: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,488 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 332: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,542 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 333: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 334: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,650 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 335: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 336: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,758 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 337: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 338: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 339: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 340: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:16,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 341: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:17,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 342: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:17,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 343: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:17,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 344: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:17,267 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 345: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:17,346 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 346: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:17,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 347: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:17,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 348: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:17,584 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 349: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:17,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 350: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:17,743 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 351: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:17,822 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 352: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:17,902 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 353: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:17,981 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 354: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:18,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 355: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:18,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 356: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:18,219 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 357: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:18,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 358: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:18,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 359: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:18,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 360: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:18,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 361: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:18,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 362: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:18,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 363: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:18,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 364: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:18,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 365: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:18,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 366: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 367: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 368: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,169 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 369: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,241 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 370: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,309 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 371: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,374 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 372: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 373: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 374: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,553 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 375: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 376: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 377: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 378: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,770 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 379: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 380: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 381: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 382: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:19,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 383: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 384: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 385: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 386: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 387: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 388: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 389: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 390: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,420 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 391: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 392: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 393: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 394: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,637 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 395: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 396: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 397: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 398: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 399: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 400: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:20,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 401: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 402: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 403: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 404: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 405: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 406: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 407: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 408: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 409: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 410: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 411: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 412: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 413: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 414: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 415: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 416: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 417: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,884 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 418: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 419: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:21,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 420: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 421: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,101 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 422: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,155 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 423: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,209 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 424: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 425: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,321 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 426: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,375 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 427: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 428: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 429: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,540 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 430: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,594 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 431: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 432: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 433: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 434: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 435: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 436: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 437: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:22,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 438: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 439: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 440: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 441: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 442: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 443: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 444: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 445: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,408 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 446: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 447: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 448: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 449: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,625 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 450: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 451: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 452: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 453: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,842 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 454: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 455: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:23,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 456: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 457: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 458: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 459: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 460: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,221 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 461: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 462: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,331 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 463: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,385 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 464: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,439 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 465: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,493 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 466: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 467: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 468: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 469: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,711 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 470: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 471: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 472: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 473: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,928 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 474: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:24,983 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 475: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,037 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 476: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,091 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 477: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,146 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 478: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 479: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 480: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 481: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 482: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 483: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,472 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 484: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,526 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 485: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 486: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,634 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 487: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 488: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,743 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 489: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,797 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 490: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 491: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 492: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:25,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 493: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:26,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 494: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:26,068 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 495: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:26,122 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 496: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:26,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 497: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:26,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 498: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:26,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 499: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:39:26,566 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.1000, 0.3000, 0.6000]), new_distribution = tensor([0.1003, 0.3005, 0.5992])
2024-12-05 15:39:26,620 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.1003, 0.3005, 0.5992]), new_distribution = tensor([0.1006, 0.3009, 0.5984])
2024-12-05 15:39:26,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.1006, 0.3009, 0.5984]), new_distribution = tensor([0.1010, 0.3014, 0.5976])
2024-12-05 15:39:26,729 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.1010, 0.3014, 0.5976]), new_distribution = tensor([0.1013, 0.3019, 0.5968])
2024-12-05 15:39:26,783 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.1013, 0.3019, 0.5968]), new_distribution = tensor([0.1016, 0.3024, 0.5960])
2024-12-05 15:39:26,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.1016, 0.3024, 0.5960]), new_distribution = tensor([0.1019, 0.3028, 0.5952])
2024-12-05 15:39:26,891 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.1019, 0.3028, 0.5952]), new_distribution = tensor([0.1022, 0.3033, 0.5944])
2024-12-05 15:39:26,945 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.1022, 0.3033, 0.5944]), new_distribution = tensor([0.1026, 0.3038, 0.5936])
2024-12-05 15:39:26,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.1026, 0.3038, 0.5936]), new_distribution = tensor([0.1029, 0.3043, 0.5928])
2024-12-05 15:39:27,053 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.1029, 0.3043, 0.5928]), new_distribution = tensor([0.1032, 0.3047, 0.5920])
2024-12-05 15:39:27,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.1032, 0.3047, 0.5920]), new_distribution = tensor([0.1036, 0.3052, 0.5913])
2024-12-05 15:39:27,162 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.1036, 0.3052, 0.5913]), new_distribution = tensor([0.1039, 0.3057, 0.5905])
2024-12-05 15:39:27,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.1039, 0.3057, 0.5905]), new_distribution = tensor([0.1042, 0.3061, 0.5897])
2024-12-05 15:39:27,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.1042, 0.3061, 0.5897]), new_distribution = tensor([0.1045, 0.3066, 0.5889])
2024-12-05 15:39:27,329 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.1045, 0.3066, 0.5889]), new_distribution = tensor([0.1049, 0.3071, 0.5881])
2024-12-05 15:39:27,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.1049, 0.3071, 0.5881]), new_distribution = tensor([0.1052, 0.3075, 0.5872])
2024-12-05 15:39:27,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.1052, 0.3075, 0.5872]), new_distribution = tensor([0.1055, 0.3080, 0.5864])
2024-12-05 15:39:27,490 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.1055, 0.3080, 0.5864]), new_distribution = tensor([0.1059, 0.3085, 0.5856])
2024-12-05 15:39:27,544 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.1059, 0.3085, 0.5856]), new_distribution = tensor([0.1062, 0.3089, 0.5848])
2024-12-05 15:39:27,598 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.1062, 0.3089, 0.5848]), new_distribution = tensor([0.1066, 0.3094, 0.5840])
2024-12-05 15:39:27,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.1066, 0.3094, 0.5840]), new_distribution = tensor([0.1069, 0.3099, 0.5832])
2024-12-05 15:39:27,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.1069, 0.3099, 0.5832]), new_distribution = tensor([0.1072, 0.3103, 0.5824])
2024-12-05 15:39:27,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.1072, 0.3103, 0.5824]), new_distribution = tensor([0.1076, 0.3108, 0.5816])
2024-12-05 15:39:27,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.1076, 0.3108, 0.5816]), new_distribution = tensor([0.1079, 0.3113, 0.5808])
2024-12-05 15:39:27,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.1079, 0.3113, 0.5808]), new_distribution = tensor([0.1083, 0.3117, 0.5800])
2024-12-05 15:39:27,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.1083, 0.3117, 0.5800]), new_distribution = tensor([0.1086, 0.3122, 0.5792])
2024-12-05 15:39:27,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.1086, 0.3122, 0.5792]), new_distribution = tensor([0.1089, 0.3127, 0.5784])
2024-12-05 15:39:28,031 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.1089, 0.3127, 0.5784]), new_distribution = tensor([0.1093, 0.3131, 0.5776])
2024-12-05 15:39:28,086 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.1093, 0.3131, 0.5776]), new_distribution = tensor([0.1096, 0.3136, 0.5768])
2024-12-05 15:39:28,140 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.1096, 0.3136, 0.5768]), new_distribution = tensor([0.1100, 0.3140, 0.5760])
2024-12-05 15:39:28,193 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.1100, 0.3140, 0.5760]), new_distribution = tensor([0.1103, 0.3145, 0.5752])
2024-12-05 15:39:28,247 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.1103, 0.3145, 0.5752]), new_distribution = tensor([0.1107, 0.3150, 0.5744])
2024-12-05 15:39:28,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.1107, 0.3150, 0.5744]), new_distribution = tensor([0.1110, 0.3154, 0.5735])
2024-12-05 15:39:28,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.1110, 0.3154, 0.5735]), new_distribution = tensor([0.1114, 0.3159, 0.5727])
2024-12-05 15:39:28,410 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.1114, 0.3159, 0.5727]), new_distribution = tensor([0.1117, 0.3163, 0.5719])
2024-12-05 15:39:28,464 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.1117, 0.3163, 0.5719]), new_distribution = tensor([0.1121, 0.3168, 0.5711])
2024-12-05 15:39:28,518 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.1121, 0.3168, 0.5711]), new_distribution = tensor([0.1124, 0.3173, 0.5703])
2024-12-05 15:39:28,572 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.1124, 0.3173, 0.5703]), new_distribution = tensor([0.1128, 0.3177, 0.5695])
2024-12-05 15:39:28,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.1128, 0.3177, 0.5695]), new_distribution = tensor([0.1132, 0.3182, 0.5687])
2024-12-05 15:39:28,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.1132, 0.3182, 0.5687]), new_distribution = tensor([0.1135, 0.3186, 0.5679])
2024-12-05 15:39:28,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.1135, 0.3186, 0.5679]), new_distribution = tensor([0.1139, 0.3191, 0.5670])
2024-12-05 15:39:28,789 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.1139, 0.3191, 0.5670]), new_distribution = tensor([0.1142, 0.3195, 0.5662])
2024-12-05 15:39:28,843 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.1142, 0.3195, 0.5662]), new_distribution = tensor([0.1146, 0.3200, 0.5654])
2024-12-05 15:39:28,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.1146, 0.3200, 0.5654]), new_distribution = tensor([0.1150, 0.3205, 0.5646])
2024-12-05 15:39:28,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.1150, 0.3205, 0.5646]), new_distribution = tensor([0.1153, 0.3209, 0.5638])
2024-12-05 15:39:29,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.1153, 0.3209, 0.5638]), new_distribution = tensor([0.1157, 0.3214, 0.5630])
2024-12-05 15:39:29,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.1157, 0.3214, 0.5630]), new_distribution = tensor([0.1160, 0.3218, 0.5621])
2024-12-05 15:39:29,115 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.1160, 0.3218, 0.5621]), new_distribution = tensor([0.1164, 0.3223, 0.5613])
2024-12-05 15:39:29,169 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.1164, 0.3223, 0.5613]), new_distribution = tensor([0.1168, 0.3227, 0.5605])
2024-12-05 15:39:29,224 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.1168, 0.3227, 0.5605]), new_distribution = tensor([0.1172, 0.3232, 0.5597])
2024-12-05 15:39:29,278 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.1172, 0.3232, 0.5597]), new_distribution = tensor([0.1175, 0.3236, 0.5589])
2024-12-05 15:39:29,332 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.1175, 0.3236, 0.5589]), new_distribution = tensor([0.1179, 0.3241, 0.5580])
2024-12-05 15:39:29,386 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.1179, 0.3241, 0.5580]), new_distribution = tensor([0.1183, 0.3245, 0.5572])
2024-12-05 15:39:29,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.1183, 0.3245, 0.5572]), new_distribution = tensor([0.1186, 0.3250, 0.5564])
2024-12-05 15:39:29,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.1186, 0.3250, 0.5564]), new_distribution = tensor([0.1190, 0.3254, 0.5556])
2024-12-05 15:39:29,549 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.1190, 0.3254, 0.5556]), new_distribution = tensor([0.1194, 0.3259, 0.5548])
2024-12-05 15:39:29,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.1194, 0.3259, 0.5548]), new_distribution = tensor([0.1198, 0.3263, 0.5539])
2024-12-05 15:39:29,657 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.1198, 0.3263, 0.5539]), new_distribution = tensor([0.1201, 0.3267, 0.5531])
2024-12-05 15:39:29,711 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.1201, 0.3267, 0.5531]), new_distribution = tensor([0.1205, 0.3272, 0.5523])
2024-12-05 15:39:29,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.1205, 0.3272, 0.5523]), new_distribution = tensor([0.1209, 0.3276, 0.5515])
2024-12-05 15:39:29,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.1209, 0.3276, 0.5515]), new_distribution = tensor([0.1213, 0.3281, 0.5506])
2024-12-05 15:39:29,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.1213, 0.3281, 0.5506]), new_distribution = tensor([0.1217, 0.3285, 0.5498])
2024-12-05 15:39:29,928 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.1217, 0.3285, 0.5498]), new_distribution = tensor([0.1220, 0.3290, 0.5490])
2024-12-05 15:39:29,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.1220, 0.3290, 0.5490]), new_distribution = tensor([0.1224, 0.3294, 0.5482])
2024-12-05 15:39:30,036 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.1224, 0.3294, 0.5482]), new_distribution = tensor([0.1228, 0.3298, 0.5474])
2024-12-05 15:39:30,090 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.1228, 0.3298, 0.5474]), new_distribution = tensor([0.1232, 0.3303, 0.5465])
2024-12-05 15:39:30,144 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.1232, 0.3303, 0.5465]), new_distribution = tensor([0.1236, 0.3307, 0.5457])
2024-12-05 15:39:30,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.1236, 0.3307, 0.5457]), new_distribution = tensor([0.1240, 0.3311, 0.5449])
2024-12-05 15:39:30,252 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.1240, 0.3311, 0.5449]), new_distribution = tensor([0.1244, 0.3316, 0.5440])
2024-12-05 15:39:30,307 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.1244, 0.3316, 0.5440]), new_distribution = tensor([0.1248, 0.3320, 0.5432])
2024-12-05 15:39:30,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.1248, 0.3320, 0.5432]), new_distribution = tensor([0.1251, 0.3325, 0.5424])
2024-12-05 15:39:30,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.1251, 0.3325, 0.5424]), new_distribution = tensor([0.1255, 0.3329, 0.5416])
2024-12-05 15:39:30,469 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.1255, 0.3329, 0.5416]), new_distribution = tensor([0.1259, 0.3333, 0.5407])
2024-12-05 15:39:30,524 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.1259, 0.3333, 0.5407]), new_distribution = tensor([0.1263, 0.3338, 0.5399])
2024-12-05 15:39:30,578 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.1263, 0.3338, 0.5399]), new_distribution = tensor([0.1267, 0.3342, 0.5391])
2024-12-05 15:39:30,632 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.1267, 0.3342, 0.5391]), new_distribution = tensor([0.1271, 0.3346, 0.5383])
2024-12-05 15:39:30,686 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.1271, 0.3346, 0.5383]), new_distribution = tensor([0.1275, 0.3350, 0.5374])
2024-12-05 15:39:30,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.1275, 0.3350, 0.5374]), new_distribution = tensor([0.1279, 0.3355, 0.5366])
2024-12-05 15:39:30,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.1279, 0.3355, 0.5366]), new_distribution = tensor([0.1283, 0.3359, 0.5358])
2024-12-05 15:39:30,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.1283, 0.3359, 0.5358]), new_distribution = tensor([0.1287, 0.3363, 0.5349])
2024-12-05 15:39:30,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.1287, 0.3363, 0.5349]), new_distribution = tensor([0.1291, 0.3368, 0.5341])
2024-12-05 15:39:30,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.1291, 0.3368, 0.5341]), new_distribution = tensor([0.1295, 0.3372, 0.5333])
2024-12-05 15:39:31,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.1295, 0.3372, 0.5333]), new_distribution = tensor([0.1299, 0.3376, 0.5324])
2024-12-05 15:39:31,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.1299, 0.3376, 0.5324]), new_distribution = tensor([0.1303, 0.3380, 0.5316])
2024-12-05 15:39:31,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.1303, 0.3380, 0.5316]), new_distribution = tensor([0.1308, 0.3385, 0.5308])
2024-12-05 15:39:31,174 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.1308, 0.3385, 0.5308]), new_distribution = tensor([0.1312, 0.3389, 0.5300])
2024-12-05 15:39:31,228 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.1312, 0.3389, 0.5300]), new_distribution = tensor([0.1316, 0.3393, 0.5291])
2024-12-05 15:39:31,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.1316, 0.3393, 0.5291]), new_distribution = tensor([0.1320, 0.3397, 0.5283])
2024-12-05 15:39:31,337 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.1320, 0.3397, 0.5283]), new_distribution = tensor([0.1324, 0.3401, 0.5275])
2024-12-05 15:39:31,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.1324, 0.3401, 0.5275]), new_distribution = tensor([0.1328, 0.3406, 0.5266])
2024-12-05 15:39:31,445 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.1328, 0.3406, 0.5266]), new_distribution = tensor([0.1332, 0.3410, 0.5258])
2024-12-05 15:39:31,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.1332, 0.3410, 0.5258]), new_distribution = tensor([0.1336, 0.3414, 0.5250])
2024-12-05 15:39:31,553 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.1336, 0.3414, 0.5250]), new_distribution = tensor([0.1341, 0.3418, 0.5241])
2024-12-05 15:39:31,607 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.1341, 0.3418, 0.5241]), new_distribution = tensor([0.1345, 0.3422, 0.5233])
2024-12-05 15:39:31,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.1345, 0.3422, 0.5233]), new_distribution = tensor([0.1349, 0.3426, 0.5225])
2024-12-05 15:39:31,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.1349, 0.3426, 0.5225]), new_distribution = tensor([0.1353, 0.3431, 0.5216])
2024-12-05 15:39:31,770 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.1353, 0.3431, 0.5216]), new_distribution = tensor([0.1357, 0.3435, 0.5208])
2024-12-05 15:39:31,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.1357, 0.3435, 0.5208]), new_distribution = tensor([0.1362, 0.3439, 0.5200])
2024-12-05 15:39:31,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.1362, 0.3439, 0.5200]), new_distribution = tensor([0.1366, 0.3443, 0.5191])
2024-12-05 15:39:31,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.1366, 0.3443, 0.5191]), new_distribution = tensor([0.1370, 0.3447, 0.5183])
2024-12-05 15:39:31,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([0.1370, 0.3447, 0.5183]), new_distribution = tensor([0.1374, 0.3451, 0.5174])
2024-12-05 15:39:32,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([0.1374, 0.3451, 0.5174]), new_distribution = tensor([0.1379, 0.3455, 0.5166])
2024-12-05 15:39:32,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([0.1379, 0.3455, 0.5166]), new_distribution = tensor([0.1383, 0.3459, 0.5158])
2024-12-05 15:39:32,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([0.1383, 0.3459, 0.5158]), new_distribution = tensor([0.1387, 0.3463, 0.5149])
2024-12-05 15:39:32,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([0.1387, 0.3463, 0.5149]), new_distribution = tensor([0.1392, 0.3467, 0.5141])
2024-12-05 15:39:32,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([0.1392, 0.3467, 0.5141]), new_distribution = tensor([0.1396, 0.3471, 0.5133])
2024-12-05 15:39:32,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([0.1396, 0.3471, 0.5133]), new_distribution = tensor([0.1400, 0.3475, 0.5124])
2024-12-05 15:39:32,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([0.1400, 0.3475, 0.5124]), new_distribution = tensor([0.1405, 0.3479, 0.5116])
2024-12-05 15:39:32,420 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([0.1405, 0.3479, 0.5116]), new_distribution = tensor([0.1409, 0.3483, 0.5108])
2024-12-05 15:39:32,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([0.1409, 0.3483, 0.5108]), new_distribution = tensor([0.1413, 0.3487, 0.5099])
2024-12-05 15:39:32,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([0.1413, 0.3487, 0.5099]), new_distribution = tensor([0.1418, 0.3491, 0.5091])
2024-12-05 15:39:32,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([0.1418, 0.3491, 0.5091]), new_distribution = tensor([0.1422, 0.3495, 0.5082])
2024-12-05 15:39:32,637 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([0.1422, 0.3495, 0.5082]), new_distribution = tensor([0.1427, 0.3499, 0.5074])
2024-12-05 15:39:32,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([0.1427, 0.3499, 0.5074]), new_distribution = tensor([0.1431, 0.3503, 0.5066])
2024-12-05 15:39:32,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([0.1431, 0.3503, 0.5066]), new_distribution = tensor([0.1435, 0.3507, 0.5057])
2024-12-05 15:39:32,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([0.1435, 0.3507, 0.5057]), new_distribution = tensor([0.1440, 0.3511, 0.5049])
2024-12-05 15:39:32,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([0.1440, 0.3511, 0.5049]), new_distribution = tensor([0.1444, 0.3515, 0.5041])
2024-12-05 15:39:32,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([0.1444, 0.3515, 0.5041]), new_distribution = tensor([0.1449, 0.3519, 0.5032])
2024-12-05 15:39:32,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([0.1449, 0.3519, 0.5032]), new_distribution = tensor([0.1453, 0.3523, 0.5024])
2024-12-05 15:39:33,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([0.1453, 0.3523, 0.5024]), new_distribution = tensor([0.1458, 0.3527, 0.5015])
2024-12-05 15:39:33,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([0.1458, 0.3527, 0.5015]), new_distribution = tensor([0.1462, 0.3531, 0.5007])
2024-12-05 15:39:33,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([0.1462, 0.3531, 0.5007]), new_distribution = tensor([0.1467, 0.3534, 0.4999])
2024-12-05 15:39:33,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([0.1467, 0.3534, 0.4999]), new_distribution = tensor([0.1471, 0.3538, 0.4990])
2024-12-05 15:39:33,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([0.1471, 0.3538, 0.4990]), new_distribution = tensor([0.1476, 0.3542, 0.4982])
2024-12-05 15:39:33,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([0.1476, 0.3542, 0.4982]), new_distribution = tensor([0.1481, 0.3546, 0.4974])
2024-12-05 15:39:33,342 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([0.1481, 0.3546, 0.4974]), new_distribution = tensor([0.1485, 0.3550, 0.4965])
2024-12-05 15:39:33,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([0.1485, 0.3550, 0.4965]), new_distribution = tensor([0.1490, 0.3554, 0.4957])
2024-12-05 15:39:33,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([0.1490, 0.3554, 0.4957]), new_distribution = tensor([0.1494, 0.3557, 0.4948])
2024-12-05 15:39:33,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([0.1494, 0.3557, 0.4948]), new_distribution = tensor([0.1499, 0.3561, 0.4940])
2024-12-05 15:39:33,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([0.1499, 0.3561, 0.4940]), new_distribution = tensor([0.1504, 0.3565, 0.4932])
2024-12-05 15:39:33,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([0.1504, 0.3565, 0.4932]), new_distribution = tensor([0.1508, 0.3569, 0.4923])
2024-12-05 15:39:33,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([0.1508, 0.3569, 0.4923]), new_distribution = tensor([0.1513, 0.3572, 0.4915])
2024-12-05 15:39:33,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([0.1513, 0.3572, 0.4915]), new_distribution = tensor([0.1517, 0.3576, 0.4906])
2024-12-05 15:39:33,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([0.1517, 0.3576, 0.4906]), new_distribution = tensor([0.1522, 0.3580, 0.4898])
2024-12-05 15:39:33,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([0.1522, 0.3580, 0.4898]), new_distribution = tensor([0.1527, 0.3584, 0.4890])
2024-12-05 15:39:33,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([0.1527, 0.3584, 0.4890]), new_distribution = tensor([0.1532, 0.3587, 0.4881])
2024-12-05 15:39:33,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([0.1532, 0.3587, 0.4881]), new_distribution = tensor([0.1536, 0.3591, 0.4873])
2024-12-05 15:39:33,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([0.1536, 0.3591, 0.4873]), new_distribution = tensor([0.1541, 0.3595, 0.4864])
2024-12-05 15:39:34,046 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([0.1541, 0.3595, 0.4864]), new_distribution = tensor([0.1546, 0.3598, 0.4856])
2024-12-05 15:39:34,100 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([0.1546, 0.3598, 0.4856]), new_distribution = tensor([0.1550, 0.3602, 0.4848])
2024-12-05 15:39:34,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([0.1550, 0.3602, 0.4848]), new_distribution = tensor([0.1555, 0.3605, 0.4839])
2024-12-05 15:39:34,209 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([0.1555, 0.3605, 0.4839]), new_distribution = tensor([0.1560, 0.3609, 0.4831])
2024-12-05 15:39:34,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([0.1560, 0.3609, 0.4831]), new_distribution = tensor([0.1565, 0.3613, 0.4823])
2024-12-05 15:39:34,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([0.1565, 0.3613, 0.4823]), new_distribution = tensor([0.1570, 0.3616, 0.4814])
2024-12-05 15:39:34,371 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([0.1570, 0.3616, 0.4814]), new_distribution = tensor([0.1574, 0.3620, 0.4806])
2024-12-05 15:39:34,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([0.1574, 0.3620, 0.4806]), new_distribution = tensor([0.1579, 0.3623, 0.4797])
2024-12-05 15:39:34,480 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([0.1579, 0.3623, 0.4797]), new_distribution = tensor([0.1584, 0.3627, 0.4789])
2024-12-05 15:39:34,534 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([0.1584, 0.3627, 0.4789]), new_distribution = tensor([0.1589, 0.3631, 0.4781])
2024-12-05 15:39:34,588 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([0.1589, 0.3631, 0.4781]), new_distribution = tensor([0.1594, 0.3634, 0.4772])
2024-12-05 15:39:34,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([0.1594, 0.3634, 0.4772]), new_distribution = tensor([0.1599, 0.3638, 0.4764])
2024-12-05 15:39:34,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([0.1599, 0.3638, 0.4764]), new_distribution = tensor([0.1604, 0.3641, 0.4755])
2024-12-05 15:39:34,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([0.1604, 0.3641, 0.4755]), new_distribution = tensor([0.1608, 0.3645, 0.4747])
2024-12-05 15:39:34,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([0.1608, 0.3645, 0.4747]), new_distribution = tensor([0.1613, 0.3648, 0.4739])
2024-12-05 15:39:34,858 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([0.1613, 0.3648, 0.4739]), new_distribution = tensor([0.1618, 0.3651, 0.4730])
2024-12-05 15:39:34,912 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([0.1618, 0.3651, 0.4730]), new_distribution = tensor([0.1623, 0.3655, 0.4722])
2024-12-05 15:39:34,966 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([0.1623, 0.3655, 0.4722]), new_distribution = tensor([0.1628, 0.3658, 0.4713])
2024-12-05 15:39:35,021 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([0.1628, 0.3658, 0.4713]), new_distribution = tensor([0.1633, 0.3662, 0.4705])
2024-12-05 15:39:35,075 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([0.1633, 0.3662, 0.4705]), new_distribution = tensor([0.1638, 0.3665, 0.4697])
2024-12-05 15:39:35,129 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([0.1638, 0.3665, 0.4697]), new_distribution = tensor([0.1643, 0.3669, 0.4688])
2024-12-05 15:39:35,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([0.1643, 0.3669, 0.4688]), new_distribution = tensor([0.1648, 0.3672, 0.4680])
2024-12-05 15:39:35,237 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([0.1648, 0.3672, 0.4680]), new_distribution = tensor([0.1653, 0.3675, 0.4671])
2024-12-05 15:39:35,291 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([0.1653, 0.3675, 0.4671]), new_distribution = tensor([0.1658, 0.3679, 0.4663])
2024-12-05 15:39:35,346 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([0.1658, 0.3679, 0.4663]), new_distribution = tensor([0.1663, 0.3682, 0.4655])
2024-12-05 15:39:35,400 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([0.1663, 0.3682, 0.4655]), new_distribution = tensor([0.1668, 0.3685, 0.4646])
2024-12-05 15:39:35,454 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([0.1668, 0.3685, 0.4646]), new_distribution = tensor([0.1673, 0.3689, 0.4638])
2024-12-05 15:39:35,508 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([0.1673, 0.3689, 0.4638]), new_distribution = tensor([0.1679, 0.3692, 0.4630])
2024-12-05 15:39:35,562 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([0.1679, 0.3692, 0.4630]), new_distribution = tensor([0.1684, 0.3695, 0.4621])
2024-12-05 15:39:35,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([0.1684, 0.3695, 0.4621]), new_distribution = tensor([0.1689, 0.3698, 0.4613])
2024-12-05 15:39:35,670 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([0.1689, 0.3698, 0.4613]), new_distribution = tensor([0.1694, 0.3702, 0.4604])
2024-12-05 15:39:35,725 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([0.1694, 0.3702, 0.4604]), new_distribution = tensor([0.1699, 0.3705, 0.4596])
2024-12-05 15:39:35,779 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([0.1699, 0.3705, 0.4596]), new_distribution = tensor([0.1704, 0.3708, 0.4588])
2024-12-05 15:39:35,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([0.1704, 0.3708, 0.4588]), new_distribution = tensor([0.1709, 0.3711, 0.4579])
2024-12-05 15:39:35,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([0.1709, 0.3711, 0.4579]), new_distribution = tensor([0.1715, 0.3714, 0.4571])
2024-12-05 15:39:35,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([0.1715, 0.3714, 0.4571]), new_distribution = tensor([0.1720, 0.3718, 0.4563])
2024-12-05 15:39:35,996 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([0.1720, 0.3718, 0.4563]), new_distribution = tensor([0.1725, 0.3721, 0.4554])
2024-12-05 15:39:36,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([0.1725, 0.3721, 0.4554]), new_distribution = tensor([0.1730, 0.3724, 0.4546])
2024-12-05 15:39:36,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([0.1730, 0.3724, 0.4546]), new_distribution = tensor([0.1735, 0.3727, 0.4538])
2024-12-05 15:39:36,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([0.1735, 0.3727, 0.4538]), new_distribution = tensor([0.1741, 0.3730, 0.4529])
2024-12-05 15:39:36,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([0.1741, 0.3730, 0.4529]), new_distribution = tensor([0.1746, 0.3733, 0.4521])
2024-12-05 15:39:36,266 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([0.1746, 0.3733, 0.4521]), new_distribution = tensor([0.1751, 0.3736, 0.4512])
2024-12-05 15:39:36,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([0.1751, 0.3736, 0.4512]), new_distribution = tensor([0.1756, 0.3739, 0.4504])
2024-12-05 15:39:36,375 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([0.1756, 0.3739, 0.4504]), new_distribution = tensor([0.1762, 0.3742, 0.4496])
2024-12-05 15:39:36,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([0.1762, 0.3742, 0.4496]), new_distribution = tensor([0.1767, 0.3746, 0.4487])
2024-12-05 15:39:36,483 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([0.1767, 0.3746, 0.4487]), new_distribution = tensor([0.1772, 0.3749, 0.4479])
2024-12-05 15:39:36,537 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([0.1772, 0.3749, 0.4479]), new_distribution = tensor([0.1778, 0.3752, 0.4471])
2024-12-05 15:39:36,591 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([0.1778, 0.3752, 0.4471]), new_distribution = tensor([0.1783, 0.3755, 0.4462])
2024-12-05 15:39:36,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([0.1783, 0.3755, 0.4462]), new_distribution = tensor([0.1788, 0.3758, 0.4454])
2024-12-05 15:39:36,699 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([0.1788, 0.3758, 0.4454]), new_distribution = tensor([0.1794, 0.3760, 0.4446])
2024-12-05 15:39:36,754 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([0.1794, 0.3760, 0.4446]), new_distribution = tensor([0.1799, 0.3763, 0.4437])
2024-12-05 15:39:36,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([0.1799, 0.3763, 0.4437]), new_distribution = tensor([0.1805, 0.3766, 0.4429])
2024-12-05 15:39:36,862 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([0.1805, 0.3766, 0.4429]), new_distribution = tensor([0.1810, 0.3769, 0.4421])
2024-12-05 15:39:36,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([0.1810, 0.3769, 0.4421]), new_distribution = tensor([0.1816, 0.3772, 0.4412])
2024-12-05 15:39:36,971 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([0.1816, 0.3772, 0.4412]), new_distribution = tensor([0.1821, 0.3775, 0.4404])
2024-12-05 15:39:37,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([0.1821, 0.3775, 0.4404]), new_distribution = tensor([0.1826, 0.3778, 0.4396])
2024-12-05 15:39:37,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([0.1826, 0.3778, 0.4396]), new_distribution = tensor([0.1832, 0.3781, 0.4387])
2024-12-05 15:39:37,133 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([0.1832, 0.3781, 0.4387]), new_distribution = tensor([0.1837, 0.3784, 0.4379])
2024-12-05 15:39:37,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([0.1837, 0.3784, 0.4379]), new_distribution = tensor([0.1843, 0.3786, 0.4371])
2024-12-05 15:39:37,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([0.1843, 0.3786, 0.4371]), new_distribution = tensor([0.1848, 0.3789, 0.4362])
2024-12-05 15:39:37,300 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([0.1848, 0.3789, 0.4362]), new_distribution = tensor([0.1854, 0.3792, 0.4354])
2024-12-05 15:39:37,355 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([0.1854, 0.3792, 0.4354]), new_distribution = tensor([0.1859, 0.3795, 0.4346])
2024-12-05 15:39:37,409 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([0.1859, 0.3795, 0.4346]), new_distribution = tensor([0.1865, 0.3797, 0.4338])
2024-12-05 15:39:37,463 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([0.1865, 0.3797, 0.4338]), new_distribution = tensor([0.1871, 0.3800, 0.4329])
2024-12-05 15:39:37,517 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([0.1871, 0.3800, 0.4329]), new_distribution = tensor([0.1876, 0.3803, 0.4321])
2024-12-05 15:39:37,571 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([0.1876, 0.3803, 0.4321]), new_distribution = tensor([0.1882, 0.3806, 0.4313])
2024-12-05 15:39:37,625 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([0.1882, 0.3806, 0.4313]), new_distribution = tensor([0.1887, 0.3808, 0.4304])
2024-12-05 15:39:37,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([0.1887, 0.3808, 0.4304]), new_distribution = tensor([0.1893, 0.3811, 0.4296])
2024-12-05 15:39:37,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([0.1893, 0.3811, 0.4296]), new_distribution = tensor([0.1899, 0.3814, 0.4288])
2024-12-05 15:39:37,788 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([0.1899, 0.3814, 0.4288]), new_distribution = tensor([0.1904, 0.3816, 0.4279])
2024-12-05 15:39:37,842 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([0.1904, 0.3816, 0.4279]), new_distribution = tensor([0.1910, 0.3819, 0.4271])
2024-12-05 15:39:37,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([0.1910, 0.3819, 0.4271]), new_distribution = tensor([0.1916, 0.3821, 0.4263])
2024-12-05 15:39:37,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([0.1916, 0.3821, 0.4263]), new_distribution = tensor([0.1921, 0.3824, 0.4255])
2024-12-05 15:39:38,005 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([0.1921, 0.3824, 0.4255]), new_distribution = tensor([0.1927, 0.3827, 0.4246])
2024-12-05 15:39:38,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([0.1927, 0.3827, 0.4246]), new_distribution = tensor([0.1933, 0.3829, 0.4238])
2024-12-05 15:39:38,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([0.1933, 0.3829, 0.4238]), new_distribution = tensor([0.1939, 0.3832, 0.4230])
2024-12-05 15:39:38,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([0.1939, 0.3832, 0.4230]), new_distribution = tensor([0.1944, 0.3834, 0.4222])
2024-12-05 15:39:38,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([0.1944, 0.3834, 0.4222]), new_distribution = tensor([0.1950, 0.3837, 0.4213])
2024-12-05 15:39:38,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([0.1950, 0.3837, 0.4213]), new_distribution = tensor([0.1956, 0.3839, 0.4205])
2024-12-05 15:39:38,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([0.1956, 0.3839, 0.4205]), new_distribution = tensor([0.1962, 0.3842, 0.4197])
2024-12-05 15:39:38,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([0.1962, 0.3842, 0.4197]), new_distribution = tensor([0.1967, 0.3844, 0.4189])
2024-12-05 15:39:38,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([0.1967, 0.3844, 0.4189]), new_distribution = tensor([0.1973, 0.3846, 0.4180])
2024-12-05 15:39:38,493 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([0.1973, 0.3846, 0.4180]), new_distribution = tensor([0.1979, 0.3849, 0.4172])
2024-12-05 15:39:38,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([0.1979, 0.3849, 0.4172]), new_distribution = tensor([0.1985, 0.3851, 0.4164])
2024-12-05 15:39:38,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([0.1985, 0.3851, 0.4164]), new_distribution = tensor([0.1991, 0.3854, 0.4156])
2024-12-05 15:39:38,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([0.1991, 0.3854, 0.4156]), new_distribution = tensor([0.1997, 0.3856, 0.4147])
2024-12-05 15:39:38,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([0.1997, 0.3856, 0.4147]), new_distribution = tensor([0.2003, 0.3858, 0.4139])
2024-12-05 15:39:38,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([0.2003, 0.3858, 0.4139]), new_distribution = tensor([0.2008, 0.3860, 0.4131])
2024-12-05 15:39:38,818 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([0.2008, 0.3860, 0.4131]), new_distribution = tensor([0.2014, 0.3863, 0.4123])
2024-12-05 15:39:38,873 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([0.2014, 0.3863, 0.4123]), new_distribution = tensor([0.2020, 0.3865, 0.4115])
2024-12-05 15:39:38,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([0.2020, 0.3865, 0.4115]), new_distribution = tensor([0.2026, 0.3867, 0.4106])
2024-12-05 15:39:38,981 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([0.2026, 0.3867, 0.4106]), new_distribution = tensor([0.2032, 0.3870, 0.4098])
2024-12-05 15:39:39,035 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([0.2032, 0.3870, 0.4098]), new_distribution = tensor([0.2038, 0.3872, 0.4090])
2024-12-05 15:39:39,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([0.2038, 0.3872, 0.4090]), new_distribution = tensor([0.2044, 0.3874, 0.4082])
2024-12-05 15:39:39,143 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([0.2044, 0.3874, 0.4082]), new_distribution = tensor([0.2050, 0.3876, 0.4074])
2024-12-05 15:39:39,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([0.2050, 0.3876, 0.4074]), new_distribution = tensor([0.2056, 0.3878, 0.4065])
2024-12-05 15:39:39,252 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([0.2056, 0.3878, 0.4065]), new_distribution = tensor([0.2062, 0.3880, 0.4057])
2024-12-05 15:39:39,306 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([0.2062, 0.3880, 0.4057]), new_distribution = tensor([0.2068, 0.3883, 0.4049])
2024-12-05 15:39:39,360 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([0.2068, 0.3883, 0.4049]), new_distribution = tensor([0.2074, 0.3885, 0.4041])
2024-12-05 15:39:39,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([0.2074, 0.3885, 0.4041]), new_distribution = tensor([0.2080, 0.3887, 0.4033])
2024-12-05 15:39:39,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([0.2080, 0.3887, 0.4033]), new_distribution = tensor([0.2086, 0.3889, 0.4025])
2024-12-05 15:39:39,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([0.2086, 0.3889, 0.4025]), new_distribution = tensor([0.2093, 0.3891, 0.4017])
2024-12-05 15:39:39,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([0.2093, 0.3891, 0.4017]), new_distribution = tensor([0.2099, 0.3893, 0.4008])
2024-12-05 15:39:39,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([0.2099, 0.3893, 0.4008]), new_distribution = tensor([0.2105, 0.3895, 0.4000])
2024-12-05 15:39:39,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([0.2105, 0.3895, 0.4000]), new_distribution = tensor([0.2111, 0.3897, 0.3992])
2024-12-05 15:39:39,739 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([0.2111, 0.3897, 0.3992]), new_distribution = tensor([0.2117, 0.3899, 0.3984])
2024-12-05 15:39:39,793 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([0.2117, 0.3899, 0.3984]), new_distribution = tensor([0.2123, 0.3901, 0.3976])
2024-12-05 15:39:39,847 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([0.2123, 0.3901, 0.3976]), new_distribution = tensor([0.2129, 0.3903, 0.3968])
2024-12-05 15:39:39,901 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([0.2129, 0.3903, 0.3968]), new_distribution = tensor([0.2136, 0.3905, 0.3960])
2024-12-05 15:39:39,955 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([0.2136, 0.3905, 0.3960]), new_distribution = tensor([0.2142, 0.3907, 0.3952])
2024-12-05 15:39:40,009 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([0.2142, 0.3907, 0.3952]), new_distribution = tensor([0.2148, 0.3909, 0.3943])
2024-12-05 15:39:40,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([0.2148, 0.3909, 0.3943]), new_distribution = tensor([0.2154, 0.3910, 0.3935])
2024-12-05 15:39:40,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([0.2154, 0.3910, 0.3935]), new_distribution = tensor([0.2161, 0.3912, 0.3927])
2024-12-05 15:39:40,173 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([0.2161, 0.3912, 0.3927]), new_distribution = tensor([0.2167, 0.3914, 0.3919])
2024-12-05 15:39:40,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([0.2167, 0.3914, 0.3919]), new_distribution = tensor([0.2173, 0.3916, 0.3911])
2024-12-05 15:39:40,281 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([0.2173, 0.3916, 0.3911]), new_distribution = tensor([0.2179, 0.3918, 0.3903])
2024-12-05 15:39:40,335 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([0.2179, 0.3918, 0.3903]), new_distribution = tensor([0.2186, 0.3919, 0.3895])
2024-12-05 15:39:40,390 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([0.2186, 0.3919, 0.3895]), new_distribution = tensor([0.2192, 0.3921, 0.3887])
2024-12-05 15:39:40,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([0.2192, 0.3921, 0.3887]), new_distribution = tensor([0.2198, 0.3923, 0.3879])
2024-12-05 15:39:40,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([0.2198, 0.3923, 0.3879]), new_distribution = tensor([0.2205, 0.3925, 0.3871])
2024-12-05 15:39:40,552 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([0.2205, 0.3925, 0.3871]), new_distribution = tensor([0.2211, 0.3926, 0.3863])
2024-12-05 15:39:40,607 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([0.2211, 0.3926, 0.3863]), new_distribution = tensor([0.2217, 0.3928, 0.3855])
2024-12-05 15:39:40,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([0.2217, 0.3928, 0.3855]), new_distribution = tensor([0.2224, 0.3930, 0.3847])
2024-12-05 15:39:40,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([0.2224, 0.3930, 0.3847]), new_distribution = tensor([0.2230, 0.3931, 0.3839])
2024-12-05 15:39:40,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([0.2230, 0.3931, 0.3839]), new_distribution = tensor([0.2237, 0.3933, 0.3831])
2024-12-05 15:39:40,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([0.2237, 0.3933, 0.3831]), new_distribution = tensor([0.2243, 0.3934, 0.3823])
2024-12-05 15:39:40,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([0.2243, 0.3934, 0.3823]), new_distribution = tensor([0.2249, 0.3936, 0.3815])
2024-12-05 15:39:40,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([0.2249, 0.3936, 0.3815]), new_distribution = tensor([0.2256, 0.3938, 0.3807])
2024-12-05 15:39:40,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([0.2256, 0.3938, 0.3807]), new_distribution = tensor([0.2262, 0.3939, 0.3799])
2024-12-05 15:39:41,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([0.2262, 0.3939, 0.3799]), new_distribution = tensor([0.2269, 0.3941, 0.3791])
2024-12-05 15:39:41,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([0.2269, 0.3941, 0.3791]), new_distribution = tensor([0.2275, 0.3942, 0.3783])
2024-12-05 15:39:41,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([0.2275, 0.3942, 0.3783]), new_distribution = tensor([0.2282, 0.3943, 0.3775])
2024-12-05 15:39:41,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([0.2282, 0.3943, 0.3775]), new_distribution = tensor([0.2288, 0.3945, 0.3767])
2024-12-05 15:39:41,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([0.2288, 0.3945, 0.3767]), new_distribution = tensor([0.2295, 0.3946, 0.3759])
2024-12-05 15:39:41,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([0.2295, 0.3946, 0.3759]), new_distribution = tensor([0.2302, 0.3948, 0.3751])
2024-12-05 15:39:41,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([0.2302, 0.3948, 0.3751]), new_distribution = tensor([0.2308, 0.3949, 0.3743])
2024-12-05 15:39:41,421 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([0.2308, 0.3949, 0.3743]), new_distribution = tensor([0.2315, 0.3951, 0.3735])
2024-12-05 15:39:41,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([0.2315, 0.3951, 0.3735]), new_distribution = tensor([0.2321, 0.3952, 0.3727])
2024-12-05 15:39:41,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([0.2321, 0.3952, 0.3727]), new_distribution = tensor([0.2328, 0.3953, 0.3719])
2024-12-05 15:39:41,584 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([0.2328, 0.3953, 0.3719]), new_distribution = tensor([0.2335, 0.3954, 0.3711])
2024-12-05 15:39:41,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([0.2335, 0.3954, 0.3711]), new_distribution = tensor([0.2341, 0.3956, 0.3703])
2024-12-05 15:39:41,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([0.2341, 0.3956, 0.3703]), new_distribution = tensor([0.2348, 0.3957, 0.3695])
2024-12-05 15:39:41,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([0.2348, 0.3957, 0.3695]), new_distribution = tensor([0.2355, 0.3958, 0.3687])
2024-12-05 15:39:41,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([0.2355, 0.3958, 0.3687]), new_distribution = tensor([0.2361, 0.3960, 0.3679])
2024-12-05 15:39:41,855 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([0.2361, 0.3960, 0.3679]), new_distribution = tensor([0.2368, 0.3961, 0.3671])
2024-12-05 15:39:41,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([0.2368, 0.3961, 0.3671]), new_distribution = tensor([0.2375, 0.3962, 0.3664])
2024-12-05 15:39:41,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([0.2375, 0.3962, 0.3664]), new_distribution = tensor([0.2381, 0.3963, 0.3656])
2024-12-05 15:39:42,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([0.2381, 0.3963, 0.3656]), new_distribution = tensor([0.2388, 0.3964, 0.3648])
2024-12-05 15:39:42,072 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([0.2388, 0.3964, 0.3648]), new_distribution = tensor([0.2395, 0.3965, 0.3640])
2024-12-05 15:39:42,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([0.2395, 0.3965, 0.3640]), new_distribution = tensor([0.2402, 0.3966, 0.3632])
2024-12-05 15:39:42,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([0.2402, 0.3966, 0.3632]), new_distribution = tensor([0.2408, 0.3967, 0.3624])
2024-12-05 15:39:42,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([0.2408, 0.3967, 0.3624]), new_distribution = tensor([0.2415, 0.3969, 0.3616])
2024-12-05 15:39:42,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([0.2415, 0.3969, 0.3616]), new_distribution = tensor([0.2422, 0.3970, 0.3608])
2024-12-05 15:39:42,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([0.2422, 0.3970, 0.3608]), new_distribution = tensor([0.2429, 0.3971, 0.3601])
2024-12-05 15:39:42,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([0.2429, 0.3971, 0.3601]), new_distribution = tensor([0.2436, 0.3972, 0.3593])
2024-12-05 15:39:42,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([0.2436, 0.3972, 0.3593]), new_distribution = tensor([0.2442, 0.3973, 0.3585])
2024-12-05 15:39:42,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([0.2442, 0.3973, 0.3585]), new_distribution = tensor([0.2449, 0.3973, 0.3577])
2024-12-05 15:39:42,560 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([0.2449, 0.3973, 0.3577]), new_distribution = tensor([0.2456, 0.3974, 0.3569])
2024-12-05 15:39:42,614 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([0.2456, 0.3974, 0.3569]), new_distribution = tensor([0.2463, 0.3975, 0.3562])
2024-12-05 15:39:42,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([0.2463, 0.3975, 0.3562]), new_distribution = tensor([0.2470, 0.3976, 0.3554])
2024-12-05 15:39:42,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([0.2470, 0.3976, 0.3554]), new_distribution = tensor([0.2477, 0.3977, 0.3546])
2024-12-05 15:39:42,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([0.2477, 0.3977, 0.3546]), new_distribution = tensor([0.2484, 0.3978, 0.3538])
2024-12-05 15:39:42,831 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 300: ref_distribution = tensor([0.2484, 0.3978, 0.3538]), new_distribution = tensor([0.2491, 0.3979, 0.3530])
2024-12-05 15:39:42,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 301: ref_distribution = tensor([0.2491, 0.3979, 0.3530]), new_distribution = tensor([0.2498, 0.3980, 0.3523])
2024-12-05 15:39:42,939 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 302: ref_distribution = tensor([0.2498, 0.3980, 0.3523]), new_distribution = tensor([0.2505, 0.3980, 0.3515])
2024-12-05 15:39:42,994 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 303: ref_distribution = tensor([0.2505, 0.3980, 0.3515]), new_distribution = tensor([0.2512, 0.3981, 0.3507])
2024-12-05 15:39:43,048 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 304: ref_distribution = tensor([0.2512, 0.3981, 0.3507]), new_distribution = tensor([0.2519, 0.3982, 0.3500])
2024-12-05 15:39:43,102 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 305: ref_distribution = tensor([0.2519, 0.3982, 0.3500]), new_distribution = tensor([0.2526, 0.3983, 0.3492])
2024-12-05 15:39:43,156 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 306: ref_distribution = tensor([0.2526, 0.3983, 0.3492]), new_distribution = tensor([0.2533, 0.3983, 0.3484])
2024-12-05 15:39:43,210 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 307: ref_distribution = tensor([0.2533, 0.3983, 0.3484]), new_distribution = tensor([0.2540, 0.3984, 0.3476])
2024-12-05 15:39:43,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 308: ref_distribution = tensor([0.2540, 0.3984, 0.3476]), new_distribution = tensor([0.2547, 0.3985, 0.3469])
2024-12-05 15:39:43,319 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 309: ref_distribution = tensor([0.2547, 0.3985, 0.3469]), new_distribution = tensor([0.2554, 0.3985, 0.3461])
2024-12-05 15:39:43,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 310: ref_distribution = tensor([0.2554, 0.3985, 0.3461]), new_distribution = tensor([0.2561, 0.3986, 0.3453])
2024-12-05 15:39:43,427 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 311: ref_distribution = tensor([0.2561, 0.3986, 0.3453]), new_distribution = tensor([0.2568, 0.3986, 0.3446])
2024-12-05 15:39:43,481 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 312: ref_distribution = tensor([0.2568, 0.3986, 0.3446]), new_distribution = tensor([0.2575, 0.3987, 0.3438])
2024-12-05 15:39:43,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 313: ref_distribution = tensor([0.2575, 0.3987, 0.3438]), new_distribution = tensor([0.2582, 0.3988, 0.3430])
2024-12-05 15:39:43,591 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 314: ref_distribution = tensor([0.2582, 0.3988, 0.3430]), new_distribution = tensor([0.2589, 0.3988, 0.3423])
2024-12-05 15:39:43,646 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 315: ref_distribution = tensor([0.2589, 0.3988, 0.3423]), new_distribution = tensor([0.2597, 0.3989, 0.3415])
2024-12-05 15:39:43,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 316: ref_distribution = tensor([0.2597, 0.3989, 0.3415]), new_distribution = tensor([0.2604, 0.3989, 0.3407])
2024-12-05 15:39:43,754 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 317: ref_distribution = tensor([0.2604, 0.3989, 0.3407]), new_distribution = tensor([0.2611, 0.3989, 0.3400])
2024-12-05 15:39:43,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 318: ref_distribution = tensor([0.2611, 0.3989, 0.3400]), new_distribution = tensor([0.2618, 0.3990, 0.3392])
2024-12-05 15:39:43,862 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 319: ref_distribution = tensor([0.2618, 0.3990, 0.3392]), new_distribution = tensor([0.2625, 0.3990, 0.3384])
2024-12-05 15:39:43,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 320: ref_distribution = tensor([0.2625, 0.3990, 0.3384]), new_distribution = tensor([0.2632, 0.3991, 0.3377])
2024-12-05 15:39:43,971 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 321: ref_distribution = tensor([0.2632, 0.3991, 0.3377]), new_distribution = tensor([0.2640, 0.3991, 0.3369])
2024-12-05 15:39:44,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 322: ref_distribution = tensor([0.2640, 0.3991, 0.3369]), new_distribution = tensor([0.2647, 0.3991, 0.3362])
2024-12-05 15:39:44,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 323: ref_distribution = tensor([0.2647, 0.3991, 0.3362]), new_distribution = tensor([0.2654, 0.3992, 0.3354])
2024-12-05 15:39:44,133 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 324: ref_distribution = tensor([0.2654, 0.3992, 0.3354]), new_distribution = tensor([0.2661, 0.3992, 0.3346])
2024-12-05 15:39:44,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 325: ref_distribution = tensor([0.2661, 0.3992, 0.3346]), new_distribution = tensor([0.2669, 0.3992, 0.3339])
2024-12-05 15:39:44,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 326: ref_distribution = tensor([0.2669, 0.3992, 0.3339]), new_distribution = tensor([0.2676, 0.3993, 0.3331])
2024-12-05 15:39:44,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 327: ref_distribution = tensor([0.2676, 0.3993, 0.3331]), new_distribution = tensor([0.2683, 0.3993, 0.3324])
2024-12-05 15:39:44,350 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 328: ref_distribution = tensor([0.2683, 0.3993, 0.3324]), new_distribution = tensor([0.2691, 0.3993, 0.3316])
2024-12-05 15:39:44,404 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 329: ref_distribution = tensor([0.2691, 0.3993, 0.3316]), new_distribution = tensor([0.2698, 0.3993, 0.3309])
2024-12-05 15:39:44,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 330: ref_distribution = tensor([0.2698, 0.3993, 0.3309]), new_distribution = tensor([0.2705, 0.3993, 0.3301])
2024-12-05 15:39:44,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 331: ref_distribution = tensor([0.2705, 0.3993, 0.3301]), new_distribution = tensor([0.2713, 0.3994, 0.3294])
2024-12-05 15:39:44,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 332: ref_distribution = tensor([0.2713, 0.3994, 0.3294]), new_distribution = tensor([0.2720, 0.3994, 0.3286])
2024-12-05 15:39:44,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 333: ref_distribution = tensor([0.2720, 0.3994, 0.3286]), new_distribution = tensor([0.2728, 0.3994, 0.3279])
2024-12-05 15:39:44,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 334: ref_distribution = tensor([0.2728, 0.3994, 0.3279]), new_distribution = tensor([0.2735, 0.3994, 0.3271])
2024-12-05 15:39:44,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 335: ref_distribution = tensor([0.2735, 0.3994, 0.3271]), new_distribution = tensor([0.2742, 0.3994, 0.3264])
2024-12-05 15:39:44,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 336: ref_distribution = tensor([0.2742, 0.3994, 0.3264]), new_distribution = tensor([0.2750, 0.3994, 0.3256])
2024-12-05 15:39:44,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 337: ref_distribution = tensor([0.2750, 0.3994, 0.3256]), new_distribution = tensor([0.2757, 0.3994, 0.3249])
2024-12-05 15:39:44,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 338: ref_distribution = tensor([0.2757, 0.3994, 0.3249]), new_distribution = tensor([0.2765, 0.3994, 0.3241])
2024-12-05 15:39:44,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 339: ref_distribution = tensor([0.2765, 0.3994, 0.3241]), new_distribution = tensor([0.2772, 0.3994, 0.3234])
2024-12-05 15:39:45,002 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 340: ref_distribution = tensor([0.2772, 0.3994, 0.3234]), new_distribution = tensor([0.2780, 0.3994, 0.3226])
2024-12-05 15:39:45,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 341: ref_distribution = tensor([0.2780, 0.3994, 0.3226]), new_distribution = tensor([0.2787, 0.3994, 0.3219])
2024-12-05 15:39:45,111 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 342: ref_distribution = tensor([0.2787, 0.3994, 0.3219]), new_distribution = tensor([0.2795, 0.3994, 0.3212])
2024-12-05 15:39:45,165 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 343: ref_distribution = tensor([0.2795, 0.3994, 0.3212]), new_distribution = tensor([0.2802, 0.3994, 0.3204])
2024-12-05 15:39:45,219 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 344: ref_distribution = tensor([0.2802, 0.3994, 0.3204]), new_distribution = tensor([0.2810, 0.3994, 0.3197])
2024-12-05 15:39:45,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 345: ref_distribution = tensor([0.2810, 0.3994, 0.3197]), new_distribution = tensor([0.2817, 0.3993, 0.3189])
2024-12-05 15:39:45,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 346: ref_distribution = tensor([0.2817, 0.3993, 0.3189]), new_distribution = tensor([0.2825, 0.3993, 0.3182])
2024-12-05 15:39:45,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 347: ref_distribution = tensor([0.2825, 0.3993, 0.3182]), new_distribution = tensor([0.2832, 0.3993, 0.3175])
2024-12-05 15:39:45,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 348: ref_distribution = tensor([0.2832, 0.3993, 0.3175]), new_distribution = tensor([0.2840, 0.3993, 0.3167])
2024-12-05 15:39:45,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 349: ref_distribution = tensor([0.2840, 0.3993, 0.3167]), new_distribution = tensor([0.2848, 0.3993, 0.3160])
2024-12-05 15:39:45,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 350: ref_distribution = tensor([0.2848, 0.3993, 0.3160]), new_distribution = tensor([0.2855, 0.3992, 0.3153])
2024-12-05 15:39:45,599 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 351: ref_distribution = tensor([0.2855, 0.3992, 0.3153]), new_distribution = tensor([0.2863, 0.3992, 0.3145])
2024-12-05 15:39:45,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 352: ref_distribution = tensor([0.2863, 0.3992, 0.3145]), new_distribution = tensor([0.2870, 0.3992, 0.3138])
2024-12-05 15:39:45,708 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 353: ref_distribution = tensor([0.2870, 0.3992, 0.3138]), new_distribution = tensor([0.2878, 0.3991, 0.3131])
2024-12-05 15:39:45,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 354: ref_distribution = tensor([0.2878, 0.3991, 0.3131]), new_distribution = tensor([0.2886, 0.3991, 0.3123])
2024-12-05 15:39:45,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 355: ref_distribution = tensor([0.2886, 0.3991, 0.3123]), new_distribution = tensor([0.2893, 0.3991, 0.3116])
2024-12-05 15:39:45,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 356: ref_distribution = tensor([0.2893, 0.3991, 0.3116]), new_distribution = tensor([0.2901, 0.3990, 0.3109])
2024-12-05 15:39:45,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 357: ref_distribution = tensor([0.2901, 0.3990, 0.3109]), new_distribution = tensor([0.2909, 0.3990, 0.3101])
2024-12-05 15:39:45,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 358: ref_distribution = tensor([0.2909, 0.3990, 0.3101]), new_distribution = tensor([0.2916, 0.3989, 0.3094])
2024-12-05 15:39:46,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 359: ref_distribution = tensor([0.2916, 0.3989, 0.3094]), new_distribution = tensor([0.2924, 0.3989, 0.3087])
2024-12-05 15:39:46,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 360: ref_distribution = tensor([0.2924, 0.3989, 0.3087]), new_distribution = tensor([0.2932, 0.3988, 0.3080])
2024-12-05 15:39:46,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 361: ref_distribution = tensor([0.2932, 0.3988, 0.3080]), new_distribution = tensor([0.2940, 0.3988, 0.3072])
2024-12-05 15:39:46,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 362: ref_distribution = tensor([0.2940, 0.3988, 0.3072]), new_distribution = tensor([0.2947, 0.3987, 0.3065])
2024-12-05 15:39:46,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 363: ref_distribution = tensor([0.2947, 0.3987, 0.3065]), new_distribution = tensor([0.2955, 0.3987, 0.3058])
2024-12-05 15:39:46,305 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 364: ref_distribution = tensor([0.2955, 0.3987, 0.3058]), new_distribution = tensor([0.2963, 0.3986, 0.3051])
2024-12-05 15:39:46,359 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 365: ref_distribution = tensor([0.2963, 0.3986, 0.3051]), new_distribution = tensor([0.2971, 0.3986, 0.3044])
2024-12-05 15:39:46,413 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 366: ref_distribution = tensor([0.2971, 0.3986, 0.3044]), new_distribution = tensor([0.2979, 0.3985, 0.3036])
2024-12-05 15:39:46,467 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 367: ref_distribution = tensor([0.2979, 0.3985, 0.3036]), new_distribution = tensor([0.2986, 0.3984, 0.3029])
2024-12-05 15:39:46,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 368: ref_distribution = tensor([0.2986, 0.3984, 0.3029]), new_distribution = tensor([0.2994, 0.3984, 0.3022])
2024-12-05 15:39:46,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 369: ref_distribution = tensor([0.2994, 0.3984, 0.3022]), new_distribution = tensor([0.3002, 0.3983, 0.3015])
2024-12-05 15:39:46,630 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 370: ref_distribution = tensor([0.3002, 0.3983, 0.3015]), new_distribution = tensor([0.3010, 0.3982, 0.3008])
2024-12-05 15:39:46,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 371: ref_distribution = tensor([0.3010, 0.3982, 0.3008]), new_distribution = tensor([0.3018, 0.3982, 0.3001])
2024-12-05 15:39:46,739 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 372: ref_distribution = tensor([0.3018, 0.3982, 0.3001]), new_distribution = tensor([0.3026, 0.3981, 0.2993])
2024-12-05 15:39:46,793 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 373: ref_distribution = tensor([0.3026, 0.3981, 0.2993]), new_distribution = tensor([0.3034, 0.3980, 0.2986])
2024-12-05 15:39:46,847 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 374: ref_distribution = tensor([0.3034, 0.3980, 0.2986]), new_distribution = tensor([0.3042, 0.3979, 0.2979])
2024-12-05 15:39:46,902 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 375: ref_distribution = tensor([0.3042, 0.3979, 0.2979]), new_distribution = tensor([0.3050, 0.3978, 0.2972])
2024-12-05 15:39:46,956 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 376: ref_distribution = tensor([0.3050, 0.3978, 0.2972]), new_distribution = tensor([0.3057, 0.3978, 0.2965])
2024-12-05 15:39:47,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 377: ref_distribution = tensor([0.3057, 0.3978, 0.2965]), new_distribution = tensor([0.3065, 0.3977, 0.2958])
2024-12-05 15:39:47,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 378: ref_distribution = tensor([0.3065, 0.3977, 0.2958]), new_distribution = tensor([0.3073, 0.3976, 0.2951])
2024-12-05 15:39:47,122 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 379: ref_distribution = tensor([0.3073, 0.3976, 0.2951]), new_distribution = tensor([0.3081, 0.3975, 0.2944])
2024-12-05 15:39:47,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 380: ref_distribution = tensor([0.3081, 0.3975, 0.2944]), new_distribution = tensor([0.3089, 0.3974, 0.2937])
2024-12-05 15:39:47,232 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 381: ref_distribution = tensor([0.3089, 0.3974, 0.2937]), new_distribution = tensor([0.3097, 0.3973, 0.2930])
2024-12-05 15:39:47,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 382: ref_distribution = tensor([0.3097, 0.3973, 0.2930]), new_distribution = tensor([0.3105, 0.3972, 0.2923])
2024-12-05 15:39:47,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 383: ref_distribution = tensor([0.3105, 0.3972, 0.2923]), new_distribution = tensor([0.3113, 0.3971, 0.2916])
2024-12-05 15:39:47,395 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 384: ref_distribution = tensor([0.3113, 0.3971, 0.2916]), new_distribution = tensor([0.3121, 0.3970, 0.2909])
2024-12-05 15:39:47,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 385: ref_distribution = tensor([0.3121, 0.3970, 0.2909]), new_distribution = tensor([0.3129, 0.3969, 0.2902])
2024-12-05 15:39:47,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 386: ref_distribution = tensor([0.3129, 0.3969, 0.2902]), new_distribution = tensor([0.3137, 0.3968, 0.2895])
2024-12-05 15:39:47,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 387: ref_distribution = tensor([0.3137, 0.3968, 0.2895]), new_distribution = tensor([0.3146, 0.3967, 0.2888])
2024-12-05 15:39:47,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 388: ref_distribution = tensor([0.3146, 0.3967, 0.2888]), new_distribution = tensor([0.3154, 0.3966, 0.2881])
2024-12-05 15:39:47,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 389: ref_distribution = tensor([0.3154, 0.3966, 0.2881]), new_distribution = tensor([0.3162, 0.3965, 0.2874])
2024-12-05 15:39:47,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 390: ref_distribution = tensor([0.3162, 0.3965, 0.2874]), new_distribution = tensor([0.3170, 0.3963, 0.2867])
2024-12-05 15:39:47,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 391: ref_distribution = tensor([0.3170, 0.3963, 0.2867]), new_distribution = tensor([0.3178, 0.3962, 0.2860])
2024-12-05 15:39:47,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 392: ref_distribution = tensor([0.3178, 0.3962, 0.2860]), new_distribution = tensor([0.3186, 0.3961, 0.2853])
2024-12-05 15:39:47,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 393: ref_distribution = tensor([0.3186, 0.3961, 0.2853]), new_distribution = tensor([0.3194, 0.3960, 0.2846])
2024-12-05 15:39:47,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 394: ref_distribution = tensor([0.3194, 0.3960, 0.2846]), new_distribution = tensor([0.3202, 0.3959, 0.2839])
2024-12-05 15:39:47,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 395: ref_distribution = tensor([0.3202, 0.3959, 0.2839]), new_distribution = tensor([0.3211, 0.3957, 0.2832])
2024-12-05 15:39:48,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 396: ref_distribution = tensor([0.3211, 0.3957, 0.2832]), new_distribution = tensor([0.3219, 0.3956, 0.2825])
2024-12-05 15:39:48,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 397: ref_distribution = tensor([0.3219, 0.3956, 0.2825]), new_distribution = tensor([0.3227, 0.3955, 0.2818])
2024-12-05 15:39:48,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 398: ref_distribution = tensor([0.3227, 0.3955, 0.2818]), new_distribution = tensor([0.3235, 0.3953, 0.2811])
2024-12-05 15:39:48,208 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 399: ref_distribution = tensor([0.3235, 0.3953, 0.2811]), new_distribution = tensor([0.3243, 0.3952, 0.2805])
2024-12-05 15:39:48,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 400: ref_distribution = tensor([0.3243, 0.3952, 0.2805]), new_distribution = tensor([0.3252, 0.3951, 0.2798])
2024-12-05 15:39:48,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 401: ref_distribution = tensor([0.3252, 0.3951, 0.2798]), new_distribution = tensor([0.3260, 0.3949, 0.2791])
2024-12-05 15:39:48,371 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 402: ref_distribution = tensor([0.3260, 0.3949, 0.2791]), new_distribution = tensor([0.3268, 0.3948, 0.2784])
2024-12-05 15:39:48,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 403: ref_distribution = tensor([0.3268, 0.3948, 0.2784]), new_distribution = tensor([0.3276, 0.3947, 0.2777])
2024-12-05 15:39:48,480 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 404: ref_distribution = tensor([0.3276, 0.3947, 0.2777]), new_distribution = tensor([0.3285, 0.3945, 0.2770])
2024-12-05 15:39:48,534 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 405: ref_distribution = tensor([0.3285, 0.3945, 0.2770]), new_distribution = tensor([0.3293, 0.3944, 0.2764])
2024-12-05 15:39:48,588 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 406: ref_distribution = tensor([0.3293, 0.3944, 0.2764]), new_distribution = tensor([0.3301, 0.3942, 0.2757])
2024-12-05 15:39:48,643 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 407: ref_distribution = tensor([0.3301, 0.3942, 0.2757]), new_distribution = tensor([0.3309, 0.3941, 0.2750])
2024-12-05 15:39:48,698 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 408: ref_distribution = tensor([0.3309, 0.3941, 0.2750]), new_distribution = tensor([0.3318, 0.3939, 0.2743])
2024-12-05 15:39:48,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 409: ref_distribution = tensor([0.3318, 0.3939, 0.2743]), new_distribution = tensor([0.3326, 0.3937, 0.2737])
2024-12-05 15:39:48,807 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 410: ref_distribution = tensor([0.3326, 0.3937, 0.2737]), new_distribution = tensor([0.3334, 0.3936, 0.2730])
2024-12-05 15:39:48,861 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 411: ref_distribution = tensor([0.3334, 0.3936, 0.2730]), new_distribution = tensor([0.3343, 0.3934, 0.2723])
2024-12-05 15:39:48,915 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 412: ref_distribution = tensor([0.3343, 0.3934, 0.2723]), new_distribution = tensor([0.3351, 0.3933, 0.2716])
2024-12-05 15:39:48,970 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 413: ref_distribution = tensor([0.3351, 0.3933, 0.2716]), new_distribution = tensor([0.3359, 0.3931, 0.2710])
2024-12-05 15:39:49,024 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 414: ref_distribution = tensor([0.3359, 0.3931, 0.2710]), new_distribution = tensor([0.3368, 0.3929, 0.2703])
2024-12-05 15:39:49,078 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 415: ref_distribution = tensor([0.3368, 0.3929, 0.2703]), new_distribution = tensor([0.3376, 0.3928, 0.2696])
2024-12-05 15:39:49,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 416: ref_distribution = tensor([0.3376, 0.3928, 0.2696]), new_distribution = tensor([0.3385, 0.3926, 0.2690])
2024-12-05 15:39:49,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 417: ref_distribution = tensor([0.3385, 0.3926, 0.2690]), new_distribution = tensor([0.3393, 0.3924, 0.2683])
2024-12-05 15:39:49,241 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 418: ref_distribution = tensor([0.3393, 0.3924, 0.2683]), new_distribution = tensor([0.3401, 0.3922, 0.2676])
2024-12-05 15:39:49,295 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 419: ref_distribution = tensor([0.3401, 0.3922, 0.2676]), new_distribution = tensor([0.3410, 0.3921, 0.2670])
2024-12-05 15:39:49,349 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 420: ref_distribution = tensor([0.3410, 0.3921, 0.2670]), new_distribution = tensor([0.3418, 0.3919, 0.2663])
2024-12-05 15:39:49,403 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 421: ref_distribution = tensor([0.3418, 0.3919, 0.2663]), new_distribution = tensor([0.3427, 0.3917, 0.2656])
2024-12-05 15:39:49,458 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 422: ref_distribution = tensor([0.3427, 0.3917, 0.2656]), new_distribution = tensor([0.3435, 0.3915, 0.2650])
2024-12-05 15:39:49,512 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 423: ref_distribution = tensor([0.3435, 0.3915, 0.2650]), new_distribution = tensor([0.3444, 0.3913, 0.2643])
2024-12-05 15:39:49,566 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 424: ref_distribution = tensor([0.3444, 0.3913, 0.2643]), new_distribution = tensor([0.3452, 0.3911, 0.2637])
2024-12-05 15:39:49,620 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 425: ref_distribution = tensor([0.3452, 0.3911, 0.2637]), new_distribution = tensor([0.3461, 0.3909, 0.2630])
2024-12-05 15:39:49,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 426: ref_distribution = tensor([0.3461, 0.3909, 0.2630]), new_distribution = tensor([0.3469, 0.3907, 0.2623])
2024-12-05 15:39:49,729 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 427: ref_distribution = tensor([0.3469, 0.3907, 0.2623]), new_distribution = tensor([0.3478, 0.3906, 0.2617])
2024-12-05 15:39:49,783 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 428: ref_distribution = tensor([0.3478, 0.3906, 0.2617]), new_distribution = tensor([0.3486, 0.3904, 0.2610])
2024-12-05 15:39:49,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 429: ref_distribution = tensor([0.3486, 0.3904, 0.2610]), new_distribution = tensor([0.3495, 0.3902, 0.2604])
2024-12-05 15:39:49,891 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 430: ref_distribution = tensor([0.3495, 0.3902, 0.2604]), new_distribution = tensor([0.3503, 0.3900, 0.2597])
2024-12-05 15:39:49,946 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 431: ref_distribution = tensor([0.3503, 0.3900, 0.2597]), new_distribution = tensor([0.3512, 0.3898, 0.2591])
2024-12-05 15:39:50,000 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 432: ref_distribution = tensor([0.3512, 0.3898, 0.2591]), new_distribution = tensor([0.3520, 0.3895, 0.2584])
2024-12-05 15:39:50,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 433: ref_distribution = tensor([0.3520, 0.3895, 0.2584]), new_distribution = tensor([0.3529, 0.3893, 0.2578])
2024-12-05 15:39:50,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 434: ref_distribution = tensor([0.3529, 0.3893, 0.2578]), new_distribution = tensor([0.3537, 0.3891, 0.2571])
2024-12-05 15:39:50,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 435: ref_distribution = tensor([0.3537, 0.3891, 0.2571]), new_distribution = tensor([0.3546, 0.3889, 0.2565])
2024-12-05 15:39:50,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 436: ref_distribution = tensor([0.3546, 0.3889, 0.2565]), new_distribution = tensor([0.3555, 0.3887, 0.2558])
2024-12-05 15:39:50,272 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 437: ref_distribution = tensor([0.3555, 0.3887, 0.2558]), new_distribution = tensor([0.3563, 0.3885, 0.2552])
2024-12-05 15:39:50,326 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 438: ref_distribution = tensor([0.3563, 0.3885, 0.2552]), new_distribution = tensor([0.3572, 0.3883, 0.2545])
2024-12-05 15:39:50,381 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 439: ref_distribution = tensor([0.3572, 0.3883, 0.2545]), new_distribution = tensor([0.3581, 0.3880, 0.2539])
2024-12-05 15:39:50,435 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 440: ref_distribution = tensor([0.3581, 0.3880, 0.2539]), new_distribution = tensor([0.3589, 0.3878, 0.2533])
2024-12-05 15:39:50,489 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 441: ref_distribution = tensor([0.3589, 0.3878, 0.2533]), new_distribution = tensor([0.3598, 0.3876, 0.2526])
2024-12-05 15:39:50,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 442: ref_distribution = tensor([0.3598, 0.3876, 0.2526]), new_distribution = tensor([0.3606, 0.3874, 0.2520])
2024-12-05 15:39:50,597 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 443: ref_distribution = tensor([0.3606, 0.3874, 0.2520]), new_distribution = tensor([0.3615, 0.3871, 0.2513])
2024-12-05 15:39:50,651 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 444: ref_distribution = tensor([0.3615, 0.3871, 0.2513]), new_distribution = tensor([0.3624, 0.3869, 0.2507])
2024-12-05 15:39:50,706 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 445: ref_distribution = tensor([0.3624, 0.3869, 0.2507]), new_distribution = tensor([0.3633, 0.3867, 0.2501])
2024-12-05 15:39:50,760 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 446: ref_distribution = tensor([0.3633, 0.3867, 0.2501]), new_distribution = tensor([0.3641, 0.3864, 0.2494])
2024-12-05 15:39:50,814 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 447: ref_distribution = tensor([0.3641, 0.3864, 0.2494]), new_distribution = tensor([0.3650, 0.3862, 0.2488])
2024-12-05 15:39:50,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 448: ref_distribution = tensor([0.3650, 0.3862, 0.2488]), new_distribution = tensor([0.3659, 0.3860, 0.2482])
2024-12-05 15:39:50,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 449: ref_distribution = tensor([0.3659, 0.3860, 0.2482]), new_distribution = tensor([0.3667, 0.3857, 0.2475])
2024-12-05 15:39:50,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 450: ref_distribution = tensor([0.3667, 0.3857, 0.2475]), new_distribution = tensor([0.3676, 0.3855, 0.2469])
2024-12-05 15:39:51,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 451: ref_distribution = tensor([0.3676, 0.3855, 0.2469]), new_distribution = tensor([0.3685, 0.3852, 0.2463])
2024-12-05 15:39:51,088 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 452: ref_distribution = tensor([0.3685, 0.3852, 0.2463]), new_distribution = tensor([0.3694, 0.3850, 0.2456])
2024-12-05 15:39:51,144 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 453: ref_distribution = tensor([0.3694, 0.3850, 0.2456]), new_distribution = tensor([0.3702, 0.3847, 0.2450])
2024-12-05 15:39:51,199 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 454: ref_distribution = tensor([0.3702, 0.3847, 0.2450]), new_distribution = tensor([0.3711, 0.3845, 0.2444])
2024-12-05 15:39:51,255 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 455: ref_distribution = tensor([0.3711, 0.3845, 0.2444]), new_distribution = tensor([0.3720, 0.3842, 0.2438])
2024-12-05 15:39:51,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 456: ref_distribution = tensor([0.3720, 0.3842, 0.2438]), new_distribution = tensor([0.3729, 0.3840, 0.2431])
2024-12-05 15:39:51,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 457: ref_distribution = tensor([0.3729, 0.3840, 0.2431]), new_distribution = tensor([0.3738, 0.3837, 0.2425])
2024-12-05 15:39:51,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 458: ref_distribution = tensor([0.3738, 0.3837, 0.2425]), new_distribution = tensor([0.3746, 0.3835, 0.2419])
2024-12-05 15:39:51,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 459: ref_distribution = tensor([0.3746, 0.3835, 0.2419]), new_distribution = tensor([0.3755, 0.3832, 0.2413])
2024-12-05 15:39:51,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 460: ref_distribution = tensor([0.3755, 0.3832, 0.2413]), new_distribution = tensor([0.3764, 0.3829, 0.2407])
2024-12-05 15:39:51,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 461: ref_distribution = tensor([0.3764, 0.3829, 0.2407]), new_distribution = tensor([0.3773, 0.3827, 0.2400])
2024-12-05 15:39:51,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 462: ref_distribution = tensor([0.3773, 0.3827, 0.2400]), new_distribution = tensor([0.3782, 0.3824, 0.2394])
2024-12-05 15:39:51,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 463: ref_distribution = tensor([0.3782, 0.3824, 0.2394]), new_distribution = tensor([0.3790, 0.3821, 0.2388])
2024-12-05 15:39:51,742 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 464: ref_distribution = tensor([0.3790, 0.3821, 0.2388]), new_distribution = tensor([0.3799, 0.3819, 0.2382])
2024-12-05 15:39:51,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 465: ref_distribution = tensor([0.3799, 0.3819, 0.2382]), new_distribution = tensor([0.3808, 0.3816, 0.2376])
2024-12-05 15:39:51,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 466: ref_distribution = tensor([0.3808, 0.3816, 0.2376]), new_distribution = tensor([0.3817, 0.3813, 0.2370])
2024-12-05 15:39:51,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 467: ref_distribution = tensor([0.3817, 0.3813, 0.2370]), new_distribution = tensor([0.3826, 0.3810, 0.2364])
2024-12-05 15:39:51,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 468: ref_distribution = tensor([0.3826, 0.3810, 0.2364]), new_distribution = tensor([0.3835, 0.3808, 0.2358])
2024-12-05 15:39:52,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 469: ref_distribution = tensor([0.3835, 0.3808, 0.2358]), new_distribution = tensor([0.3844, 0.3805, 0.2351])
2024-12-05 15:39:52,067 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 470: ref_distribution = tensor([0.3844, 0.3805, 0.2351]), new_distribution = tensor([0.3853, 0.3802, 0.2345])
2024-12-05 15:39:52,121 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 471: ref_distribution = tensor([0.3853, 0.3802, 0.2345]), new_distribution = tensor([0.3862, 0.3799, 0.2339])
2024-12-05 15:39:52,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 472: ref_distribution = tensor([0.3862, 0.3799, 0.2339]), new_distribution = tensor([0.3870, 0.3796, 0.2333])
2024-12-05 15:39:52,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 473: ref_distribution = tensor([0.3870, 0.3796, 0.2333]), new_distribution = tensor([0.3879, 0.3793, 0.2327])
2024-12-05 15:39:52,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 474: ref_distribution = tensor([0.3879, 0.3793, 0.2327]), new_distribution = tensor([0.3888, 0.3790, 0.2321])
2024-12-05 15:39:52,337 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 475: ref_distribution = tensor([0.3888, 0.3790, 0.2321]), new_distribution = tensor([0.3897, 0.3788, 0.2315])
2024-12-05 15:39:52,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 476: ref_distribution = tensor([0.3897, 0.3788, 0.2315]), new_distribution = tensor([0.3906, 0.3785, 0.2309])
2024-12-05 15:39:52,445 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 477: ref_distribution = tensor([0.3906, 0.3785, 0.2309]), new_distribution = tensor([0.3915, 0.3782, 0.2303])
2024-12-05 15:39:52,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 478: ref_distribution = tensor([0.3915, 0.3782, 0.2303]), new_distribution = tensor([0.3924, 0.3779, 0.2297])
2024-12-05 15:39:52,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 479: ref_distribution = tensor([0.3924, 0.3779, 0.2297]), new_distribution = tensor([0.3933, 0.3776, 0.2291])
2024-12-05 15:39:52,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 480: ref_distribution = tensor([0.3933, 0.3776, 0.2291]), new_distribution = tensor([0.3942, 0.3773, 0.2285])
2024-12-05 15:39:52,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 481: ref_distribution = tensor([0.3942, 0.3773, 0.2285]), new_distribution = tensor([0.3951, 0.3770, 0.2279])
2024-12-05 15:39:52,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 482: ref_distribution = tensor([0.3951, 0.3770, 0.2279]), new_distribution = tensor([0.3960, 0.3766, 0.2273])
2024-12-05 15:39:52,770 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 483: ref_distribution = tensor([0.3960, 0.3766, 0.2273]), new_distribution = tensor([0.3969, 0.3763, 0.2267])
2024-12-05 15:39:52,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 484: ref_distribution = tensor([0.3969, 0.3763, 0.2267]), new_distribution = tensor([0.3978, 0.3760, 0.2262])
2024-12-05 15:39:52,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 485: ref_distribution = tensor([0.3978, 0.3760, 0.2262]), new_distribution = tensor([0.3987, 0.3757, 0.2256])
2024-12-05 15:39:52,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 486: ref_distribution = tensor([0.3987, 0.3757, 0.2256]), new_distribution = tensor([0.3996, 0.3754, 0.2250])
2024-12-05 15:39:52,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 487: ref_distribution = tensor([0.3996, 0.3754, 0.2250]), new_distribution = tensor([0.4005, 0.3751, 0.2244])
2024-12-05 15:39:53,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 488: ref_distribution = tensor([0.4005, 0.3751, 0.2244]), new_distribution = tensor([0.4014, 0.3748, 0.2238])
2024-12-05 15:39:53,096 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 489: ref_distribution = tensor([0.4014, 0.3748, 0.2238]), new_distribution = tensor([0.4023, 0.3745, 0.2232])
2024-12-05 15:39:53,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 490: ref_distribution = tensor([0.4023, 0.3745, 0.2232]), new_distribution = tensor([0.4032, 0.3741, 0.2226])
2024-12-05 15:39:53,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 491: ref_distribution = tensor([0.4032, 0.3741, 0.2226]), new_distribution = tensor([0.4042, 0.3738, 0.2220])
2024-12-05 15:39:53,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 492: ref_distribution = tensor([0.4042, 0.3738, 0.2220]), new_distribution = tensor([0.4051, 0.3735, 0.2215])
2024-12-05 15:39:53,313 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 493: ref_distribution = tensor([0.4051, 0.3735, 0.2215]), new_distribution = tensor([0.4060, 0.3732, 0.2209])
2024-12-05 15:39:53,367 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 494: ref_distribution = tensor([0.4060, 0.3732, 0.2209]), new_distribution = tensor([0.4069, 0.3728, 0.2203])
2024-12-05 15:39:53,421 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 495: ref_distribution = tensor([0.4069, 0.3728, 0.2203]), new_distribution = tensor([0.4078, 0.3725, 0.2197])
2024-12-05 15:39:53,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 496: ref_distribution = tensor([0.4078, 0.3725, 0.2197]), new_distribution = tensor([0.4087, 0.3722, 0.2191])
2024-12-05 15:39:53,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 497: ref_distribution = tensor([0.4087, 0.3722, 0.2191]), new_distribution = tensor([0.4096, 0.3718, 0.2186])
2024-12-05 15:39:53,585 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 498: ref_distribution = tensor([0.4096, 0.3718, 0.2186]), new_distribution = tensor([0.4105, 0.3715, 0.2180])
2024-12-05 15:39:53,639 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 499: ref_distribution = tensor([0.4105, 0.3715, 0.2180]), new_distribution = tensor([0.4114, 0.3712, 0.2174])
2024-12-05 15:42:20,978 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.9563, 0.0255, 0.0181]), new_distribution = tensor([0.9565, 0.0254, 0.0181])
2024-12-05 15:42:21,085 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.9565, 0.0254, 0.0181]), new_distribution = tensor([0.9566, 0.0254, 0.0180])
2024-12-05 15:42:21,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.9566, 0.0254, 0.0180]), new_distribution = tensor([0.9568, 0.0253, 0.0180])
2024-12-05 15:42:21,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.9568, 0.0253, 0.0180]), new_distribution = tensor([0.9569, 0.0252, 0.0179])
2024-12-05 15:42:21,402 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.9569, 0.0252, 0.0179]), new_distribution = tensor([0.9571, 0.0251, 0.0179])
2024-12-05 15:42:21,507 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.9571, 0.0251, 0.0179]), new_distribution = tensor([0.9572, 0.0250, 0.0178])
2024-12-05 15:42:21,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.9572, 0.0250, 0.0178]), new_distribution = tensor([0.9574, 0.0249, 0.0177])
2024-12-05 15:42:21,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.9574, 0.0249, 0.0177]), new_distribution = tensor([0.9575, 0.0248, 0.0177])
2024-12-05 15:42:21,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.9575, 0.0248, 0.0177]), new_distribution = tensor([0.9577, 0.0247, 0.0176])
2024-12-05 15:42:21,930 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.9577, 0.0247, 0.0176]), new_distribution = tensor([0.9578, 0.0246, 0.0176])
2024-12-05 15:42:22,036 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.9578, 0.0246, 0.0176]), new_distribution = tensor([0.9580, 0.0245, 0.0175])
2024-12-05 15:42:22,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.9580, 0.0245, 0.0175]), new_distribution = tensor([0.9581, 0.0244, 0.0175])
2024-12-05 15:42:22,247 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.9581, 0.0244, 0.0175]), new_distribution = tensor([0.9582, 0.0243, 0.0174])
2024-12-05 15:42:22,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.9582, 0.0243, 0.0174]), new_distribution = tensor([0.9584, 0.0242, 0.0174])
2024-12-05 15:42:22,458 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.9584, 0.0242, 0.0174]), new_distribution = tensor([0.9585, 0.0241, 0.0173])
2024-12-05 15:42:22,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.9585, 0.0241, 0.0173]), new_distribution = tensor([0.9587, 0.0240, 0.0173])
2024-12-05 15:42:22,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.9587, 0.0240, 0.0173]), new_distribution = tensor([0.9588, 0.0240, 0.0172])
2024-12-05 15:42:22,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.9588, 0.0240, 0.0172]), new_distribution = tensor([0.9590, 0.0239, 0.0172])
2024-12-05 15:42:22,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.9590, 0.0239, 0.0172]), new_distribution = tensor([0.9591, 0.0238, 0.0171])
2024-12-05 15:42:22,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.9591, 0.0238, 0.0171]), new_distribution = tensor([0.9592, 0.0237, 0.0171])
2024-12-05 15:42:23,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.9592, 0.0237, 0.0171]), new_distribution = tensor([0.9594, 0.0236, 0.0170])
2024-12-05 15:42:23,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.9594, 0.0236, 0.0170]), new_distribution = tensor([0.9595, 0.0235, 0.0170])
2024-12-05 15:42:23,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.9595, 0.0235, 0.0170]), new_distribution = tensor([0.9597, 0.0234, 0.0169])
2024-12-05 15:42:23,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.9597, 0.0234, 0.0169]), new_distribution = tensor([0.9598, 0.0233, 0.0169])
2024-12-05 15:42:23,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.9598, 0.0233, 0.0169]), new_distribution = tensor([0.9599, 0.0232, 0.0168])
2024-12-05 15:42:23,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.9599, 0.0232, 0.0168]), new_distribution = tensor([0.9601, 0.0232, 0.0168])
2024-12-05 15:42:23,424 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.9601, 0.0232, 0.0168]), new_distribution = tensor([0.9602, 0.0231, 0.0167])
2024-12-05 15:42:23,481 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.9602, 0.0231, 0.0167]), new_distribution = tensor([0.9603, 0.0230, 0.0167])
2024-12-05 15:42:23,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.9603, 0.0230, 0.0167]), new_distribution = tensor([0.9605, 0.0229, 0.0166])
2024-12-05 15:42:23,590 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.9605, 0.0229, 0.0166]), new_distribution = tensor([0.9606, 0.0228, 0.0166])
2024-12-05 15:42:23,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.9606, 0.0228, 0.0166]), new_distribution = tensor([0.9608, 0.0227, 0.0165])
2024-12-05 15:42:23,699 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.9608, 0.0227, 0.0165]), new_distribution = tensor([0.9609, 0.0226, 0.0165])
2024-12-05 15:42:23,753 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.9609, 0.0226, 0.0165]), new_distribution = tensor([0.9610, 0.0225, 0.0164])
2024-12-05 15:42:23,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.9610, 0.0225, 0.0164]), new_distribution = tensor([0.9612, 0.0225, 0.0164])
2024-12-05 15:42:23,862 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.9612, 0.0225, 0.0164]), new_distribution = tensor([0.9613, 0.0224, 0.0163])
2024-12-05 15:42:23,916 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.9613, 0.0224, 0.0163]), new_distribution = tensor([0.9614, 0.0223, 0.0163])
2024-12-05 15:42:23,971 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.9614, 0.0223, 0.0163]), new_distribution = tensor([0.9616, 0.0222, 0.0162])
2024-12-05 15:42:24,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.9616, 0.0222, 0.0162]), new_distribution = tensor([0.9617, 0.0221, 0.0162])
2024-12-05 15:42:24,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.9617, 0.0221, 0.0162]), new_distribution = tensor([0.9618, 0.0220, 0.0161])
2024-12-05 15:42:24,134 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.9618, 0.0220, 0.0161]), new_distribution = tensor([0.9620, 0.0220, 0.0161])
2024-12-05 15:42:24,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.9620, 0.0220, 0.0161]), new_distribution = tensor([0.9621, 0.0219, 0.0160])
2024-12-05 15:42:24,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.9621, 0.0219, 0.0160]), new_distribution = tensor([0.9622, 0.0218, 0.0160])
2024-12-05 15:42:24,297 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.9622, 0.0218, 0.0160]), new_distribution = tensor([0.9623, 0.0217, 0.0159])
2024-12-05 15:42:24,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.9623, 0.0217, 0.0159]), new_distribution = tensor([0.9625, 0.0216, 0.0159])
2024-12-05 15:42:24,405 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.9625, 0.0216, 0.0159]), new_distribution = tensor([0.9626, 0.0215, 0.0159])
2024-12-05 15:42:24,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.9626, 0.0215, 0.0159]), new_distribution = tensor([0.9627, 0.0215, 0.0158])
2024-12-05 15:42:24,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.9627, 0.0215, 0.0158]), new_distribution = tensor([0.9629, 0.0214, 0.0158])
2024-12-05 15:42:24,568 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.9629, 0.0214, 0.0158]), new_distribution = tensor([0.9630, 0.0213, 0.0157])
2024-12-05 15:42:24,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.9630, 0.0213, 0.0157]), new_distribution = tensor([0.9631, 0.0212, 0.0157])
2024-12-05 15:42:24,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.9631, 0.0212, 0.0157]), new_distribution = tensor([0.9632, 0.0211, 0.0156])
2024-12-05 15:42:24,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.9632, 0.0211, 0.0156]), new_distribution = tensor([0.9634, 0.0211, 0.0156])
2024-12-05 15:42:24,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.9634, 0.0211, 0.0156]), new_distribution = tensor([0.9635, 0.0210, 0.0155])
2024-12-05 15:42:24,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.9635, 0.0210, 0.0155]), new_distribution = tensor([0.9636, 0.0209, 0.0155])
2024-12-05 15:42:24,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.9636, 0.0209, 0.0155]), new_distribution = tensor([0.9637, 0.0208, 0.0154])
2024-12-05 15:42:24,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.9637, 0.0208, 0.0154]), new_distribution = tensor([0.9639, 0.0207, 0.0154])
2024-12-05 15:42:25,002 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.9639, 0.0207, 0.0154]), new_distribution = tensor([0.9640, 0.0207, 0.0153])
2024-12-05 15:42:25,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.9640, 0.0207, 0.0153]), new_distribution = tensor([0.9641, 0.0206, 0.0153])
2024-12-05 15:42:25,110 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.9641, 0.0206, 0.0153]), new_distribution = tensor([0.9642, 0.0205, 0.0153])
2024-12-05 15:42:25,164 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.9642, 0.0205, 0.0153]), new_distribution = tensor([0.9644, 0.0204, 0.0152])
2024-12-05 15:42:25,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.9644, 0.0204, 0.0152]), new_distribution = tensor([0.9645, 0.0203, 0.0152])
2024-12-05 15:42:25,272 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.9645, 0.0203, 0.0152]), new_distribution = tensor([0.9646, 0.0203, 0.0151])
2024-12-05 15:42:25,327 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.9646, 0.0203, 0.0151]), new_distribution = tensor([0.9647, 0.0202, 0.0151])
2024-12-05 15:42:25,381 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.9647, 0.0202, 0.0151]), new_distribution = tensor([0.9649, 0.0201, 0.0150])
2024-12-05 15:42:25,435 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.9649, 0.0201, 0.0150]), new_distribution = tensor([0.9650, 0.0200, 0.0150])
2024-12-05 15:42:25,489 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.9650, 0.0200, 0.0150]), new_distribution = tensor([0.9651, 0.0200, 0.0149])
2024-12-05 15:42:25,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.9651, 0.0200, 0.0149]), new_distribution = tensor([0.9652, 0.0199, 0.0149])
2024-12-05 15:42:25,597 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.9652, 0.0199, 0.0149]), new_distribution = tensor([0.9653, 0.0198, 0.0148])
2024-12-05 15:42:25,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.9653, 0.0198, 0.0148]), new_distribution = tensor([0.9655, 0.0197, 0.0148])
2024-12-05 15:42:25,706 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.9655, 0.0197, 0.0148]), new_distribution = tensor([0.9656, 0.0197, 0.0148])
2024-12-05 15:42:25,760 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.9656, 0.0197, 0.0148]), new_distribution = tensor([0.9657, 0.0196, 0.0147])
2024-12-05 15:42:25,814 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.9657, 0.0196, 0.0147]), new_distribution = tensor([0.9658, 0.0195, 0.0147])
2024-12-05 15:42:25,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.9658, 0.0195, 0.0147]), new_distribution = tensor([0.9659, 0.0194, 0.0146])
2024-12-05 15:42:25,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.9659, 0.0194, 0.0146]), new_distribution = tensor([0.9661, 0.0194, 0.0146])
2024-12-05 15:42:25,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.9661, 0.0194, 0.0146]), new_distribution = tensor([0.9662, 0.0193, 0.0145])
2024-12-05 15:42:26,031 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.9662, 0.0193, 0.0145]), new_distribution = tensor([0.9663, 0.0192, 0.0145])
2024-12-05 15:42:26,085 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.9663, 0.0192, 0.0145]), new_distribution = tensor([0.9664, 0.0191, 0.0145])
2024-12-05 15:42:26,140 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.9664, 0.0191, 0.0145]), new_distribution = tensor([0.9665, 0.0191, 0.0144])
2024-12-05 15:42:26,194 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.9665, 0.0191, 0.0144]), new_distribution = tensor([0.9666, 0.0190, 0.0144])
2024-12-05 15:42:26,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.9666, 0.0190, 0.0144]), new_distribution = tensor([0.9667, 0.0189, 0.0143])
2024-12-05 15:42:26,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.9667, 0.0189, 0.0143]), new_distribution = tensor([0.9669, 0.0189, 0.0143])
2024-12-05 15:42:26,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.9669, 0.0189, 0.0143]), new_distribution = tensor([0.9670, 0.0188, 0.0142])
2024-12-05 15:42:26,410 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.9670, 0.0188, 0.0142]), new_distribution = tensor([0.9671, 0.0187, 0.0142])
2024-12-05 15:42:26,464 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.9671, 0.0187, 0.0142]), new_distribution = tensor([0.9672, 0.0186, 0.0142])
2024-12-05 15:42:26,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.9672, 0.0186, 0.0142]), new_distribution = tensor([0.9673, 0.0186, 0.0141])
2024-12-05 15:42:26,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.9673, 0.0186, 0.0141]), new_distribution = tensor([0.9674, 0.0185, 0.0141])
2024-12-05 15:42:26,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.9674, 0.0185, 0.0141]), new_distribution = tensor([0.9675, 0.0184, 0.0140])
2024-12-05 15:42:26,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.9675, 0.0184, 0.0140]), new_distribution = tensor([0.9677, 0.0184, 0.0140])
2024-12-05 15:42:26,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.9677, 0.0184, 0.0140]), new_distribution = tensor([0.9678, 0.0183, 0.0139])
2024-12-05 15:42:26,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.9678, 0.0183, 0.0139]), new_distribution = tensor([0.9679, 0.0182, 0.0139])
2024-12-05 15:42:26,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.9679, 0.0182, 0.0139]), new_distribution = tensor([0.9680, 0.0181, 0.0139])
2024-12-05 15:42:26,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.9680, 0.0181, 0.0139]), new_distribution = tensor([0.9681, 0.0181, 0.0138])
2024-12-05 15:42:26,953 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.9681, 0.0181, 0.0138]), new_distribution = tensor([0.9682, 0.0180, 0.0138])
2024-12-05 15:42:27,007 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.9682, 0.0180, 0.0138]), new_distribution = tensor([0.9683, 0.0179, 0.0137])
2024-12-05 15:42:27,061 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.9683, 0.0179, 0.0137]), new_distribution = tensor([0.9684, 0.0179, 0.0137])
2024-12-05 15:42:27,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.9684, 0.0179, 0.0137]), new_distribution = tensor([0.9685, 0.0178, 0.0137])
2024-12-05 15:42:27,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.9685, 0.0178, 0.0137]), new_distribution = tensor([0.9686, 0.0177, 0.0136])
2024-12-05 15:42:27,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.9686, 0.0177, 0.0136]), new_distribution = tensor([0.9688, 0.0177, 0.0136])
2024-12-05 15:42:27,281 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.9688, 0.0177, 0.0136]), new_distribution = tensor([0.9689, 0.0176, 0.0135])
2024-12-05 15:42:27,335 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.9689, 0.0176, 0.0135]), new_distribution = tensor([0.9690, 0.0175, 0.0135])
2024-12-05 15:42:27,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.9690, 0.0175, 0.0135]), new_distribution = tensor([0.9691, 0.0175, 0.0135])
2024-12-05 15:42:27,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([0.9691, 0.0175, 0.0135]), new_distribution = tensor([0.9692, 0.0174, 0.0134])
2024-12-05 15:42:27,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([0.9692, 0.0174, 0.0134]), new_distribution = tensor([0.9693, 0.0173, 0.0134])
2024-12-05 15:42:27,552 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([0.9693, 0.0173, 0.0134]), new_distribution = tensor([0.9694, 0.0173, 0.0133])
2024-12-05 15:42:27,606 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([0.9694, 0.0173, 0.0133]), new_distribution = tensor([0.9695, 0.0172, 0.0133])
2024-12-05 15:42:27,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([0.9695, 0.0172, 0.0133]), new_distribution = tensor([0.9696, 0.0171, 0.0133])
2024-12-05 15:42:27,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([0.9696, 0.0171, 0.0133]), new_distribution = tensor([0.9697, 0.0171, 0.0132])
2024-12-05 15:42:27,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([0.9697, 0.0171, 0.0132]), new_distribution = tensor([0.9698, 0.0170, 0.0132])
2024-12-05 15:42:27,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([0.9698, 0.0170, 0.0132]), new_distribution = tensor([0.9699, 0.0169, 0.0131])
2024-12-05 15:42:27,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([0.9699, 0.0169, 0.0131]), new_distribution = tensor([0.9700, 0.0169, 0.0131])
2024-12-05 15:42:27,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([0.9700, 0.0169, 0.0131]), new_distribution = tensor([0.9701, 0.0168, 0.0131])
2024-12-05 15:42:27,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([0.9701, 0.0168, 0.0131]), new_distribution = tensor([0.9702, 0.0167, 0.0130])
2024-12-05 15:42:28,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([0.9702, 0.0167, 0.0130]), new_distribution = tensor([0.9703, 0.0167, 0.0130])
2024-12-05 15:42:28,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([0.9703, 0.0167, 0.0130]), new_distribution = tensor([0.9704, 0.0166, 0.0129])
2024-12-05 15:42:28,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([0.9704, 0.0166, 0.0129]), new_distribution = tensor([0.9705, 0.0165, 0.0129])
2024-12-05 15:42:28,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([0.9705, 0.0165, 0.0129]), new_distribution = tensor([0.9706, 0.0165, 0.0129])
2024-12-05 15:42:28,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([0.9706, 0.0165, 0.0129]), new_distribution = tensor([0.9707, 0.0164, 0.0128])
2024-12-05 15:42:28,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([0.9707, 0.0164, 0.0128]), new_distribution = tensor([0.9708, 0.0164, 0.0128])
2024-12-05 15:42:28,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([0.9708, 0.0164, 0.0128]), new_distribution = tensor([0.9709, 0.0163, 0.0128])
2024-12-05 15:42:28,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([0.9709, 0.0163, 0.0128]), new_distribution = tensor([0.9710, 0.0162, 0.0127])
2024-12-05 15:42:28,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([0.9710, 0.0162, 0.0127]), new_distribution = tensor([0.9711, 0.0162, 0.0127])
2024-12-05 15:42:28,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([0.9711, 0.0162, 0.0127]), new_distribution = tensor([0.9712, 0.0161, 0.0126])
2024-12-05 15:42:28,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([0.9712, 0.0161, 0.0126]), new_distribution = tensor([0.9713, 0.0160, 0.0126])
2024-12-05 15:42:28,637 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([0.9713, 0.0160, 0.0126]), new_distribution = tensor([0.9714, 0.0160, 0.0126])
2024-12-05 15:42:28,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([0.9714, 0.0160, 0.0126]), new_distribution = tensor([0.9715, 0.0159, 0.0125])
2024-12-05 15:42:28,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([0.9715, 0.0159, 0.0125]), new_distribution = tensor([0.9716, 0.0159, 0.0125])
2024-12-05 15:42:28,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([0.9716, 0.0159, 0.0125]), new_distribution = tensor([0.9717, 0.0158, 0.0125])
2024-12-05 15:42:28,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([0.9717, 0.0158, 0.0125]), new_distribution = tensor([0.9718, 0.0157, 0.0124])
2024-12-05 15:42:28,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([0.9718, 0.0157, 0.0124]), new_distribution = tensor([0.9719, 0.0157, 0.0124])
2024-12-05 15:42:28,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([0.9719, 0.0157, 0.0124]), new_distribution = tensor([0.9720, 0.0156, 0.0123])
2024-12-05 15:42:29,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([0.9720, 0.0156, 0.0123]), new_distribution = tensor([0.9721, 0.0156, 0.0123])
2024-12-05 15:42:29,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([0.9721, 0.0156, 0.0123]), new_distribution = tensor([0.9722, 0.0155, 0.0123])
2024-12-05 15:42:29,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([0.9722, 0.0155, 0.0123]), new_distribution = tensor([0.9723, 0.0154, 0.0122])
2024-12-05 15:42:29,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([0.9723, 0.0154, 0.0122]), new_distribution = tensor([0.9724, 0.0154, 0.0122])
2024-12-05 15:42:29,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([0.9724, 0.0154, 0.0122]), new_distribution = tensor([0.9725, 0.0153, 0.0122])
2024-12-05 15:42:29,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([0.9725, 0.0153, 0.0122]), new_distribution = tensor([0.9726, 0.0153, 0.0121])
2024-12-05 15:42:29,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([0.9726, 0.0153, 0.0121]), new_distribution = tensor([0.9727, 0.0152, 0.0121])
2024-12-05 15:42:29,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([0.9727, 0.0152, 0.0121]), new_distribution = tensor([0.9728, 0.0151, 0.0121])
2024-12-05 15:42:29,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([0.9728, 0.0151, 0.0121]), new_distribution = tensor([0.9729, 0.0151, 0.0120])
2024-12-05 15:42:29,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([0.9729, 0.0151, 0.0120]), new_distribution = tensor([0.9730, 0.0150, 0.0120])
2024-12-05 15:42:29,560 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([0.9730, 0.0150, 0.0120]), new_distribution = tensor([0.9731, 0.0150, 0.0119])
2024-12-05 15:42:29,614 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([0.9731, 0.0150, 0.0119]), new_distribution = tensor([0.9732, 0.0149, 0.0119])
2024-12-05 15:42:29,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([0.9732, 0.0149, 0.0119]), new_distribution = tensor([0.9733, 0.0149, 0.0119])
2024-12-05 15:42:29,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([0.9733, 0.0149, 0.0119]), new_distribution = tensor([0.9734, 0.0148, 0.0118])
2024-12-05 15:42:29,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([0.9734, 0.0148, 0.0118]), new_distribution = tensor([0.9735, 0.0147, 0.0118])
2024-12-05 15:42:29,831 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([0.9735, 0.0147, 0.0118]), new_distribution = tensor([0.9735, 0.0147, 0.0118])
2024-12-05 15:42:29,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([0.9735, 0.0147, 0.0118]), new_distribution = tensor([0.9736, 0.0146, 0.0117])
2024-12-05 15:42:29,939 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([0.9736, 0.0146, 0.0117]), new_distribution = tensor([0.9737, 0.0146, 0.0117])
2024-12-05 15:42:29,996 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([0.9737, 0.0146, 0.0117]), new_distribution = tensor([0.9738, 0.0145, 0.0117])
2024-12-05 15:42:30,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([0.9738, 0.0145, 0.0117]), new_distribution = tensor([0.9739, 0.0145, 0.0116])
2024-12-05 15:42:30,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([0.9739, 0.0145, 0.0116]), new_distribution = tensor([0.9740, 0.0144, 0.0116])
2024-12-05 15:42:30,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([0.9740, 0.0144, 0.0116]), new_distribution = tensor([0.9741, 0.0143, 0.0116])
2024-12-05 15:42:30,214 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([0.9741, 0.0143, 0.0116]), new_distribution = tensor([0.9742, 0.0143, 0.0115])
2024-12-05 15:42:30,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([0.9742, 0.0143, 0.0115]), new_distribution = tensor([0.9743, 0.0142, 0.0115])
2024-12-05 15:42:30,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([0.9743, 0.0142, 0.0115]), new_distribution = tensor([0.9744, 0.0142, 0.0115])
2024-12-05 15:42:30,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([0.9744, 0.0142, 0.0115]), new_distribution = tensor([0.9744, 0.0141, 0.0114])
2024-12-05 15:42:30,431 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([0.9744, 0.0141, 0.0114]), new_distribution = tensor([0.9745, 0.0141, 0.0114])
2024-12-05 15:42:30,486 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([0.9745, 0.0141, 0.0114]), new_distribution = tensor([0.9746, 0.0140, 0.0114])
2024-12-05 15:42:30,540 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([0.9746, 0.0140, 0.0114]), new_distribution = tensor([0.9747, 0.0140, 0.0113])
2024-12-05 15:42:30,594 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([0.9747, 0.0140, 0.0113]), new_distribution = tensor([0.9748, 0.0139, 0.0113])
2024-12-05 15:42:30,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([0.9748, 0.0139, 0.0113]), new_distribution = tensor([0.9749, 0.0139, 0.0113])
2024-12-05 15:42:30,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([0.9749, 0.0139, 0.0113]), new_distribution = tensor([0.9750, 0.0138, 0.0112])
2024-12-05 15:42:30,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([0.9750, 0.0138, 0.0112]), new_distribution = tensor([0.9751, 0.0138, 0.0112])
2024-12-05 15:42:30,810 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([0.9751, 0.0138, 0.0112]), new_distribution = tensor([0.9751, 0.0137, 0.0112])
2024-12-05 15:42:30,864 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([0.9751, 0.0137, 0.0112]), new_distribution = tensor([0.9752, 0.0136, 0.0111])
2024-12-05 15:42:30,918 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([0.9752, 0.0136, 0.0111]), new_distribution = tensor([0.9753, 0.0136, 0.0111])
2024-12-05 15:42:30,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([0.9753, 0.0136, 0.0111]), new_distribution = tensor([0.9754, 0.0135, 0.0111])
2024-12-05 15:42:31,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([0.9754, 0.0135, 0.0111]), new_distribution = tensor([0.9755, 0.0135, 0.0110])
2024-12-05 15:42:31,081 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([0.9755, 0.0135, 0.0110]), new_distribution = tensor([0.9756, 0.0134, 0.0110])
2024-12-05 15:42:31,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([0.9756, 0.0134, 0.0110]), new_distribution = tensor([0.9757, 0.0134, 0.0110])
2024-12-05 15:42:31,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([0.9757, 0.0134, 0.0110]), new_distribution = tensor([0.9757, 0.0133, 0.0109])
2024-12-05 15:42:31,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([0.9757, 0.0133, 0.0109]), new_distribution = tensor([0.9758, 0.0133, 0.0109])
2024-12-05 15:42:31,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([0.9758, 0.0133, 0.0109]), new_distribution = tensor([0.9759, 0.0132, 0.0109])
2024-12-05 15:42:31,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([0.9759, 0.0132, 0.0109]), new_distribution = tensor([0.9760, 0.0132, 0.0108])
2024-12-05 15:42:31,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([0.9760, 0.0132, 0.0108]), new_distribution = tensor([0.9761, 0.0131, 0.0108])
2024-12-05 15:42:31,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([0.9761, 0.0131, 0.0108]), new_distribution = tensor([0.9762, 0.0131, 0.0108])
2024-12-05 15:42:31,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([0.9762, 0.0131, 0.0108]), new_distribution = tensor([0.9762, 0.0130, 0.0107])
2024-12-05 15:42:31,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([0.9762, 0.0130, 0.0107]), new_distribution = tensor([0.9763, 0.0130, 0.0107])
2024-12-05 15:42:31,624 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([0.9763, 0.0130, 0.0107]), new_distribution = tensor([0.9764, 0.0129, 0.0107])
2024-12-05 15:42:31,678 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([0.9764, 0.0129, 0.0107]), new_distribution = tensor([0.9765, 0.0129, 0.0106])
2024-12-05 15:42:31,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([0.9765, 0.0129, 0.0106]), new_distribution = tensor([0.9766, 0.0128, 0.0106])
2024-12-05 15:42:31,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([0.9766, 0.0128, 0.0106]), new_distribution = tensor([0.9766, 0.0128, 0.0106])
2024-12-05 15:42:31,841 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([0.9766, 0.0128, 0.0106]), new_distribution = tensor([0.9767, 0.0127, 0.0105])
2024-12-05 15:42:31,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([0.9767, 0.0127, 0.0105]), new_distribution = tensor([0.9768, 0.0127, 0.0105])
2024-12-05 15:42:31,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([0.9768, 0.0127, 0.0105]), new_distribution = tensor([0.9769, 0.0126, 0.0105])
2024-12-05 15:42:32,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([0.9769, 0.0126, 0.0105]), new_distribution = tensor([0.9770, 0.0126, 0.0104])
2024-12-05 15:42:32,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([0.9770, 0.0126, 0.0104]), new_distribution = tensor([0.9771, 0.0125, 0.0104])
2024-12-05 15:42:32,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([0.9771, 0.0125, 0.0104]), new_distribution = tensor([0.9771, 0.0125, 0.0104])
2024-12-05 15:42:32,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([0.9771, 0.0125, 0.0104]), new_distribution = tensor([0.9772, 0.0124, 0.0104])
2024-12-05 15:42:32,221 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([0.9772, 0.0124, 0.0104]), new_distribution = tensor([0.9773, 0.0124, 0.0103])
2024-12-05 15:42:32,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([0.9773, 0.0124, 0.0103]), new_distribution = tensor([0.9774, 0.0123, 0.0103])
2024-12-05 15:42:32,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([0.9774, 0.0123, 0.0103]), new_distribution = tensor([0.9774, 0.0123, 0.0103])
2024-12-05 15:42:32,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([0.9774, 0.0123, 0.0103]), new_distribution = tensor([0.9775, 0.0122, 0.0102])
2024-12-05 15:42:32,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([0.9775, 0.0122, 0.0102]), new_distribution = tensor([0.9776, 0.0122, 0.0102])
2024-12-05 15:42:32,493 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([0.9776, 0.0122, 0.0102]), new_distribution = tensor([0.9777, 0.0121, 0.0102])
2024-12-05 15:42:32,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([0.9777, 0.0121, 0.0102]), new_distribution = tensor([0.9778, 0.0121, 0.0101])
2024-12-05 15:42:32,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([0.9778, 0.0121, 0.0101]), new_distribution = tensor([0.9778, 0.0121, 0.0101])
2024-12-05 15:42:32,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([0.9778, 0.0121, 0.0101]), new_distribution = tensor([0.9779, 0.0120, 0.0101])
2024-12-05 15:42:32,709 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([0.9779, 0.0120, 0.0101]), new_distribution = tensor([0.9780, 0.0120, 0.0101])
2024-12-05 15:42:32,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([0.9780, 0.0120, 0.0101]), new_distribution = tensor([0.9781, 0.0119, 0.0100])
2024-12-05 15:42:32,818 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([0.9781, 0.0119, 0.0100]), new_distribution = tensor([0.9781, 0.0119, 0.0100])
2024-12-05 15:42:32,872 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([0.9781, 0.0119, 0.0100]), new_distribution = tensor([0.9782, 0.0118, 0.0100])
2024-12-05 15:42:32,926 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([0.9782, 0.0118, 0.0100]), new_distribution = tensor([0.9783, 0.0118, 0.0099])
2024-12-05 15:42:32,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([0.9783, 0.0118, 0.0099]), new_distribution = tensor([0.9784, 0.0117, 0.0099])
2024-12-05 15:42:33,035 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([0.9784, 0.0117, 0.0099]), new_distribution = tensor([0.9784, 0.0117, 0.0099])
2024-12-05 15:42:33,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([0.9784, 0.0117, 0.0099]), new_distribution = tensor([0.9785, 0.0116, 0.0098])
2024-12-05 15:42:33,143 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([0.9785, 0.0116, 0.0098]), new_distribution = tensor([0.9786, 0.0116, 0.0098])
2024-12-05 15:42:33,197 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([0.9786, 0.0116, 0.0098]), new_distribution = tensor([0.9787, 0.0116, 0.0098])
2024-12-05 15:42:33,252 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([0.9787, 0.0116, 0.0098]), new_distribution = tensor([0.9787, 0.0115, 0.0098])
2024-12-05 15:42:33,306 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([0.9787, 0.0115, 0.0098]), new_distribution = tensor([0.9788, 0.0115, 0.0097])
2024-12-05 15:42:33,360 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([0.9788, 0.0115, 0.0097]), new_distribution = tensor([0.9789, 0.0114, 0.0097])
2024-12-05 15:42:33,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([0.9789, 0.0114, 0.0097]), new_distribution = tensor([0.9790, 0.0114, 0.0097])
2024-12-05 15:42:33,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([0.9790, 0.0114, 0.0097]), new_distribution = tensor([0.9790, 0.0113, 0.0096])
2024-12-05 15:42:33,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([0.9790, 0.0113, 0.0096]), new_distribution = tensor([0.9791, 0.0113, 0.0096])
2024-12-05 15:42:33,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([0.9791, 0.0113, 0.0096]), new_distribution = tensor([0.9792, 0.0112, 0.0096])
2024-12-05 15:42:33,630 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([0.9792, 0.0112, 0.0096]), new_distribution = tensor([0.9792, 0.0112, 0.0096])
2024-12-05 15:42:33,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([0.9792, 0.0112, 0.0096]), new_distribution = tensor([0.9793, 0.0112, 0.0095])
2024-12-05 15:42:33,738 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([0.9793, 0.0112, 0.0095]), new_distribution = tensor([0.9794, 0.0111, 0.0095])
2024-12-05 15:42:33,793 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([0.9794, 0.0111, 0.0095]), new_distribution = tensor([0.9795, 0.0111, 0.0095])
2024-12-05 15:42:33,847 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([0.9795, 0.0111, 0.0095]), new_distribution = tensor([0.9795, 0.0110, 0.0094])
2024-12-05 15:42:33,901 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([0.9795, 0.0110, 0.0094]), new_distribution = tensor([0.9796, 0.0110, 0.0094])
2024-12-05 15:42:33,955 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([0.9796, 0.0110, 0.0094]), new_distribution = tensor([0.9797, 0.0109, 0.0094])
2024-12-05 15:42:34,009 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([0.9797, 0.0109, 0.0094]), new_distribution = tensor([0.9797, 0.0109, 0.0094])
2024-12-05 15:42:34,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([0.9797, 0.0109, 0.0094]), new_distribution = tensor([0.9798, 0.0109, 0.0093])
2024-12-05 15:42:34,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([0.9798, 0.0109, 0.0093]), new_distribution = tensor([0.9799, 0.0108, 0.0093])
2024-12-05 15:42:34,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([0.9799, 0.0108, 0.0093]), new_distribution = tensor([0.9800, 0.0108, 0.0093])
2024-12-05 15:42:34,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([0.9800, 0.0108, 0.0093]), new_distribution = tensor([0.9800, 0.0107, 0.0092])
2024-12-05 15:42:34,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([0.9800, 0.0107, 0.0092]), new_distribution = tensor([0.9801, 0.0107, 0.0092])
2024-12-05 15:42:34,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([0.9801, 0.0107, 0.0092]), new_distribution = tensor([0.9802, 0.0106, 0.0092])
2024-12-05 15:42:34,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([0.9802, 0.0106, 0.0092]), new_distribution = tensor([0.9802, 0.0106, 0.0092])
2024-12-05 15:42:34,442 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([0.9802, 0.0106, 0.0092]), new_distribution = tensor([0.9803, 0.0106, 0.0091])
2024-12-05 15:42:34,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([0.9803, 0.0106, 0.0091]), new_distribution = tensor([0.9804, 0.0105, 0.0091])
2024-12-05 15:42:34,550 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([0.9804, 0.0105, 0.0091]), new_distribution = tensor([0.9804, 0.0105, 0.0091])
2024-12-05 15:42:34,605 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([0.9804, 0.0105, 0.0091]), new_distribution = tensor([0.9805, 0.0104, 0.0091])
2024-12-05 15:42:34,659 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([0.9805, 0.0104, 0.0091]), new_distribution = tensor([0.9806, 0.0104, 0.0090])
2024-12-05 15:42:34,713 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([0.9806, 0.0104, 0.0090]), new_distribution = tensor([0.9806, 0.0104, 0.0090])
2024-12-05 15:42:34,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([0.9806, 0.0104, 0.0090]), new_distribution = tensor([0.9807, 0.0103, 0.0090])
2024-12-05 15:42:34,822 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([0.9807, 0.0103, 0.0090]), new_distribution = tensor([0.9808, 0.0103, 0.0089])
2024-12-05 15:42:34,876 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([0.9808, 0.0103, 0.0089]), new_distribution = tensor([0.9808, 0.0102, 0.0089])
2024-12-05 15:42:34,930 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([0.9808, 0.0102, 0.0089]), new_distribution = tensor([0.9809, 0.0102, 0.0089])
2024-12-05 15:42:34,984 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([0.9809, 0.0102, 0.0089]), new_distribution = tensor([0.9810, 0.0102, 0.0089])
2024-12-05 15:42:35,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([0.9810, 0.0102, 0.0089]), new_distribution = tensor([0.9810, 0.0101, 0.0088])
2024-12-05 15:42:35,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([0.9810, 0.0101, 0.0088]), new_distribution = tensor([0.9811, 0.0101, 0.0088])
2024-12-05 15:42:35,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([0.9811, 0.0101, 0.0088]), new_distribution = tensor([0.9812, 0.0100, 0.0088])
2024-12-05 15:42:35,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([0.9812, 0.0100, 0.0088]), new_distribution = tensor([0.9812, 0.0100, 0.0088])
2024-12-05 15:42:35,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([0.9812, 0.0100, 0.0088]), new_distribution = tensor([0.9813, 0.0100, 0.0087])
2024-12-05 15:42:35,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([0.9813, 0.0100, 0.0087]), new_distribution = tensor([0.9814, 0.0099, 0.0087])
2024-12-05 15:42:35,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([0.9814, 0.0099, 0.0087]), new_distribution = tensor([0.9814, 0.0099, 0.0087])
2024-12-05 15:42:35,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([0.9814, 0.0099, 0.0087]), new_distribution = tensor([0.9815, 0.0098, 0.0087])
2024-12-05 15:42:35,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([0.9815, 0.0098, 0.0087]), new_distribution = tensor([0.9816, 0.0098, 0.0086])
2024-12-05 15:42:35,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([0.9816, 0.0098, 0.0086]), new_distribution = tensor([0.9816, 0.0098, 0.0086])
2024-12-05 15:42:35,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([0.9816, 0.0098, 0.0086]), new_distribution = tensor([0.9817, 0.0097, 0.0086])
2024-12-05 15:42:35,636 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([0.9817, 0.0097, 0.0086]), new_distribution = tensor([0.9817, 0.0097, 0.0086])
2024-12-05 15:42:35,690 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([0.9817, 0.0097, 0.0086]), new_distribution = tensor([0.9818, 0.0097, 0.0085])
2024-12-05 15:42:35,744 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([0.9818, 0.0097, 0.0085]), new_distribution = tensor([0.9819, 0.0096, 0.0085])
2024-12-05 15:42:35,798 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([0.9819, 0.0096, 0.0085]), new_distribution = tensor([0.9819, 0.0096, 0.0085])
2024-12-05 15:42:35,852 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([0.9819, 0.0096, 0.0085]), new_distribution = tensor([0.9820, 0.0095, 0.0085])
2024-12-05 15:42:35,906 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([0.9820, 0.0095, 0.0085]), new_distribution = tensor([0.9821, 0.0095, 0.0084])
2024-12-05 15:42:35,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([0.9821, 0.0095, 0.0084]), new_distribution = tensor([0.9821, 0.0095, 0.0084])
2024-12-05 15:42:36,015 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([0.9821, 0.0095, 0.0084]), new_distribution = tensor([0.9822, 0.0094, 0.0084])
2024-12-05 15:42:36,069 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([0.9822, 0.0094, 0.0084]), new_distribution = tensor([0.9822, 0.0094, 0.0084])
2024-12-05 15:42:36,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([0.9822, 0.0094, 0.0084]), new_distribution = tensor([0.9823, 0.0094, 0.0083])
2024-12-05 15:42:36,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([0.9823, 0.0094, 0.0083]), new_distribution = tensor([0.9824, 0.0093, 0.0083])
2024-12-05 15:42:36,232 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([0.9824, 0.0093, 0.0083]), new_distribution = tensor([0.9824, 0.0093, 0.0083])
2024-12-05 15:42:36,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([0.9824, 0.0093, 0.0083]), new_distribution = tensor([0.9825, 0.0093, 0.0083])
2024-12-05 15:42:36,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([0.9825, 0.0093, 0.0083]), new_distribution = tensor([0.9826, 0.0092, 0.0082])
2024-12-05 15:42:36,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([0.9826, 0.0092, 0.0082]), new_distribution = tensor([0.9826, 0.0092, 0.0082])
2024-12-05 15:42:36,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([0.9826, 0.0092, 0.0082]), new_distribution = tensor([0.9827, 0.0091, 0.0082])
2024-12-05 15:42:36,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([0.9827, 0.0091, 0.0082]), new_distribution = tensor([0.9827, 0.0091, 0.0082])
2024-12-05 15:42:36,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([0.9827, 0.0091, 0.0082]), new_distribution = tensor([0.9828, 0.0091, 0.0081])
2024-12-05 15:42:36,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([0.9828, 0.0091, 0.0081]), new_distribution = tensor([0.9829, 0.0090, 0.0081])
2024-12-05 15:42:36,666 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([0.9829, 0.0090, 0.0081]), new_distribution = tensor([0.9829, 0.0090, 0.0081])
2024-12-05 15:42:36,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([0.9829, 0.0090, 0.0081]), new_distribution = tensor([0.9830, 0.0090, 0.0081])
2024-12-05 15:42:36,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([0.9830, 0.0090, 0.0081]), new_distribution = tensor([0.9830, 0.0089, 0.0080])
2024-12-05 15:42:36,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([0.9830, 0.0089, 0.0080]), new_distribution = tensor([0.9831, 0.0089, 0.0080])
2024-12-05 15:42:36,884 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([0.9831, 0.0089, 0.0080]), new_distribution = tensor([0.9831, 0.0089, 0.0080])
2024-12-05 15:42:36,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([0.9831, 0.0089, 0.0080]), new_distribution = tensor([0.9832, 0.0088, 0.0080])
2024-12-05 15:42:36,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([0.9832, 0.0088, 0.0080]), new_distribution = tensor([0.9833, 0.0088, 0.0079])
2024-12-05 15:42:37,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([0.9833, 0.0088, 0.0079]), new_distribution = tensor([0.9833, 0.0088, 0.0079])
2024-12-05 15:42:37,101 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([0.9833, 0.0088, 0.0079]), new_distribution = tensor([0.9834, 0.0087, 0.0079])
2024-12-05 15:42:37,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([0.9834, 0.0087, 0.0079]), new_distribution = tensor([0.9834, 0.0087, 0.0079])
2024-12-05 15:42:37,213 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([0.9834, 0.0087, 0.0079]), new_distribution = tensor([0.9835, 0.0087, 0.0078])
2024-12-05 15:42:37,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([0.9835, 0.0087, 0.0078]), new_distribution = tensor([0.9836, 0.0086, 0.0078])
2024-12-05 15:42:37,322 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([0.9836, 0.0086, 0.0078]), new_distribution = tensor([0.9836, 0.0086, 0.0078])
2024-12-05 15:42:37,376 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([0.9836, 0.0086, 0.0078]), new_distribution = tensor([0.9837, 0.0086, 0.0078])
2024-12-05 15:42:37,431 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([0.9837, 0.0086, 0.0078]), new_distribution = tensor([0.9837, 0.0085, 0.0078])
2024-12-05 15:42:37,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([0.9837, 0.0085, 0.0078]), new_distribution = tensor([0.9838, 0.0085, 0.0077])
2024-12-05 15:42:37,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([0.9838, 0.0085, 0.0077]), new_distribution = tensor([0.9838, 0.0085, 0.0077])
2024-12-05 15:42:37,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([0.9838, 0.0085, 0.0077]), new_distribution = tensor([0.9839, 0.0084, 0.0077])
2024-12-05 15:42:37,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([0.9839, 0.0084, 0.0077]), new_distribution = tensor([0.9839, 0.0084, 0.0077])
2024-12-05 15:42:37,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([0.9839, 0.0084, 0.0077]), new_distribution = tensor([0.9840, 0.0084, 0.0076])
2024-12-05 15:42:37,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([0.9840, 0.0084, 0.0076]), new_distribution = tensor([0.9841, 0.0083, 0.0076])
2024-12-05 15:42:37,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([0.9841, 0.0083, 0.0076]), new_distribution = tensor([0.9841, 0.0083, 0.0076])
2024-12-05 15:42:37,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([0.9841, 0.0083, 0.0076]), new_distribution = tensor([0.9842, 0.0083, 0.0076])
2024-12-05 15:42:37,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([0.9842, 0.0083, 0.0076]), new_distribution = tensor([0.9842, 0.0082, 0.0075])
2024-12-05 15:42:37,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([0.9842, 0.0082, 0.0075]), new_distribution = tensor([0.9843, 0.0082, 0.0075])
2024-12-05 15:42:38,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([0.9843, 0.0082, 0.0075]), new_distribution = tensor([0.9843, 0.0082, 0.0075])
2024-12-05 15:42:38,081 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([0.9843, 0.0082, 0.0075]), new_distribution = tensor([0.9844, 0.0081, 0.0075])
2024-12-05 15:42:38,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([0.9844, 0.0081, 0.0075]), new_distribution = tensor([0.9844, 0.0081, 0.0075])
2024-12-05 15:42:38,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([0.9844, 0.0081, 0.0075]), new_distribution = tensor([0.9845, 0.0081, 0.0074])
2024-12-05 15:42:38,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([0.9845, 0.0081, 0.0074]), new_distribution = tensor([0.9845, 0.0080, 0.0074])
2024-12-05 15:42:38,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 300: ref_distribution = tensor([0.9845, 0.0080, 0.0074]), new_distribution = tensor([0.9846, 0.0080, 0.0074])
2024-12-05 15:42:38,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 301: ref_distribution = tensor([0.9846, 0.0080, 0.0074]), new_distribution = tensor([0.9847, 0.0080, 0.0074])
2024-12-05 15:42:38,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 302: ref_distribution = tensor([0.9847, 0.0080, 0.0074]), new_distribution = tensor([0.9847, 0.0079, 0.0073])
2024-12-05 15:42:38,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 303: ref_distribution = tensor([0.9847, 0.0079, 0.0073]), new_distribution = tensor([0.9848, 0.0079, 0.0073])
2024-12-05 15:42:38,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 304: ref_distribution = tensor([0.9848, 0.0079, 0.0073]), new_distribution = tensor([0.9848, 0.0079, 0.0073])
2024-12-05 15:42:38,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 305: ref_distribution = tensor([0.9848, 0.0079, 0.0073]), new_distribution = tensor([0.9849, 0.0078, 0.0073])
2024-12-05 15:42:38,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 306: ref_distribution = tensor([0.9849, 0.0078, 0.0073]), new_distribution = tensor([0.9849, 0.0078, 0.0073])
2024-12-05 15:42:38,678 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 307: ref_distribution = tensor([0.9849, 0.0078, 0.0073]), new_distribution = tensor([0.9850, 0.0078, 0.0072])
2024-12-05 15:42:38,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 308: ref_distribution = tensor([0.9850, 0.0078, 0.0072]), new_distribution = tensor([0.9850, 0.0078, 0.0072])
2024-12-05 15:42:38,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 309: ref_distribution = tensor([0.9850, 0.0078, 0.0072]), new_distribution = tensor([0.9851, 0.0077, 0.0072])
2024-12-05 15:42:38,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 310: ref_distribution = tensor([0.9851, 0.0077, 0.0072]), new_distribution = tensor([0.9851, 0.0077, 0.0072])
2024-12-05 15:42:38,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 311: ref_distribution = tensor([0.9851, 0.0077, 0.0072]), new_distribution = tensor([0.9852, 0.0077, 0.0072])
2024-12-05 15:42:38,949 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 312: ref_distribution = tensor([0.9852, 0.0077, 0.0072]), new_distribution = tensor([0.9852, 0.0076, 0.0071])
2024-12-05 15:42:39,003 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 313: ref_distribution = tensor([0.9852, 0.0076, 0.0071]), new_distribution = tensor([0.9853, 0.0076, 0.0071])
2024-12-05 15:42:39,057 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 314: ref_distribution = tensor([0.9853, 0.0076, 0.0071]), new_distribution = tensor([0.9853, 0.0076, 0.0071])
2024-12-05 15:42:39,111 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 315: ref_distribution = tensor([0.9853, 0.0076, 0.0071]), new_distribution = tensor([0.9854, 0.0075, 0.0071])
2024-12-05 15:42:39,165 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 316: ref_distribution = tensor([0.9854, 0.0075, 0.0071]), new_distribution = tensor([0.9854, 0.0075, 0.0070])
2024-12-05 15:42:39,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 317: ref_distribution = tensor([0.9854, 0.0075, 0.0070]), new_distribution = tensor([0.9855, 0.0075, 0.0070])
2024-12-05 15:42:39,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 318: ref_distribution = tensor([0.9855, 0.0075, 0.0070]), new_distribution = tensor([0.9855, 0.0075, 0.0070])
2024-12-05 15:42:39,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 319: ref_distribution = tensor([0.9855, 0.0075, 0.0070]), new_distribution = tensor([0.9856, 0.0074, 0.0070])
2024-12-05 15:42:39,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 320: ref_distribution = tensor([0.9856, 0.0074, 0.0070]), new_distribution = tensor([0.9856, 0.0074, 0.0070])
2024-12-05 15:42:39,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 321: ref_distribution = tensor([0.9856, 0.0074, 0.0070]), new_distribution = tensor([0.9857, 0.0074, 0.0069])
2024-12-05 15:42:39,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 322: ref_distribution = tensor([0.9857, 0.0074, 0.0069]), new_distribution = tensor([0.9857, 0.0073, 0.0069])
2024-12-05 15:42:39,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 323: ref_distribution = tensor([0.9857, 0.0073, 0.0069]), new_distribution = tensor([0.9858, 0.0073, 0.0069])
2024-12-05 15:42:39,599 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 324: ref_distribution = tensor([0.9858, 0.0073, 0.0069]), new_distribution = tensor([0.9858, 0.0073, 0.0069])
2024-12-05 15:42:39,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 325: ref_distribution = tensor([0.9858, 0.0073, 0.0069]), new_distribution = tensor([0.9859, 0.0073, 0.0069])
2024-12-05 15:42:39,708 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 326: ref_distribution = tensor([0.9859, 0.0073, 0.0069]), new_distribution = tensor([0.9859, 0.0072, 0.0068])
2024-12-05 15:42:39,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 327: ref_distribution = tensor([0.9859, 0.0072, 0.0068]), new_distribution = tensor([0.9860, 0.0072, 0.0068])
2024-12-05 15:42:39,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 328: ref_distribution = tensor([0.9860, 0.0072, 0.0068]), new_distribution = tensor([0.9860, 0.0072, 0.0068])
2024-12-05 15:42:39,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 329: ref_distribution = tensor([0.9860, 0.0072, 0.0068]), new_distribution = tensor([0.9861, 0.0071, 0.0068])
2024-12-05 15:42:39,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 330: ref_distribution = tensor([0.9861, 0.0071, 0.0068]), new_distribution = tensor([0.9861, 0.0071, 0.0068])
2024-12-05 15:42:39,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 331: ref_distribution = tensor([0.9861, 0.0071, 0.0068]), new_distribution = tensor([0.9862, 0.0071, 0.0067])
2024-12-05 15:42:40,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 332: ref_distribution = tensor([0.9862, 0.0071, 0.0067]), new_distribution = tensor([0.9862, 0.0071, 0.0067])
2024-12-05 15:42:40,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 333: ref_distribution = tensor([0.9862, 0.0071, 0.0067]), new_distribution = tensor([0.9863, 0.0070, 0.0067])
2024-12-05 15:42:40,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 334: ref_distribution = tensor([0.9863, 0.0070, 0.0067]), new_distribution = tensor([0.9863, 0.0070, 0.0067])
2024-12-05 15:42:40,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 335: ref_distribution = tensor([0.9863, 0.0070, 0.0067]), new_distribution = tensor([0.9864, 0.0070, 0.0067])
2024-12-05 15:42:40,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 336: ref_distribution = tensor([0.9864, 0.0070, 0.0067]), new_distribution = tensor([0.9864, 0.0070, 0.0066])
2024-12-05 15:42:40,304 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 337: ref_distribution = tensor([0.9864, 0.0070, 0.0066]), new_distribution = tensor([0.9865, 0.0069, 0.0066])
2024-12-05 15:42:40,359 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 338: ref_distribution = tensor([0.9865, 0.0069, 0.0066]), new_distribution = tensor([0.9865, 0.0069, 0.0066])
2024-12-05 15:42:40,413 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 339: ref_distribution = tensor([0.9865, 0.0069, 0.0066]), new_distribution = tensor([0.9866, 0.0069, 0.0066])
2024-12-05 15:42:40,467 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 340: ref_distribution = tensor([0.9866, 0.0069, 0.0066]), new_distribution = tensor([0.9866, 0.0068, 0.0066])
2024-12-05 15:42:40,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 341: ref_distribution = tensor([0.9866, 0.0068, 0.0066]), new_distribution = tensor([0.9866, 0.0068, 0.0065])
2024-12-05 15:42:40,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 342: ref_distribution = tensor([0.9866, 0.0068, 0.0065]), new_distribution = tensor([0.9867, 0.0068, 0.0065])
2024-12-05 15:42:40,630 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 343: ref_distribution = tensor([0.9867, 0.0068, 0.0065]), new_distribution = tensor([0.9867, 0.0068, 0.0065])
2024-12-05 15:42:40,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 344: ref_distribution = tensor([0.9867, 0.0068, 0.0065]), new_distribution = tensor([0.9868, 0.0067, 0.0065])
2024-12-05 15:42:40,739 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 345: ref_distribution = tensor([0.9868, 0.0067, 0.0065]), new_distribution = tensor([0.9868, 0.0067, 0.0065])
2024-12-05 15:42:40,793 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 346: ref_distribution = tensor([0.9868, 0.0067, 0.0065]), new_distribution = tensor([0.9869, 0.0067, 0.0064])
2024-12-05 15:42:40,847 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 347: ref_distribution = tensor([0.9869, 0.0067, 0.0064]), new_distribution = tensor([0.9869, 0.0067, 0.0064])
2024-12-05 15:42:40,901 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 348: ref_distribution = tensor([0.9869, 0.0067, 0.0064]), new_distribution = tensor([0.9870, 0.0066, 0.0064])
2024-12-05 15:42:40,956 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 349: ref_distribution = tensor([0.9870, 0.0066, 0.0064]), new_distribution = tensor([0.9870, 0.0066, 0.0064])
2024-12-05 15:42:41,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 350: ref_distribution = tensor([0.9870, 0.0066, 0.0064]), new_distribution = tensor([0.9871, 0.0066, 0.0064])
2024-12-05 15:42:41,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 351: ref_distribution = tensor([0.9871, 0.0066, 0.0064]), new_distribution = tensor([0.9871, 0.0066, 0.0063])
2024-12-05 15:42:41,119 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 352: ref_distribution = tensor([0.9871, 0.0066, 0.0063]), new_distribution = tensor([0.9871, 0.0065, 0.0063])
2024-12-05 15:42:41,173 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 353: ref_distribution = tensor([0.9871, 0.0065, 0.0063]), new_distribution = tensor([0.9872, 0.0065, 0.0063])
2024-12-05 15:42:41,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 354: ref_distribution = tensor([0.9872, 0.0065, 0.0063]), new_distribution = tensor([0.9872, 0.0065, 0.0063])
2024-12-05 15:42:41,282 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 355: ref_distribution = tensor([0.9872, 0.0065, 0.0063]), new_distribution = tensor([0.9873, 0.0065, 0.0063])
2024-12-05 15:42:41,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 356: ref_distribution = tensor([0.9873, 0.0065, 0.0063]), new_distribution = tensor([0.9873, 0.0064, 0.0063])
2024-12-05 15:42:41,390 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 357: ref_distribution = tensor([0.9873, 0.0064, 0.0063]), new_distribution = tensor([0.9874, 0.0064, 0.0062])
2024-12-05 15:42:41,445 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 358: ref_distribution = tensor([0.9874, 0.0064, 0.0062]), new_distribution = tensor([0.9874, 0.0064, 0.0062])
2024-12-05 15:42:41,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 359: ref_distribution = tensor([0.9874, 0.0064, 0.0062]), new_distribution = tensor([0.9875, 0.0064, 0.0062])
2024-12-05 15:42:41,553 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 360: ref_distribution = tensor([0.9875, 0.0064, 0.0062]), new_distribution = tensor([0.9875, 0.0063, 0.0062])
2024-12-05 15:42:41,607 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 361: ref_distribution = tensor([0.9875, 0.0063, 0.0062]), new_distribution = tensor([0.9875, 0.0063, 0.0062])
2024-12-05 15:42:41,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 362: ref_distribution = tensor([0.9875, 0.0063, 0.0062]), new_distribution = tensor([0.9876, 0.0063, 0.0061])
2024-12-05 15:42:41,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 363: ref_distribution = tensor([0.9876, 0.0063, 0.0061]), new_distribution = tensor([0.9876, 0.0063, 0.0061])
2024-12-05 15:42:41,770 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 364: ref_distribution = tensor([0.9876, 0.0063, 0.0061]), new_distribution = tensor([0.9877, 0.0062, 0.0061])
2024-12-05 15:42:41,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 365: ref_distribution = tensor([0.9877, 0.0062, 0.0061]), new_distribution = tensor([0.9877, 0.0062, 0.0061])
2024-12-05 15:42:41,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 366: ref_distribution = tensor([0.9877, 0.0062, 0.0061]), new_distribution = tensor([0.9878, 0.0062, 0.0061])
2024-12-05 15:42:41,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 367: ref_distribution = tensor([0.9878, 0.0062, 0.0061]), new_distribution = tensor([0.9878, 0.0062, 0.0061])
2024-12-05 15:42:41,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 368: ref_distribution = tensor([0.9878, 0.0062, 0.0061]), new_distribution = tensor([0.9878, 0.0061, 0.0060])
2024-12-05 15:42:42,042 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 369: ref_distribution = tensor([0.9878, 0.0061, 0.0060]), new_distribution = tensor([0.9879, 0.0061, 0.0060])
2024-12-05 15:42:42,096 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 370: ref_distribution = tensor([0.9879, 0.0061, 0.0060]), new_distribution = tensor([0.9879, 0.0061, 0.0060])
2024-12-05 15:42:42,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 371: ref_distribution = tensor([0.9879, 0.0061, 0.0060]), new_distribution = tensor([0.9880, 0.0061, 0.0060])
2024-12-05 15:42:42,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 372: ref_distribution = tensor([0.9880, 0.0061, 0.0060]), new_distribution = tensor([0.9880, 0.0060, 0.0060])
2024-12-05 15:42:42,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 373: ref_distribution = tensor([0.9880, 0.0060, 0.0060]), new_distribution = tensor([0.9880, 0.0060, 0.0059])
2024-12-05 15:42:42,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 374: ref_distribution = tensor([0.9880, 0.0060, 0.0059]), new_distribution = tensor([0.9881, 0.0060, 0.0059])
2024-12-05 15:42:42,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 375: ref_distribution = tensor([0.9881, 0.0060, 0.0059]), new_distribution = tensor([0.9881, 0.0060, 0.0059])
2024-12-05 15:42:42,420 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 376: ref_distribution = tensor([0.9881, 0.0060, 0.0059]), new_distribution = tensor([0.9882, 0.0059, 0.0059])
2024-12-05 15:42:42,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 377: ref_distribution = tensor([0.9882, 0.0059, 0.0059]), new_distribution = tensor([0.9882, 0.0059, 0.0059])
2024-12-05 15:42:42,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 378: ref_distribution = tensor([0.9882, 0.0059, 0.0059]), new_distribution = tensor([0.9883, 0.0059, 0.0059])
2024-12-05 15:42:42,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 379: ref_distribution = tensor([0.9883, 0.0059, 0.0059]), new_distribution = tensor([0.9883, 0.0059, 0.0058])
2024-12-05 15:42:42,636 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 380: ref_distribution = tensor([0.9883, 0.0059, 0.0058]), new_distribution = tensor([0.9883, 0.0058, 0.0058])
2024-12-05 15:42:42,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 381: ref_distribution = tensor([0.9883, 0.0058, 0.0058]), new_distribution = tensor([0.9884, 0.0058, 0.0058])
2024-12-05 15:42:42,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 382: ref_distribution = tensor([0.9884, 0.0058, 0.0058]), new_distribution = tensor([0.9884, 0.0058, 0.0058])
2024-12-05 15:42:42,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 383: ref_distribution = tensor([0.9884, 0.0058, 0.0058]), new_distribution = tensor([0.9885, 0.0058, 0.0058])
2024-12-05 15:42:42,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 384: ref_distribution = tensor([0.9885, 0.0058, 0.0058]), new_distribution = tensor([0.9885, 0.0058, 0.0058])
2024-12-05 15:42:42,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 385: ref_distribution = tensor([0.9885, 0.0058, 0.0058]), new_distribution = tensor([0.9885, 0.0057, 0.0057])
2024-12-05 15:42:42,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 386: ref_distribution = tensor([0.9885, 0.0057, 0.0057]), new_distribution = tensor([0.9886, 0.0057, 0.0057])
2024-12-05 15:42:43,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 387: ref_distribution = tensor([0.9886, 0.0057, 0.0057]), new_distribution = tensor([0.9886, 0.0057, 0.0057])
2024-12-05 15:42:43,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 388: ref_distribution = tensor([0.9886, 0.0057, 0.0057]), new_distribution = tensor([0.9887, 0.0057, 0.0057])
2024-12-05 15:42:43,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 389: ref_distribution = tensor([0.9887, 0.0057, 0.0057]), new_distribution = tensor([0.9887, 0.0056, 0.0057])
2024-12-05 15:42:43,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 390: ref_distribution = tensor([0.9887, 0.0056, 0.0057]), new_distribution = tensor([0.9887, 0.0056, 0.0056])
2024-12-05 15:42:43,232 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 391: ref_distribution = tensor([0.9887, 0.0056, 0.0056]), new_distribution = tensor([0.9888, 0.0056, 0.0056])
2024-12-05 15:42:43,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 392: ref_distribution = tensor([0.9888, 0.0056, 0.0056]), new_distribution = tensor([0.9888, 0.0056, 0.0056])
2024-12-05 15:42:43,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 393: ref_distribution = tensor([0.9888, 0.0056, 0.0056]), new_distribution = tensor([0.9888, 0.0056, 0.0056])
2024-12-05 15:42:43,395 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 394: ref_distribution = tensor([0.9888, 0.0056, 0.0056]), new_distribution = tensor([0.9889, 0.0055, 0.0056])
2024-12-05 15:42:43,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 395: ref_distribution = tensor([0.9889, 0.0055, 0.0056]), new_distribution = tensor([0.9889, 0.0055, 0.0056])
2024-12-05 15:42:43,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 396: ref_distribution = tensor([0.9889, 0.0055, 0.0056]), new_distribution = tensor([0.9890, 0.0055, 0.0055])
2024-12-05 15:42:43,557 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 397: ref_distribution = tensor([0.9890, 0.0055, 0.0055]), new_distribution = tensor([0.9890, 0.0055, 0.0055])
2024-12-05 15:42:43,611 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 398: ref_distribution = tensor([0.9890, 0.0055, 0.0055]), new_distribution = tensor([0.9890, 0.0054, 0.0055])
2024-12-05 15:42:43,665 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 399: ref_distribution = tensor([0.9890, 0.0054, 0.0055]), new_distribution = tensor([0.9891, 0.0054, 0.0055])
2024-12-05 15:42:43,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 400: ref_distribution = tensor([0.9891, 0.0054, 0.0055]), new_distribution = tensor([0.9891, 0.0054, 0.0055])
2024-12-05 15:42:43,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 401: ref_distribution = tensor([0.9891, 0.0054, 0.0055]), new_distribution = tensor([0.9892, 0.0054, 0.0055])
2024-12-05 15:42:43,828 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 402: ref_distribution = tensor([0.9892, 0.0054, 0.0055]), new_distribution = tensor([0.9892, 0.0054, 0.0055])
2024-12-05 15:42:43,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 403: ref_distribution = tensor([0.9892, 0.0054, 0.0055]), new_distribution = tensor([0.9892, 0.0053, 0.0054])
2024-12-05 15:42:43,936 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 404: ref_distribution = tensor([0.9892, 0.0053, 0.0054]), new_distribution = tensor([0.9893, 0.0053, 0.0054])
2024-12-05 15:42:43,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 405: ref_distribution = tensor([0.9893, 0.0053, 0.0054]), new_distribution = tensor([0.9893, 0.0053, 0.0054])
2024-12-05 15:42:44,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 406: ref_distribution = tensor([0.9893, 0.0053, 0.0054]), new_distribution = tensor([0.9893, 0.0053, 0.0054])
2024-12-05 15:42:44,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 407: ref_distribution = tensor([0.9893, 0.0053, 0.0054]), new_distribution = tensor([0.9894, 0.0053, 0.0054])
2024-12-05 15:42:44,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 408: ref_distribution = tensor([0.9894, 0.0053, 0.0054]), new_distribution = tensor([0.9894, 0.0052, 0.0054])
2024-12-05 15:42:44,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 409: ref_distribution = tensor([0.9894, 0.0052, 0.0054]), new_distribution = tensor([0.9894, 0.0052, 0.0053])
2024-12-05 15:42:44,262 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 410: ref_distribution = tensor([0.9894, 0.0052, 0.0053]), new_distribution = tensor([0.9895, 0.0052, 0.0053])
2024-12-05 15:42:44,316 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 411: ref_distribution = tensor([0.9895, 0.0052, 0.0053]), new_distribution = tensor([0.9895, 0.0052, 0.0053])
2024-12-05 15:42:44,370 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 412: ref_distribution = tensor([0.9895, 0.0052, 0.0053]), new_distribution = tensor([0.9896, 0.0052, 0.0053])
2024-12-05 15:42:44,424 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 413: ref_distribution = tensor([0.9896, 0.0052, 0.0053]), new_distribution = tensor([0.9896, 0.0051, 0.0053])
2024-12-05 15:42:44,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 414: ref_distribution = tensor([0.9896, 0.0051, 0.0053]), new_distribution = tensor([0.9896, 0.0051, 0.0053])
2024-12-05 15:42:44,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 415: ref_distribution = tensor([0.9896, 0.0051, 0.0053]), new_distribution = tensor([0.9897, 0.0051, 0.0052])
2024-12-05 15:42:44,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 416: ref_distribution = tensor([0.9897, 0.0051, 0.0052]), new_distribution = tensor([0.9897, 0.0051, 0.0052])
2024-12-05 15:42:44,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 417: ref_distribution = tensor([0.9897, 0.0051, 0.0052]), new_distribution = tensor([0.9897, 0.0051, 0.0052])
2024-12-05 15:42:44,698 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 418: ref_distribution = tensor([0.9897, 0.0051, 0.0052]), new_distribution = tensor([0.9898, 0.0050, 0.0052])
2024-12-05 15:42:44,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 419: ref_distribution = tensor([0.9898, 0.0050, 0.0052]), new_distribution = tensor([0.9898, 0.0050, 0.0052])
2024-12-05 15:42:44,806 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 420: ref_distribution = tensor([0.9898, 0.0050, 0.0052]), new_distribution = tensor([0.9898, 0.0050, 0.0052])
2024-12-05 15:42:44,861 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 421: ref_distribution = tensor([0.9898, 0.0050, 0.0052]), new_distribution = tensor([0.9899, 0.0050, 0.0051])
2024-12-05 15:42:44,915 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 422: ref_distribution = tensor([0.9899, 0.0050, 0.0051]), new_distribution = tensor([0.9899, 0.0050, 0.0051])
2024-12-05 15:42:44,969 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 423: ref_distribution = tensor([0.9899, 0.0050, 0.0051]), new_distribution = tensor([0.9899, 0.0049, 0.0051])
2024-12-05 15:42:45,023 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 424: ref_distribution = tensor([0.9899, 0.0049, 0.0051]), new_distribution = tensor([0.9900, 0.0049, 0.0051])
2024-12-05 15:42:45,077 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 425: ref_distribution = tensor([0.9900, 0.0049, 0.0051]), new_distribution = tensor([0.9900, 0.0049, 0.0051])
2024-12-05 15:42:45,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 426: ref_distribution = tensor([0.9900, 0.0049, 0.0051]), new_distribution = tensor([0.9900, 0.0049, 0.0051])
2024-12-05 15:42:45,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 427: ref_distribution = tensor([0.9900, 0.0049, 0.0051]), new_distribution = tensor([0.9901, 0.0049, 0.0051])
2024-12-05 15:42:45,240 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 428: ref_distribution = tensor([0.9901, 0.0049, 0.0051]), new_distribution = tensor([0.9901, 0.0048, 0.0050])
2024-12-05 15:42:45,294 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 429: ref_distribution = tensor([0.9901, 0.0048, 0.0050]), new_distribution = tensor([0.9902, 0.0048, 0.0050])
2024-12-05 15:42:45,349 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 430: ref_distribution = tensor([0.9902, 0.0048, 0.0050]), new_distribution = tensor([0.9902, 0.0048, 0.0050])
2024-12-05 15:42:45,403 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 431: ref_distribution = tensor([0.9902, 0.0048, 0.0050]), new_distribution = tensor([0.9902, 0.0048, 0.0050])
2024-12-05 15:42:45,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 432: ref_distribution = tensor([0.9902, 0.0048, 0.0050]), new_distribution = tensor([0.9903, 0.0048, 0.0050])
2024-12-05 15:42:45,512 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 433: ref_distribution = tensor([0.9903, 0.0048, 0.0050]), new_distribution = tensor([0.9903, 0.0047, 0.0050])
2024-12-05 15:42:45,566 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 434: ref_distribution = tensor([0.9903, 0.0047, 0.0050]), new_distribution = tensor([0.9903, 0.0047, 0.0050])
2024-12-05 15:42:45,620 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 435: ref_distribution = tensor([0.9903, 0.0047, 0.0050]), new_distribution = tensor([0.9904, 0.0047, 0.0049])
2024-12-05 15:42:45,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 436: ref_distribution = tensor([0.9904, 0.0047, 0.0049]), new_distribution = tensor([0.9904, 0.0047, 0.0049])
2024-12-05 15:42:45,728 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 437: ref_distribution = tensor([0.9904, 0.0047, 0.0049]), new_distribution = tensor([0.9904, 0.0047, 0.0049])
2024-12-05 15:42:45,783 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 438: ref_distribution = tensor([0.9904, 0.0047, 0.0049]), new_distribution = tensor([0.9905, 0.0047, 0.0049])
2024-12-05 15:42:45,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 439: ref_distribution = tensor([0.9905, 0.0047, 0.0049]), new_distribution = tensor([0.9905, 0.0046, 0.0049])
2024-12-05 15:42:45,891 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 440: ref_distribution = tensor([0.9905, 0.0046, 0.0049]), new_distribution = tensor([0.9905, 0.0046, 0.0049])
2024-12-05 15:42:45,945 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 441: ref_distribution = tensor([0.9905, 0.0046, 0.0049]), new_distribution = tensor([0.9906, 0.0046, 0.0049])
2024-12-05 15:42:45,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 442: ref_distribution = tensor([0.9906, 0.0046, 0.0049]), new_distribution = tensor([0.9906, 0.0046, 0.0048])
2024-12-05 15:42:46,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 443: ref_distribution = tensor([0.9906, 0.0046, 0.0048]), new_distribution = tensor([0.9906, 0.0046, 0.0048])
2024-12-05 15:42:46,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 444: ref_distribution = tensor([0.9906, 0.0046, 0.0048]), new_distribution = tensor([0.9906, 0.0045, 0.0048])
2024-12-05 15:42:46,162 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 445: ref_distribution = tensor([0.9906, 0.0045, 0.0048]), new_distribution = tensor([0.9907, 0.0045, 0.0048])
2024-12-05 15:42:46,216 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 446: ref_distribution = tensor([0.9907, 0.0045, 0.0048]), new_distribution = tensor([0.9907, 0.0045, 0.0048])
2024-12-05 15:42:46,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 447: ref_distribution = tensor([0.9907, 0.0045, 0.0048]), new_distribution = tensor([0.9907, 0.0045, 0.0048])
2024-12-05 15:42:46,324 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 448: ref_distribution = tensor([0.9907, 0.0045, 0.0048]), new_distribution = tensor([0.9908, 0.0045, 0.0047])
2024-12-05 15:42:46,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 449: ref_distribution = tensor([0.9908, 0.0045, 0.0047]), new_distribution = tensor([0.9908, 0.0045, 0.0047])
2024-12-05 15:42:46,433 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 450: ref_distribution = tensor([0.9908, 0.0045, 0.0047]), new_distribution = tensor([0.9908, 0.0044, 0.0047])
2024-12-05 15:42:46,488 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 451: ref_distribution = tensor([0.9908, 0.0044, 0.0047]), new_distribution = tensor([0.9909, 0.0044, 0.0047])
2024-12-05 15:42:46,542 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 452: ref_distribution = tensor([0.9909, 0.0044, 0.0047]), new_distribution = tensor([0.9909, 0.0044, 0.0047])
2024-12-05 15:42:46,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 453: ref_distribution = tensor([0.9909, 0.0044, 0.0047]), new_distribution = tensor([0.9909, 0.0044, 0.0047])
2024-12-05 15:42:46,651 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 454: ref_distribution = tensor([0.9909, 0.0044, 0.0047]), new_distribution = tensor([0.9910, 0.0044, 0.0047])
2024-12-05 15:42:46,705 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 455: ref_distribution = tensor([0.9910, 0.0044, 0.0047]), new_distribution = tensor([0.9910, 0.0044, 0.0047])
2024-12-05 15:42:46,760 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 456: ref_distribution = tensor([0.9910, 0.0044, 0.0047]), new_distribution = tensor([0.9910, 0.0043, 0.0046])
2024-12-05 15:42:46,814 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 457: ref_distribution = tensor([0.9910, 0.0043, 0.0046]), new_distribution = tensor([0.9911, 0.0043, 0.0046])
2024-12-05 15:42:46,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 458: ref_distribution = tensor([0.9911, 0.0043, 0.0046]), new_distribution = tensor([0.9911, 0.0043, 0.0046])
2024-12-05 15:42:46,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 459: ref_distribution = tensor([0.9911, 0.0043, 0.0046]), new_distribution = tensor([0.9911, 0.0043, 0.0046])
2024-12-05 15:42:46,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 460: ref_distribution = tensor([0.9911, 0.0043, 0.0046]), new_distribution = tensor([0.9912, 0.0043, 0.0046])
2024-12-05 15:42:47,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 461: ref_distribution = tensor([0.9912, 0.0043, 0.0046]), new_distribution = tensor([0.9912, 0.0042, 0.0046])
2024-12-05 15:42:47,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 462: ref_distribution = tensor([0.9912, 0.0042, 0.0046]), new_distribution = tensor([0.9912, 0.0042, 0.0046])
2024-12-05 15:42:47,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 463: ref_distribution = tensor([0.9912, 0.0042, 0.0046]), new_distribution = tensor([0.9912, 0.0042, 0.0045])
2024-12-05 15:42:47,193 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 464: ref_distribution = tensor([0.9912, 0.0042, 0.0045]), new_distribution = tensor([0.9913, 0.0042, 0.0045])
2024-12-05 15:42:47,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 465: ref_distribution = tensor([0.9913, 0.0042, 0.0045]), new_distribution = tensor([0.9913, 0.0042, 0.0045])
2024-12-05 15:42:47,305 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 466: ref_distribution = tensor([0.9913, 0.0042, 0.0045]), new_distribution = tensor([0.9913, 0.0042, 0.0045])
2024-12-05 15:42:47,360 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 467: ref_distribution = tensor([0.9913, 0.0042, 0.0045]), new_distribution = tensor([0.9914, 0.0041, 0.0045])
2024-12-05 15:42:47,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 468: ref_distribution = tensor([0.9914, 0.0041, 0.0045]), new_distribution = tensor([0.9914, 0.0041, 0.0045])
2024-12-05 15:42:47,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 469: ref_distribution = tensor([0.9914, 0.0041, 0.0045]), new_distribution = tensor([0.9914, 0.0041, 0.0045])
2024-12-05 15:42:47,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 470: ref_distribution = tensor([0.9914, 0.0041, 0.0045]), new_distribution = tensor([0.9915, 0.0041, 0.0044])
2024-12-05 15:42:47,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 471: ref_distribution = tensor([0.9915, 0.0041, 0.0044]), new_distribution = tensor([0.9915, 0.0041, 0.0044])
2024-12-05 15:42:47,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 472: ref_distribution = tensor([0.9915, 0.0041, 0.0044]), new_distribution = tensor([0.9915, 0.0041, 0.0044])
2024-12-05 15:42:47,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 473: ref_distribution = tensor([0.9915, 0.0041, 0.0044]), new_distribution = tensor([0.9915, 0.0041, 0.0044])
2024-12-05 15:42:47,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 474: ref_distribution = tensor([0.9915, 0.0041, 0.0044]), new_distribution = tensor([0.9916, 0.0040, 0.0044])
2024-12-05 15:42:47,794 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 475: ref_distribution = tensor([0.9916, 0.0040, 0.0044]), new_distribution = tensor([0.9916, 0.0040, 0.0044])
2024-12-05 15:42:47,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 476: ref_distribution = tensor([0.9916, 0.0040, 0.0044]), new_distribution = tensor([0.9916, 0.0040, 0.0044])
2024-12-05 15:42:47,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 477: ref_distribution = tensor([0.9916, 0.0040, 0.0044]), new_distribution = tensor([0.9917, 0.0040, 0.0044])
2024-12-05 15:42:47,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 478: ref_distribution = tensor([0.9917, 0.0040, 0.0044]), new_distribution = tensor([0.9917, 0.0040, 0.0043])
2024-12-05 15:42:48,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 479: ref_distribution = tensor([0.9917, 0.0040, 0.0043]), new_distribution = tensor([0.9917, 0.0040, 0.0043])
2024-12-05 15:42:48,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 480: ref_distribution = tensor([0.9917, 0.0040, 0.0043]), new_distribution = tensor([0.9917, 0.0039, 0.0043])
2024-12-05 15:42:48,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 481: ref_distribution = tensor([0.9917, 0.0039, 0.0043]), new_distribution = tensor([0.9918, 0.0039, 0.0043])
2024-12-05 15:42:48,174 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 482: ref_distribution = tensor([0.9918, 0.0039, 0.0043]), new_distribution = tensor([0.9918, 0.0039, 0.0043])
2024-12-05 15:42:48,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 483: ref_distribution = tensor([0.9918, 0.0039, 0.0043]), new_distribution = tensor([0.9918, 0.0039, 0.0043])
2024-12-05 15:42:48,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 484: ref_distribution = tensor([0.9918, 0.0039, 0.0043]), new_distribution = tensor([0.9919, 0.0039, 0.0043])
2024-12-05 15:42:48,337 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 485: ref_distribution = tensor([0.9919, 0.0039, 0.0043]), new_distribution = tensor([0.9919, 0.0039, 0.0043])
2024-12-05 15:42:48,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 486: ref_distribution = tensor([0.9919, 0.0039, 0.0043]), new_distribution = tensor([0.9919, 0.0038, 0.0042])
2024-12-05 15:42:48,446 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 487: ref_distribution = tensor([0.9919, 0.0038, 0.0042]), new_distribution = tensor([0.9919, 0.0038, 0.0042])
2024-12-05 15:42:48,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 488: ref_distribution = tensor([0.9919, 0.0038, 0.0042]), new_distribution = tensor([0.9920, 0.0038, 0.0042])
2024-12-05 15:42:48,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 489: ref_distribution = tensor([0.9920, 0.0038, 0.0042]), new_distribution = tensor([0.9920, 0.0038, 0.0042])
2024-12-05 15:42:48,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 490: ref_distribution = tensor([0.9920, 0.0038, 0.0042]), new_distribution = tensor([0.9920, 0.0038, 0.0042])
2024-12-05 15:42:48,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 491: ref_distribution = tensor([0.9920, 0.0038, 0.0042]), new_distribution = tensor([0.9921, 0.0038, 0.0042])
2024-12-05 15:42:48,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 492: ref_distribution = tensor([0.9921, 0.0038, 0.0042]), new_distribution = tensor([0.9921, 0.0038, 0.0042])
2024-12-05 15:42:48,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 493: ref_distribution = tensor([0.9921, 0.0038, 0.0042]), new_distribution = tensor([0.9921, 0.0037, 0.0042])
2024-12-05 15:42:48,826 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 494: ref_distribution = tensor([0.9921, 0.0037, 0.0042]), new_distribution = tensor([0.9921, 0.0037, 0.0041])
2024-12-05 15:42:48,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 495: ref_distribution = tensor([0.9921, 0.0037, 0.0041]), new_distribution = tensor([0.9922, 0.0037, 0.0041])
2024-12-05 15:42:48,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 496: ref_distribution = tensor([0.9922, 0.0037, 0.0041]), new_distribution = tensor([0.9922, 0.0037, 0.0041])
2024-12-05 15:42:48,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 497: ref_distribution = tensor([0.9922, 0.0037, 0.0041]), new_distribution = tensor([0.9922, 0.0037, 0.0041])
2024-12-05 15:42:49,043 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 498: ref_distribution = tensor([0.9922, 0.0037, 0.0041]), new_distribution = tensor([0.9922, 0.0037, 0.0041])
2024-12-05 15:42:49,097 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 499: ref_distribution = tensor([0.9922, 0.0037, 0.0041]), new_distribution = tensor([0.9923, 0.0037, 0.0041])
2024-12-05 15:42:49,152 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 500: ref_distribution = tensor([0.9923, 0.0037, 0.0041]), new_distribution = tensor([0.9923, 0.0036, 0.0041])
2024-12-05 15:42:49,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 501: ref_distribution = tensor([0.9923, 0.0036, 0.0041]), new_distribution = tensor([0.9923, 0.0036, 0.0041])
2024-12-05 15:42:49,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 502: ref_distribution = tensor([0.9923, 0.0036, 0.0041]), new_distribution = tensor([0.9923, 0.0036, 0.0040])
2024-12-05 15:42:49,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 503: ref_distribution = tensor([0.9923, 0.0036, 0.0040]), new_distribution = tensor([0.9924, 0.0036, 0.0040])
2024-12-05 15:42:49,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 504: ref_distribution = tensor([0.9924, 0.0036, 0.0040]), new_distribution = tensor([0.9924, 0.0036, 0.0040])
2024-12-05 15:42:49,424 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 505: ref_distribution = tensor([0.9924, 0.0036, 0.0040]), new_distribution = tensor([0.9924, 0.0036, 0.0040])
2024-12-05 15:42:49,478 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 506: ref_distribution = tensor([0.9924, 0.0036, 0.0040]), new_distribution = tensor([0.9925, 0.0036, 0.0040])
2024-12-05 15:42:49,532 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 507: ref_distribution = tensor([0.9925, 0.0036, 0.0040]), new_distribution = tensor([0.9925, 0.0035, 0.0040])
2024-12-05 15:42:49,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 508: ref_distribution = tensor([0.9925, 0.0035, 0.0040]), new_distribution = tensor([0.9925, 0.0035, 0.0040])
2024-12-05 15:42:49,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 509: ref_distribution = tensor([0.9925, 0.0035, 0.0040]), new_distribution = tensor([0.9925, 0.0035, 0.0040])
2024-12-05 15:42:49,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 510: ref_distribution = tensor([0.9925, 0.0035, 0.0040]), new_distribution = tensor([0.9926, 0.0035, 0.0039])
2024-12-05 15:42:49,751 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 511: ref_distribution = tensor([0.9926, 0.0035, 0.0039]), new_distribution = tensor([0.9926, 0.0035, 0.0039])
2024-12-05 15:42:49,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 512: ref_distribution = tensor([0.9926, 0.0035, 0.0039]), new_distribution = tensor([0.9926, 0.0035, 0.0039])
2024-12-05 15:42:49,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 513: ref_distribution = tensor([0.9926, 0.0035, 0.0039]), new_distribution = tensor([0.9926, 0.0035, 0.0039])
2024-12-05 15:42:49,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 514: ref_distribution = tensor([0.9926, 0.0035, 0.0039]), new_distribution = tensor([0.9927, 0.0034, 0.0039])
2024-12-05 15:42:49,968 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 515: ref_distribution = tensor([0.9927, 0.0034, 0.0039]), new_distribution = tensor([0.9927, 0.0034, 0.0039])
2024-12-05 15:42:50,023 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 516: ref_distribution = tensor([0.9927, 0.0034, 0.0039]), new_distribution = tensor([0.9927, 0.0034, 0.0039])
2024-12-05 15:42:50,077 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 517: ref_distribution = tensor([0.9927, 0.0034, 0.0039]), new_distribution = tensor([0.9927, 0.0034, 0.0039])
2024-12-05 15:42:50,131 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 518: ref_distribution = tensor([0.9927, 0.0034, 0.0039]), new_distribution = tensor([0.9928, 0.0034, 0.0039])
2024-12-05 15:42:50,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 519: ref_distribution = tensor([0.9928, 0.0034, 0.0039]), new_distribution = tensor([0.9928, 0.0034, 0.0038])
2024-12-05 15:42:50,240 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 520: ref_distribution = tensor([0.9928, 0.0034, 0.0038]), new_distribution = tensor([0.9928, 0.0034, 0.0038])
2024-12-05 15:42:50,294 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 521: ref_distribution = tensor([0.9928, 0.0034, 0.0038]), new_distribution = tensor([0.9928, 0.0034, 0.0038])
2024-12-05 15:42:50,349 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 522: ref_distribution = tensor([0.9928, 0.0034, 0.0038]), new_distribution = tensor([0.9929, 0.0033, 0.0038])
2024-12-05 15:42:50,403 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 523: ref_distribution = tensor([0.9929, 0.0033, 0.0038]), new_distribution = tensor([0.9929, 0.0033, 0.0038])
2024-12-05 15:42:50,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 524: ref_distribution = tensor([0.9929, 0.0033, 0.0038]), new_distribution = tensor([0.9929, 0.0033, 0.0038])
2024-12-05 15:42:50,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 525: ref_distribution = tensor([0.9929, 0.0033, 0.0038]), new_distribution = tensor([0.9929, 0.0033, 0.0038])
2024-12-05 15:42:50,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 526: ref_distribution = tensor([0.9929, 0.0033, 0.0038]), new_distribution = tensor([0.9930, 0.0033, 0.0038])
2024-12-05 15:42:50,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 527: ref_distribution = tensor([0.9930, 0.0033, 0.0038]), new_distribution = tensor([0.9930, 0.0033, 0.0038])
2024-12-05 15:42:50,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 528: ref_distribution = tensor([0.9930, 0.0033, 0.0038]), new_distribution = tensor([0.9930, 0.0033, 0.0037])
2024-12-05 15:42:50,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 529: ref_distribution = tensor([0.9930, 0.0033, 0.0037]), new_distribution = tensor([0.9930, 0.0032, 0.0037])
2024-12-05 15:42:50,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 530: ref_distribution = tensor([0.9930, 0.0032, 0.0037]), new_distribution = tensor([0.9931, 0.0032, 0.0037])
2024-12-05 15:42:50,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 531: ref_distribution = tensor([0.9931, 0.0032, 0.0037]), new_distribution = tensor([0.9931, 0.0032, 0.0037])
2024-12-05 15:42:50,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 532: ref_distribution = tensor([0.9931, 0.0032, 0.0037]), new_distribution = tensor([0.9931, 0.0032, 0.0037])
2024-12-05 15:42:50,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 533: ref_distribution = tensor([0.9931, 0.0032, 0.0037]), new_distribution = tensor([0.9931, 0.0032, 0.0037])
2024-12-05 15:42:51,002 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 534: ref_distribution = tensor([0.9931, 0.0032, 0.0037]), new_distribution = tensor([0.9931, 0.0032, 0.0037])
2024-12-05 15:42:51,057 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 535: ref_distribution = tensor([0.9931, 0.0032, 0.0037]), new_distribution = tensor([0.9932, 0.0032, 0.0037])
2024-12-05 15:42:51,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 536: ref_distribution = tensor([0.9932, 0.0032, 0.0037]), new_distribution = tensor([0.9932, 0.0032, 0.0037])
2024-12-05 15:42:51,166 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 537: ref_distribution = tensor([0.9932, 0.0032, 0.0037]), new_distribution = tensor([0.9932, 0.0031, 0.0036])
2024-12-05 15:42:51,221 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 538: ref_distribution = tensor([0.9932, 0.0031, 0.0036]), new_distribution = tensor([0.9932, 0.0031, 0.0036])
2024-12-05 15:42:51,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 539: ref_distribution = tensor([0.9932, 0.0031, 0.0036]), new_distribution = tensor([0.9933, 0.0031, 0.0036])
2024-12-05 15:42:51,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 540: ref_distribution = tensor([0.9933, 0.0031, 0.0036]), new_distribution = tensor([0.9933, 0.0031, 0.0036])
2024-12-05 15:42:51,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 541: ref_distribution = tensor([0.9933, 0.0031, 0.0036]), new_distribution = tensor([0.9933, 0.0031, 0.0036])
2024-12-05 15:42:51,439 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 542: ref_distribution = tensor([0.9933, 0.0031, 0.0036]), new_distribution = tensor([0.9933, 0.0031, 0.0036])
2024-12-05 15:42:51,493 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 543: ref_distribution = tensor([0.9933, 0.0031, 0.0036]), new_distribution = tensor([0.9934, 0.0031, 0.0036])
2024-12-05 15:42:51,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 544: ref_distribution = tensor([0.9934, 0.0031, 0.0036]), new_distribution = tensor([0.9934, 0.0031, 0.0036])
2024-12-05 15:42:51,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 545: ref_distribution = tensor([0.9934, 0.0031, 0.0036]), new_distribution = tensor([0.9934, 0.0030, 0.0036])
2024-12-05 15:42:51,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 546: ref_distribution = tensor([0.9934, 0.0030, 0.0036]), new_distribution = tensor([0.9934, 0.0030, 0.0035])
2024-12-05 15:42:51,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 547: ref_distribution = tensor([0.9934, 0.0030, 0.0035]), new_distribution = tensor([0.9934, 0.0030, 0.0035])
2024-12-05 15:42:51,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 548: ref_distribution = tensor([0.9934, 0.0030, 0.0035]), new_distribution = tensor([0.9935, 0.0030, 0.0035])
2024-12-05 15:42:51,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 549: ref_distribution = tensor([0.9935, 0.0030, 0.0035]), new_distribution = tensor([0.9935, 0.0030, 0.0035])
2024-12-05 15:42:51,875 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 550: ref_distribution = tensor([0.9935, 0.0030, 0.0035]), new_distribution = tensor([0.9935, 0.0030, 0.0035])
2024-12-05 15:42:51,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 551: ref_distribution = tensor([0.9935, 0.0030, 0.0035]), new_distribution = tensor([0.9935, 0.0030, 0.0035])
2024-12-05 15:42:51,984 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 552: ref_distribution = tensor([0.9935, 0.0030, 0.0035]), new_distribution = tensor([0.9936, 0.0030, 0.0035])
2024-12-05 15:42:52,039 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 553: ref_distribution = tensor([0.9936, 0.0030, 0.0035]), new_distribution = tensor([0.9936, 0.0030, 0.0035])
2024-12-05 15:42:52,093 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 554: ref_distribution = tensor([0.9936, 0.0030, 0.0035]), new_distribution = tensor([0.9936, 0.0029, 0.0035])
2024-12-05 15:42:52,147 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 555: ref_distribution = tensor([0.9936, 0.0029, 0.0035]), new_distribution = tensor([0.9936, 0.0029, 0.0034])
2024-12-05 15:42:52,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 556: ref_distribution = tensor([0.9936, 0.0029, 0.0034]), new_distribution = tensor([0.9936, 0.0029, 0.0034])
2024-12-05 15:42:52,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 557: ref_distribution = tensor([0.9936, 0.0029, 0.0034]), new_distribution = tensor([0.9937, 0.0029, 0.0034])
2024-12-05 15:42:52,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 558: ref_distribution = tensor([0.9937, 0.0029, 0.0034]), new_distribution = tensor([0.9937, 0.0029, 0.0034])
2024-12-05 15:42:52,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 559: ref_distribution = tensor([0.9937, 0.0029, 0.0034]), new_distribution = tensor([0.9937, 0.0029, 0.0034])
2024-12-05 15:42:52,420 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 560: ref_distribution = tensor([0.9937, 0.0029, 0.0034]), new_distribution = tensor([0.9937, 0.0029, 0.0034])
2024-12-05 15:42:52,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 561: ref_distribution = tensor([0.9937, 0.0029, 0.0034]), new_distribution = tensor([0.9938, 0.0029, 0.0034])
2024-12-05 15:42:52,529 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 562: ref_distribution = tensor([0.9938, 0.0029, 0.0034]), new_distribution = tensor([0.9938, 0.0028, 0.0034])
2024-12-05 15:42:52,584 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 563: ref_distribution = tensor([0.9938, 0.0028, 0.0034]), new_distribution = tensor([0.9938, 0.0028, 0.0034])
2024-12-05 15:42:52,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 564: ref_distribution = tensor([0.9938, 0.0028, 0.0034]), new_distribution = tensor([0.9938, 0.0028, 0.0034])
2024-12-05 15:42:52,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 565: ref_distribution = tensor([0.9938, 0.0028, 0.0034]), new_distribution = tensor([0.9938, 0.0028, 0.0033])
2024-12-05 15:42:52,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 566: ref_distribution = tensor([0.9938, 0.0028, 0.0033]), new_distribution = tensor([0.9939, 0.0028, 0.0033])
2024-12-05 15:42:52,802 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 567: ref_distribution = tensor([0.9939, 0.0028, 0.0033]), new_distribution = tensor([0.9939, 0.0028, 0.0033])
2024-12-05 15:42:52,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 568: ref_distribution = tensor([0.9939, 0.0028, 0.0033]), new_distribution = tensor([0.9939, 0.0028, 0.0033])
2024-12-05 15:42:52,910 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 569: ref_distribution = tensor([0.9939, 0.0028, 0.0033]), new_distribution = tensor([0.9939, 0.0028, 0.0033])
2024-12-05 15:42:52,965 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 570: ref_distribution = tensor([0.9939, 0.0028, 0.0033]), new_distribution = tensor([0.9939, 0.0028, 0.0033])
2024-12-05 15:42:53,019 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 571: ref_distribution = tensor([0.9939, 0.0028, 0.0033]), new_distribution = tensor([0.9940, 0.0027, 0.0033])
2024-12-05 15:42:53,074 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 572: ref_distribution = tensor([0.9940, 0.0027, 0.0033]), new_distribution = tensor([0.9940, 0.0027, 0.0033])
2024-12-05 15:42:53,128 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 573: ref_distribution = tensor([0.9940, 0.0027, 0.0033]), new_distribution = tensor([0.9940, 0.0027, 0.0033])
2024-12-05 15:42:53,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 574: ref_distribution = tensor([0.9940, 0.0027, 0.0033]), new_distribution = tensor([0.9940, 0.0027, 0.0033])
2024-12-05 15:42:53,237 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 575: ref_distribution = tensor([0.9940, 0.0027, 0.0033]), new_distribution = tensor([0.9940, 0.0027, 0.0032])
2024-12-05 15:42:53,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 576: ref_distribution = tensor([0.9940, 0.0027, 0.0032]), new_distribution = tensor([0.9941, 0.0027, 0.0032])
2024-12-05 15:42:53,346 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 577: ref_distribution = tensor([0.9941, 0.0027, 0.0032]), new_distribution = tensor([0.9941, 0.0027, 0.0032])
2024-12-05 15:42:53,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 578: ref_distribution = tensor([0.9941, 0.0027, 0.0032]), new_distribution = tensor([0.9941, 0.0027, 0.0032])
2024-12-05 15:42:53,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 579: ref_distribution = tensor([0.9941, 0.0027, 0.0032]), new_distribution = tensor([0.9941, 0.0027, 0.0032])
2024-12-05 15:42:53,509 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 580: ref_distribution = tensor([0.9941, 0.0027, 0.0032]), new_distribution = tensor([0.9941, 0.0027, 0.0032])
2024-12-05 15:42:53,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 581: ref_distribution = tensor([0.9941, 0.0027, 0.0032]), new_distribution = tensor([0.9942, 0.0026, 0.0032])
2024-12-05 15:42:53,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 582: ref_distribution = tensor([0.9942, 0.0026, 0.0032]), new_distribution = tensor([0.9942, 0.0026, 0.0032])
2024-12-05 15:42:53,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 583: ref_distribution = tensor([0.9942, 0.0026, 0.0032]), new_distribution = tensor([0.9942, 0.0026, 0.0032])
2024-12-05 15:42:53,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 584: ref_distribution = tensor([0.9942, 0.0026, 0.0032]), new_distribution = tensor([0.9942, 0.0026, 0.0032])
2024-12-05 15:42:53,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 585: ref_distribution = tensor([0.9942, 0.0026, 0.0032]), new_distribution = tensor([0.9942, 0.0026, 0.0032])
2024-12-05 15:42:53,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 586: ref_distribution = tensor([0.9942, 0.0026, 0.0032]), new_distribution = tensor([0.9943, 0.0026, 0.0031])
2024-12-05 15:42:53,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 587: ref_distribution = tensor([0.9943, 0.0026, 0.0031]), new_distribution = tensor([0.9943, 0.0026, 0.0031])
2024-12-05 15:42:53,945 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 588: ref_distribution = tensor([0.9943, 0.0026, 0.0031]), new_distribution = tensor([0.9943, 0.0026, 0.0031])
2024-12-05 15:42:54,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 589: ref_distribution = tensor([0.9943, 0.0026, 0.0031]), new_distribution = tensor([0.9943, 0.0026, 0.0031])
2024-12-05 15:42:54,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 590: ref_distribution = tensor([0.9943, 0.0026, 0.0031]), new_distribution = tensor([0.9943, 0.0025, 0.0031])
2024-12-05 15:42:54,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 591: ref_distribution = tensor([0.9943, 0.0025, 0.0031]), new_distribution = tensor([0.9944, 0.0025, 0.0031])
2024-12-05 15:42:54,324 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 592: ref_distribution = tensor([0.9944, 0.0025, 0.0031]), new_distribution = tensor([0.9944, 0.0025, 0.0031])
2024-12-05 15:42:54,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 593: ref_distribution = tensor([0.9944, 0.0025, 0.0031]), new_distribution = tensor([0.9944, 0.0025, 0.0031])
2024-12-05 15:42:54,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 594: ref_distribution = tensor([0.9944, 0.0025, 0.0031]), new_distribution = tensor([0.9944, 0.0025, 0.0031])
2024-12-05 15:42:54,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 595: ref_distribution = tensor([0.9944, 0.0025, 0.0031]), new_distribution = tensor([0.9944, 0.0025, 0.0031])
2024-12-05 15:42:54,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 596: ref_distribution = tensor([0.9944, 0.0025, 0.0031]), new_distribution = tensor([0.9945, 0.0025, 0.0031])
2024-12-05 15:42:54,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 597: ref_distribution = tensor([0.9945, 0.0025, 0.0031]), new_distribution = tensor([0.9945, 0.0025, 0.0030])
2024-12-05 15:42:54,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 598: ref_distribution = tensor([0.9945, 0.0025, 0.0030]), new_distribution = tensor([0.9945, 0.0025, 0.0030])
2024-12-05 15:42:55,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 599: ref_distribution = tensor([0.9945, 0.0025, 0.0030]), new_distribution = tensor([0.9945, 0.0025, 0.0030])
2024-12-05 15:42:55,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 600: ref_distribution = tensor([0.9945, 0.0025, 0.0030]), new_distribution = tensor([0.9945, 0.0024, 0.0030])
2024-12-05 15:42:55,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 601: ref_distribution = tensor([0.9945, 0.0024, 0.0030]), new_distribution = tensor([0.9946, 0.0024, 0.0030])
2024-12-05 15:42:55,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 602: ref_distribution = tensor([0.9946, 0.0024, 0.0030]), new_distribution = tensor([0.9946, 0.0024, 0.0030])
2024-12-05 15:42:55,488 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 603: ref_distribution = tensor([0.9946, 0.0024, 0.0030]), new_distribution = tensor([0.9946, 0.0024, 0.0030])
2024-12-05 15:42:55,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 604: ref_distribution = tensor([0.9946, 0.0024, 0.0030]), new_distribution = tensor([0.9946, 0.0024, 0.0030])
2024-12-05 15:42:55,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 605: ref_distribution = tensor([0.9946, 0.0024, 0.0030]), new_distribution = tensor([0.9946, 0.0024, 0.0030])
2024-12-05 15:42:55,788 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 606: ref_distribution = tensor([0.9946, 0.0024, 0.0030]), new_distribution = tensor([0.9946, 0.0024, 0.0030])
2024-12-05 15:42:55,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 607: ref_distribution = tensor([0.9946, 0.0024, 0.0030]), new_distribution = tensor([0.9947, 0.0024, 0.0030])
2024-12-05 15:42:55,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 608: ref_distribution = tensor([0.9947, 0.0024, 0.0030]), new_distribution = tensor([0.9947, 0.0024, 0.0029])
2024-12-05 15:42:56,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 609: ref_distribution = tensor([0.9947, 0.0024, 0.0029]), new_distribution = tensor([0.9947, 0.0024, 0.0029])
2024-12-05 15:42:56,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 610: ref_distribution = tensor([0.9947, 0.0024, 0.0029]), new_distribution = tensor([0.9947, 0.0024, 0.0029])
2024-12-05 15:42:56,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 611: ref_distribution = tensor([0.9947, 0.0024, 0.0029]), new_distribution = tensor([0.9947, 0.0023, 0.0029])
2024-12-05 15:42:56,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 612: ref_distribution = tensor([0.9947, 0.0023, 0.0029]), new_distribution = tensor([0.9948, 0.0023, 0.0029])
2024-12-05 15:42:56,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 613: ref_distribution = tensor([0.9948, 0.0023, 0.0029]), new_distribution = tensor([0.9948, 0.0023, 0.0029])
2024-12-05 15:42:56,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 614: ref_distribution = tensor([0.9948, 0.0023, 0.0029]), new_distribution = tensor([0.9948, 0.0023, 0.0029])
2024-12-05 15:42:56,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 615: ref_distribution = tensor([0.9948, 0.0023, 0.0029]), new_distribution = tensor([0.9948, 0.0023, 0.0029])
2024-12-05 15:42:56,508 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 616: ref_distribution = tensor([0.9948, 0.0023, 0.0029]), new_distribution = tensor([0.9948, 0.0023, 0.0029])
2024-12-05 15:42:56,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 617: ref_distribution = tensor([0.9948, 0.0023, 0.0029]), new_distribution = tensor([0.9948, 0.0023, 0.0029])
2024-12-05 15:42:56,617 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 618: ref_distribution = tensor([0.9948, 0.0023, 0.0029]), new_distribution = tensor([0.9949, 0.0023, 0.0029])
2024-12-05 15:42:56,671 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 619: ref_distribution = tensor([0.9949, 0.0023, 0.0029]), new_distribution = tensor([0.9949, 0.0023, 0.0028])
2024-12-05 15:42:56,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 620: ref_distribution = tensor([0.9949, 0.0023, 0.0028]), new_distribution = tensor([0.9949, 0.0023, 0.0028])
2024-12-05 15:42:56,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 621: ref_distribution = tensor([0.9949, 0.0023, 0.0028]), new_distribution = tensor([0.9949, 0.0023, 0.0028])
2024-12-05 15:42:56,835 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 622: ref_distribution = tensor([0.9949, 0.0023, 0.0028]), new_distribution = tensor([0.9949, 0.0022, 0.0028])
2024-12-05 15:42:56,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 623: ref_distribution = tensor([0.9949, 0.0022, 0.0028]), new_distribution = tensor([0.9950, 0.0022, 0.0028])
2024-12-05 15:42:56,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 624: ref_distribution = tensor([0.9950, 0.0022, 0.0028]), new_distribution = tensor([0.9950, 0.0022, 0.0028])
2024-12-05 15:42:56,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 625: ref_distribution = tensor([0.9950, 0.0022, 0.0028]), new_distribution = tensor([0.9950, 0.0022, 0.0028])
2024-12-05 15:42:57,053 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 626: ref_distribution = tensor([0.9950, 0.0022, 0.0028]), new_distribution = tensor([0.9950, 0.0022, 0.0028])
2024-12-05 15:42:57,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 627: ref_distribution = tensor([0.9950, 0.0022, 0.0028]), new_distribution = tensor([0.9950, 0.0022, 0.0028])
2024-12-05 15:42:57,166 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 628: ref_distribution = tensor([0.9950, 0.0022, 0.0028]), new_distribution = tensor([0.9950, 0.0022, 0.0028])
2024-12-05 15:42:57,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 629: ref_distribution = tensor([0.9950, 0.0022, 0.0028]), new_distribution = tensor([0.9951, 0.0022, 0.0028])
2024-12-05 15:42:57,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 630: ref_distribution = tensor([0.9951, 0.0022, 0.0028]), new_distribution = tensor([0.9951, 0.0022, 0.0028])
2024-12-05 15:42:57,329 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 631: ref_distribution = tensor([0.9951, 0.0022, 0.0028]), new_distribution = tensor([0.9951, 0.0022, 0.0027])
2024-12-05 15:42:57,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 632: ref_distribution = tensor([0.9951, 0.0022, 0.0027]), new_distribution = tensor([0.9951, 0.0022, 0.0027])
2024-12-05 15:42:57,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 633: ref_distribution = tensor([0.9951, 0.0022, 0.0027]), new_distribution = tensor([0.9951, 0.0021, 0.0027])
2024-12-05 15:42:57,492 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 634: ref_distribution = tensor([0.9951, 0.0021, 0.0027]), new_distribution = tensor([0.9951, 0.0021, 0.0027])
2024-12-05 15:42:57,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 635: ref_distribution = tensor([0.9951, 0.0021, 0.0027]), new_distribution = tensor([0.9952, 0.0021, 0.0027])
2024-12-05 15:42:57,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 636: ref_distribution = tensor([0.9952, 0.0021, 0.0027]), new_distribution = tensor([0.9952, 0.0021, 0.0027])
2024-12-05 15:42:57,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 637: ref_distribution = tensor([0.9952, 0.0021, 0.0027]), new_distribution = tensor([0.9952, 0.0021, 0.0027])
2024-12-05 15:42:57,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 638: ref_distribution = tensor([0.9952, 0.0021, 0.0027]), new_distribution = tensor([0.9952, 0.0021, 0.0027])
2024-12-05 15:42:57,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 639: ref_distribution = tensor([0.9952, 0.0021, 0.0027]), new_distribution = tensor([0.9952, 0.0021, 0.0027])
2024-12-05 15:42:57,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 640: ref_distribution = tensor([0.9952, 0.0021, 0.0027]), new_distribution = tensor([0.9952, 0.0021, 0.0027])
2024-12-05 15:42:57,873 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 641: ref_distribution = tensor([0.9952, 0.0021, 0.0027]), new_distribution = tensor([0.9953, 0.0021, 0.0027])
2024-12-05 15:42:57,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 642: ref_distribution = tensor([0.9953, 0.0021, 0.0027]), new_distribution = tensor([0.9953, 0.0021, 0.0027])
2024-12-05 15:42:57,981 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 643: ref_distribution = tensor([0.9953, 0.0021, 0.0027]), new_distribution = tensor([0.9953, 0.0021, 0.0027])
2024-12-05 15:42:58,035 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 644: ref_distribution = tensor([0.9953, 0.0021, 0.0027]), new_distribution = tensor([0.9953, 0.0021, 0.0026])
2024-12-05 15:42:58,090 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 645: ref_distribution = tensor([0.9953, 0.0021, 0.0026]), new_distribution = tensor([0.9953, 0.0020, 0.0026])
2024-12-05 15:42:58,144 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 646: ref_distribution = tensor([0.9953, 0.0020, 0.0026]), new_distribution = tensor([0.9953, 0.0020, 0.0026])
2024-12-05 15:42:58,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 647: ref_distribution = tensor([0.9953, 0.0020, 0.0026]), new_distribution = tensor([0.9953, 0.0020, 0.0026])
2024-12-05 15:42:58,252 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 648: ref_distribution = tensor([0.9953, 0.0020, 0.0026]), new_distribution = tensor([0.9954, 0.0020, 0.0026])
2024-12-05 15:42:58,306 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 649: ref_distribution = tensor([0.9954, 0.0020, 0.0026]), new_distribution = tensor([0.9954, 0.0020, 0.0026])
2024-12-05 15:42:58,360 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 650: ref_distribution = tensor([0.9954, 0.0020, 0.0026]), new_distribution = tensor([0.9954, 0.0020, 0.0026])
2024-12-05 15:42:58,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 651: ref_distribution = tensor([0.9954, 0.0020, 0.0026]), new_distribution = tensor([0.9954, 0.0020, 0.0026])
2024-12-05 15:42:58,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 652: ref_distribution = tensor([0.9954, 0.0020, 0.0026]), new_distribution = tensor([0.9954, 0.0020, 0.0026])
2024-12-05 15:42:58,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 653: ref_distribution = tensor([0.9954, 0.0020, 0.0026]), new_distribution = tensor([0.9954, 0.0020, 0.0026])
2024-12-05 15:42:58,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 654: ref_distribution = tensor([0.9954, 0.0020, 0.0026]), new_distribution = tensor([0.9955, 0.0020, 0.0026])
2024-12-05 15:42:58,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 655: ref_distribution = tensor([0.9955, 0.0020, 0.0026]), new_distribution = tensor([0.9955, 0.0020, 0.0026])
2024-12-05 15:42:58,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 656: ref_distribution = tensor([0.9955, 0.0020, 0.0026]), new_distribution = tensor([0.9955, 0.0020, 0.0025])
2024-12-05 15:42:58,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 657: ref_distribution = tensor([0.9955, 0.0020, 0.0025]), new_distribution = tensor([0.9955, 0.0020, 0.0025])
2024-12-05 15:42:58,794 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 658: ref_distribution = tensor([0.9955, 0.0020, 0.0025]), new_distribution = tensor([0.9955, 0.0019, 0.0025])
2024-12-05 15:42:58,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 659: ref_distribution = tensor([0.9955, 0.0019, 0.0025]), new_distribution = tensor([0.9955, 0.0019, 0.0025])
2024-12-05 15:42:58,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 660: ref_distribution = tensor([0.9955, 0.0019, 0.0025]), new_distribution = tensor([0.9956, 0.0019, 0.0025])
2024-12-05 15:42:58,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 661: ref_distribution = tensor([0.9956, 0.0019, 0.0025]), new_distribution = tensor([0.9956, 0.0019, 0.0025])
2024-12-05 15:42:59,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 662: ref_distribution = tensor([0.9956, 0.0019, 0.0025]), new_distribution = tensor([0.9956, 0.0019, 0.0025])
2024-12-05 15:42:59,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 663: ref_distribution = tensor([0.9956, 0.0019, 0.0025]), new_distribution = tensor([0.9956, 0.0019, 0.0025])
2024-12-05 15:42:59,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 664: ref_distribution = tensor([0.9956, 0.0019, 0.0025]), new_distribution = tensor([0.9956, 0.0019, 0.0025])
2024-12-05 15:42:59,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 665: ref_distribution = tensor([0.9956, 0.0019, 0.0025]), new_distribution = tensor([0.9956, 0.0019, 0.0025])
2024-12-05 15:42:59,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 666: ref_distribution = tensor([0.9956, 0.0019, 0.0025]), new_distribution = tensor([0.9956, 0.0019, 0.0025])
2024-12-05 15:42:59,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 667: ref_distribution = tensor([0.9956, 0.0019, 0.0025]), new_distribution = tensor([0.9957, 0.0019, 0.0025])
2024-12-05 15:42:59,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 668: ref_distribution = tensor([0.9957, 0.0019, 0.0025]), new_distribution = tensor([0.9957, 0.0019, 0.0025])
2024-12-05 15:42:59,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 669: ref_distribution = tensor([0.9957, 0.0019, 0.0025]), new_distribution = tensor([0.9957, 0.0019, 0.0025])
2024-12-05 15:42:59,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 670: ref_distribution = tensor([0.9957, 0.0019, 0.0025]), new_distribution = tensor([0.9957, 0.0019, 0.0024])
2024-12-05 15:42:59,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 671: ref_distribution = tensor([0.9957, 0.0019, 0.0024]), new_distribution = tensor([0.9957, 0.0018, 0.0024])
2024-12-05 15:42:59,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 672: ref_distribution = tensor([0.9957, 0.0018, 0.0024]), new_distribution = tensor([0.9957, 0.0018, 0.0024])
2024-12-05 15:42:59,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 673: ref_distribution = tensor([0.9957, 0.0018, 0.0024]), new_distribution = tensor([0.9957, 0.0018, 0.0024])
2024-12-05 15:42:59,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 674: ref_distribution = tensor([0.9957, 0.0018, 0.0024]), new_distribution = tensor([0.9958, 0.0018, 0.0024])
2024-12-05 15:42:59,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 675: ref_distribution = tensor([0.9958, 0.0018, 0.0024]), new_distribution = tensor([0.9958, 0.0018, 0.0024])
2024-12-05 15:42:59,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 676: ref_distribution = tensor([0.9958, 0.0018, 0.0024]), new_distribution = tensor([0.9958, 0.0018, 0.0024])
2024-12-05 15:42:59,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 677: ref_distribution = tensor([0.9958, 0.0018, 0.0024]), new_distribution = tensor([0.9958, 0.0018, 0.0024])
2024-12-05 15:42:59,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 678: ref_distribution = tensor([0.9958, 0.0018, 0.0024]), new_distribution = tensor([0.9958, 0.0018, 0.0024])
2024-12-05 15:42:59,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 679: ref_distribution = tensor([0.9958, 0.0018, 0.0024]), new_distribution = tensor([0.9958, 0.0018, 0.0024])
2024-12-05 15:42:59,988 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 680: ref_distribution = tensor([0.9958, 0.0018, 0.0024]), new_distribution = tensor([0.9958, 0.0018, 0.0024])
2024-12-05 15:43:00,043 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 681: ref_distribution = tensor([0.9958, 0.0018, 0.0024]), new_distribution = tensor([0.9959, 0.0018, 0.0024])
2024-12-05 15:43:00,097 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 682: ref_distribution = tensor([0.9959, 0.0018, 0.0024]), new_distribution = tensor([0.9959, 0.0018, 0.0024])
2024-12-05 15:43:00,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 683: ref_distribution = tensor([0.9959, 0.0018, 0.0024]), new_distribution = tensor([0.9959, 0.0018, 0.0024])
2024-12-05 15:43:00,205 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 684: ref_distribution = tensor([0.9959, 0.0018, 0.0024]), new_distribution = tensor([0.9959, 0.0018, 0.0023])
2024-12-05 15:43:00,259 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 685: ref_distribution = tensor([0.9959, 0.0018, 0.0023]), new_distribution = tensor([0.9959, 0.0017, 0.0023])
2024-12-05 15:43:00,313 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 686: ref_distribution = tensor([0.9959, 0.0017, 0.0023]), new_distribution = tensor([0.9959, 0.0017, 0.0023])
2024-12-05 15:43:00,368 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 687: ref_distribution = tensor([0.9959, 0.0017, 0.0023]), new_distribution = tensor([0.9959, 0.0017, 0.0023])
2024-12-05 15:43:00,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 688: ref_distribution = tensor([0.9959, 0.0017, 0.0023]), new_distribution = tensor([0.9960, 0.0017, 0.0023])
2024-12-05 15:43:00,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 689: ref_distribution = tensor([0.9960, 0.0017, 0.0023]), new_distribution = tensor([0.9960, 0.0017, 0.0023])
2024-12-05 15:43:00,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 690: ref_distribution = tensor([0.9960, 0.0017, 0.0023]), new_distribution = tensor([0.9960, 0.0017, 0.0023])
2024-12-05 15:43:00,585 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 691: ref_distribution = tensor([0.9960, 0.0017, 0.0023]), new_distribution = tensor([0.9960, 0.0017, 0.0023])
2024-12-05 15:43:00,639 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 692: ref_distribution = tensor([0.9960, 0.0017, 0.0023]), new_distribution = tensor([0.9960, 0.0017, 0.0023])
2024-12-05 15:43:00,694 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 693: ref_distribution = tensor([0.9960, 0.0017, 0.0023]), new_distribution = tensor([0.9960, 0.0017, 0.0023])
2024-12-05 15:43:00,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 694: ref_distribution = tensor([0.9960, 0.0017, 0.0023]), new_distribution = tensor([0.9960, 0.0017, 0.0023])
2024-12-05 15:43:00,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 695: ref_distribution = tensor([0.9960, 0.0017, 0.0023]), new_distribution = tensor([0.9961, 0.0017, 0.0023])
2024-12-05 15:43:00,857 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 696: ref_distribution = tensor([0.9961, 0.0017, 0.0023]), new_distribution = tensor([0.9961, 0.0017, 0.0023])
2024-12-05 15:43:00,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 697: ref_distribution = tensor([0.9961, 0.0017, 0.0023]), new_distribution = tensor([0.9961, 0.0017, 0.0023])
2024-12-05 15:43:00,965 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 698: ref_distribution = tensor([0.9961, 0.0017, 0.0023]), new_distribution = tensor([0.9961, 0.0017, 0.0022])
2024-12-05 15:43:01,019 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 699: ref_distribution = tensor([0.9961, 0.0017, 0.0022]), new_distribution = tensor([0.9961, 0.0017, 0.0022])
2024-12-05 15:43:01,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.7000, 0.2000, 0.1000]), new_distribution = tensor([0.7008, 0.1995, 0.0997])
2024-12-05 15:43:01,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.7008, 0.1995, 0.0997]), new_distribution = tensor([0.7016, 0.1990, 0.0994])
2024-12-05 15:43:01,420 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.7016, 0.1990, 0.0994]), new_distribution = tensor([0.7023, 0.1985, 0.0991])
2024-12-05 15:43:01,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.7023, 0.1985, 0.0991]), new_distribution = tensor([0.7031, 0.1980, 0.0989])
2024-12-05 15:43:01,529 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.7031, 0.1980, 0.0989]), new_distribution = tensor([0.7039, 0.1975, 0.0986])
2024-12-05 15:43:01,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.7039, 0.1975, 0.0986]), new_distribution = tensor([0.7047, 0.1970, 0.0983])
2024-12-05 15:43:01,637 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.7047, 0.1970, 0.0983]), new_distribution = tensor([0.7055, 0.1965, 0.0980])
2024-12-05 15:43:01,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.7055, 0.1965, 0.0980]), new_distribution = tensor([0.7062, 0.1960, 0.0977])
2024-12-05 15:43:01,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.7062, 0.1960, 0.0977]), new_distribution = tensor([0.7070, 0.1956, 0.0974])
2024-12-05 15:43:01,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.7070, 0.1956, 0.0974]), new_distribution = tensor([0.7078, 0.1951, 0.0972])
2024-12-05 15:43:01,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.7078, 0.1951, 0.0972]), new_distribution = tensor([0.7086, 0.1946, 0.0969])
2024-12-05 15:43:01,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.7086, 0.1946, 0.0969]), new_distribution = tensor([0.7093, 0.1941, 0.0966])
2024-12-05 15:43:01,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.7093, 0.1941, 0.0966]), new_distribution = tensor([0.7101, 0.1936, 0.0963])
2024-12-05 15:43:02,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.7101, 0.1936, 0.0963]), new_distribution = tensor([0.7109, 0.1931, 0.0960])
2024-12-05 15:43:02,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.7109, 0.1931, 0.0960]), new_distribution = tensor([0.7116, 0.1926, 0.0958])
2024-12-05 15:43:02,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.7116, 0.1926, 0.0958]), new_distribution = tensor([0.7124, 0.1921, 0.0955])
2024-12-05 15:43:02,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.7124, 0.1921, 0.0955]), new_distribution = tensor([0.7132, 0.1916, 0.0952])
2024-12-05 15:43:02,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.7132, 0.1916, 0.0952]), new_distribution = tensor([0.7139, 0.1911, 0.0949])
2024-12-05 15:43:02,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.7139, 0.1911, 0.0949]), new_distribution = tensor([0.7147, 0.1907, 0.0947])
2024-12-05 15:43:02,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.7147, 0.1907, 0.0947]), new_distribution = tensor([0.7154, 0.1902, 0.0944])
2024-12-05 15:43:02,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.7154, 0.1902, 0.0944]), new_distribution = tensor([0.7162, 0.1897, 0.0941])
2024-12-05 15:43:02,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.7162, 0.1897, 0.0941]), new_distribution = tensor([0.7170, 0.1892, 0.0938])
2024-12-05 15:43:02,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.7170, 0.1892, 0.0938]), new_distribution = tensor([0.7177, 0.1887, 0.0936])
2024-12-05 15:43:02,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.7177, 0.1887, 0.0936]), new_distribution = tensor([0.7185, 0.1882, 0.0933])
2024-12-05 15:43:02,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.7185, 0.1882, 0.0933]), new_distribution = tensor([0.7192, 0.1877, 0.0930])
2024-12-05 15:43:02,666 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.7192, 0.1877, 0.0930]), new_distribution = tensor([0.7200, 0.1873, 0.0928])
2024-12-05 15:43:02,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.7200, 0.1873, 0.0928]), new_distribution = tensor([0.7207, 0.1868, 0.0925])
2024-12-05 15:43:02,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.7207, 0.1868, 0.0925]), new_distribution = tensor([0.7215, 0.1863, 0.0922])
2024-12-05 15:43:02,828 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.7215, 0.1863, 0.0922]), new_distribution = tensor([0.7222, 0.1858, 0.0920])
2024-12-05 15:43:02,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.7222, 0.1858, 0.0920]), new_distribution = tensor([0.7230, 0.1853, 0.0917])
2024-12-05 15:43:02,936 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.7230, 0.1853, 0.0917]), new_distribution = tensor([0.7237, 0.1848, 0.0914])
2024-12-05 15:43:02,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.7237, 0.1848, 0.0914]), new_distribution = tensor([0.7245, 0.1844, 0.0912])
2024-12-05 15:43:03,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.7245, 0.1844, 0.0912]), new_distribution = tensor([0.7252, 0.1839, 0.0909])
2024-12-05 15:43:03,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.7252, 0.1839, 0.0909]), new_distribution = tensor([0.7260, 0.1834, 0.0906])
2024-12-05 15:43:03,152 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.7260, 0.1834, 0.0906]), new_distribution = tensor([0.7267, 0.1829, 0.0904])
2024-12-05 15:43:03,206 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.7267, 0.1829, 0.0904]), new_distribution = tensor([0.7274, 0.1824, 0.0901])
2024-12-05 15:43:03,260 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.7274, 0.1824, 0.0901]), new_distribution = tensor([0.7282, 0.1820, 0.0899])
2024-12-05 15:43:03,314 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.7282, 0.1820, 0.0899]), new_distribution = tensor([0.7289, 0.1815, 0.0896])
2024-12-05 15:43:03,368 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.7289, 0.1815, 0.0896]), new_distribution = tensor([0.7296, 0.1810, 0.0893])
2024-12-05 15:43:03,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.7296, 0.1810, 0.0893]), new_distribution = tensor([0.7304, 0.1805, 0.0891])
2024-12-05 15:43:03,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.7304, 0.1805, 0.0891]), new_distribution = tensor([0.7311, 0.1801, 0.0888])
2024-12-05 15:43:03,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.7311, 0.1801, 0.0888]), new_distribution = tensor([0.7318, 0.1796, 0.0886])
2024-12-05 15:43:03,584 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.7318, 0.1796, 0.0886]), new_distribution = tensor([0.7326, 0.1791, 0.0883])
2024-12-05 15:43:03,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.7326, 0.1791, 0.0883]), new_distribution = tensor([0.7333, 0.1786, 0.0881])
2024-12-05 15:43:03,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.7333, 0.1786, 0.0881]), new_distribution = tensor([0.7340, 0.1782, 0.0878])
2024-12-05 15:43:03,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.7340, 0.1782, 0.0878]), new_distribution = tensor([0.7348, 0.1777, 0.0875])
2024-12-05 15:43:03,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.7348, 0.1777, 0.0875]), new_distribution = tensor([0.7355, 0.1772, 0.0873])
2024-12-05 15:43:03,855 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.7355, 0.1772, 0.0873]), new_distribution = tensor([0.7362, 0.1767, 0.0870])
2024-12-05 15:43:03,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.7362, 0.1767, 0.0870]), new_distribution = tensor([0.7369, 0.1763, 0.0868])
2024-12-05 15:43:03,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.7369, 0.1763, 0.0868]), new_distribution = tensor([0.7377, 0.1758, 0.0865])
2024-12-05 15:43:04,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.7377, 0.1758, 0.0865]), new_distribution = tensor([0.7384, 0.1753, 0.0863])
2024-12-05 15:43:04,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.7384, 0.1753, 0.0863]), new_distribution = tensor([0.7391, 0.1749, 0.0860])
2024-12-05 15:43:04,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.7391, 0.1749, 0.0860]), new_distribution = tensor([0.7398, 0.1744, 0.0858])
2024-12-05 15:43:04,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.7398, 0.1744, 0.0858]), new_distribution = tensor([0.7405, 0.1739, 0.0855])
2024-12-05 15:43:04,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.7405, 0.1739, 0.0855]), new_distribution = tensor([0.7413, 0.1735, 0.0853])
2024-12-05 15:43:04,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.7413, 0.1735, 0.0853]), new_distribution = tensor([0.7420, 0.1730, 0.0850])
2024-12-05 15:43:04,342 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.7420, 0.1730, 0.0850]), new_distribution = tensor([0.7427, 0.1725, 0.0848])
2024-12-05 15:43:04,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.7427, 0.1725, 0.0848]), new_distribution = tensor([0.7434, 0.1721, 0.0845])
2024-12-05 15:43:04,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.7434, 0.1721, 0.0845]), new_distribution = tensor([0.7441, 0.1716, 0.0843])
2024-12-05 15:43:04,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.7441, 0.1716, 0.0843]), new_distribution = tensor([0.7448, 0.1711, 0.0841])
2024-12-05 15:43:04,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.7448, 0.1711, 0.0841]), new_distribution = tensor([0.7455, 0.1707, 0.0838])
2024-12-05 15:43:04,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.7455, 0.1707, 0.0838]), new_distribution = tensor([0.7462, 0.1702, 0.0836])
2024-12-05 15:43:04,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.7462, 0.1702, 0.0836]), new_distribution = tensor([0.7469, 0.1697, 0.0833])
2024-12-05 15:43:04,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.7469, 0.1697, 0.0833]), new_distribution = tensor([0.7476, 0.1693, 0.0831])
2024-12-05 15:43:04,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.7476, 0.1693, 0.0831]), new_distribution = tensor([0.7483, 0.1688, 0.0828])
2024-12-05 15:43:04,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.7483, 0.1688, 0.0828]), new_distribution = tensor([0.7490, 0.1684, 0.0826])
2024-12-05 15:43:04,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.7490, 0.1684, 0.0826]), new_distribution = tensor([0.7497, 0.1679, 0.0824])
2024-12-05 15:43:04,939 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.7497, 0.1679, 0.0824]), new_distribution = tensor([0.7504, 0.1674, 0.0821])
2024-12-05 15:43:04,993 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.7504, 0.1674, 0.0821]), new_distribution = tensor([0.7511, 0.1670, 0.0819])
2024-12-05 15:43:05,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.7511, 0.1670, 0.0819]), new_distribution = tensor([0.7518, 0.1665, 0.0817])
2024-12-05 15:43:05,101 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.7518, 0.1665, 0.0817]), new_distribution = tensor([0.7525, 0.1661, 0.0814])
2024-12-05 15:43:05,155 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.7525, 0.1661, 0.0814]), new_distribution = tensor([0.7532, 0.1656, 0.0812])
2024-12-05 15:43:05,210 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.7532, 0.1656, 0.0812]), new_distribution = tensor([0.7539, 0.1652, 0.0809])
2024-12-05 15:43:05,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.7539, 0.1652, 0.0809]), new_distribution = tensor([0.7546, 0.1647, 0.0807])
2024-12-05 15:43:05,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.7546, 0.1647, 0.0807]), new_distribution = tensor([0.7553, 0.1642, 0.0805])
2024-12-05 15:43:05,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.7553, 0.1642, 0.0805]), new_distribution = tensor([0.7560, 0.1638, 0.0802])
2024-12-05 15:43:05,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.7560, 0.1638, 0.0802]), new_distribution = tensor([0.7567, 0.1633, 0.0800])
2024-12-05 15:43:05,480 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.7567, 0.1633, 0.0800]), new_distribution = tensor([0.7573, 0.1629, 0.0798])
2024-12-05 15:43:05,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.7573, 0.1629, 0.0798]), new_distribution = tensor([0.7580, 0.1624, 0.0795])
2024-12-05 15:43:05,589 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.7580, 0.1624, 0.0795]), new_distribution = tensor([0.7587, 0.1620, 0.0793])
2024-12-05 15:43:05,643 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.7587, 0.1620, 0.0793]), new_distribution = tensor([0.7594, 0.1615, 0.0791])
2024-12-05 15:43:05,698 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.7594, 0.1615, 0.0791]), new_distribution = tensor([0.7601, 0.1611, 0.0788])
2024-12-05 15:43:05,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.7601, 0.1611, 0.0788]), new_distribution = tensor([0.7608, 0.1606, 0.0786])
2024-12-05 15:43:05,806 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.7608, 0.1606, 0.0786]), new_distribution = tensor([0.7614, 0.1602, 0.0784])
2024-12-05 15:43:05,860 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.7614, 0.1602, 0.0784]), new_distribution = tensor([0.7621, 0.1597, 0.0782])
2024-12-05 15:43:05,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.7621, 0.1597, 0.0782]), new_distribution = tensor([0.7628, 0.1593, 0.0779])
2024-12-05 15:43:05,969 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.7628, 0.1593, 0.0779]), new_distribution = tensor([0.7635, 0.1588, 0.0777])
2024-12-05 15:43:06,023 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.7635, 0.1588, 0.0777]), new_distribution = tensor([0.7641, 0.1584, 0.0775])
2024-12-05 15:43:06,077 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.7641, 0.1584, 0.0775]), new_distribution = tensor([0.7648, 0.1579, 0.0773])
2024-12-05 15:43:06,131 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.7648, 0.1579, 0.0773]), new_distribution = tensor([0.7655, 0.1575, 0.0770])
2024-12-05 15:43:06,185 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.7655, 0.1575, 0.0770]), new_distribution = tensor([0.7661, 0.1571, 0.0768])
2024-12-05 15:43:06,239 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.7661, 0.1571, 0.0768]), new_distribution = tensor([0.7668, 0.1566, 0.0766])
2024-12-05 15:43:06,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.7668, 0.1566, 0.0766]), new_distribution = tensor([0.7675, 0.1562, 0.0764])
2024-12-05 15:43:06,348 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.7675, 0.1562, 0.0764]), new_distribution = tensor([0.7681, 0.1557, 0.0761])
2024-12-05 15:43:06,402 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.7681, 0.1557, 0.0761]), new_distribution = tensor([0.7688, 0.1553, 0.0759])
2024-12-05 15:43:06,456 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.7688, 0.1553, 0.0759]), new_distribution = tensor([0.7695, 0.1549, 0.0757])
2024-12-05 15:43:06,510 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.7695, 0.1549, 0.0757]), new_distribution = tensor([0.7701, 0.1544, 0.0755])
2024-12-05 15:43:06,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.7701, 0.1544, 0.0755]), new_distribution = tensor([0.7708, 0.1540, 0.0753])
2024-12-05 15:43:06,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.7708, 0.1540, 0.0753]), new_distribution = tensor([0.7714, 0.1535, 0.0750])
2024-12-05 15:43:06,673 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.7714, 0.1535, 0.0750]), new_distribution = tensor([0.7721, 0.1531, 0.0748])
2024-12-05 15:43:06,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([0.7721, 0.1531, 0.0748]), new_distribution = tensor([0.7727, 0.1527, 0.0746])
2024-12-05 15:43:06,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([0.7727, 0.1527, 0.0746]), new_distribution = tensor([0.7734, 0.1522, 0.0744])
2024-12-05 15:43:06,835 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([0.7734, 0.1522, 0.0744]), new_distribution = tensor([0.7740, 0.1518, 0.0742])
2024-12-05 15:43:06,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([0.7740, 0.1518, 0.0742]), new_distribution = tensor([0.7747, 0.1514, 0.0739])
2024-12-05 15:43:06,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([0.7747, 0.1514, 0.0739]), new_distribution = tensor([0.7753, 0.1509, 0.0737])
2024-12-05 15:43:06,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([0.7753, 0.1509, 0.0737]), new_distribution = tensor([0.7760, 0.1505, 0.0735])
2024-12-05 15:43:07,053 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([0.7760, 0.1505, 0.0735]), new_distribution = tensor([0.7766, 0.1501, 0.0733])
2024-12-05 15:43:07,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([0.7766, 0.1501, 0.0733]), new_distribution = tensor([0.7773, 0.1496, 0.0731])
2024-12-05 15:43:07,166 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([0.7773, 0.1496, 0.0731]), new_distribution = tensor([0.7779, 0.1492, 0.0729])
2024-12-05 15:43:07,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([0.7779, 0.1492, 0.0729]), new_distribution = tensor([0.7786, 0.1488, 0.0727])
2024-12-05 15:43:07,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([0.7786, 0.1488, 0.0727]), new_distribution = tensor([0.7792, 0.1483, 0.0725])
2024-12-05 15:43:07,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([0.7792, 0.1483, 0.0725]), new_distribution = tensor([0.7798, 0.1479, 0.0722])
2024-12-05 15:43:07,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([0.7798, 0.1479, 0.0722]), new_distribution = tensor([0.7805, 0.1475, 0.0720])
2024-12-05 15:43:07,436 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([0.7805, 0.1475, 0.0720]), new_distribution = tensor([0.7811, 0.1471, 0.0718])
2024-12-05 15:43:07,490 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([0.7811, 0.1471, 0.0718]), new_distribution = tensor([0.7818, 0.1466, 0.0716])
2024-12-05 15:43:07,544 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([0.7818, 0.1466, 0.0716]), new_distribution = tensor([0.7824, 0.1462, 0.0714])
2024-12-05 15:43:07,598 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([0.7824, 0.1462, 0.0714]), new_distribution = tensor([0.7830, 0.1458, 0.0712])
2024-12-05 15:43:07,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([0.7830, 0.1458, 0.0712]), new_distribution = tensor([0.7837, 0.1454, 0.0710])
2024-12-05 15:43:07,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([0.7837, 0.1454, 0.0710]), new_distribution = tensor([0.7843, 0.1449, 0.0708])
2024-12-05 15:43:07,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([0.7843, 0.1449, 0.0708]), new_distribution = tensor([0.7849, 0.1445, 0.0706])
2024-12-05 15:43:07,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([0.7849, 0.1445, 0.0706]), new_distribution = tensor([0.7855, 0.1441, 0.0704])
2024-12-05 15:43:07,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([0.7855, 0.1441, 0.0704]), new_distribution = tensor([0.7862, 0.1437, 0.0702])
2024-12-05 15:43:07,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([0.7862, 0.1437, 0.0702]), new_distribution = tensor([0.7868, 0.1433, 0.0700])
2024-12-05 15:43:07,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([0.7868, 0.1433, 0.0700]), new_distribution = tensor([0.7874, 0.1428, 0.0698])
2024-12-05 15:43:08,031 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([0.7874, 0.1428, 0.0698]), new_distribution = tensor([0.7880, 0.1424, 0.0695])
2024-12-05 15:43:08,085 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([0.7880, 0.1424, 0.0695]), new_distribution = tensor([0.7887, 0.1420, 0.0693])
2024-12-05 15:43:08,140 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([0.7887, 0.1420, 0.0693]), new_distribution = tensor([0.7893, 0.1416, 0.0691])
2024-12-05 15:43:08,194 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([0.7893, 0.1416, 0.0691]), new_distribution = tensor([0.7899, 0.1412, 0.0689])
2024-12-05 15:43:08,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([0.7899, 0.1412, 0.0689]), new_distribution = tensor([0.7905, 0.1408, 0.0687])
2024-12-05 15:43:08,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([0.7905, 0.1408, 0.0687]), new_distribution = tensor([0.7911, 0.1403, 0.0685])
2024-12-05 15:43:08,357 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([0.7911, 0.1403, 0.0685]), new_distribution = tensor([0.7917, 0.1399, 0.0683])
2024-12-05 15:43:08,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([0.7917, 0.1399, 0.0683]), new_distribution = tensor([0.7923, 0.1395, 0.0681])
2024-12-05 15:43:08,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([0.7923, 0.1395, 0.0681]), new_distribution = tensor([0.7930, 0.1391, 0.0679])
2024-12-05 15:43:08,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([0.7930, 0.1391, 0.0679]), new_distribution = tensor([0.7936, 0.1387, 0.0677])
2024-12-05 15:43:08,574 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([0.7936, 0.1387, 0.0677]), new_distribution = tensor([0.7942, 0.1383, 0.0675])
2024-12-05 15:43:08,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([0.7942, 0.1383, 0.0675]), new_distribution = tensor([0.7948, 0.1379, 0.0673])
2024-12-05 15:43:08,683 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([0.7948, 0.1379, 0.0673]), new_distribution = tensor([0.7954, 0.1375, 0.0671])
2024-12-05 15:43:08,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([0.7954, 0.1375, 0.0671]), new_distribution = tensor([0.7960, 0.1371, 0.0670])
2024-12-05 15:43:08,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([0.7960, 0.1371, 0.0670]), new_distribution = tensor([0.7966, 0.1366, 0.0668])
2024-12-05 15:43:08,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([0.7966, 0.1366, 0.0668]), new_distribution = tensor([0.7972, 0.1362, 0.0666])
2024-12-05 15:43:08,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([0.7972, 0.1362, 0.0666]), new_distribution = tensor([0.7978, 0.1358, 0.0664])
2024-12-05 15:43:08,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([0.7978, 0.1358, 0.0664]), new_distribution = tensor([0.7984, 0.1354, 0.0662])
2024-12-05 15:43:09,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([0.7984, 0.1354, 0.0662]), new_distribution = tensor([0.7990, 0.1350, 0.0660])
2024-12-05 15:43:09,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([0.7990, 0.1350, 0.0660]), new_distribution = tensor([0.7996, 0.1346, 0.0658])
2024-12-05 15:43:09,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([0.7996, 0.1346, 0.0658]), new_distribution = tensor([0.8002, 0.1342, 0.0656])
2024-12-05 15:43:09,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([0.8002, 0.1342, 0.0656]), new_distribution = tensor([0.8008, 0.1338, 0.0654])
2024-12-05 15:43:09,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([0.8008, 0.1338, 0.0654]), new_distribution = tensor([0.8014, 0.1334, 0.0652])
2024-12-05 15:43:09,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([0.8014, 0.1334, 0.0652]), new_distribution = tensor([0.8020, 0.1330, 0.0650])
2024-12-05 15:43:09,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([0.8020, 0.1330, 0.0650]), new_distribution = tensor([0.8026, 0.1326, 0.0648])
2024-12-05 15:43:09,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([0.8026, 0.1326, 0.0648]), new_distribution = tensor([0.8031, 0.1322, 0.0646])
2024-12-05 15:43:09,442 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([0.8031, 0.1322, 0.0646]), new_distribution = tensor([0.8037, 0.1318, 0.0644])
2024-12-05 15:43:09,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([0.8037, 0.1318, 0.0644]), new_distribution = tensor([0.8043, 0.1314, 0.0643])
2024-12-05 15:43:09,550 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([0.8043, 0.1314, 0.0643]), new_distribution = tensor([0.8049, 0.1310, 0.0641])
2024-12-05 15:43:09,604 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([0.8049, 0.1310, 0.0641]), new_distribution = tensor([0.8055, 0.1306, 0.0639])
2024-12-05 15:43:09,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([0.8055, 0.1306, 0.0639]), new_distribution = tensor([0.8061, 0.1302, 0.0637])
2024-12-05 15:43:09,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([0.8061, 0.1302, 0.0637]), new_distribution = tensor([0.8066, 0.1298, 0.0635])
2024-12-05 15:43:09,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([0.8066, 0.1298, 0.0635]), new_distribution = tensor([0.8072, 0.1295, 0.0633])
2024-12-05 15:43:09,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([0.8072, 0.1295, 0.0633]), new_distribution = tensor([0.8078, 0.1291, 0.0631])
2024-12-05 15:43:09,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([0.8078, 0.1291, 0.0631]), new_distribution = tensor([0.8084, 0.1287, 0.0630])
2024-12-05 15:43:09,928 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([0.8084, 0.1287, 0.0630]), new_distribution = tensor([0.8089, 0.1283, 0.0628])
2024-12-05 15:43:09,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([0.8089, 0.1283, 0.0628]), new_distribution = tensor([0.8095, 0.1279, 0.0626])
2024-12-05 15:43:10,037 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([0.8095, 0.1279, 0.0626]), new_distribution = tensor([0.8101, 0.1275, 0.0624])
2024-12-05 15:43:10,091 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([0.8101, 0.1275, 0.0624]), new_distribution = tensor([0.8107, 0.1271, 0.0622])
2024-12-05 15:43:10,145 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([0.8107, 0.1271, 0.0622]), new_distribution = tensor([0.8112, 0.1267, 0.0620])
2024-12-05 15:43:10,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([0.8112, 0.1267, 0.0620]), new_distribution = tensor([0.8118, 0.1263, 0.0619])
2024-12-05 15:43:10,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([0.8118, 0.1263, 0.0619]), new_distribution = tensor([0.8124, 0.1260, 0.0617])
2024-12-05 15:43:10,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([0.8124, 0.1260, 0.0617]), new_distribution = tensor([0.8129, 0.1256, 0.0615])
2024-12-05 15:43:10,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([0.8129, 0.1256, 0.0615]), new_distribution = tensor([0.8135, 0.1252, 0.0613])
2024-12-05 15:43:10,416 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([0.8135, 0.1252, 0.0613]), new_distribution = tensor([0.8141, 0.1248, 0.0611])
2024-12-05 15:43:10,470 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([0.8141, 0.1248, 0.0611]), new_distribution = tensor([0.8146, 0.1244, 0.0610])
2024-12-05 15:43:10,524 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([0.8146, 0.1244, 0.0610]), new_distribution = tensor([0.8152, 0.1240, 0.0608])
2024-12-05 15:43:10,578 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([0.8152, 0.1240, 0.0608]), new_distribution = tensor([0.8157, 0.1237, 0.0606])
2024-12-05 15:43:10,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([0.8157, 0.1237, 0.0606]), new_distribution = tensor([0.8163, 0.1233, 0.0604])
2024-12-05 15:43:10,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([0.8163, 0.1233, 0.0604]), new_distribution = tensor([0.8169, 0.1229, 0.0602])
2024-12-05 15:43:10,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([0.8169, 0.1229, 0.0602]), new_distribution = tensor([0.8174, 0.1225, 0.0601])
2024-12-05 15:43:10,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([0.8174, 0.1225, 0.0601]), new_distribution = tensor([0.8180, 0.1222, 0.0599])
2024-12-05 15:43:10,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([0.8180, 0.1222, 0.0599]), new_distribution = tensor([0.8185, 0.1218, 0.0597])
2024-12-05 15:43:10,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([0.8185, 0.1218, 0.0597]), new_distribution = tensor([0.8191, 0.1214, 0.0595])
2024-12-05 15:43:10,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([0.8191, 0.1214, 0.0595]), new_distribution = tensor([0.8196, 0.1210, 0.0594])
2024-12-05 15:43:11,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([0.8196, 0.1210, 0.0594]), new_distribution = tensor([0.8202, 0.1206, 0.0592])
2024-12-05 15:43:11,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([0.8202, 0.1206, 0.0592]), new_distribution = tensor([0.8207, 0.1203, 0.0590])
2024-12-05 15:43:11,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([0.8207, 0.1203, 0.0590]), new_distribution = tensor([0.8213, 0.1199, 0.0588])
2024-12-05 15:43:11,174 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([0.8213, 0.1199, 0.0588]), new_distribution = tensor([0.8218, 0.1195, 0.0587])
2024-12-05 15:43:11,228 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([0.8218, 0.1195, 0.0587]), new_distribution = tensor([0.8223, 0.1192, 0.0585])
2024-12-05 15:43:11,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([0.8223, 0.1192, 0.0585]), new_distribution = tensor([0.8229, 0.1188, 0.0583])
2024-12-05 15:43:11,337 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([0.8229, 0.1188, 0.0583]), new_distribution = tensor([0.8234, 0.1184, 0.0582])
2024-12-05 15:43:11,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([0.8234, 0.1184, 0.0582]), new_distribution = tensor([0.8240, 0.1181, 0.0580])
2024-12-05 15:43:11,445 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([0.8240, 0.1181, 0.0580]), new_distribution = tensor([0.8245, 0.1177, 0.0578])
2024-12-05 15:43:11,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([0.8245, 0.1177, 0.0578]), new_distribution = tensor([0.8250, 0.1173, 0.0576])
2024-12-05 15:43:11,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([0.8250, 0.1173, 0.0576]), new_distribution = tensor([0.8256, 0.1170, 0.0575])
2024-12-05 15:43:11,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([0.8256, 0.1170, 0.0575]), new_distribution = tensor([0.8261, 0.1166, 0.0573])
2024-12-05 15:43:11,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([0.8261, 0.1166, 0.0573]), new_distribution = tensor([0.8266, 0.1162, 0.0571])
2024-12-05 15:43:11,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([0.8266, 0.1162, 0.0571]), new_distribution = tensor([0.8272, 0.1159, 0.0570])
2024-12-05 15:43:11,770 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([0.8272, 0.1159, 0.0570]), new_distribution = tensor([0.8277, 0.1155, 0.0568])
2024-12-05 15:43:11,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([0.8277, 0.1155, 0.0568]), new_distribution = tensor([0.8282, 0.1151, 0.0566])
2024-12-05 15:43:11,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([0.8282, 0.1151, 0.0566]), new_distribution = tensor([0.8287, 0.1148, 0.0565])
2024-12-05 15:43:11,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([0.8287, 0.1148, 0.0565]), new_distribution = tensor([0.8293, 0.1144, 0.0563])
2024-12-05 15:43:11,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([0.8293, 0.1144, 0.0563]), new_distribution = tensor([0.8298, 0.1141, 0.0561])
2024-12-05 15:43:12,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([0.8298, 0.1141, 0.0561]), new_distribution = tensor([0.8303, 0.1137, 0.0560])
2024-12-05 15:43:12,096 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([0.8303, 0.1137, 0.0560]), new_distribution = tensor([0.8308, 0.1133, 0.0558])
2024-12-05 15:43:12,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([0.8308, 0.1133, 0.0558]), new_distribution = tensor([0.8314, 0.1130, 0.0556])
2024-12-05 15:43:12,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([0.8314, 0.1130, 0.0556]), new_distribution = tensor([0.8319, 0.1126, 0.0555])
2024-12-05 15:43:12,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([0.8319, 0.1126, 0.0555]), new_distribution = tensor([0.8324, 0.1123, 0.0553])
2024-12-05 15:43:12,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([0.8324, 0.1123, 0.0553]), new_distribution = tensor([0.8329, 0.1119, 0.0552])
2024-12-05 15:43:12,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([0.8329, 0.1119, 0.0552]), new_distribution = tensor([0.8334, 0.1116, 0.0550])
2024-12-05 15:43:12,421 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([0.8334, 0.1116, 0.0550]), new_distribution = tensor([0.8339, 0.1112, 0.0548])
2024-12-05 15:43:12,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([0.8339, 0.1112, 0.0548]), new_distribution = tensor([0.8345, 0.1109, 0.0547])
2024-12-05 15:43:12,529 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([0.8345, 0.1109, 0.0547]), new_distribution = tensor([0.8350, 0.1105, 0.0545])
2024-12-05 15:43:12,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([0.8350, 0.1105, 0.0545]), new_distribution = tensor([0.8355, 0.1102, 0.0544])
2024-12-05 15:43:12,637 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([0.8355, 0.1102, 0.0544]), new_distribution = tensor([0.8360, 0.1098, 0.0542])
2024-12-05 15:43:12,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([0.8360, 0.1098, 0.0542]), new_distribution = tensor([0.8365, 0.1095, 0.0540])
2024-12-05 15:43:12,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([0.8365, 0.1095, 0.0540]), new_distribution = tensor([0.8370, 0.1091, 0.0539])
2024-12-05 15:43:12,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([0.8370, 0.1091, 0.0539]), new_distribution = tensor([0.8375, 0.1088, 0.0537])
2024-12-05 15:43:12,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([0.8375, 0.1088, 0.0537]), new_distribution = tensor([0.8380, 0.1084, 0.0536])
2024-12-05 15:43:12,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([0.8380, 0.1084, 0.0536]), new_distribution = tensor([0.8385, 0.1081, 0.0534])
2024-12-05 15:43:12,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([0.8385, 0.1081, 0.0534]), new_distribution = tensor([0.8390, 0.1077, 0.0532])
2024-12-05 15:43:13,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([0.8390, 0.1077, 0.0532]), new_distribution = tensor([0.8395, 0.1074, 0.0531])
2024-12-05 15:43:13,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([0.8395, 0.1074, 0.0531]), new_distribution = tensor([0.8400, 0.1071, 0.0529])
2024-12-05 15:43:13,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([0.8400, 0.1071, 0.0529]), new_distribution = tensor([0.8405, 0.1067, 0.0528])
2024-12-05 15:43:13,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([0.8405, 0.1067, 0.0528]), new_distribution = tensor([0.8410, 0.1064, 0.0526])
2024-12-05 15:43:13,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([0.8410, 0.1064, 0.0526]), new_distribution = tensor([0.8415, 0.1060, 0.0525])
2024-12-05 15:43:13,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([0.8415, 0.1060, 0.0525]), new_distribution = tensor([0.8420, 0.1057, 0.0523])
2024-12-05 15:43:13,342 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([0.8420, 0.1057, 0.0523]), new_distribution = tensor([0.8425, 0.1054, 0.0522])
2024-12-05 15:43:13,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([0.8425, 0.1054, 0.0522]), new_distribution = tensor([0.8430, 0.1050, 0.0520])
2024-12-05 15:43:13,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([0.8430, 0.1050, 0.0520]), new_distribution = tensor([0.8435, 0.1047, 0.0519])
2024-12-05 15:43:13,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([0.8435, 0.1047, 0.0519]), new_distribution = tensor([0.8440, 0.1043, 0.0517])
2024-12-05 15:43:13,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([0.8440, 0.1043, 0.0517]), new_distribution = tensor([0.8444, 0.1040, 0.0516])
2024-12-05 15:43:13,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([0.8444, 0.1040, 0.0516]), new_distribution = tensor([0.8449, 0.1037, 0.0514])
2024-12-05 15:43:13,666 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([0.8449, 0.1037, 0.0514]), new_distribution = tensor([0.8454, 0.1033, 0.0512])
2024-12-05 15:43:13,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([0.8454, 0.1033, 0.0512]), new_distribution = tensor([0.8459, 0.1030, 0.0511])
2024-12-05 15:43:13,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([0.8459, 0.1030, 0.0511]), new_distribution = tensor([0.8464, 0.1027, 0.0509])
2024-12-05 15:43:13,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([0.8464, 0.1027, 0.0509]), new_distribution = tensor([0.8469, 0.1023, 0.0508])
2024-12-05 15:43:13,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([0.8469, 0.1023, 0.0508]), new_distribution = tensor([0.8473, 0.1020, 0.0506])
2024-12-05 15:43:13,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([0.8473, 0.1020, 0.0506]), new_distribution = tensor([0.8478, 0.1017, 0.0505])
2024-12-05 15:43:13,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([0.8478, 0.1017, 0.0505]), new_distribution = tensor([0.8483, 0.1014, 0.0503])
2024-12-05 15:43:14,046 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([0.8483, 0.1014, 0.0503]), new_distribution = tensor([0.8488, 0.1010, 0.0502])
2024-12-05 15:43:14,100 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([0.8488, 0.1010, 0.0502]), new_distribution = tensor([0.8492, 0.1007, 0.0501])
2024-12-05 15:43:14,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([0.8492, 0.1007, 0.0501]), new_distribution = tensor([0.8497, 0.1004, 0.0499])
2024-12-05 15:43:14,208 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([0.8497, 0.1004, 0.0499]), new_distribution = tensor([0.8502, 0.1001, 0.0498])
2024-12-05 15:43:14,262 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([0.8502, 0.1001, 0.0498]), new_distribution = tensor([0.8507, 0.0997, 0.0496])
2024-12-05 15:43:14,316 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([0.8507, 0.0997, 0.0496]), new_distribution = tensor([0.8511, 0.0994, 0.0495])
2024-12-05 15:43:14,371 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([0.8511, 0.0994, 0.0495]), new_distribution = tensor([0.8516, 0.0991, 0.0493])
2024-12-05 15:43:14,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([0.8516, 0.0991, 0.0493]), new_distribution = tensor([0.8521, 0.0988, 0.0492])
2024-12-05 15:43:14,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([0.8521, 0.0988, 0.0492]), new_distribution = tensor([0.8525, 0.0984, 0.0490])
2024-12-05 15:43:14,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([0.8525, 0.0984, 0.0490]), new_distribution = tensor([0.8530, 0.0981, 0.0489])
2024-12-05 15:43:14,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([0.8530, 0.0981, 0.0489]), new_distribution = tensor([0.8535, 0.0978, 0.0487])
2024-12-05 15:43:14,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([0.8535, 0.0978, 0.0487]), new_distribution = tensor([0.8539, 0.0975, 0.0486])
2024-12-05 15:43:14,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([0.8539, 0.0975, 0.0486]), new_distribution = tensor([0.8544, 0.0972, 0.0485])
2024-12-05 15:43:14,749 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([0.8544, 0.0972, 0.0485]), new_distribution = tensor([0.8548, 0.0968, 0.0483])
2024-12-05 15:43:14,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([0.8548, 0.0968, 0.0483]), new_distribution = tensor([0.8553, 0.0965, 0.0482])
2024-12-05 15:43:14,858 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([0.8553, 0.0965, 0.0482]), new_distribution = tensor([0.8558, 0.0962, 0.0480])
2024-12-05 15:43:14,912 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([0.8558, 0.0962, 0.0480]), new_distribution = tensor([0.8562, 0.0959, 0.0479])
2024-12-05 15:43:14,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([0.8562, 0.0959, 0.0479]), new_distribution = tensor([0.8567, 0.0956, 0.0477])
2024-12-05 15:43:15,021 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([0.8567, 0.0956, 0.0477]), new_distribution = tensor([0.8571, 0.0953, 0.0476])
2024-12-05 15:43:15,075 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([0.8571, 0.0953, 0.0476]), new_distribution = tensor([0.8576, 0.0950, 0.0475])
2024-12-05 15:43:15,129 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([0.8576, 0.0950, 0.0475]), new_distribution = tensor([0.8580, 0.0946, 0.0473])
2024-12-05 15:43:15,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([0.8580, 0.0946, 0.0473]), new_distribution = tensor([0.8585, 0.0943, 0.0472])
2024-12-05 15:43:15,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([0.8585, 0.0943, 0.0472]), new_distribution = tensor([0.8589, 0.0940, 0.0470])
2024-12-05 15:43:15,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([0.8589, 0.0940, 0.0470]), new_distribution = tensor([0.8594, 0.0937, 0.0469])
2024-12-05 15:43:15,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([0.8594, 0.0937, 0.0469]), new_distribution = tensor([0.8598, 0.0934, 0.0468])
2024-12-05 15:43:15,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([0.8598, 0.0934, 0.0468]), new_distribution = tensor([0.8603, 0.0931, 0.0466])
2024-12-05 15:43:15,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([0.8603, 0.0931, 0.0466]), new_distribution = tensor([0.8607, 0.0928, 0.0465])
2024-12-05 15:43:15,510 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([0.8607, 0.0928, 0.0465]), new_distribution = tensor([0.8611, 0.0925, 0.0464])
2024-12-05 15:43:15,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([0.8611, 0.0925, 0.0464]), new_distribution = tensor([0.8616, 0.0922, 0.0462])
2024-12-05 15:43:15,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([0.8616, 0.0922, 0.0462]), new_distribution = tensor([0.8620, 0.0919, 0.0461])
2024-12-05 15:43:15,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([0.8620, 0.0919, 0.0461]), new_distribution = tensor([0.8625, 0.0916, 0.0460])
2024-12-05 15:43:15,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([0.8625, 0.0916, 0.0460]), new_distribution = tensor([0.8629, 0.0913, 0.0458])
2024-12-05 15:43:15,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([0.8629, 0.0913, 0.0458]), new_distribution = tensor([0.8633, 0.0910, 0.0457])
2024-12-05 15:43:15,835 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([0.8633, 0.0910, 0.0457]), new_distribution = tensor([0.8638, 0.0907, 0.0455])
2024-12-05 15:43:15,889 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([0.8638, 0.0907, 0.0455]), new_distribution = tensor([0.8642, 0.0904, 0.0454])
2024-12-05 15:43:15,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([0.8642, 0.0904, 0.0454]), new_distribution = tensor([0.8646, 0.0901, 0.0453])
2024-12-05 15:43:15,998 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([0.8646, 0.0901, 0.0453]), new_distribution = tensor([0.8651, 0.0898, 0.0451])
2024-12-05 15:43:16,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([0.8651, 0.0898, 0.0451]), new_distribution = tensor([0.8655, 0.0895, 0.0450])
2024-12-05 15:43:16,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([0.8655, 0.0895, 0.0450]), new_distribution = tensor([0.8659, 0.0892, 0.0449])
2024-12-05 15:43:16,161 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([0.8659, 0.0892, 0.0449]), new_distribution = tensor([0.8664, 0.0889, 0.0447])
2024-12-05 15:43:16,215 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([0.8664, 0.0889, 0.0447]), new_distribution = tensor([0.8668, 0.0886, 0.0446])
2024-12-05 15:43:16,269 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([0.8668, 0.0886, 0.0446]), new_distribution = tensor([0.8672, 0.0883, 0.0445])
2024-12-05 15:43:16,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([0.8672, 0.0883, 0.0445]), new_distribution = tensor([0.8676, 0.0880, 0.0444])
2024-12-05 15:43:16,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([0.8676, 0.0880, 0.0444]), new_distribution = tensor([0.8681, 0.0877, 0.0442])
2024-12-05 15:43:16,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([0.8681, 0.0877, 0.0442]), new_distribution = tensor([0.8685, 0.0874, 0.0441])
2024-12-05 15:43:16,486 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([0.8685, 0.0874, 0.0441]), new_distribution = tensor([0.8689, 0.0871, 0.0440])
2024-12-05 15:43:16,540 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([0.8689, 0.0871, 0.0440]), new_distribution = tensor([0.8693, 0.0868, 0.0438])
2024-12-05 15:43:16,594 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([0.8693, 0.0868, 0.0438]), new_distribution = tensor([0.8698, 0.0865, 0.0437])
2024-12-05 15:43:16,649 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([0.8698, 0.0865, 0.0437]), new_distribution = tensor([0.8702, 0.0863, 0.0436])
2024-12-05 15:43:16,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([0.8702, 0.0863, 0.0436]), new_distribution = tensor([0.8706, 0.0860, 0.0434])
2024-12-05 15:43:16,758 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([0.8706, 0.0860, 0.0434]), new_distribution = tensor([0.8710, 0.0857, 0.0433])
2024-12-05 15:43:16,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([0.8710, 0.0857, 0.0433]), new_distribution = tensor([0.8714, 0.0854, 0.0432])
2024-12-05 15:43:16,867 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([0.8714, 0.0854, 0.0432]), new_distribution = tensor([0.8718, 0.0851, 0.0431])
2024-12-05 15:43:16,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([0.8718, 0.0851, 0.0431]), new_distribution = tensor([0.8722, 0.0848, 0.0429])
2024-12-05 15:43:16,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([0.8722, 0.0848, 0.0429]), new_distribution = tensor([0.8727, 0.0845, 0.0428])
2024-12-05 15:43:17,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([0.8727, 0.0845, 0.0428]), new_distribution = tensor([0.8731, 0.0843, 0.0427])
2024-12-05 15:43:17,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([0.8731, 0.0843, 0.0427]), new_distribution = tensor([0.8735, 0.0840, 0.0426])
2024-12-05 15:43:17,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([0.8735, 0.0840, 0.0426]), new_distribution = tensor([0.8739, 0.0837, 0.0424])
2024-12-05 15:43:17,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([0.8739, 0.0837, 0.0424]), new_distribution = tensor([0.8743, 0.0834, 0.0423])
2024-12-05 15:43:17,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([0.8743, 0.0834, 0.0423]), new_distribution = tensor([0.8747, 0.0831, 0.0422])
2024-12-05 15:43:17,309 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([0.8747, 0.0831, 0.0422]), new_distribution = tensor([0.8751, 0.0828, 0.0421])
2024-12-05 15:43:17,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([0.8751, 0.0828, 0.0421]), new_distribution = tensor([0.8755, 0.0826, 0.0419])
2024-12-05 15:43:17,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([0.8755, 0.0826, 0.0419]), new_distribution = tensor([0.8759, 0.0823, 0.0418])
2024-12-05 15:43:17,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([0.8759, 0.0823, 0.0418]), new_distribution = tensor([0.8763, 0.0820, 0.0417])
2024-12-05 15:43:17,526 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([0.8763, 0.0820, 0.0417]), new_distribution = tensor([0.8767, 0.0817, 0.0416])
2024-12-05 15:43:17,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 300: ref_distribution = tensor([0.8767, 0.0817, 0.0416]), new_distribution = tensor([0.8771, 0.0815, 0.0414])
2024-12-05 15:43:17,634 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 301: ref_distribution = tensor([0.8771, 0.0815, 0.0414]), new_distribution = tensor([0.8775, 0.0812, 0.0413])
2024-12-05 15:43:17,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 302: ref_distribution = tensor([0.8775, 0.0812, 0.0413]), new_distribution = tensor([0.8779, 0.0809, 0.0412])
2024-12-05 15:43:17,742 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 303: ref_distribution = tensor([0.8779, 0.0809, 0.0412]), new_distribution = tensor([0.8783, 0.0806, 0.0411])
2024-12-05 15:43:17,797 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 304: ref_distribution = tensor([0.8783, 0.0806, 0.0411]), new_distribution = tensor([0.8787, 0.0804, 0.0410])
2024-12-05 15:43:17,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 305: ref_distribution = tensor([0.8787, 0.0804, 0.0410]), new_distribution = tensor([0.8791, 0.0801, 0.0408])
2024-12-05 15:43:17,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 306: ref_distribution = tensor([0.8791, 0.0801, 0.0408]), new_distribution = tensor([0.8795, 0.0798, 0.0407])
2024-12-05 15:43:17,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 307: ref_distribution = tensor([0.8795, 0.0798, 0.0407]), new_distribution = tensor([0.8799, 0.0796, 0.0406])
2024-12-05 15:43:18,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 308: ref_distribution = tensor([0.8799, 0.0796, 0.0406]), new_distribution = tensor([0.8802, 0.0793, 0.0405])
2024-12-05 15:43:18,068 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 309: ref_distribution = tensor([0.8802, 0.0793, 0.0405]), new_distribution = tensor([0.8806, 0.0790, 0.0404])
2024-12-05 15:43:18,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 310: ref_distribution = tensor([0.8806, 0.0790, 0.0404]), new_distribution = tensor([0.8810, 0.0787, 0.0402])
2024-12-05 15:43:18,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 311: ref_distribution = tensor([0.8810, 0.0787, 0.0402]), new_distribution = tensor([0.8814, 0.0785, 0.0401])
2024-12-05 15:43:18,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 312: ref_distribution = tensor([0.8814, 0.0785, 0.0401]), new_distribution = tensor([0.8818, 0.0782, 0.0400])
2024-12-05 15:43:18,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 313: ref_distribution = tensor([0.8818, 0.0782, 0.0400]), new_distribution = tensor([0.8822, 0.0779, 0.0399])
2024-12-05 15:43:18,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 314: ref_distribution = tensor([0.8822, 0.0779, 0.0399]), new_distribution = tensor([0.8826, 0.0777, 0.0398])
2024-12-05 15:43:18,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 315: ref_distribution = tensor([0.8826, 0.0777, 0.0398]), new_distribution = tensor([0.8829, 0.0774, 0.0396])
2024-12-05 15:43:18,448 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 316: ref_distribution = tensor([0.8829, 0.0774, 0.0396]), new_distribution = tensor([0.8833, 0.0772, 0.0395])
2024-12-05 15:43:18,502 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 317: ref_distribution = tensor([0.8833, 0.0772, 0.0395]), new_distribution = tensor([0.8837, 0.0769, 0.0394])
2024-12-05 15:43:18,556 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 318: ref_distribution = tensor([0.8837, 0.0769, 0.0394]), new_distribution = tensor([0.8841, 0.0766, 0.0393])
2024-12-05 15:43:18,611 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 319: ref_distribution = tensor([0.8841, 0.0766, 0.0393]), new_distribution = tensor([0.8845, 0.0764, 0.0392])
2024-12-05 15:43:18,665 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 320: ref_distribution = tensor([0.8845, 0.0764, 0.0392]), new_distribution = tensor([0.8848, 0.0761, 0.0391])
2024-12-05 15:43:18,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 321: ref_distribution = tensor([0.8848, 0.0761, 0.0391]), new_distribution = tensor([0.8852, 0.0758, 0.0389])
2024-12-05 15:43:18,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 322: ref_distribution = tensor([0.8852, 0.0758, 0.0389]), new_distribution = tensor([0.8856, 0.0756, 0.0388])
2024-12-05 15:43:18,827 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 323: ref_distribution = tensor([0.8856, 0.0756, 0.0388]), new_distribution = tensor([0.8860, 0.0753, 0.0387])
2024-12-05 15:43:18,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 324: ref_distribution = tensor([0.8860, 0.0753, 0.0387]), new_distribution = tensor([0.8863, 0.0751, 0.0386])
2024-12-05 15:43:18,936 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 325: ref_distribution = tensor([0.8863, 0.0751, 0.0386]), new_distribution = tensor([0.8867, 0.0748, 0.0385])
2024-12-05 15:43:18,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 326: ref_distribution = tensor([0.8867, 0.0748, 0.0385]), new_distribution = tensor([0.8871, 0.0746, 0.0384])
2024-12-05 15:43:19,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 327: ref_distribution = tensor([0.8871, 0.0746, 0.0384]), new_distribution = tensor([0.8874, 0.0743, 0.0383])
2024-12-05 15:43:19,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 328: ref_distribution = tensor([0.8874, 0.0743, 0.0383]), new_distribution = tensor([0.8878, 0.0741, 0.0381])
2024-12-05 15:43:19,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 329: ref_distribution = tensor([0.8878, 0.0741, 0.0381]), new_distribution = tensor([0.8882, 0.0738, 0.0380])
2024-12-05 15:43:19,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 330: ref_distribution = tensor([0.8882, 0.0738, 0.0380]), new_distribution = tensor([0.8885, 0.0735, 0.0379])
2024-12-05 15:43:19,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 331: ref_distribution = tensor([0.8885, 0.0735, 0.0379]), new_distribution = tensor([0.8889, 0.0733, 0.0378])
2024-12-05 15:43:19,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 332: ref_distribution = tensor([0.8889, 0.0733, 0.0378]), new_distribution = tensor([0.8893, 0.0730, 0.0377])
2024-12-05 15:43:19,370 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 333: ref_distribution = tensor([0.8893, 0.0730, 0.0377]), new_distribution = tensor([0.8896, 0.0728, 0.0376])
2024-12-05 15:43:19,424 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 334: ref_distribution = tensor([0.8896, 0.0728, 0.0376]), new_distribution = tensor([0.8900, 0.0725, 0.0375])
2024-12-05 15:43:19,478 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 335: ref_distribution = tensor([0.8900, 0.0725, 0.0375]), new_distribution = tensor([0.8903, 0.0723, 0.0374])
2024-12-05 15:43:19,532 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 336: ref_distribution = tensor([0.8903, 0.0723, 0.0374]), new_distribution = tensor([0.8907, 0.0720, 0.0373])
2024-12-05 15:43:19,586 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 337: ref_distribution = tensor([0.8907, 0.0720, 0.0373]), new_distribution = tensor([0.8911, 0.0718, 0.0371])
2024-12-05 15:43:19,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 338: ref_distribution = tensor([0.8911, 0.0718, 0.0371]), new_distribution = tensor([0.8914, 0.0715, 0.0370])
2024-12-05 15:43:19,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 339: ref_distribution = tensor([0.8914, 0.0715, 0.0370]), new_distribution = tensor([0.8918, 0.0713, 0.0369])
2024-12-05 15:43:19,749 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 340: ref_distribution = tensor([0.8918, 0.0713, 0.0369]), new_distribution = tensor([0.8921, 0.0711, 0.0368])
2024-12-05 15:43:19,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 341: ref_distribution = tensor([0.8921, 0.0711, 0.0368]), new_distribution = tensor([0.8925, 0.0708, 0.0367])
2024-12-05 15:43:19,858 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 342: ref_distribution = tensor([0.8925, 0.0708, 0.0367]), new_distribution = tensor([0.8928, 0.0706, 0.0366])
2024-12-05 15:43:19,912 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 343: ref_distribution = tensor([0.8928, 0.0706, 0.0366]), new_distribution = tensor([0.8932, 0.0703, 0.0365])
2024-12-05 15:43:19,966 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 344: ref_distribution = tensor([0.8932, 0.0703, 0.0365]), new_distribution = tensor([0.8935, 0.0701, 0.0364])
2024-12-05 15:43:20,020 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 345: ref_distribution = tensor([0.8935, 0.0701, 0.0364]), new_distribution = tensor([0.8939, 0.0698, 0.0363])
2024-12-05 15:43:20,074 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 346: ref_distribution = tensor([0.8939, 0.0698, 0.0363]), new_distribution = tensor([0.8942, 0.0696, 0.0362])
2024-12-05 15:43:20,128 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 347: ref_distribution = tensor([0.8942, 0.0696, 0.0362]), new_distribution = tensor([0.8946, 0.0694, 0.0361])
2024-12-05 15:43:20,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 348: ref_distribution = tensor([0.8946, 0.0694, 0.0361]), new_distribution = tensor([0.8949, 0.0691, 0.0360])
2024-12-05 15:43:20,237 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 349: ref_distribution = tensor([0.8949, 0.0691, 0.0360]), new_distribution = tensor([0.8953, 0.0689, 0.0359])
2024-12-05 15:43:20,291 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 350: ref_distribution = tensor([0.8953, 0.0689, 0.0359]), new_distribution = tensor([0.8956, 0.0686, 0.0357])
2024-12-05 15:43:20,345 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 351: ref_distribution = tensor([0.8956, 0.0686, 0.0357]), new_distribution = tensor([0.8960, 0.0684, 0.0356])
2024-12-05 15:43:20,399 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 352: ref_distribution = tensor([0.8960, 0.0684, 0.0356]), new_distribution = tensor([0.8963, 0.0682, 0.0355])
2024-12-05 15:43:20,454 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 353: ref_distribution = tensor([0.8963, 0.0682, 0.0355]), new_distribution = tensor([0.8967, 0.0679, 0.0354])
2024-12-05 15:43:20,508 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 354: ref_distribution = tensor([0.8967, 0.0679, 0.0354]), new_distribution = tensor([0.8970, 0.0677, 0.0353])
2024-12-05 15:43:20,562 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 355: ref_distribution = tensor([0.8970, 0.0677, 0.0353]), new_distribution = tensor([0.8973, 0.0674, 0.0352])
2024-12-05 15:43:20,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 356: ref_distribution = tensor([0.8973, 0.0674, 0.0352]), new_distribution = tensor([0.8977, 0.0672, 0.0351])
2024-12-05 15:43:20,671 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 357: ref_distribution = tensor([0.8977, 0.0672, 0.0351]), new_distribution = tensor([0.8980, 0.0670, 0.0350])
2024-12-05 15:43:20,725 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 358: ref_distribution = tensor([0.8980, 0.0670, 0.0350]), new_distribution = tensor([0.8983, 0.0667, 0.0349])
2024-12-05 15:43:20,780 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 359: ref_distribution = tensor([0.8983, 0.0667, 0.0349]), new_distribution = tensor([0.8987, 0.0665, 0.0348])
2024-12-05 15:43:20,834 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 360: ref_distribution = tensor([0.8987, 0.0665, 0.0348]), new_distribution = tensor([0.8990, 0.0663, 0.0347])
2024-12-05 15:43:20,888 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 361: ref_distribution = tensor([0.8990, 0.0663, 0.0347]), new_distribution = tensor([0.8993, 0.0661, 0.0346])
2024-12-05 15:43:20,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 362: ref_distribution = tensor([0.8993, 0.0661, 0.0346]), new_distribution = tensor([0.8997, 0.0658, 0.0345])
2024-12-05 15:43:20,996 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 363: ref_distribution = tensor([0.8997, 0.0658, 0.0345]), new_distribution = tensor([0.9000, 0.0656, 0.0344])
2024-12-05 15:43:21,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 364: ref_distribution = tensor([0.9000, 0.0656, 0.0344]), new_distribution = tensor([0.9003, 0.0654, 0.0343])
2024-12-05 15:43:21,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 365: ref_distribution = tensor([0.9003, 0.0654, 0.0343]), new_distribution = tensor([0.9007, 0.0651, 0.0342])
2024-12-05 15:43:21,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 366: ref_distribution = tensor([0.9007, 0.0651, 0.0342]), new_distribution = tensor([0.9010, 0.0649, 0.0341])
2024-12-05 15:43:21,213 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 367: ref_distribution = tensor([0.9010, 0.0649, 0.0341]), new_distribution = tensor([0.9013, 0.0647, 0.0340])
2024-12-05 15:43:21,267 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 368: ref_distribution = tensor([0.9013, 0.0647, 0.0340]), new_distribution = tensor([0.9017, 0.0645, 0.0339])
2024-12-05 15:43:21,321 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 369: ref_distribution = tensor([0.9017, 0.0645, 0.0339]), new_distribution = tensor([0.9020, 0.0642, 0.0338])
2024-12-05 15:43:21,375 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 370: ref_distribution = tensor([0.9020, 0.0642, 0.0338]), new_distribution = tensor([0.9023, 0.0640, 0.0337])
2024-12-05 15:43:21,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 371: ref_distribution = tensor([0.9023, 0.0640, 0.0337]), new_distribution = tensor([0.9026, 0.0638, 0.0336])
2024-12-05 15:43:21,484 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 372: ref_distribution = tensor([0.9026, 0.0638, 0.0336]), new_distribution = tensor([0.9030, 0.0636, 0.0335])
2024-12-05 15:43:21,538 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 373: ref_distribution = tensor([0.9030, 0.0636, 0.0335]), new_distribution = tensor([0.9033, 0.0633, 0.0334])
2024-12-05 15:43:21,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 374: ref_distribution = tensor([0.9033, 0.0633, 0.0334]), new_distribution = tensor([0.9036, 0.0631, 0.0333])
2024-12-05 15:43:21,646 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 375: ref_distribution = tensor([0.9036, 0.0631, 0.0333]), new_distribution = tensor([0.9039, 0.0629, 0.0332])
2024-12-05 15:43:21,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 376: ref_distribution = tensor([0.9039, 0.0629, 0.0332]), new_distribution = tensor([0.9042, 0.0627, 0.0331])
2024-12-05 15:43:21,754 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 377: ref_distribution = tensor([0.9042, 0.0627, 0.0331]), new_distribution = tensor([0.9045, 0.0625, 0.0330])
2024-12-05 15:43:21,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 378: ref_distribution = tensor([0.9045, 0.0625, 0.0330]), new_distribution = tensor([0.9049, 0.0622, 0.0329])
2024-12-05 15:43:21,862 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 379: ref_distribution = tensor([0.9049, 0.0622, 0.0329]), new_distribution = tensor([0.9052, 0.0620, 0.0328])
2024-12-05 15:43:21,916 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 380: ref_distribution = tensor([0.9052, 0.0620, 0.0328]), new_distribution = tensor([0.9055, 0.0618, 0.0327])
2024-12-05 15:43:21,970 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 381: ref_distribution = tensor([0.9055, 0.0618, 0.0327]), new_distribution = tensor([0.9058, 0.0616, 0.0326])
2024-12-05 15:43:22,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 382: ref_distribution = tensor([0.9058, 0.0616, 0.0326]), new_distribution = tensor([0.9061, 0.0614, 0.0325])
2024-12-05 15:43:22,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 383: ref_distribution = tensor([0.9061, 0.0614, 0.0325]), new_distribution = tensor([0.9064, 0.0611, 0.0324])
2024-12-05 15:43:22,133 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 384: ref_distribution = tensor([0.9064, 0.0611, 0.0324]), new_distribution = tensor([0.9067, 0.0609, 0.0323])
2024-12-05 15:43:22,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 385: ref_distribution = tensor([0.9067, 0.0609, 0.0323]), new_distribution = tensor([0.9071, 0.0607, 0.0322])
2024-12-05 15:43:22,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 386: ref_distribution = tensor([0.9071, 0.0607, 0.0322]), new_distribution = tensor([0.9074, 0.0605, 0.0321])
2024-12-05 15:43:22,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 387: ref_distribution = tensor([0.9074, 0.0605, 0.0321]), new_distribution = tensor([0.9077, 0.0603, 0.0320])
2024-12-05 15:43:22,350 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 388: ref_distribution = tensor([0.9077, 0.0603, 0.0320]), new_distribution = tensor([0.9080, 0.0601, 0.0319])
2024-12-05 15:43:22,404 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 389: ref_distribution = tensor([0.9080, 0.0601, 0.0319]), new_distribution = tensor([0.9083, 0.0599, 0.0318])
2024-12-05 15:43:22,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 390: ref_distribution = tensor([0.9083, 0.0599, 0.0318]), new_distribution = tensor([0.9086, 0.0597, 0.0318])
2024-12-05 15:43:22,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 391: ref_distribution = tensor([0.9086, 0.0597, 0.0318]), new_distribution = tensor([0.9089, 0.0594, 0.0317])
2024-12-05 15:43:22,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 392: ref_distribution = tensor([0.9089, 0.0594, 0.0317]), new_distribution = tensor([0.9092, 0.0592, 0.0316])
2024-12-05 15:43:22,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 393: ref_distribution = tensor([0.9092, 0.0592, 0.0316]), new_distribution = tensor([0.9095, 0.0590, 0.0315])
2024-12-05 15:43:22,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 394: ref_distribution = tensor([0.9095, 0.0590, 0.0315]), new_distribution = tensor([0.9098, 0.0588, 0.0314])
2024-12-05 15:43:22,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 395: ref_distribution = tensor([0.9098, 0.0588, 0.0314]), new_distribution = tensor([0.9101, 0.0586, 0.0313])
2024-12-05 15:43:22,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 396: ref_distribution = tensor([0.9101, 0.0586, 0.0313]), new_distribution = tensor([0.9104, 0.0584, 0.0312])
2024-12-05 15:43:22,838 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 397: ref_distribution = tensor([0.9104, 0.0584, 0.0312]), new_distribution = tensor([0.9107, 0.0582, 0.0311])
2024-12-05 15:43:22,892 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 398: ref_distribution = tensor([0.9107, 0.0582, 0.0311]), new_distribution = tensor([0.9110, 0.0580, 0.0310])
2024-12-05 15:43:22,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 399: ref_distribution = tensor([0.9110, 0.0580, 0.0310]), new_distribution = tensor([0.9113, 0.0578, 0.0309])
2024-12-05 15:43:23,001 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 400: ref_distribution = tensor([0.9113, 0.0578, 0.0309]), new_distribution = tensor([0.9116, 0.0576, 0.0308])
2024-12-05 15:43:23,055 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 401: ref_distribution = tensor([0.9116, 0.0576, 0.0308]), new_distribution = tensor([0.9119, 0.0574, 0.0307])
2024-12-05 15:43:23,110 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 402: ref_distribution = tensor([0.9119, 0.0574, 0.0307]), new_distribution = tensor([0.9122, 0.0572, 0.0306])
2024-12-05 15:43:23,164 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 403: ref_distribution = tensor([0.9122, 0.0572, 0.0306]), new_distribution = tensor([0.9125, 0.0570, 0.0306])
2024-12-05 15:43:23,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 404: ref_distribution = tensor([0.9125, 0.0570, 0.0306]), new_distribution = tensor([0.9128, 0.0568, 0.0305])
2024-12-05 15:43:23,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 405: ref_distribution = tensor([0.9128, 0.0568, 0.0305]), new_distribution = tensor([0.9131, 0.0566, 0.0304])
2024-12-05 15:43:23,327 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 406: ref_distribution = tensor([0.9131, 0.0566, 0.0304]), new_distribution = tensor([0.9134, 0.0564, 0.0303])
2024-12-05 15:43:23,381 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 407: ref_distribution = tensor([0.9134, 0.0564, 0.0303]), new_distribution = tensor([0.9136, 0.0562, 0.0302])
2024-12-05 15:43:23,436 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 408: ref_distribution = tensor([0.9136, 0.0562, 0.0302]), new_distribution = tensor([0.9139, 0.0560, 0.0301])
2024-12-05 15:43:23,490 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 409: ref_distribution = tensor([0.9139, 0.0560, 0.0301]), new_distribution = tensor([0.9142, 0.0558, 0.0300])
2024-12-05 15:43:23,544 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 410: ref_distribution = tensor([0.9142, 0.0558, 0.0300]), new_distribution = tensor([0.9145, 0.0556, 0.0299])
2024-12-05 15:43:23,598 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 411: ref_distribution = tensor([0.9145, 0.0556, 0.0299]), new_distribution = tensor([0.9148, 0.0554, 0.0298])
2024-12-05 15:43:23,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 412: ref_distribution = tensor([0.9148, 0.0554, 0.0298]), new_distribution = tensor([0.9151, 0.0552, 0.0297])
2024-12-05 15:43:23,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 413: ref_distribution = tensor([0.9151, 0.0552, 0.0297]), new_distribution = tensor([0.9154, 0.0550, 0.0297])
2024-12-05 15:43:23,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 414: ref_distribution = tensor([0.9154, 0.0550, 0.0297]), new_distribution = tensor([0.9157, 0.0548, 0.0296])
2024-12-05 15:43:23,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 415: ref_distribution = tensor([0.9157, 0.0548, 0.0296]), new_distribution = tensor([0.9159, 0.0546, 0.0295])
2024-12-05 15:43:23,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 416: ref_distribution = tensor([0.9159, 0.0546, 0.0295]), new_distribution = tensor([0.9162, 0.0544, 0.0294])
2024-12-05 15:43:23,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 417: ref_distribution = tensor([0.9162, 0.0544, 0.0294]), new_distribution = tensor([0.9165, 0.0542, 0.0293])
2024-12-05 15:43:23,978 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 418: ref_distribution = tensor([0.9165, 0.0542, 0.0293]), new_distribution = tensor([0.9168, 0.0540, 0.0292])
2024-12-05 15:43:24,032 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 419: ref_distribution = tensor([0.9168, 0.0540, 0.0292]), new_distribution = tensor([0.9171, 0.0538, 0.0291])
2024-12-05 15:43:24,086 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 420: ref_distribution = tensor([0.9171, 0.0538, 0.0291]), new_distribution = tensor([0.9173, 0.0536, 0.0291])
2024-12-05 15:43:24,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 421: ref_distribution = tensor([0.9173, 0.0536, 0.0291]), new_distribution = tensor([0.9176, 0.0534, 0.0290])
2024-12-05 15:43:24,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 422: ref_distribution = tensor([0.9176, 0.0534, 0.0290]), new_distribution = tensor([0.9179, 0.0532, 0.0289])
2024-12-05 15:43:24,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 423: ref_distribution = tensor([0.9179, 0.0532, 0.0289]), new_distribution = tensor([0.9182, 0.0530, 0.0288])
2024-12-05 15:43:24,303 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 424: ref_distribution = tensor([0.9182, 0.0530, 0.0288]), new_distribution = tensor([0.9184, 0.0528, 0.0287])
2024-12-05 15:43:24,357 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 425: ref_distribution = tensor([0.9184, 0.0528, 0.0287]), new_distribution = tensor([0.9187, 0.0527, 0.0286])
2024-12-05 15:43:24,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 426: ref_distribution = tensor([0.9187, 0.0527, 0.0286]), new_distribution = tensor([0.9190, 0.0525, 0.0285])
2024-12-05 15:43:24,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 427: ref_distribution = tensor([0.9190, 0.0525, 0.0285]), new_distribution = tensor([0.9193, 0.0523, 0.0285])
2024-12-05 15:43:24,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 428: ref_distribution = tensor([0.9193, 0.0523, 0.0285]), new_distribution = tensor([0.9195, 0.0521, 0.0284])
2024-12-05 15:43:24,574 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 429: ref_distribution = tensor([0.9195, 0.0521, 0.0284]), new_distribution = tensor([0.9198, 0.0519, 0.0283])
2024-12-05 15:43:24,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 430: ref_distribution = tensor([0.9198, 0.0519, 0.0283]), new_distribution = tensor([0.9201, 0.0517, 0.0282])
2024-12-05 15:43:24,682 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 431: ref_distribution = tensor([0.9201, 0.0517, 0.0282]), new_distribution = tensor([0.9203, 0.0515, 0.0281])
2024-12-05 15:43:24,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 432: ref_distribution = tensor([0.9203, 0.0515, 0.0281]), new_distribution = tensor([0.9206, 0.0514, 0.0280])
2024-12-05 15:43:24,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 433: ref_distribution = tensor([0.9206, 0.0514, 0.0280]), new_distribution = tensor([0.9209, 0.0512, 0.0280])
2024-12-05 15:43:24,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 434: ref_distribution = tensor([0.9209, 0.0512, 0.0280]), new_distribution = tensor([0.9211, 0.0510, 0.0279])
2024-12-05 15:43:24,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 435: ref_distribution = tensor([0.9211, 0.0510, 0.0279]), new_distribution = tensor([0.9214, 0.0508, 0.0278])
2024-12-05 15:43:24,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 436: ref_distribution = tensor([0.9214, 0.0508, 0.0278]), new_distribution = tensor([0.9217, 0.0506, 0.0277])
2024-12-05 15:43:25,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 437: ref_distribution = tensor([0.9217, 0.0506, 0.0277]), new_distribution = tensor([0.9219, 0.0504, 0.0276])
2024-12-05 15:43:25,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 438: ref_distribution = tensor([0.9219, 0.0504, 0.0276]), new_distribution = tensor([0.9222, 0.0503, 0.0275])
2024-12-05 15:43:25,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 439: ref_distribution = tensor([0.9222, 0.0503, 0.0275]), new_distribution = tensor([0.9225, 0.0501, 0.0275])
2024-12-05 15:43:25,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 440: ref_distribution = tensor([0.9225, 0.0501, 0.0275]), new_distribution = tensor([0.9227, 0.0499, 0.0274])
2024-12-05 15:43:25,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 441: ref_distribution = tensor([0.9227, 0.0499, 0.0274]), new_distribution = tensor([0.9230, 0.0497, 0.0273])
2024-12-05 15:43:25,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 442: ref_distribution = tensor([0.9230, 0.0497, 0.0273]), new_distribution = tensor([0.9232, 0.0495, 0.0272])
2024-12-05 15:43:25,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 443: ref_distribution = tensor([0.9232, 0.0495, 0.0272]), new_distribution = tensor([0.9235, 0.0494, 0.0271])
2024-12-05 15:43:25,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 444: ref_distribution = tensor([0.9235, 0.0494, 0.0271]), new_distribution = tensor([0.9238, 0.0492, 0.0271])
2024-12-05 15:43:25,442 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 445: ref_distribution = tensor([0.9238, 0.0492, 0.0271]), new_distribution = tensor([0.9240, 0.0490, 0.0270])
2024-12-05 15:43:25,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 446: ref_distribution = tensor([0.9240, 0.0490, 0.0270]), new_distribution = tensor([0.9243, 0.0488, 0.0269])
2024-12-05 15:43:25,551 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 447: ref_distribution = tensor([0.9243, 0.0488, 0.0269]), new_distribution = tensor([0.9245, 0.0486, 0.0268])
2024-12-05 15:43:25,605 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 448: ref_distribution = tensor([0.9245, 0.0486, 0.0268]), new_distribution = tensor([0.9248, 0.0485, 0.0267])
2024-12-05 15:43:25,659 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 449: ref_distribution = tensor([0.9248, 0.0485, 0.0267]), new_distribution = tensor([0.9250, 0.0483, 0.0267])
2024-12-05 15:43:25,714 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 450: ref_distribution = tensor([0.9250, 0.0483, 0.0267]), new_distribution = tensor([0.9253, 0.0481, 0.0266])
2024-12-05 15:43:25,768 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 451: ref_distribution = tensor([0.9253, 0.0481, 0.0266]), new_distribution = tensor([0.9256, 0.0479, 0.0265])
2024-12-05 15:43:25,822 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 452: ref_distribution = tensor([0.9256, 0.0479, 0.0265]), new_distribution = tensor([0.9258, 0.0478, 0.0264])
2024-12-05 15:43:25,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 453: ref_distribution = tensor([0.9258, 0.0478, 0.0264]), new_distribution = tensor([0.9261, 0.0476, 0.0263])
2024-12-05 15:43:25,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 454: ref_distribution = tensor([0.9261, 0.0476, 0.0263]), new_distribution = tensor([0.9263, 0.0474, 0.0263])
2024-12-05 15:43:25,985 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 455: ref_distribution = tensor([0.9263, 0.0474, 0.0263]), new_distribution = tensor([0.9266, 0.0473, 0.0262])
2024-12-05 15:43:26,039 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 456: ref_distribution = tensor([0.9266, 0.0473, 0.0262]), new_distribution = tensor([0.9268, 0.0471, 0.0261])
2024-12-05 15:43:26,093 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 457: ref_distribution = tensor([0.9268, 0.0471, 0.0261]), new_distribution = tensor([0.9271, 0.0469, 0.0260])
2024-12-05 15:43:26,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 458: ref_distribution = tensor([0.9271, 0.0469, 0.0260]), new_distribution = tensor([0.9273, 0.0467, 0.0260])
2024-12-05 15:43:26,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 459: ref_distribution = tensor([0.9273, 0.0467, 0.0260]), new_distribution = tensor([0.9275, 0.0466, 0.0259])
2024-12-05 15:43:26,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 460: ref_distribution = tensor([0.9275, 0.0466, 0.0259]), new_distribution = tensor([0.9278, 0.0464, 0.0258])
2024-12-05 15:43:26,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 461: ref_distribution = tensor([0.9278, 0.0464, 0.0258]), new_distribution = tensor([0.9280, 0.0462, 0.0257])
2024-12-05 15:43:26,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 462: ref_distribution = tensor([0.9280, 0.0462, 0.0257]), new_distribution = tensor([0.9283, 0.0461, 0.0256])
2024-12-05 15:43:26,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 463: ref_distribution = tensor([0.9283, 0.0461, 0.0256]), new_distribution = tensor([0.9285, 0.0459, 0.0256])
2024-12-05 15:43:26,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 464: ref_distribution = tensor([0.9285, 0.0459, 0.0256]), new_distribution = tensor([0.9288, 0.0457, 0.0255])
2024-12-05 15:43:26,526 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 465: ref_distribution = tensor([0.9288, 0.0457, 0.0255]), new_distribution = tensor([0.9290, 0.0456, 0.0254])
2024-12-05 15:43:26,581 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 466: ref_distribution = tensor([0.9290, 0.0456, 0.0254]), new_distribution = tensor([0.9292, 0.0454, 0.0253])
2024-12-05 15:43:26,635 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 467: ref_distribution = tensor([0.9292, 0.0454, 0.0253]), new_distribution = tensor([0.9295, 0.0452, 0.0253])
2024-12-05 15:43:26,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 468: ref_distribution = tensor([0.9295, 0.0452, 0.0253]), new_distribution = tensor([0.9297, 0.0451, 0.0252])
2024-12-05 15:43:26,744 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 469: ref_distribution = tensor([0.9297, 0.0451, 0.0252]), new_distribution = tensor([0.9300, 0.0449, 0.0251])
2024-12-05 15:43:26,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 470: ref_distribution = tensor([0.9300, 0.0449, 0.0251]), new_distribution = tensor([0.9302, 0.0448, 0.0250])
2024-12-05 15:43:26,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 471: ref_distribution = tensor([0.9302, 0.0448, 0.0250]), new_distribution = tensor([0.9304, 0.0446, 0.0250])
2024-12-05 15:43:26,907 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 472: ref_distribution = tensor([0.9304, 0.0446, 0.0250]), new_distribution = tensor([0.9307, 0.0444, 0.0249])
2024-12-05 15:43:26,961 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 473: ref_distribution = tensor([0.9307, 0.0444, 0.0249]), new_distribution = tensor([0.9309, 0.0443, 0.0248])
2024-12-05 15:43:27,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 474: ref_distribution = tensor([0.9309, 0.0443, 0.0248]), new_distribution = tensor([0.9311, 0.0441, 0.0247])
2024-12-05 15:43:27,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 475: ref_distribution = tensor([0.9311, 0.0441, 0.0247]), new_distribution = tensor([0.9314, 0.0439, 0.0247])
2024-12-05 15:43:27,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 476: ref_distribution = tensor([0.9314, 0.0439, 0.0247]), new_distribution = tensor([0.9316, 0.0438, 0.0246])
2024-12-05 15:43:27,182 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 477: ref_distribution = tensor([0.9316, 0.0438, 0.0246]), new_distribution = tensor([0.9318, 0.0436, 0.0245])
2024-12-05 15:43:27,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 478: ref_distribution = tensor([0.9318, 0.0436, 0.0245]), new_distribution = tensor([0.9321, 0.0435, 0.0245])
2024-12-05 15:43:27,291 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 479: ref_distribution = tensor([0.9321, 0.0435, 0.0245]), new_distribution = tensor([0.9323, 0.0433, 0.0244])
2024-12-05 15:43:27,345 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 480: ref_distribution = tensor([0.9323, 0.0433, 0.0244]), new_distribution = tensor([0.9325, 0.0431, 0.0243])
2024-12-05 15:43:27,399 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 481: ref_distribution = tensor([0.9325, 0.0431, 0.0243]), new_distribution = tensor([0.9328, 0.0430, 0.0242])
2024-12-05 15:43:27,453 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 482: ref_distribution = tensor([0.9328, 0.0430, 0.0242]), new_distribution = tensor([0.9330, 0.0428, 0.0242])
2024-12-05 15:43:27,508 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 483: ref_distribution = tensor([0.9330, 0.0428, 0.0242]), new_distribution = tensor([0.9332, 0.0427, 0.0241])
2024-12-05 15:43:27,562 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 484: ref_distribution = tensor([0.9332, 0.0427, 0.0241]), new_distribution = tensor([0.9335, 0.0425, 0.0240])
2024-12-05 15:43:27,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 485: ref_distribution = tensor([0.9335, 0.0425, 0.0240]), new_distribution = tensor([0.9337, 0.0424, 0.0240])
2024-12-05 15:43:27,671 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 486: ref_distribution = tensor([0.9337, 0.0424, 0.0240]), new_distribution = tensor([0.9339, 0.0422, 0.0239])
2024-12-05 15:43:27,725 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 487: ref_distribution = tensor([0.9339, 0.0422, 0.0239]), new_distribution = tensor([0.9341, 0.0421, 0.0238])
2024-12-05 15:43:27,779 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 488: ref_distribution = tensor([0.9341, 0.0421, 0.0238]), new_distribution = tensor([0.9344, 0.0419, 0.0237])
2024-12-05 15:43:27,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 489: ref_distribution = tensor([0.9344, 0.0419, 0.0237]), new_distribution = tensor([0.9346, 0.0417, 0.0237])
2024-12-05 15:43:27,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 490: ref_distribution = tensor([0.9346, 0.0417, 0.0237]), new_distribution = tensor([0.9348, 0.0416, 0.0236])
2024-12-05 15:43:27,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 491: ref_distribution = tensor([0.9348, 0.0416, 0.0236]), new_distribution = tensor([0.9350, 0.0414, 0.0235])
2024-12-05 15:43:27,996 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 492: ref_distribution = tensor([0.9350, 0.0414, 0.0235]), new_distribution = tensor([0.9352, 0.0413, 0.0235])
2024-12-05 15:43:28,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 493: ref_distribution = tensor([0.9352, 0.0413, 0.0235]), new_distribution = tensor([0.9355, 0.0411, 0.0234])
2024-12-05 15:43:28,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 494: ref_distribution = tensor([0.9355, 0.0411, 0.0234]), new_distribution = tensor([0.9357, 0.0410, 0.0233])
2024-12-05 15:43:28,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 495: ref_distribution = tensor([0.9357, 0.0410, 0.0233]), new_distribution = tensor([0.9359, 0.0408, 0.0233])
2024-12-05 15:43:28,213 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 496: ref_distribution = tensor([0.9359, 0.0408, 0.0233]), new_distribution = tensor([0.9361, 0.0407, 0.0232])
2024-12-05 15:43:28,267 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 497: ref_distribution = tensor([0.9361, 0.0407, 0.0232]), new_distribution = tensor([0.9363, 0.0405, 0.0231])
2024-12-05 15:43:28,322 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 498: ref_distribution = tensor([0.9363, 0.0405, 0.0231]), new_distribution = tensor([0.9366, 0.0404, 0.0230])
2024-12-05 15:43:28,376 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 499: ref_distribution = tensor([0.9366, 0.0404, 0.0230]), new_distribution = tensor([0.9368, 0.0402, 0.0230])
2024-12-05 15:43:28,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 500: ref_distribution = tensor([0.9368, 0.0402, 0.0230]), new_distribution = tensor([0.9370, 0.0401, 0.0229])
2024-12-05 15:43:28,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 501: ref_distribution = tensor([0.9370, 0.0401, 0.0229]), new_distribution = tensor([0.9372, 0.0399, 0.0228])
2024-12-05 15:43:28,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 502: ref_distribution = tensor([0.9372, 0.0399, 0.0228]), new_distribution = tensor([0.9374, 0.0398, 0.0228])
2024-12-05 15:43:28,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 503: ref_distribution = tensor([0.9374, 0.0398, 0.0228]), new_distribution = tensor([0.9376, 0.0397, 0.0227])
2024-12-05 15:43:28,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 504: ref_distribution = tensor([0.9376, 0.0397, 0.0227]), new_distribution = tensor([0.9379, 0.0395, 0.0226])
2024-12-05 15:43:28,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 505: ref_distribution = tensor([0.9379, 0.0395, 0.0226]), new_distribution = tensor([0.9381, 0.0394, 0.0226])
2024-12-05 15:43:28,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 506: ref_distribution = tensor([0.9381, 0.0394, 0.0226]), new_distribution = tensor([0.9383, 0.0392, 0.0225])
2024-12-05 15:43:28,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 507: ref_distribution = tensor([0.9383, 0.0392, 0.0225]), new_distribution = tensor([0.9385, 0.0391, 0.0224])
2024-12-05 15:43:28,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 508: ref_distribution = tensor([0.9385, 0.0391, 0.0224]), new_distribution = tensor([0.9387, 0.0389, 0.0224])
2024-12-05 15:43:28,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 509: ref_distribution = tensor([0.9387, 0.0389, 0.0224]), new_distribution = tensor([0.9389, 0.0388, 0.0223])
2024-12-05 15:43:28,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 510: ref_distribution = tensor([0.9389, 0.0388, 0.0223]), new_distribution = tensor([0.9391, 0.0386, 0.0222])
2024-12-05 15:43:29,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 511: ref_distribution = tensor([0.9391, 0.0386, 0.0222]), new_distribution = tensor([0.9393, 0.0385, 0.0222])
2024-12-05 15:43:29,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 512: ref_distribution = tensor([0.9393, 0.0385, 0.0222]), new_distribution = tensor([0.9395, 0.0384, 0.0221])
2024-12-05 15:43:29,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 513: ref_distribution = tensor([0.9395, 0.0384, 0.0221]), new_distribution = tensor([0.9397, 0.0382, 0.0220])
2024-12-05 15:43:29,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 514: ref_distribution = tensor([0.9397, 0.0382, 0.0220]), new_distribution = tensor([0.9399, 0.0381, 0.0220])
2024-12-05 15:43:29,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 515: ref_distribution = tensor([0.9399, 0.0381, 0.0220]), new_distribution = tensor([0.9401, 0.0379, 0.0219])
2024-12-05 15:43:29,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 516: ref_distribution = tensor([0.9401, 0.0379, 0.0219]), new_distribution = tensor([0.9404, 0.0378, 0.0218])
2024-12-05 15:43:29,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 517: ref_distribution = tensor([0.9404, 0.0378, 0.0218]), new_distribution = tensor([0.9406, 0.0377, 0.0218])
2024-12-05 15:43:29,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 518: ref_distribution = tensor([0.9406, 0.0377, 0.0218]), new_distribution = tensor([0.9408, 0.0375, 0.0217])
2024-12-05 15:43:29,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 519: ref_distribution = tensor([0.9408, 0.0375, 0.0217]), new_distribution = tensor([0.9410, 0.0374, 0.0217])
2024-12-05 15:43:29,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 520: ref_distribution = tensor([0.9410, 0.0374, 0.0217]), new_distribution = tensor([0.9412, 0.0372, 0.0216])
2024-12-05 15:43:29,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 521: ref_distribution = tensor([0.9412, 0.0372, 0.0216]), new_distribution = tensor([0.9414, 0.0371, 0.0215])
2024-12-05 15:43:29,624 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 522: ref_distribution = tensor([0.9414, 0.0371, 0.0215]), new_distribution = tensor([0.9416, 0.0370, 0.0215])
2024-12-05 15:43:29,678 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 523: ref_distribution = tensor([0.9416, 0.0370, 0.0215]), new_distribution = tensor([0.9418, 0.0368, 0.0214])
2024-12-05 15:43:29,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 524: ref_distribution = tensor([0.9418, 0.0368, 0.0214]), new_distribution = tensor([0.9420, 0.0367, 0.0213])
2024-12-05 15:43:29,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 525: ref_distribution = tensor([0.9420, 0.0367, 0.0213]), new_distribution = tensor([0.9422, 0.0366, 0.0213])
2024-12-05 15:43:29,842 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 526: ref_distribution = tensor([0.9422, 0.0366, 0.0213]), new_distribution = tensor([0.9424, 0.0364, 0.0212])
2024-12-05 15:43:29,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 527: ref_distribution = tensor([0.9424, 0.0364, 0.0212]), new_distribution = tensor([0.9426, 0.0363, 0.0211])
2024-12-05 15:43:29,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 528: ref_distribution = tensor([0.9426, 0.0363, 0.0211]), new_distribution = tensor([0.9428, 0.0362, 0.0211])
2024-12-05 15:43:30,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 529: ref_distribution = tensor([0.9428, 0.0362, 0.0211]), new_distribution = tensor([0.9430, 0.0360, 0.0210])
2024-12-05 15:43:30,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 530: ref_distribution = tensor([0.9430, 0.0360, 0.0210]), new_distribution = tensor([0.9432, 0.0359, 0.0210])
2024-12-05 15:43:30,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 531: ref_distribution = tensor([0.9432, 0.0359, 0.0210]), new_distribution = tensor([0.9433, 0.0358, 0.0209])
2024-12-05 15:43:30,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 532: ref_distribution = tensor([0.9433, 0.0358, 0.0209]), new_distribution = tensor([0.9435, 0.0356, 0.0208])
2024-12-05 15:43:30,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 533: ref_distribution = tensor([0.9435, 0.0356, 0.0208]), new_distribution = tensor([0.9437, 0.0355, 0.0208])
2024-12-05 15:43:30,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 534: ref_distribution = tensor([0.9437, 0.0355, 0.0208]), new_distribution = tensor([0.9439, 0.0354, 0.0207])
2024-12-05 15:43:30,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 535: ref_distribution = tensor([0.9439, 0.0354, 0.0207]), new_distribution = tensor([0.9441, 0.0352, 0.0206])
2024-12-05 15:43:30,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 536: ref_distribution = tensor([0.9441, 0.0352, 0.0206]), new_distribution = tensor([0.9443, 0.0351, 0.0206])
2024-12-05 15:43:30,439 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 537: ref_distribution = tensor([0.9443, 0.0351, 0.0206]), new_distribution = tensor([0.9445, 0.0350, 0.0205])
2024-12-05 15:43:30,493 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 538: ref_distribution = tensor([0.9445, 0.0350, 0.0205]), new_distribution = tensor([0.9447, 0.0348, 0.0205])
2024-12-05 15:43:30,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 539: ref_distribution = tensor([0.9447, 0.0348, 0.0205]), new_distribution = tensor([0.9449, 0.0347, 0.0204])
2024-12-05 15:43:30,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 540: ref_distribution = tensor([0.9449, 0.0347, 0.0204]), new_distribution = tensor([0.9451, 0.0346, 0.0203])
2024-12-05 15:43:30,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 541: ref_distribution = tensor([0.9451, 0.0346, 0.0203]), new_distribution = tensor([0.9453, 0.0345, 0.0203])
2024-12-05 15:43:30,711 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 542: ref_distribution = tensor([0.9453, 0.0345, 0.0203]), new_distribution = tensor([0.9455, 0.0343, 0.0202])
2024-12-05 15:43:30,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 543: ref_distribution = tensor([0.9455, 0.0343, 0.0202]), new_distribution = tensor([0.9456, 0.0342, 0.0202])
2024-12-05 15:43:30,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 544: ref_distribution = tensor([0.9456, 0.0342, 0.0202]), new_distribution = tensor([0.9458, 0.0341, 0.0201])
2024-12-05 15:43:30,873 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 545: ref_distribution = tensor([0.9458, 0.0341, 0.0201]), new_distribution = tensor([0.9460, 0.0339, 0.0200])
2024-12-05 15:43:30,928 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 546: ref_distribution = tensor([0.9460, 0.0339, 0.0200]), new_distribution = tensor([0.9462, 0.0338, 0.0200])
2024-12-05 15:43:30,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 547: ref_distribution = tensor([0.9462, 0.0338, 0.0200]), new_distribution = tensor([0.9464, 0.0337, 0.0199])
2024-12-05 15:43:31,036 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 548: ref_distribution = tensor([0.9464, 0.0337, 0.0199]), new_distribution = tensor([0.9466, 0.0336, 0.0199])
2024-12-05 15:43:31,091 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 549: ref_distribution = tensor([0.9466, 0.0336, 0.0199]), new_distribution = tensor([0.9468, 0.0334, 0.0198])
2024-12-05 15:43:31,145 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 550: ref_distribution = tensor([0.9468, 0.0334, 0.0198]), new_distribution = tensor([0.9469, 0.0333, 0.0197])
2024-12-05 15:43:31,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 551: ref_distribution = tensor([0.9469, 0.0333, 0.0197]), new_distribution = tensor([0.9471, 0.0332, 0.0197])
2024-12-05 15:43:31,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 552: ref_distribution = tensor([0.9471, 0.0332, 0.0197]), new_distribution = tensor([0.9473, 0.0331, 0.0196])
2024-12-05 15:43:31,309 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 553: ref_distribution = tensor([0.9473, 0.0331, 0.0196]), new_distribution = tensor([0.9475, 0.0329, 0.0196])
2024-12-05 15:43:31,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 554: ref_distribution = tensor([0.9475, 0.0329, 0.0196]), new_distribution = tensor([0.9477, 0.0328, 0.0195])
2024-12-05 15:43:31,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 555: ref_distribution = tensor([0.9477, 0.0328, 0.0195]), new_distribution = tensor([0.9478, 0.0327, 0.0195])
2024-12-05 15:43:31,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 556: ref_distribution = tensor([0.9478, 0.0327, 0.0195]), new_distribution = tensor([0.9480, 0.0326, 0.0194])
2024-12-05 15:43:31,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 557: ref_distribution = tensor([0.9480, 0.0326, 0.0194]), new_distribution = tensor([0.9482, 0.0325, 0.0193])
2024-12-05 15:43:31,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 558: ref_distribution = tensor([0.9482, 0.0325, 0.0193]), new_distribution = tensor([0.9484, 0.0323, 0.0193])
2024-12-05 15:43:31,634 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 559: ref_distribution = tensor([0.9484, 0.0323, 0.0193]), new_distribution = tensor([0.9486, 0.0322, 0.0192])
2024-12-05 15:43:31,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 560: ref_distribution = tensor([0.9486, 0.0322, 0.0192]), new_distribution = tensor([0.9487, 0.0321, 0.0192])
2024-12-05 15:43:31,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 561: ref_distribution = tensor([0.9487, 0.0321, 0.0192]), new_distribution = tensor([0.9489, 0.0320, 0.0191])
2024-12-05 15:43:31,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 562: ref_distribution = tensor([0.9489, 0.0320, 0.0191]), new_distribution = tensor([0.9491, 0.0319, 0.0191])
2024-12-05 15:43:31,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 563: ref_distribution = tensor([0.9491, 0.0319, 0.0191]), new_distribution = tensor([0.9493, 0.0317, 0.0190])
2024-12-05 15:43:31,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 564: ref_distribution = tensor([0.9493, 0.0317, 0.0190]), new_distribution = tensor([0.9494, 0.0316, 0.0189])
2024-12-05 15:43:31,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 565: ref_distribution = tensor([0.9494, 0.0316, 0.0189]), new_distribution = tensor([0.9496, 0.0315, 0.0189])
2024-12-05 15:43:32,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 566: ref_distribution = tensor([0.9496, 0.0315, 0.0189]), new_distribution = tensor([0.9498, 0.0314, 0.0188])
2024-12-05 15:43:32,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 567: ref_distribution = tensor([0.9498, 0.0314, 0.0188]), new_distribution = tensor([0.9500, 0.0313, 0.0188])
2024-12-05 15:43:32,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 568: ref_distribution = tensor([0.9500, 0.0313, 0.0188]), new_distribution = tensor([0.9501, 0.0312, 0.0187])
2024-12-05 15:43:32,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 569: ref_distribution = tensor([0.9501, 0.0312, 0.0187]), new_distribution = tensor([0.9503, 0.0310, 0.0187])
2024-12-05 15:43:32,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 570: ref_distribution = tensor([0.9503, 0.0310, 0.0187]), new_distribution = tensor([0.9505, 0.0309, 0.0186])
2024-12-05 15:43:32,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 571: ref_distribution = tensor([0.9505, 0.0309, 0.0186]), new_distribution = tensor([0.9506, 0.0308, 0.0186])
2024-12-05 15:43:32,342 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 572: ref_distribution = tensor([0.9506, 0.0308, 0.0186]), new_distribution = tensor([0.9508, 0.0307, 0.0185])
2024-12-05 15:43:32,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 573: ref_distribution = tensor([0.9508, 0.0307, 0.0185]), new_distribution = tensor([0.9510, 0.0306, 0.0184])
2024-12-05 15:43:32,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 574: ref_distribution = tensor([0.9510, 0.0306, 0.0184]), new_distribution = tensor([0.9512, 0.0305, 0.0184])
2024-12-05 15:43:32,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 575: ref_distribution = tensor([0.9512, 0.0305, 0.0184]), new_distribution = tensor([0.9513, 0.0303, 0.0183])
2024-12-05 15:43:32,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 576: ref_distribution = tensor([0.9513, 0.0303, 0.0183]), new_distribution = tensor([0.9515, 0.0302, 0.0183])
2024-12-05 15:43:32,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 577: ref_distribution = tensor([0.9515, 0.0302, 0.0183]), new_distribution = tensor([0.9517, 0.0301, 0.0182])
2024-12-05 15:43:32,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 578: ref_distribution = tensor([0.9517, 0.0301, 0.0182]), new_distribution = tensor([0.9518, 0.0300, 0.0182])
2024-12-05 15:43:32,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 579: ref_distribution = tensor([0.9518, 0.0300, 0.0182]), new_distribution = tensor([0.9520, 0.0299, 0.0181])
2024-12-05 15:43:32,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 580: ref_distribution = tensor([0.9520, 0.0299, 0.0181]), new_distribution = tensor([0.9522, 0.0298, 0.0181])
2024-12-05 15:43:32,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 581: ref_distribution = tensor([0.9522, 0.0298, 0.0181]), new_distribution = tensor([0.9523, 0.0297, 0.0180])
2024-12-05 15:43:32,884 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 582: ref_distribution = tensor([0.9523, 0.0297, 0.0180]), new_distribution = tensor([0.9525, 0.0296, 0.0180])
2024-12-05 15:43:32,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 583: ref_distribution = tensor([0.9525, 0.0296, 0.0180]), new_distribution = tensor([0.9527, 0.0294, 0.0179])
2024-12-05 15:43:32,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 584: ref_distribution = tensor([0.9527, 0.0294, 0.0179]), new_distribution = tensor([0.9528, 0.0293, 0.0178])
2024-12-05 15:43:33,046 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 585: ref_distribution = tensor([0.9528, 0.0293, 0.0178]), new_distribution = tensor([0.9530, 0.0292, 0.0178])
2024-12-05 15:43:33,100 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 586: ref_distribution = tensor([0.9530, 0.0292, 0.0178]), new_distribution = tensor([0.9531, 0.0291, 0.0177])
2024-12-05 15:43:33,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 587: ref_distribution = tensor([0.9531, 0.0291, 0.0177]), new_distribution = tensor([0.9533, 0.0290, 0.0177])
2024-12-05 15:43:33,209 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 588: ref_distribution = tensor([0.9533, 0.0290, 0.0177]), new_distribution = tensor([0.9535, 0.0289, 0.0176])
2024-12-05 15:43:33,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 589: ref_distribution = tensor([0.9535, 0.0289, 0.0176]), new_distribution = tensor([0.9536, 0.0288, 0.0176])
2024-12-05 15:43:33,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 590: ref_distribution = tensor([0.9536, 0.0288, 0.0176]), new_distribution = tensor([0.9538, 0.0287, 0.0175])
2024-12-05 15:43:33,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 591: ref_distribution = tensor([0.9538, 0.0287, 0.0175]), new_distribution = tensor([0.9539, 0.0286, 0.0175])
2024-12-05 15:43:33,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 592: ref_distribution = tensor([0.9539, 0.0286, 0.0175]), new_distribution = tensor([0.9541, 0.0285, 0.0174])
2024-12-05 15:43:33,480 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 593: ref_distribution = tensor([0.9541, 0.0285, 0.0174]), new_distribution = tensor([0.9543, 0.0284, 0.0174])
2024-12-05 15:43:33,534 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 594: ref_distribution = tensor([0.9543, 0.0284, 0.0174]), new_distribution = tensor([0.9544, 0.0283, 0.0173])
2024-12-05 15:43:33,589 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 595: ref_distribution = tensor([0.9544, 0.0283, 0.0173]), new_distribution = tensor([0.9546, 0.0281, 0.0173])
2024-12-05 15:43:33,643 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 596: ref_distribution = tensor([0.9546, 0.0281, 0.0173]), new_distribution = tensor([0.9547, 0.0280, 0.0172])
2024-12-05 15:43:33,697 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 597: ref_distribution = tensor([0.9547, 0.0280, 0.0172]), new_distribution = tensor([0.9549, 0.0279, 0.0172])
2024-12-05 15:43:33,751 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 598: ref_distribution = tensor([0.9549, 0.0279, 0.0172]), new_distribution = tensor([0.9551, 0.0278, 0.0171])
2024-12-05 15:43:33,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 599: ref_distribution = tensor([0.9551, 0.0278, 0.0171]), new_distribution = tensor([0.9552, 0.0277, 0.0171])
2024-12-05 15:43:33,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 600: ref_distribution = tensor([0.9552, 0.0277, 0.0171]), new_distribution = tensor([0.9554, 0.0276, 0.0170])
2024-12-05 15:43:33,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 601: ref_distribution = tensor([0.9554, 0.0276, 0.0170]), new_distribution = tensor([0.9555, 0.0275, 0.0170])
2024-12-05 15:43:33,968 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 602: ref_distribution = tensor([0.9555, 0.0275, 0.0170]), new_distribution = tensor([0.9557, 0.0274, 0.0169])
2024-12-05 15:43:34,022 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 603: ref_distribution = tensor([0.9557, 0.0274, 0.0169]), new_distribution = tensor([0.9558, 0.0273, 0.0169])
2024-12-05 15:43:34,076 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 604: ref_distribution = tensor([0.9558, 0.0273, 0.0169]), new_distribution = tensor([0.9560, 0.0272, 0.0168])
2024-12-05 15:43:34,130 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 605: ref_distribution = tensor([0.9560, 0.0272, 0.0168]), new_distribution = tensor([0.9561, 0.0271, 0.0168])
2024-12-05 15:43:34,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 606: ref_distribution = tensor([0.9561, 0.0271, 0.0168]), new_distribution = tensor([0.9563, 0.0270, 0.0167])
2024-12-05 15:43:34,239 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 607: ref_distribution = tensor([0.9563, 0.0270, 0.0167]), new_distribution = tensor([0.9564, 0.0269, 0.0167])
2024-12-05 15:43:34,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 608: ref_distribution = tensor([0.9564, 0.0269, 0.0167]), new_distribution = tensor([0.9566, 0.0268, 0.0166])
2024-12-05 15:43:34,348 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 609: ref_distribution = tensor([0.9566, 0.0268, 0.0166]), new_distribution = tensor([0.9567, 0.0267, 0.0166])
2024-12-05 15:43:34,402 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 610: ref_distribution = tensor([0.9567, 0.0267, 0.0166]), new_distribution = tensor([0.9569, 0.0266, 0.0165])
2024-12-05 15:43:34,456 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 611: ref_distribution = tensor([0.9569, 0.0266, 0.0165]), new_distribution = tensor([0.9570, 0.0265, 0.0165])
2024-12-05 15:43:34,511 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 612: ref_distribution = tensor([0.9570, 0.0265, 0.0165]), new_distribution = tensor([0.9572, 0.0264, 0.0164])
2024-12-05 15:43:34,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 613: ref_distribution = tensor([0.9572, 0.0264, 0.0164]), new_distribution = tensor([0.9573, 0.0263, 0.0164])
2024-12-05 15:43:34,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 614: ref_distribution = tensor([0.9573, 0.0263, 0.0164]), new_distribution = tensor([0.9575, 0.0262, 0.0163])
2024-12-05 15:43:34,673 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 615: ref_distribution = tensor([0.9575, 0.0262, 0.0163]), new_distribution = tensor([0.9576, 0.0261, 0.0163])
2024-12-05 15:43:34,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 616: ref_distribution = tensor([0.9576, 0.0261, 0.0163]), new_distribution = tensor([0.9578, 0.0260, 0.0162])
2024-12-05 15:43:34,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 617: ref_distribution = tensor([0.9578, 0.0260, 0.0162]), new_distribution = tensor([0.9579, 0.0259, 0.0162])
2024-12-05 15:43:34,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 618: ref_distribution = tensor([0.9579, 0.0259, 0.0162]), new_distribution = tensor([0.9581, 0.0258, 0.0161])
2024-12-05 15:43:34,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 619: ref_distribution = tensor([0.9581, 0.0258, 0.0161]), new_distribution = tensor([0.9582, 0.0257, 0.0161])
2024-12-05 15:43:34,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 620: ref_distribution = tensor([0.9582, 0.0257, 0.0161]), new_distribution = tensor([0.9584, 0.0256, 0.0160])
2024-12-05 15:43:34,998 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 621: ref_distribution = tensor([0.9584, 0.0256, 0.0160]), new_distribution = tensor([0.9585, 0.0255, 0.0160])
2024-12-05 15:43:35,053 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 622: ref_distribution = tensor([0.9585, 0.0255, 0.0160]), new_distribution = tensor([0.9586, 0.0254, 0.0159])
2024-12-05 15:43:35,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 623: ref_distribution = tensor([0.9586, 0.0254, 0.0159]), new_distribution = tensor([0.9588, 0.0253, 0.0159])
2024-12-05 15:43:35,161 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 624: ref_distribution = tensor([0.9588, 0.0253, 0.0159]), new_distribution = tensor([0.9589, 0.0252, 0.0158])
2024-12-05 15:43:35,215 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 625: ref_distribution = tensor([0.9589, 0.0252, 0.0158]), new_distribution = tensor([0.9591, 0.0251, 0.0158])
2024-12-05 15:43:35,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 626: ref_distribution = tensor([0.9591, 0.0251, 0.0158]), new_distribution = tensor([0.9592, 0.0250, 0.0157])
2024-12-05 15:43:35,324 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 627: ref_distribution = tensor([0.9592, 0.0250, 0.0157]), new_distribution = tensor([0.9594, 0.0249, 0.0157])
2024-12-05 15:43:35,378 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 628: ref_distribution = tensor([0.9594, 0.0249, 0.0157]), new_distribution = tensor([0.9595, 0.0248, 0.0157])
2024-12-05 15:43:35,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 629: ref_distribution = tensor([0.9595, 0.0248, 0.0157]), new_distribution = tensor([0.9596, 0.0248, 0.0156])
2024-12-05 15:43:35,486 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 630: ref_distribution = tensor([0.9596, 0.0248, 0.0156]), new_distribution = tensor([0.9598, 0.0247, 0.0156])
2024-12-05 15:43:35,540 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 631: ref_distribution = tensor([0.9598, 0.0247, 0.0156]), new_distribution = tensor([0.9599, 0.0246, 0.0155])
2024-12-05 15:43:35,594 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 632: ref_distribution = tensor([0.9599, 0.0246, 0.0155]), new_distribution = tensor([0.9601, 0.0245, 0.0155])
2024-12-05 15:43:35,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 633: ref_distribution = tensor([0.9601, 0.0245, 0.0155]), new_distribution = tensor([0.9602, 0.0244, 0.0154])
2024-12-05 15:43:35,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 634: ref_distribution = tensor([0.9602, 0.0244, 0.0154]), new_distribution = tensor([0.9603, 0.0243, 0.0154])
2024-12-05 15:43:35,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 635: ref_distribution = tensor([0.9603, 0.0243, 0.0154]), new_distribution = tensor([0.9605, 0.0242, 0.0153])
2024-12-05 15:43:35,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 636: ref_distribution = tensor([0.9605, 0.0242, 0.0153]), new_distribution = tensor([0.9606, 0.0241, 0.0153])
2024-12-05 15:43:35,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 637: ref_distribution = tensor([0.9606, 0.0241, 0.0153]), new_distribution = tensor([0.9607, 0.0240, 0.0152])
2024-12-05 15:43:35,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 638: ref_distribution = tensor([0.9607, 0.0240, 0.0152]), new_distribution = tensor([0.9609, 0.0239, 0.0152])
2024-12-05 15:43:35,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 639: ref_distribution = tensor([0.9609, 0.0239, 0.0152]), new_distribution = tensor([0.9610, 0.0238, 0.0152])
2024-12-05 15:43:36,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 640: ref_distribution = tensor([0.9610, 0.0238, 0.0152]), new_distribution = tensor([0.9612, 0.0237, 0.0151])
2024-12-05 15:43:36,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 641: ref_distribution = tensor([0.9612, 0.0237, 0.0151]), new_distribution = tensor([0.9613, 0.0237, 0.0151])
2024-12-05 15:43:36,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 642: ref_distribution = tensor([0.9613, 0.0237, 0.0151]), new_distribution = tensor([0.9614, 0.0236, 0.0150])
2024-12-05 15:43:36,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 643: ref_distribution = tensor([0.9614, 0.0236, 0.0150]), new_distribution = tensor([0.9616, 0.0235, 0.0150])
2024-12-05 15:43:36,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 644: ref_distribution = tensor([0.9616, 0.0235, 0.0150]), new_distribution = tensor([0.9617, 0.0234, 0.0149])
2024-12-05 15:43:36,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 645: ref_distribution = tensor([0.9617, 0.0234, 0.0149]), new_distribution = tensor([0.9618, 0.0233, 0.0149])
2024-12-05 15:43:36,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 646: ref_distribution = tensor([0.9618, 0.0233, 0.0149]), new_distribution = tensor([0.9620, 0.0232, 0.0148])
2024-12-05 15:43:36,408 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 647: ref_distribution = tensor([0.9620, 0.0232, 0.0148]), new_distribution = tensor([0.9621, 0.0231, 0.0148])
2024-12-05 15:43:36,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 648: ref_distribution = tensor([0.9621, 0.0231, 0.0148]), new_distribution = tensor([0.9622, 0.0230, 0.0148])
2024-12-05 15:43:36,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 649: ref_distribution = tensor([0.9622, 0.0230, 0.0148]), new_distribution = tensor([0.9624, 0.0229, 0.0147])
2024-12-05 15:43:36,571 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 650: ref_distribution = tensor([0.9624, 0.0229, 0.0147]), new_distribution = tensor([0.9625, 0.0229, 0.0147])
2024-12-05 15:43:36,625 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 651: ref_distribution = tensor([0.9625, 0.0229, 0.0147]), new_distribution = tensor([0.9626, 0.0228, 0.0146])
2024-12-05 15:43:36,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 652: ref_distribution = tensor([0.9626, 0.0228, 0.0146]), new_distribution = tensor([0.9627, 0.0227, 0.0146])
2024-12-05 15:43:36,734 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 653: ref_distribution = tensor([0.9627, 0.0227, 0.0146]), new_distribution = tensor([0.9629, 0.0226, 0.0145])
2024-12-05 15:43:36,788 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 654: ref_distribution = tensor([0.9629, 0.0226, 0.0145]), new_distribution = tensor([0.9630, 0.0225, 0.0145])
2024-12-05 15:43:36,842 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 655: ref_distribution = tensor([0.9630, 0.0225, 0.0145]), new_distribution = tensor([0.9631, 0.0224, 0.0144])
2024-12-05 15:43:36,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 656: ref_distribution = tensor([0.9631, 0.0224, 0.0144]), new_distribution = tensor([0.9633, 0.0223, 0.0144])
2024-12-05 15:43:36,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 657: ref_distribution = tensor([0.9633, 0.0223, 0.0144]), new_distribution = tensor([0.9634, 0.0223, 0.0144])
2024-12-05 15:43:37,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 658: ref_distribution = tensor([0.9634, 0.0223, 0.0144]), new_distribution = tensor([0.9635, 0.0222, 0.0143])
2024-12-05 15:43:37,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 659: ref_distribution = tensor([0.9635, 0.0222, 0.0143]), new_distribution = tensor([0.9636, 0.0221, 0.0143])
2024-12-05 15:43:37,116 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 660: ref_distribution = tensor([0.9636, 0.0221, 0.0143]), new_distribution = tensor([0.9638, 0.0220, 0.0142])
2024-12-05 15:43:37,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 661: ref_distribution = tensor([0.9638, 0.0220, 0.0142]), new_distribution = tensor([0.9639, 0.0219, 0.0142])
2024-12-05 15:43:37,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 662: ref_distribution = tensor([0.9639, 0.0219, 0.0142]), new_distribution = tensor([0.9640, 0.0218, 0.0141])
2024-12-05 15:43:37,281 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 663: ref_distribution = tensor([0.9640, 0.0218, 0.0141]), new_distribution = tensor([0.9641, 0.0218, 0.0141])
2024-12-05 15:43:37,335 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 664: ref_distribution = tensor([0.9641, 0.0218, 0.0141]), new_distribution = tensor([0.9643, 0.0217, 0.0141])
2024-12-05 15:43:37,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 665: ref_distribution = tensor([0.9643, 0.0217, 0.0141]), new_distribution = tensor([0.9644, 0.0216, 0.0140])
2024-12-05 15:43:37,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 666: ref_distribution = tensor([0.9644, 0.0216, 0.0140]), new_distribution = tensor([0.9645, 0.0215, 0.0140])
2024-12-05 15:43:37,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 667: ref_distribution = tensor([0.9645, 0.0215, 0.0140]), new_distribution = tensor([0.9646, 0.0214, 0.0139])
2024-12-05 15:43:37,552 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 668: ref_distribution = tensor([0.9646, 0.0214, 0.0139]), new_distribution = tensor([0.9648, 0.0213, 0.0139])
2024-12-05 15:43:37,607 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 669: ref_distribution = tensor([0.9648, 0.0213, 0.0139]), new_distribution = tensor([0.9649, 0.0213, 0.0139])
2024-12-05 15:43:37,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 670: ref_distribution = tensor([0.9649, 0.0213, 0.0139]), new_distribution = tensor([0.9650, 0.0212, 0.0138])
2024-12-05 15:43:37,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 671: ref_distribution = tensor([0.9650, 0.0212, 0.0138]), new_distribution = tensor([0.9651, 0.0211, 0.0138])
2024-12-05 15:43:37,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 672: ref_distribution = tensor([0.9651, 0.0211, 0.0138]), new_distribution = tensor([0.9653, 0.0210, 0.0137])
2024-12-05 15:43:37,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 673: ref_distribution = tensor([0.9653, 0.0210, 0.0137]), new_distribution = tensor([0.9654, 0.0209, 0.0137])
2024-12-05 15:43:37,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 674: ref_distribution = tensor([0.9654, 0.0209, 0.0137]), new_distribution = tensor([0.9655, 0.0209, 0.0137])
2024-12-05 15:43:37,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 675: ref_distribution = tensor([0.9655, 0.0209, 0.0137]), new_distribution = tensor([0.9656, 0.0208, 0.0136])
2024-12-05 15:43:37,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 676: ref_distribution = tensor([0.9656, 0.0208, 0.0136]), new_distribution = tensor([0.9657, 0.0207, 0.0136])
2024-12-05 15:43:38,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 677: ref_distribution = tensor([0.9657, 0.0207, 0.0136]), new_distribution = tensor([0.9659, 0.0206, 0.0135])
2024-12-05 15:43:38,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 678: ref_distribution = tensor([0.9659, 0.0206, 0.0135]), new_distribution = tensor([0.9660, 0.0205, 0.0135])
2024-12-05 15:43:38,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 679: ref_distribution = tensor([0.9660, 0.0205, 0.0135]), new_distribution = tensor([0.9661, 0.0205, 0.0134])
2024-12-05 15:43:38,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 680: ref_distribution = tensor([0.9661, 0.0205, 0.0134]), new_distribution = tensor([0.9662, 0.0204, 0.0134])
2024-12-05 15:43:38,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 681: ref_distribution = tensor([0.9662, 0.0204, 0.0134]), new_distribution = tensor([0.9663, 0.0203, 0.0134])
2024-12-05 15:43:38,313 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 682: ref_distribution = tensor([0.9663, 0.0203, 0.0134]), new_distribution = tensor([0.9664, 0.0202, 0.0133])
2024-12-05 15:43:38,367 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 683: ref_distribution = tensor([0.9664, 0.0202, 0.0133]), new_distribution = tensor([0.9666, 0.0202, 0.0133])
2024-12-05 15:43:38,421 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 684: ref_distribution = tensor([0.9666, 0.0202, 0.0133]), new_distribution = tensor([0.9667, 0.0201, 0.0133])
2024-12-05 15:43:38,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 685: ref_distribution = tensor([0.9667, 0.0201, 0.0133]), new_distribution = tensor([0.9668, 0.0200, 0.0132])
2024-12-05 15:43:38,529 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 686: ref_distribution = tensor([0.9668, 0.0200, 0.0132]), new_distribution = tensor([0.9669, 0.0199, 0.0132])
2024-12-05 15:43:38,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 687: ref_distribution = tensor([0.9669, 0.0199, 0.0132]), new_distribution = tensor([0.9670, 0.0198, 0.0131])
2024-12-05 15:43:38,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 688: ref_distribution = tensor([0.9670, 0.0198, 0.0131]), new_distribution = tensor([0.9671, 0.0198, 0.0131])
2024-12-05 15:43:38,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 689: ref_distribution = tensor([0.9671, 0.0198, 0.0131]), new_distribution = tensor([0.9673, 0.0197, 0.0131])
2024-12-05 15:43:38,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 690: ref_distribution = tensor([0.9673, 0.0197, 0.0131]), new_distribution = tensor([0.9674, 0.0196, 0.0130])
2024-12-05 15:43:38,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 691: ref_distribution = tensor([0.9674, 0.0196, 0.0130]), new_distribution = tensor([0.9675, 0.0195, 0.0130])
2024-12-05 15:43:38,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 692: ref_distribution = tensor([0.9675, 0.0195, 0.0130]), new_distribution = tensor([0.9676, 0.0195, 0.0129])
2024-12-05 15:43:38,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 693: ref_distribution = tensor([0.9676, 0.0195, 0.0129]), new_distribution = tensor([0.9677, 0.0194, 0.0129])
2024-12-05 15:43:38,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 694: ref_distribution = tensor([0.9677, 0.0194, 0.0129]), new_distribution = tensor([0.9678, 0.0193, 0.0129])
2024-12-05 15:43:39,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 695: ref_distribution = tensor([0.9678, 0.0193, 0.0129]), new_distribution = tensor([0.9679, 0.0192, 0.0128])
2024-12-05 15:43:39,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 696: ref_distribution = tensor([0.9679, 0.0192, 0.0128]), new_distribution = tensor([0.9680, 0.0192, 0.0128])
2024-12-05 15:43:39,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 697: ref_distribution = tensor([0.9680, 0.0192, 0.0128]), new_distribution = tensor([0.9682, 0.0191, 0.0127])
2024-12-05 15:43:39,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 698: ref_distribution = tensor([0.9682, 0.0191, 0.0127]), new_distribution = tensor([0.9683, 0.0190, 0.0127])
2024-12-05 15:43:39,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 699: ref_distribution = tensor([0.9683, 0.0190, 0.0127]), new_distribution = tensor([0.9684, 0.0190, 0.0127])
2024-12-05 15:43:39,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:39,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:39,828 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:39,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:39,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:39,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,208 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,262 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,316 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,370 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,424 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,478 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,858 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:40,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,021 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,075 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,129 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,237 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,346 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,400 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,454 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,508 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,562 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,671 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,725 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,779 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:41,996 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,213 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,267 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,321 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,375 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,484 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,538 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,647 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,701 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,810 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,864 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,918 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:42,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,081 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,189 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,243 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,297 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,678 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,895 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:43,949 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,003 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,166 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,708 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,871 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:44,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,088 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,197 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,305 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,360 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:45,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,337 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,445 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:46,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,156 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,210 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,427 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,481 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,588 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,697 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,751 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:47,968 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,022 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,076 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,131 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,185 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,239 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,402 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,456 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,510 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,835 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,889 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,943 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:48,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,214 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,322 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,376 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,647 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,810 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,864 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:49,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,678 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:50,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,002 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,111 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,165 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,219 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,327 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,492 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,708 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,871 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:51,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,304 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,412 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,521 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,575 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,629 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,683 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,738 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,792 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:52,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,116 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,170 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,549 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,875 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:53,983 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,037 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,091 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,146 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,526 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,634 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,743 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,797 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,906 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:54,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,015 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,069 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,232 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,395 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,557 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,611 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,665 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,828 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,936 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:55,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 300: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 301: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 302: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 303: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,208 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 304: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,262 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 305: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,316 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 306: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,374 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 307: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 308: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 309: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 310: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 311: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,647 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 312: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 313: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 314: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 315: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 316: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 317: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:56,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 318: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 319: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 320: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 321: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 322: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 323: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,303 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 324: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 325: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,412 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 326: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 327: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,521 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 328: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,575 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 329: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,629 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 330: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,683 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 331: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,738 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 332: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,792 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 333: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 334: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 335: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:57,955 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 336: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,009 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 337: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 338: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 339: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 340: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 341: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 342: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 343: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 344: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 345: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 346: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,552 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 347: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,606 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 348: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,660 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 349: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,714 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 350: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 351: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 352: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 353: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 354: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:58,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 355: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 356: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 357: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 358: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 359: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 360: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 361: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 362: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 363: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 364: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 365: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 366: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,636 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 367: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,690 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 368: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 369: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 370: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 371: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 372: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:43:59,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 373: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 374: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 375: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 376: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 377: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 378: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 379: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 380: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 381: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 382: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 383: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 384: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 385: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 386: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 387: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 388: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 389: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,884 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 390: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 391: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:00,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 392: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,046 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 393: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,101 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 394: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,155 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 395: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,209 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 396: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 397: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 398: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,371 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 399: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 400: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,480 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 401: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,534 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 402: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,588 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 403: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 404: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 405: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,751 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 406: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 407: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 408: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 409: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:01,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 410: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,021 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 411: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,076 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 412: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,130 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 413: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 414: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 415: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 416: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,346 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 417: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,400 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 418: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,454 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 419: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,509 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 420: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 421: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,617 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 422: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,671 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 423: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 424: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,780 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 425: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,834 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 426: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,888 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 427: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,943 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 428: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:02,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 429: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 430: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 431: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 432: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,214 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 433: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 434: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 435: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 436: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,431 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 437: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 438: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,540 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 439: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,594 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 440: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 441: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 442: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 443: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 444: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 445: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 446: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:03,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 447: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 448: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,081 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 449: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 450: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,189 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 451: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 452: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 453: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 454: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 455: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 456: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 457: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 458: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 459: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 460: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 461: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 462: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 463: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 464: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:04,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 465: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,002 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 466: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 467: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,111 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 468: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,165 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 469: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,219 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 470: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 471: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 472: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 473: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,436 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 474: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,490 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 475: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 476: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,599 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 477: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 478: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 479: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 480: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 481: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 482: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 483: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:05,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 484: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 485: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 486: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 487: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 488: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 489: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 490: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 491: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 492: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 493: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 494: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 495: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 496: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 497: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 498: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,802 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 499: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 500: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,910 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 501: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:06,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 502: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,019 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 503: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,073 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 504: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 505: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 506: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,240 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 507: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,294 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 508: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,348 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 509: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,403 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 510: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 511: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,511 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 512: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 513: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 514: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 515: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,728 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 516: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 517: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 518: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,891 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 519: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,945 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 520: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:07,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 521: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 522: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 523: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,162 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 524: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,216 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 525: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 526: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,324 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 527: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 528: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,433 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 529: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 530: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,542 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 531: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 532: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,650 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 533: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 534: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,758 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 535: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 536: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,867 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 537: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 538: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:08,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 539: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,029 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 540: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 541: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 542: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,193 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 543: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,247 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 544: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,301 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 545: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 546: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,410 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 547: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,464 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 548: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,518 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 549: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,572 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 550: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 551: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 552: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 553: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,789 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 554: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,843 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 555: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 556: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:09,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 557: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 558: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,061 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 559: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,115 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 560: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,169 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 561: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,223 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 562: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,277 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 563: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,332 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 564: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,386 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 565: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 566: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,494 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 567: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,549 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 568: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 569: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,657 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 570: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,711 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 571: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 572: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 573: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 574: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,928 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 575: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:10,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 576: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,036 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 577: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,091 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 578: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,146 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 579: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 580: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 581: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 582: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 583: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 584: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 585: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 586: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 587: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,634 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 588: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 589: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,742 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 590: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 591: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 592: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 593: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:11,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 594: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,013 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 595: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,067 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 596: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,122 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 597: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 598: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,230 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 599: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 600: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 601: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 602: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 603: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,502 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 604: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,556 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 605: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 606: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 607: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 608: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 609: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,827 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 610: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 611: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 612: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:12,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 613: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 614: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 615: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,152 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 616: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,206 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 617: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,260 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 618: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,314 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 619: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,368 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 620: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,423 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 621: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,477 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 622: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,531 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 623: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,585 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 624: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,639 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 625: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 626: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 627: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,802 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 628: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 629: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,910 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 630: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:13,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 631: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 632: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,073 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 633: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,127 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 634: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,181 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 635: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,235 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 636: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 637: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,344 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 638: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,398 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 639: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,452 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 640: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,506 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 641: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 642: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,615 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 643: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,669 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 644: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,724 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 645: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,778 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 646: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,832 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 647: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,886 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 648: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 649: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:14,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 650: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,049 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 651: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,103 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 652: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 653: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 654: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,266 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 655: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,321 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 656: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,375 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 657: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 658: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,483 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 659: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,537 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 660: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,591 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 661: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,646 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 662: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,701 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 663: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 664: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,810 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 665: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,864 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 666: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,918 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 667: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:15,972 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 668: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,026 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 669: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,081 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 670: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 671: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,189 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 672: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,243 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 673: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,297 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 674: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 675: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,405 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 676: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 677: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 678: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,568 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 679: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 680: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 681: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 682: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 683: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 684: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 685: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:16,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 686: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,001 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 687: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 688: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 689: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,168 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 690: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 691: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 692: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 693: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 694: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 695: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,493 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 696: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 697: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 698: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 699: ref_distribution = tensor([1., 0., 0.]), new_distribution = tensor([1., 0., 0.])
2024-12-05 15:44:17,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.1000, 0.3000, 0.6000]), new_distribution = tensor([0.1003, 0.3005, 0.5992])
2024-12-05 15:44:17,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.1003, 0.3005, 0.5992]), new_distribution = tensor([0.1006, 0.3009, 0.5984])
2024-12-05 15:44:18,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.1006, 0.3009, 0.5984]), new_distribution = tensor([0.1010, 0.3014, 0.5976])
2024-12-05 15:44:18,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.1010, 0.3014, 0.5976]), new_distribution = tensor([0.1013, 0.3019, 0.5968])
2024-12-05 15:44:18,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.1013, 0.3019, 0.5968]), new_distribution = tensor([0.1016, 0.3024, 0.5960])
2024-12-05 15:44:18,213 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.1016, 0.3024, 0.5960]), new_distribution = tensor([0.1019, 0.3028, 0.5952])
2024-12-05 15:44:18,267 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.1019, 0.3028, 0.5952]), new_distribution = tensor([0.1022, 0.3033, 0.5944])
2024-12-05 15:44:18,321 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.1022, 0.3033, 0.5944]), new_distribution = tensor([0.1026, 0.3038, 0.5936])
2024-12-05 15:44:18,375 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.1026, 0.3038, 0.5936]), new_distribution = tensor([0.1029, 0.3043, 0.5928])
2024-12-05 15:44:18,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.1029, 0.3043, 0.5928]), new_distribution = tensor([0.1032, 0.3047, 0.5920])
2024-12-05 15:44:18,484 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.1032, 0.3047, 0.5920]), new_distribution = tensor([0.1036, 0.3052, 0.5913])
2024-12-05 15:44:18,538 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.1036, 0.3052, 0.5913]), new_distribution = tensor([0.1039, 0.3057, 0.5905])
2024-12-05 15:44:18,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.1039, 0.3057, 0.5905]), new_distribution = tensor([0.1042, 0.3061, 0.5897])
2024-12-05 15:44:18,646 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.1042, 0.3061, 0.5897]), new_distribution = tensor([0.1045, 0.3066, 0.5889])
2024-12-05 15:44:18,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.1045, 0.3066, 0.5889]), new_distribution = tensor([0.1049, 0.3071, 0.5881])
2024-12-05 15:44:18,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.1049, 0.3071, 0.5881]), new_distribution = tensor([0.1052, 0.3075, 0.5872])
2024-12-05 15:44:18,809 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.1052, 0.3075, 0.5872]), new_distribution = tensor([0.1055, 0.3080, 0.5864])
2024-12-05 15:44:18,863 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.1055, 0.3080, 0.5864]), new_distribution = tensor([0.1059, 0.3085, 0.5856])
2024-12-05 15:44:18,918 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.1059, 0.3085, 0.5856]), new_distribution = tensor([0.1062, 0.3089, 0.5848])
2024-12-05 15:44:18,972 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.1062, 0.3089, 0.5848]), new_distribution = tensor([0.1066, 0.3094, 0.5840])
2024-12-05 15:44:19,026 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.1066, 0.3094, 0.5840]), new_distribution = tensor([0.1069, 0.3099, 0.5832])
2024-12-05 15:44:19,080 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.1069, 0.3099, 0.5832]), new_distribution = tensor([0.1072, 0.3103, 0.5824])
2024-12-05 15:44:19,134 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.1072, 0.3103, 0.5824]), new_distribution = tensor([0.1076, 0.3108, 0.5816])
2024-12-05 15:44:19,189 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.1076, 0.3108, 0.5816]), new_distribution = tensor([0.1079, 0.3113, 0.5808])
2024-12-05 15:44:19,243 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.1079, 0.3113, 0.5808]), new_distribution = tensor([0.1083, 0.3117, 0.5800])
2024-12-05 15:44:19,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.1083, 0.3117, 0.5800]), new_distribution = tensor([0.1086, 0.3122, 0.5792])
2024-12-05 15:44:19,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.1086, 0.3122, 0.5792]), new_distribution = tensor([0.1089, 0.3127, 0.5784])
2024-12-05 15:44:19,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.1089, 0.3127, 0.5784]), new_distribution = tensor([0.1093, 0.3131, 0.5776])
2024-12-05 15:44:19,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.1093, 0.3131, 0.5776]), new_distribution = tensor([0.1096, 0.3136, 0.5768])
2024-12-05 15:44:19,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.1096, 0.3136, 0.5768]), new_distribution = tensor([0.1100, 0.3140, 0.5760])
2024-12-05 15:44:19,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.1100, 0.3140, 0.5760]), new_distribution = tensor([0.1103, 0.3145, 0.5752])
2024-12-05 15:44:19,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.1103, 0.3145, 0.5752]), new_distribution = tensor([0.1107, 0.3150, 0.5744])
2024-12-05 15:44:19,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.1107, 0.3150, 0.5744]), new_distribution = tensor([0.1110, 0.3154, 0.5735])
2024-12-05 15:44:19,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.1110, 0.3154, 0.5735]), new_distribution = tensor([0.1114, 0.3159, 0.5727])
2024-12-05 15:44:19,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.1114, 0.3159, 0.5727]), new_distribution = tensor([0.1117, 0.3163, 0.5719])
2024-12-05 15:44:19,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.1117, 0.3163, 0.5719]), new_distribution = tensor([0.1121, 0.3168, 0.5711])
2024-12-05 15:44:19,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.1121, 0.3168, 0.5711]), new_distribution = tensor([0.1124, 0.3173, 0.5703])
2024-12-05 15:44:19,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.1124, 0.3173, 0.5703]), new_distribution = tensor([0.1128, 0.3177, 0.5695])
2024-12-05 15:44:20,002 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.1128, 0.3177, 0.5695]), new_distribution = tensor([0.1132, 0.3182, 0.5687])
2024-12-05 15:44:20,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.1132, 0.3182, 0.5687]), new_distribution = tensor([0.1135, 0.3186, 0.5679])
2024-12-05 15:44:20,111 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.1135, 0.3186, 0.5679]), new_distribution = tensor([0.1139, 0.3191, 0.5670])
2024-12-05 15:44:20,165 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.1139, 0.3191, 0.5670]), new_distribution = tensor([0.1142, 0.3195, 0.5662])
2024-12-05 15:44:20,219 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.1142, 0.3195, 0.5662]), new_distribution = tensor([0.1146, 0.3200, 0.5654])
2024-12-05 15:44:20,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.1146, 0.3200, 0.5654]), new_distribution = tensor([0.1150, 0.3205, 0.5646])
2024-12-05 15:44:20,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.1150, 0.3205, 0.5646]), new_distribution = tensor([0.1153, 0.3209, 0.5638])
2024-12-05 15:44:20,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.1153, 0.3209, 0.5638]), new_distribution = tensor([0.1157, 0.3214, 0.5630])
2024-12-05 15:44:20,436 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.1157, 0.3214, 0.5630]), new_distribution = tensor([0.1160, 0.3218, 0.5621])
2024-12-05 15:44:20,490 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.1160, 0.3218, 0.5621]), new_distribution = tensor([0.1164, 0.3223, 0.5613])
2024-12-05 15:44:20,544 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.1164, 0.3223, 0.5613]), new_distribution = tensor([0.1168, 0.3227, 0.5605])
2024-12-05 15:44:20,599 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.1168, 0.3227, 0.5605]), new_distribution = tensor([0.1172, 0.3232, 0.5597])
2024-12-05 15:44:20,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.1172, 0.3232, 0.5597]), new_distribution = tensor([0.1175, 0.3236, 0.5589])
2024-12-05 15:44:20,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.1175, 0.3236, 0.5589]), new_distribution = tensor([0.1179, 0.3241, 0.5580])
2024-12-05 15:44:20,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.1179, 0.3241, 0.5580]), new_distribution = tensor([0.1183, 0.3245, 0.5572])
2024-12-05 15:44:20,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.1183, 0.3245, 0.5572]), new_distribution = tensor([0.1186, 0.3250, 0.5564])
2024-12-05 15:44:20,871 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.1186, 0.3250, 0.5564]), new_distribution = tensor([0.1190, 0.3254, 0.5556])
2024-12-05 15:44:20,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.1190, 0.3254, 0.5556]), new_distribution = tensor([0.1194, 0.3259, 0.5548])
2024-12-05 15:44:20,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.1194, 0.3259, 0.5548]), new_distribution = tensor([0.1198, 0.3263, 0.5539])
2024-12-05 15:44:21,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.1198, 0.3263, 0.5539]), new_distribution = tensor([0.1201, 0.3267, 0.5531])
2024-12-05 15:44:21,088 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.1201, 0.3267, 0.5531]), new_distribution = tensor([0.1205, 0.3272, 0.5523])
2024-12-05 15:44:21,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.1205, 0.3272, 0.5523]), new_distribution = tensor([0.1209, 0.3276, 0.5515])
2024-12-05 15:44:21,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.1209, 0.3276, 0.5515]), new_distribution = tensor([0.1213, 0.3281, 0.5506])
2024-12-05 15:44:21,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.1213, 0.3281, 0.5506]), new_distribution = tensor([0.1217, 0.3285, 0.5498])
2024-12-05 15:44:21,305 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.1217, 0.3285, 0.5498]), new_distribution = tensor([0.1220, 0.3290, 0.5490])
2024-12-05 15:44:21,359 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.1220, 0.3290, 0.5490]), new_distribution = tensor([0.1224, 0.3294, 0.5482])
2024-12-05 15:44:21,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.1224, 0.3294, 0.5482]), new_distribution = tensor([0.1228, 0.3298, 0.5474])
2024-12-05 15:44:21,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.1228, 0.3298, 0.5474]), new_distribution = tensor([0.1232, 0.3303, 0.5465])
2024-12-05 15:44:21,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.1232, 0.3303, 0.5465]), new_distribution = tensor([0.1236, 0.3307, 0.5457])
2024-12-05 15:44:21,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.1236, 0.3307, 0.5457]), new_distribution = tensor([0.1240, 0.3311, 0.5449])
2024-12-05 15:44:21,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.1240, 0.3311, 0.5449]), new_distribution = tensor([0.1244, 0.3316, 0.5440])
2024-12-05 15:44:21,686 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.1244, 0.3316, 0.5440]), new_distribution = tensor([0.1248, 0.3320, 0.5432])
2024-12-05 15:44:21,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.1248, 0.3320, 0.5432]), new_distribution = tensor([0.1251, 0.3325, 0.5424])
2024-12-05 15:44:21,794 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.1251, 0.3325, 0.5424]), new_distribution = tensor([0.1255, 0.3329, 0.5416])
2024-12-05 15:44:21,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.1255, 0.3329, 0.5416]), new_distribution = tensor([0.1259, 0.3333, 0.5407])
2024-12-05 15:44:21,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.1259, 0.3333, 0.5407]), new_distribution = tensor([0.1263, 0.3338, 0.5399])
2024-12-05 15:44:21,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.1263, 0.3338, 0.5399]), new_distribution = tensor([0.1267, 0.3342, 0.5391])
2024-12-05 15:44:22,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.1267, 0.3342, 0.5391]), new_distribution = tensor([0.1271, 0.3346, 0.5383])
2024-12-05 15:44:22,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.1271, 0.3346, 0.5383]), new_distribution = tensor([0.1275, 0.3350, 0.5374])
2024-12-05 15:44:22,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.1275, 0.3350, 0.5374]), new_distribution = tensor([0.1279, 0.3355, 0.5366])
2024-12-05 15:44:22,174 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.1279, 0.3355, 0.5366]), new_distribution = tensor([0.1283, 0.3359, 0.5358])
2024-12-05 15:44:22,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.1283, 0.3359, 0.5358]), new_distribution = tensor([0.1287, 0.3363, 0.5349])
2024-12-05 15:44:22,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.1287, 0.3363, 0.5349]), new_distribution = tensor([0.1291, 0.3368, 0.5341])
2024-12-05 15:44:22,337 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.1291, 0.3368, 0.5341]), new_distribution = tensor([0.1295, 0.3372, 0.5333])
2024-12-05 15:44:22,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.1295, 0.3372, 0.5333]), new_distribution = tensor([0.1299, 0.3376, 0.5324])
2024-12-05 15:44:22,446 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.1299, 0.3376, 0.5324]), new_distribution = tensor([0.1303, 0.3380, 0.5316])
2024-12-05 15:44:22,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.1303, 0.3380, 0.5316]), new_distribution = tensor([0.1308, 0.3385, 0.5308])
2024-12-05 15:44:22,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.1308, 0.3385, 0.5308]), new_distribution = tensor([0.1312, 0.3389, 0.5300])
2024-12-05 15:44:22,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.1312, 0.3389, 0.5300]), new_distribution = tensor([0.1316, 0.3393, 0.5291])
2024-12-05 15:44:22,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.1316, 0.3393, 0.5291]), new_distribution = tensor([0.1320, 0.3397, 0.5283])
2024-12-05 15:44:22,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.1320, 0.3397, 0.5283]), new_distribution = tensor([0.1324, 0.3401, 0.5275])
2024-12-05 15:44:22,772 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.1324, 0.3401, 0.5275]), new_distribution = tensor([0.1328, 0.3406, 0.5266])
2024-12-05 15:44:22,826 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.1328, 0.3406, 0.5266]), new_distribution = tensor([0.1332, 0.3410, 0.5258])
2024-12-05 15:44:22,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.1332, 0.3410, 0.5258]), new_distribution = tensor([0.1336, 0.3414, 0.5250])
2024-12-05 15:44:22,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.1336, 0.3414, 0.5250]), new_distribution = tensor([0.1341, 0.3418, 0.5241])
2024-12-05 15:44:22,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.1341, 0.3418, 0.5241]), new_distribution = tensor([0.1345, 0.3422, 0.5233])
2024-12-05 15:44:23,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.1345, 0.3422, 0.5233]), new_distribution = tensor([0.1349, 0.3426, 0.5225])
2024-12-05 15:44:23,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.1349, 0.3426, 0.5225]), new_distribution = tensor([0.1353, 0.3431, 0.5216])
2024-12-05 15:44:23,152 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.1353, 0.3431, 0.5216]), new_distribution = tensor([0.1357, 0.3435, 0.5208])
2024-12-05 15:44:23,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.1357, 0.3435, 0.5208]), new_distribution = tensor([0.1362, 0.3439, 0.5200])
2024-12-05 15:44:23,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.1362, 0.3439, 0.5200]), new_distribution = tensor([0.1366, 0.3443, 0.5191])
2024-12-05 15:44:23,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.1366, 0.3443, 0.5191]), new_distribution = tensor([0.1370, 0.3447, 0.5183])
2024-12-05 15:44:23,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([0.1370, 0.3447, 0.5183]), new_distribution = tensor([0.1374, 0.3451, 0.5174])
2024-12-05 15:44:23,424 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([0.1374, 0.3451, 0.5174]), new_distribution = tensor([0.1379, 0.3455, 0.5166])
2024-12-05 15:44:23,478 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([0.1379, 0.3455, 0.5166]), new_distribution = tensor([0.1383, 0.3459, 0.5158])
2024-12-05 15:44:23,532 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([0.1383, 0.3459, 0.5158]), new_distribution = tensor([0.1387, 0.3463, 0.5149])
2024-12-05 15:44:23,586 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([0.1387, 0.3463, 0.5149]), new_distribution = tensor([0.1392, 0.3467, 0.5141])
2024-12-05 15:44:23,640 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([0.1392, 0.3467, 0.5141]), new_distribution = tensor([0.1396, 0.3471, 0.5133])
2024-12-05 15:44:23,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([0.1396, 0.3471, 0.5133]), new_distribution = tensor([0.1400, 0.3475, 0.5124])
2024-12-05 15:44:23,749 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([0.1400, 0.3475, 0.5124]), new_distribution = tensor([0.1405, 0.3479, 0.5116])
2024-12-05 15:44:23,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([0.1405, 0.3479, 0.5116]), new_distribution = tensor([0.1409, 0.3483, 0.5108])
2024-12-05 15:44:23,858 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([0.1409, 0.3483, 0.5108]), new_distribution = tensor([0.1413, 0.3487, 0.5099])
2024-12-05 15:44:23,912 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([0.1413, 0.3487, 0.5099]), new_distribution = tensor([0.1418, 0.3491, 0.5091])
2024-12-05 15:44:23,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([0.1418, 0.3491, 0.5091]), new_distribution = tensor([0.1422, 0.3495, 0.5082])
2024-12-05 15:44:24,021 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([0.1422, 0.3495, 0.5082]), new_distribution = tensor([0.1427, 0.3499, 0.5074])
2024-12-05 15:44:24,075 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([0.1427, 0.3499, 0.5074]), new_distribution = tensor([0.1431, 0.3503, 0.5066])
2024-12-05 15:44:24,129 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([0.1431, 0.3503, 0.5066]), new_distribution = tensor([0.1435, 0.3507, 0.5057])
2024-12-05 15:44:24,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([0.1435, 0.3507, 0.5057]), new_distribution = tensor([0.1440, 0.3511, 0.5049])
2024-12-05 15:44:24,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([0.1440, 0.3511, 0.5049]), new_distribution = tensor([0.1444, 0.3515, 0.5041])
2024-12-05 15:44:24,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([0.1444, 0.3515, 0.5041]), new_distribution = tensor([0.1449, 0.3519, 0.5032])
2024-12-05 15:44:24,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([0.1449, 0.3519, 0.5032]), new_distribution = tensor([0.1453, 0.3523, 0.5024])
2024-12-05 15:44:24,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([0.1453, 0.3523, 0.5024]), new_distribution = tensor([0.1458, 0.3527, 0.5015])
2024-12-05 15:44:24,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([0.1458, 0.3527, 0.5015]), new_distribution = tensor([0.1462, 0.3531, 0.5007])
2024-12-05 15:44:24,510 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([0.1462, 0.3531, 0.5007]), new_distribution = tensor([0.1467, 0.3534, 0.4999])
2024-12-05 15:44:24,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([0.1467, 0.3534, 0.4999]), new_distribution = tensor([0.1471, 0.3538, 0.4990])
2024-12-05 15:44:24,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([0.1471, 0.3538, 0.4990]), new_distribution = tensor([0.1476, 0.3542, 0.4982])
2024-12-05 15:44:24,673 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([0.1476, 0.3542, 0.4982]), new_distribution = tensor([0.1481, 0.3546, 0.4974])
2024-12-05 15:44:24,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([0.1481, 0.3546, 0.4974]), new_distribution = tensor([0.1485, 0.3550, 0.4965])
2024-12-05 15:44:24,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([0.1485, 0.3550, 0.4965]), new_distribution = tensor([0.1490, 0.3554, 0.4957])
2024-12-05 15:44:24,835 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([0.1490, 0.3554, 0.4957]), new_distribution = tensor([0.1494, 0.3557, 0.4948])
2024-12-05 15:44:24,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([0.1494, 0.3557, 0.4948]), new_distribution = tensor([0.1499, 0.3561, 0.4940])
2024-12-05 15:44:24,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([0.1499, 0.3561, 0.4940]), new_distribution = tensor([0.1504, 0.3565, 0.4932])
2024-12-05 15:44:24,998 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([0.1504, 0.3565, 0.4932]), new_distribution = tensor([0.1508, 0.3569, 0.4923])
2024-12-05 15:44:25,053 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([0.1508, 0.3569, 0.4923]), new_distribution = tensor([0.1513, 0.3572, 0.4915])
2024-12-05 15:44:25,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([0.1513, 0.3572, 0.4915]), new_distribution = tensor([0.1517, 0.3576, 0.4906])
2024-12-05 15:44:25,161 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([0.1517, 0.3576, 0.4906]), new_distribution = tensor([0.1522, 0.3580, 0.4898])
2024-12-05 15:44:25,216 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([0.1522, 0.3580, 0.4898]), new_distribution = tensor([0.1527, 0.3584, 0.4890])
2024-12-05 15:44:25,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([0.1527, 0.3584, 0.4890]), new_distribution = tensor([0.1532, 0.3587, 0.4881])
2024-12-05 15:44:25,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([0.1532, 0.3587, 0.4881]), new_distribution = tensor([0.1536, 0.3591, 0.4873])
2024-12-05 15:44:25,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([0.1536, 0.3591, 0.4873]), new_distribution = tensor([0.1541, 0.3595, 0.4864])
2024-12-05 15:44:25,433 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([0.1541, 0.3595, 0.4864]), new_distribution = tensor([0.1546, 0.3598, 0.4856])
2024-12-05 15:44:25,488 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([0.1546, 0.3598, 0.4856]), new_distribution = tensor([0.1550, 0.3602, 0.4848])
2024-12-05 15:44:25,542 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([0.1550, 0.3602, 0.4848]), new_distribution = tensor([0.1555, 0.3605, 0.4839])
2024-12-05 15:44:25,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([0.1555, 0.3605, 0.4839]), new_distribution = tensor([0.1560, 0.3609, 0.4831])
2024-12-05 15:44:25,650 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([0.1560, 0.3609, 0.4831]), new_distribution = tensor([0.1565, 0.3613, 0.4823])
2024-12-05 15:44:25,705 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([0.1565, 0.3613, 0.4823]), new_distribution = tensor([0.1570, 0.3616, 0.4814])
2024-12-05 15:44:25,759 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([0.1570, 0.3616, 0.4814]), new_distribution = tensor([0.1574, 0.3620, 0.4806])
2024-12-05 15:44:25,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([0.1574, 0.3620, 0.4806]), new_distribution = tensor([0.1579, 0.3623, 0.4797])
2024-12-05 15:44:25,867 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([0.1579, 0.3623, 0.4797]), new_distribution = tensor([0.1584, 0.3627, 0.4789])
2024-12-05 15:44:25,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([0.1584, 0.3627, 0.4789]), new_distribution = tensor([0.1589, 0.3631, 0.4781])
2024-12-05 15:44:25,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([0.1589, 0.3631, 0.4781]), new_distribution = tensor([0.1594, 0.3634, 0.4772])
2024-12-05 15:44:26,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([0.1594, 0.3634, 0.4772]), new_distribution = tensor([0.1599, 0.3638, 0.4764])
2024-12-05 15:44:26,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([0.1599, 0.3638, 0.4764]), new_distribution = tensor([0.1604, 0.3641, 0.4755])
2024-12-05 15:44:26,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([0.1604, 0.3641, 0.4755]), new_distribution = tensor([0.1608, 0.3645, 0.4747])
2024-12-05 15:44:26,193 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([0.1608, 0.3645, 0.4747]), new_distribution = tensor([0.1613, 0.3648, 0.4739])
2024-12-05 15:44:26,247 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([0.1613, 0.3648, 0.4739]), new_distribution = tensor([0.1618, 0.3651, 0.4730])
2024-12-05 15:44:26,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([0.1618, 0.3651, 0.4730]), new_distribution = tensor([0.1623, 0.3655, 0.4722])
2024-12-05 15:44:26,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([0.1623, 0.3655, 0.4722]), new_distribution = tensor([0.1628, 0.3658, 0.4713])
2024-12-05 15:44:26,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([0.1628, 0.3658, 0.4713]), new_distribution = tensor([0.1633, 0.3662, 0.4705])
2024-12-05 15:44:26,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([0.1633, 0.3662, 0.4705]), new_distribution = tensor([0.1638, 0.3665, 0.4697])
2024-12-05 15:44:26,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([0.1638, 0.3665, 0.4697]), new_distribution = tensor([0.1643, 0.3669, 0.4688])
2024-12-05 15:44:26,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([0.1643, 0.3669, 0.4688]), new_distribution = tensor([0.1648, 0.3672, 0.4680])
2024-12-05 15:44:26,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([0.1648, 0.3672, 0.4680]), new_distribution = tensor([0.1653, 0.3675, 0.4671])
2024-12-05 15:44:26,682 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([0.1653, 0.3675, 0.4671]), new_distribution = tensor([0.1658, 0.3679, 0.4663])
2024-12-05 15:44:26,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([0.1658, 0.3679, 0.4663]), new_distribution = tensor([0.1663, 0.3682, 0.4655])
2024-12-05 15:44:26,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([0.1663, 0.3682, 0.4655]), new_distribution = tensor([0.1668, 0.3685, 0.4646])
2024-12-05 15:44:26,845 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([0.1668, 0.3685, 0.4646]), new_distribution = tensor([0.1673, 0.3689, 0.4638])
2024-12-05 15:44:26,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([0.1673, 0.3689, 0.4638]), new_distribution = tensor([0.1679, 0.3692, 0.4630])
2024-12-05 15:44:26,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([0.1679, 0.3692, 0.4630]), new_distribution = tensor([0.1684, 0.3695, 0.4621])
2024-12-05 15:44:27,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([0.1684, 0.3695, 0.4621]), new_distribution = tensor([0.1689, 0.3698, 0.4613])
2024-12-05 15:44:27,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([0.1689, 0.3698, 0.4613]), new_distribution = tensor([0.1694, 0.3702, 0.4604])
2024-12-05 15:44:27,119 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([0.1694, 0.3702, 0.4604]), new_distribution = tensor([0.1699, 0.3705, 0.4596])
2024-12-05 15:44:27,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([0.1699, 0.3705, 0.4596]), new_distribution = tensor([0.1704, 0.3708, 0.4588])
2024-12-05 15:44:27,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([0.1704, 0.3708, 0.4588]), new_distribution = tensor([0.1709, 0.3711, 0.4579])
2024-12-05 15:44:27,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([0.1709, 0.3711, 0.4579]), new_distribution = tensor([0.1715, 0.3714, 0.4571])
2024-12-05 15:44:27,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([0.1715, 0.3714, 0.4571]), new_distribution = tensor([0.1720, 0.3718, 0.4563])
2024-12-05 15:44:27,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([0.1720, 0.3718, 0.4563]), new_distribution = tensor([0.1725, 0.3721, 0.4554])
2024-12-05 15:44:27,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([0.1725, 0.3721, 0.4554]), new_distribution = tensor([0.1730, 0.3724, 0.4546])
2024-12-05 15:44:27,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([0.1730, 0.3724, 0.4546]), new_distribution = tensor([0.1735, 0.3727, 0.4538])
2024-12-05 15:44:27,556 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([0.1735, 0.3727, 0.4538]), new_distribution = tensor([0.1741, 0.3730, 0.4529])
2024-12-05 15:44:27,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([0.1741, 0.3730, 0.4529]), new_distribution = tensor([0.1746, 0.3733, 0.4521])
2024-12-05 15:44:27,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([0.1746, 0.3733, 0.4521]), new_distribution = tensor([0.1751, 0.3736, 0.4512])
2024-12-05 15:44:27,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([0.1751, 0.3736, 0.4512]), new_distribution = tensor([0.1756, 0.3739, 0.4504])
2024-12-05 15:44:27,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([0.1756, 0.3739, 0.4504]), new_distribution = tensor([0.1762, 0.3742, 0.4496])
2024-12-05 15:44:27,827 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([0.1762, 0.3742, 0.4496]), new_distribution = tensor([0.1767, 0.3746, 0.4487])
2024-12-05 15:44:27,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([0.1767, 0.3746, 0.4487]), new_distribution = tensor([0.1772, 0.3749, 0.4479])
2024-12-05 15:44:27,936 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([0.1772, 0.3749, 0.4479]), new_distribution = tensor([0.1778, 0.3752, 0.4471])
2024-12-05 15:44:27,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([0.1778, 0.3752, 0.4471]), new_distribution = tensor([0.1783, 0.3755, 0.4462])
2024-12-05 15:44:28,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([0.1783, 0.3755, 0.4462]), new_distribution = tensor([0.1788, 0.3758, 0.4454])
2024-12-05 15:44:28,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([0.1788, 0.3758, 0.4454]), new_distribution = tensor([0.1794, 0.3760, 0.4446])
2024-12-05 15:44:28,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([0.1794, 0.3760, 0.4446]), new_distribution = tensor([0.1799, 0.3763, 0.4437])
2024-12-05 15:44:28,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([0.1799, 0.3763, 0.4437]), new_distribution = tensor([0.1805, 0.3766, 0.4429])
2024-12-05 15:44:28,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([0.1805, 0.3766, 0.4429]), new_distribution = tensor([0.1810, 0.3769, 0.4421])
2024-12-05 15:44:28,316 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([0.1810, 0.3769, 0.4421]), new_distribution = tensor([0.1816, 0.3772, 0.4412])
2024-12-05 15:44:28,370 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([0.1816, 0.3772, 0.4412]), new_distribution = tensor([0.1821, 0.3775, 0.4404])
2024-12-05 15:44:28,424 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([0.1821, 0.3775, 0.4404]), new_distribution = tensor([0.1826, 0.3778, 0.4396])
2024-12-05 15:44:28,478 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([0.1826, 0.3778, 0.4396]), new_distribution = tensor([0.1832, 0.3781, 0.4387])
2024-12-05 15:44:28,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([0.1832, 0.3781, 0.4387]), new_distribution = tensor([0.1837, 0.3784, 0.4379])
2024-12-05 15:44:28,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([0.1837, 0.3784, 0.4379]), new_distribution = tensor([0.1843, 0.3786, 0.4371])
2024-12-05 15:44:28,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([0.1843, 0.3786, 0.4371]), new_distribution = tensor([0.1848, 0.3789, 0.4362])
2024-12-05 15:44:28,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([0.1848, 0.3789, 0.4362]), new_distribution = tensor([0.1854, 0.3792, 0.4354])
2024-12-05 15:44:28,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([0.1854, 0.3792, 0.4354]), new_distribution = tensor([0.1859, 0.3795, 0.4346])
2024-12-05 15:44:28,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([0.1859, 0.3795, 0.4346]), new_distribution = tensor([0.1865, 0.3797, 0.4338])
2024-12-05 15:44:28,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([0.1865, 0.3797, 0.4338]), new_distribution = tensor([0.1871, 0.3800, 0.4329])
2024-12-05 15:44:28,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([0.1871, 0.3800, 0.4329]), new_distribution = tensor([0.1876, 0.3803, 0.4321])
2024-12-05 15:44:28,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([0.1876, 0.3803, 0.4321]), new_distribution = tensor([0.1882, 0.3806, 0.4313])
2024-12-05 15:44:29,021 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([0.1882, 0.3806, 0.4313]), new_distribution = tensor([0.1887, 0.3808, 0.4304])
2024-12-05 15:44:29,076 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([0.1887, 0.3808, 0.4304]), new_distribution = tensor([0.1893, 0.3811, 0.4296])
2024-12-05 15:44:29,130 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([0.1893, 0.3811, 0.4296]), new_distribution = tensor([0.1899, 0.3814, 0.4288])
2024-12-05 15:44:29,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([0.1899, 0.3814, 0.4288]), new_distribution = tensor([0.1904, 0.3816, 0.4279])
2024-12-05 15:44:29,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([0.1904, 0.3816, 0.4279]), new_distribution = tensor([0.1910, 0.3819, 0.4271])
2024-12-05 15:44:29,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([0.1910, 0.3819, 0.4271]), new_distribution = tensor([0.1916, 0.3821, 0.4263])
2024-12-05 15:44:29,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([0.1916, 0.3821, 0.4263]), new_distribution = tensor([0.1921, 0.3824, 0.4255])
2024-12-05 15:44:29,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([0.1921, 0.3824, 0.4255]), new_distribution = tensor([0.1927, 0.3827, 0.4246])
2024-12-05 15:44:29,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([0.1927, 0.3827, 0.4246]), new_distribution = tensor([0.1933, 0.3829, 0.4238])
2024-12-05 15:44:29,510 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([0.1933, 0.3829, 0.4238]), new_distribution = tensor([0.1939, 0.3832, 0.4230])
2024-12-05 15:44:29,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([0.1939, 0.3832, 0.4230]), new_distribution = tensor([0.1944, 0.3834, 0.4222])
2024-12-05 15:44:29,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([0.1944, 0.3834, 0.4222]), new_distribution = tensor([0.1950, 0.3837, 0.4213])
2024-12-05 15:44:29,673 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([0.1950, 0.3837, 0.4213]), new_distribution = tensor([0.1956, 0.3839, 0.4205])
2024-12-05 15:44:29,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([0.1956, 0.3839, 0.4205]), new_distribution = tensor([0.1962, 0.3842, 0.4197])
2024-12-05 15:44:29,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([0.1962, 0.3842, 0.4197]), new_distribution = tensor([0.1967, 0.3844, 0.4189])
2024-12-05 15:44:29,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([0.1967, 0.3844, 0.4189]), new_distribution = tensor([0.1973, 0.3846, 0.4180])
2024-12-05 15:44:29,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([0.1973, 0.3846, 0.4180]), new_distribution = tensor([0.1979, 0.3849, 0.4172])
2024-12-05 15:44:29,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([0.1979, 0.3849, 0.4172]), new_distribution = tensor([0.1985, 0.3851, 0.4164])
2024-12-05 15:44:29,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([0.1985, 0.3851, 0.4164]), new_distribution = tensor([0.1991, 0.3854, 0.4156])
2024-12-05 15:44:30,053 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([0.1991, 0.3854, 0.4156]), new_distribution = tensor([0.1997, 0.3856, 0.4147])
2024-12-05 15:44:30,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([0.1997, 0.3856, 0.4147]), new_distribution = tensor([0.2003, 0.3858, 0.4139])
2024-12-05 15:44:30,161 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([0.2003, 0.3858, 0.4139]), new_distribution = tensor([0.2008, 0.3860, 0.4131])
2024-12-05 15:44:30,216 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([0.2008, 0.3860, 0.4131]), new_distribution = tensor([0.2014, 0.3863, 0.4123])
2024-12-05 15:44:30,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([0.2014, 0.3863, 0.4123]), new_distribution = tensor([0.2020, 0.3865, 0.4115])
2024-12-05 15:44:30,324 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([0.2020, 0.3865, 0.4115]), new_distribution = tensor([0.2026, 0.3867, 0.4106])
2024-12-05 15:44:30,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([0.2026, 0.3867, 0.4106]), new_distribution = tensor([0.2032, 0.3870, 0.4098])
2024-12-05 15:44:30,433 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([0.2032, 0.3870, 0.4098]), new_distribution = tensor([0.2038, 0.3872, 0.4090])
2024-12-05 15:44:30,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([0.2038, 0.3872, 0.4090]), new_distribution = tensor([0.2044, 0.3874, 0.4082])
2024-12-05 15:44:30,541 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([0.2044, 0.3874, 0.4082]), new_distribution = tensor([0.2050, 0.3876, 0.4074])
2024-12-05 15:44:30,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([0.2050, 0.3876, 0.4074]), new_distribution = tensor([0.2056, 0.3878, 0.4065])
2024-12-05 15:44:30,650 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([0.2056, 0.3878, 0.4065]), new_distribution = tensor([0.2062, 0.3880, 0.4057])
2024-12-05 15:44:30,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([0.2062, 0.3880, 0.4057]), new_distribution = tensor([0.2068, 0.3883, 0.4049])
2024-12-05 15:44:30,758 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([0.2068, 0.3883, 0.4049]), new_distribution = tensor([0.2074, 0.3885, 0.4041])
2024-12-05 15:44:30,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([0.2074, 0.3885, 0.4041]), new_distribution = tensor([0.2080, 0.3887, 0.4033])
2024-12-05 15:44:30,867 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([0.2080, 0.3887, 0.4033]), new_distribution = tensor([0.2086, 0.3889, 0.4025])
2024-12-05 15:44:30,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([0.2086, 0.3889, 0.4025]), new_distribution = tensor([0.2093, 0.3891, 0.4017])
2024-12-05 15:44:30,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([0.2093, 0.3891, 0.4017]), new_distribution = tensor([0.2099, 0.3893, 0.4008])
2024-12-05 15:44:31,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([0.2099, 0.3893, 0.4008]), new_distribution = tensor([0.2105, 0.3895, 0.4000])
2024-12-05 15:44:31,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([0.2105, 0.3895, 0.4000]), new_distribution = tensor([0.2111, 0.3897, 0.3992])
2024-12-05 15:44:31,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([0.2111, 0.3897, 0.3992]), new_distribution = tensor([0.2117, 0.3899, 0.3984])
2024-12-05 15:44:31,193 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([0.2117, 0.3899, 0.3984]), new_distribution = tensor([0.2123, 0.3901, 0.3976])
2024-12-05 15:44:31,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([0.2123, 0.3901, 0.3976]), new_distribution = tensor([0.2129, 0.3903, 0.3968])
2024-12-05 15:44:31,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([0.2129, 0.3903, 0.3968]), new_distribution = tensor([0.2136, 0.3905, 0.3960])
2024-12-05 15:44:31,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([0.2136, 0.3905, 0.3960]), new_distribution = tensor([0.2142, 0.3907, 0.3952])
2024-12-05 15:44:31,410 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([0.2142, 0.3907, 0.3952]), new_distribution = tensor([0.2148, 0.3909, 0.3943])
2024-12-05 15:44:31,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([0.2148, 0.3909, 0.3943]), new_distribution = tensor([0.2154, 0.3910, 0.3935])
2024-12-05 15:44:31,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([0.2154, 0.3910, 0.3935]), new_distribution = tensor([0.2161, 0.3912, 0.3927])
2024-12-05 15:44:31,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([0.2161, 0.3912, 0.3927]), new_distribution = tensor([0.2167, 0.3914, 0.3919])
2024-12-05 15:44:31,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([0.2167, 0.3914, 0.3919]), new_distribution = tensor([0.2173, 0.3916, 0.3911])
2024-12-05 15:44:31,682 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([0.2173, 0.3916, 0.3911]), new_distribution = tensor([0.2179, 0.3918, 0.3903])
2024-12-05 15:44:31,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([0.2179, 0.3918, 0.3903]), new_distribution = tensor([0.2186, 0.3919, 0.3895])
2024-12-05 15:44:31,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([0.2186, 0.3919, 0.3895]), new_distribution = tensor([0.2192, 0.3921, 0.3887])
2024-12-05 15:44:31,845 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([0.2192, 0.3921, 0.3887]), new_distribution = tensor([0.2198, 0.3923, 0.3879])
2024-12-05 15:44:31,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([0.2198, 0.3923, 0.3879]), new_distribution = tensor([0.2205, 0.3925, 0.3871])
2024-12-05 15:44:31,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([0.2205, 0.3925, 0.3871]), new_distribution = tensor([0.2211, 0.3926, 0.3863])
2024-12-05 15:44:32,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([0.2211, 0.3926, 0.3863]), new_distribution = tensor([0.2217, 0.3928, 0.3855])
2024-12-05 15:44:32,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([0.2217, 0.3928, 0.3855]), new_distribution = tensor([0.2224, 0.3930, 0.3847])
2024-12-05 15:44:32,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([0.2224, 0.3930, 0.3847]), new_distribution = tensor([0.2230, 0.3931, 0.3839])
2024-12-05 15:44:32,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([0.2230, 0.3931, 0.3839]), new_distribution = tensor([0.2237, 0.3933, 0.3831])
2024-12-05 15:44:32,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([0.2237, 0.3933, 0.3831]), new_distribution = tensor([0.2243, 0.3934, 0.3823])
2024-12-05 15:44:32,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([0.2243, 0.3934, 0.3823]), new_distribution = tensor([0.2249, 0.3936, 0.3815])
2024-12-05 15:44:32,335 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([0.2249, 0.3936, 0.3815]), new_distribution = tensor([0.2256, 0.3938, 0.3807])
2024-12-05 15:44:32,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([0.2256, 0.3938, 0.3807]), new_distribution = tensor([0.2262, 0.3939, 0.3799])
2024-12-05 15:44:32,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([0.2262, 0.3939, 0.3799]), new_distribution = tensor([0.2269, 0.3941, 0.3791])
2024-12-05 15:44:32,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([0.2269, 0.3941, 0.3791]), new_distribution = tensor([0.2275, 0.3942, 0.3783])
2024-12-05 15:44:32,552 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([0.2275, 0.3942, 0.3783]), new_distribution = tensor([0.2282, 0.3943, 0.3775])
2024-12-05 15:44:32,606 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([0.2282, 0.3943, 0.3775]), new_distribution = tensor([0.2288, 0.3945, 0.3767])
2024-12-05 15:44:32,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([0.2288, 0.3945, 0.3767]), new_distribution = tensor([0.2295, 0.3946, 0.3759])
2024-12-05 15:44:32,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([0.2295, 0.3946, 0.3759]), new_distribution = tensor([0.2302, 0.3948, 0.3751])
2024-12-05 15:44:32,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([0.2302, 0.3948, 0.3751]), new_distribution = tensor([0.2308, 0.3949, 0.3743])
2024-12-05 15:44:32,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([0.2308, 0.3949, 0.3743]), new_distribution = tensor([0.2315, 0.3951, 0.3735])
2024-12-05 15:44:32,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([0.2315, 0.3951, 0.3735]), new_distribution = tensor([0.2321, 0.3952, 0.3727])
2024-12-05 15:44:32,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([0.2321, 0.3952, 0.3727]), new_distribution = tensor([0.2328, 0.3953, 0.3719])
2024-12-05 15:44:32,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([0.2328, 0.3953, 0.3719]), new_distribution = tensor([0.2335, 0.3954, 0.3711])
2024-12-05 15:44:33,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([0.2335, 0.3954, 0.3711]), new_distribution = tensor([0.2341, 0.3956, 0.3703])
2024-12-05 15:44:33,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([0.2341, 0.3956, 0.3703]), new_distribution = tensor([0.2348, 0.3957, 0.3695])
2024-12-05 15:44:33,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([0.2348, 0.3957, 0.3695]), new_distribution = tensor([0.2355, 0.3958, 0.3687])
2024-12-05 15:44:33,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([0.2355, 0.3958, 0.3687]), new_distribution = tensor([0.2361, 0.3960, 0.3679])
2024-12-05 15:44:33,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([0.2361, 0.3960, 0.3679]), new_distribution = tensor([0.2368, 0.3961, 0.3671])
2024-12-05 15:44:33,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([0.2368, 0.3961, 0.3671]), new_distribution = tensor([0.2375, 0.3962, 0.3664])
2024-12-05 15:44:33,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([0.2375, 0.3962, 0.3664]), new_distribution = tensor([0.2381, 0.3963, 0.3656])
2024-12-05 15:44:33,421 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([0.2381, 0.3963, 0.3656]), new_distribution = tensor([0.2388, 0.3964, 0.3648])
2024-12-05 15:44:33,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([0.2388, 0.3964, 0.3648]), new_distribution = tensor([0.2395, 0.3965, 0.3640])
2024-12-05 15:44:33,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([0.2395, 0.3965, 0.3640]), new_distribution = tensor([0.2402, 0.3966, 0.3632])
2024-12-05 15:44:33,584 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([0.2402, 0.3966, 0.3632]), new_distribution = tensor([0.2408, 0.3967, 0.3624])
2024-12-05 15:44:33,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([0.2408, 0.3967, 0.3624]), new_distribution = tensor([0.2415, 0.3969, 0.3616])
2024-12-05 15:44:33,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([0.2415, 0.3969, 0.3616]), new_distribution = tensor([0.2422, 0.3970, 0.3608])
2024-12-05 15:44:33,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([0.2422, 0.3970, 0.3608]), new_distribution = tensor([0.2429, 0.3971, 0.3601])
2024-12-05 15:44:33,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([0.2429, 0.3971, 0.3601]), new_distribution = tensor([0.2436, 0.3972, 0.3593])
2024-12-05 15:44:33,855 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([0.2436, 0.3972, 0.3593]), new_distribution = tensor([0.2442, 0.3973, 0.3585])
2024-12-05 15:44:33,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([0.2442, 0.3973, 0.3585]), new_distribution = tensor([0.2449, 0.3973, 0.3577])
2024-12-05 15:44:33,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([0.2449, 0.3973, 0.3577]), new_distribution = tensor([0.2456, 0.3974, 0.3569])
2024-12-05 15:44:34,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([0.2456, 0.3974, 0.3569]), new_distribution = tensor([0.2463, 0.3975, 0.3562])
2024-12-05 15:44:34,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([0.2463, 0.3975, 0.3562]), new_distribution = tensor([0.2470, 0.3976, 0.3554])
2024-12-05 15:44:34,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([0.2470, 0.3976, 0.3554]), new_distribution = tensor([0.2477, 0.3977, 0.3546])
2024-12-05 15:44:34,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([0.2477, 0.3977, 0.3546]), new_distribution = tensor([0.2484, 0.3978, 0.3538])
2024-12-05 15:44:34,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 300: ref_distribution = tensor([0.2484, 0.3978, 0.3538]), new_distribution = tensor([0.2491, 0.3979, 0.3530])
2024-12-05 15:44:34,289 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 301: ref_distribution = tensor([0.2491, 0.3979, 0.3530]), new_distribution = tensor([0.2498, 0.3980, 0.3523])
2024-12-05 15:44:34,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 302: ref_distribution = tensor([0.2498, 0.3980, 0.3523]), new_distribution = tensor([0.2505, 0.3980, 0.3515])
2024-12-05 15:44:34,398 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 303: ref_distribution = tensor([0.2505, 0.3980, 0.3515]), new_distribution = tensor([0.2512, 0.3981, 0.3507])
2024-12-05 15:44:34,452 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 304: ref_distribution = tensor([0.2512, 0.3981, 0.3507]), new_distribution = tensor([0.2519, 0.3982, 0.3500])
2024-12-05 15:44:34,506 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 305: ref_distribution = tensor([0.2519, 0.3982, 0.3500]), new_distribution = tensor([0.2526, 0.3983, 0.3492])
2024-12-05 15:44:34,560 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 306: ref_distribution = tensor([0.2526, 0.3983, 0.3492]), new_distribution = tensor([0.2533, 0.3983, 0.3484])
2024-12-05 15:44:34,614 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 307: ref_distribution = tensor([0.2533, 0.3983, 0.3484]), new_distribution = tensor([0.2540, 0.3984, 0.3476])
2024-12-05 15:44:34,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 308: ref_distribution = tensor([0.2540, 0.3984, 0.3476]), new_distribution = tensor([0.2547, 0.3985, 0.3469])
2024-12-05 15:44:34,723 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 309: ref_distribution = tensor([0.2547, 0.3985, 0.3469]), new_distribution = tensor([0.2554, 0.3985, 0.3461])
2024-12-05 15:44:34,777 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 310: ref_distribution = tensor([0.2554, 0.3985, 0.3461]), new_distribution = tensor([0.2561, 0.3986, 0.3453])
2024-12-05 15:44:34,831 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 311: ref_distribution = tensor([0.2561, 0.3986, 0.3453]), new_distribution = tensor([0.2568, 0.3986, 0.3446])
2024-12-05 15:44:34,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 312: ref_distribution = tensor([0.2568, 0.3986, 0.3446]), new_distribution = tensor([0.2575, 0.3987, 0.3438])
2024-12-05 15:44:34,939 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 313: ref_distribution = tensor([0.2575, 0.3987, 0.3438]), new_distribution = tensor([0.2582, 0.3988, 0.3430])
2024-12-05 15:44:34,994 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 314: ref_distribution = tensor([0.2582, 0.3988, 0.3430]), new_distribution = tensor([0.2589, 0.3988, 0.3423])
2024-12-05 15:44:35,048 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 315: ref_distribution = tensor([0.2589, 0.3988, 0.3423]), new_distribution = tensor([0.2597, 0.3989, 0.3415])
2024-12-05 15:44:35,103 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 316: ref_distribution = tensor([0.2597, 0.3989, 0.3415]), new_distribution = tensor([0.2604, 0.3989, 0.3407])
2024-12-05 15:44:35,157 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 317: ref_distribution = tensor([0.2604, 0.3989, 0.3407]), new_distribution = tensor([0.2611, 0.3989, 0.3400])
2024-12-05 15:44:35,211 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 318: ref_distribution = tensor([0.2611, 0.3989, 0.3400]), new_distribution = tensor([0.2618, 0.3990, 0.3392])
2024-12-05 15:44:35,266 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 319: ref_distribution = tensor([0.2618, 0.3990, 0.3392]), new_distribution = tensor([0.2625, 0.3990, 0.3384])
2024-12-05 15:44:35,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 320: ref_distribution = tensor([0.2625, 0.3990, 0.3384]), new_distribution = tensor([0.2632, 0.3991, 0.3377])
2024-12-05 15:44:35,375 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 321: ref_distribution = tensor([0.2632, 0.3991, 0.3377]), new_distribution = tensor([0.2640, 0.3991, 0.3369])
2024-12-05 15:44:35,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 322: ref_distribution = tensor([0.2640, 0.3991, 0.3369]), new_distribution = tensor([0.2647, 0.3991, 0.3362])
2024-12-05 15:44:35,483 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 323: ref_distribution = tensor([0.2647, 0.3991, 0.3362]), new_distribution = tensor([0.2654, 0.3992, 0.3354])
2024-12-05 15:44:35,538 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 324: ref_distribution = tensor([0.2654, 0.3992, 0.3354]), new_distribution = tensor([0.2661, 0.3992, 0.3346])
2024-12-05 15:44:35,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 325: ref_distribution = tensor([0.2661, 0.3992, 0.3346]), new_distribution = tensor([0.2669, 0.3992, 0.3339])
2024-12-05 15:44:35,646 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 326: ref_distribution = tensor([0.2669, 0.3992, 0.3339]), new_distribution = tensor([0.2676, 0.3993, 0.3331])
2024-12-05 15:44:35,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 327: ref_distribution = tensor([0.2676, 0.3993, 0.3331]), new_distribution = tensor([0.2683, 0.3993, 0.3324])
2024-12-05 15:44:35,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 328: ref_distribution = tensor([0.2683, 0.3993, 0.3324]), new_distribution = tensor([0.2691, 0.3993, 0.3316])
2024-12-05 15:44:35,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 329: ref_distribution = tensor([0.2691, 0.3993, 0.3316]), new_distribution = tensor([0.2698, 0.3993, 0.3309])
2024-12-05 15:44:35,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 330: ref_distribution = tensor([0.2698, 0.3993, 0.3309]), new_distribution = tensor([0.2705, 0.3993, 0.3301])
2024-12-05 15:44:35,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 331: ref_distribution = tensor([0.2705, 0.3993, 0.3301]), new_distribution = tensor([0.2713, 0.3994, 0.3294])
2024-12-05 15:44:35,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 332: ref_distribution = tensor([0.2713, 0.3994, 0.3294]), new_distribution = tensor([0.2720, 0.3994, 0.3286])
2024-12-05 15:44:36,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 333: ref_distribution = tensor([0.2720, 0.3994, 0.3286]), new_distribution = tensor([0.2728, 0.3994, 0.3279])
2024-12-05 15:44:36,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 334: ref_distribution = tensor([0.2728, 0.3994, 0.3279]), new_distribution = tensor([0.2735, 0.3994, 0.3271])
2024-12-05 15:44:36,137 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 335: ref_distribution = tensor([0.2735, 0.3994, 0.3271]), new_distribution = tensor([0.2742, 0.3994, 0.3264])
2024-12-05 15:44:36,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 336: ref_distribution = tensor([0.2742, 0.3994, 0.3264]), new_distribution = tensor([0.2750, 0.3994, 0.3256])
2024-12-05 15:44:36,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 337: ref_distribution = tensor([0.2750, 0.3994, 0.3256]), new_distribution = tensor([0.2757, 0.3994, 0.3249])
2024-12-05 15:44:36,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 338: ref_distribution = tensor([0.2757, 0.3994, 0.3249]), new_distribution = tensor([0.2765, 0.3994, 0.3241])
2024-12-05 15:44:36,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 339: ref_distribution = tensor([0.2765, 0.3994, 0.3241]), new_distribution = tensor([0.2772, 0.3994, 0.3234])
2024-12-05 15:44:36,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 340: ref_distribution = tensor([0.2772, 0.3994, 0.3234]), new_distribution = tensor([0.2780, 0.3994, 0.3226])
2024-12-05 15:44:36,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 341: ref_distribution = tensor([0.2780, 0.3994, 0.3226]), new_distribution = tensor([0.2787, 0.3994, 0.3219])
2024-12-05 15:44:36,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 342: ref_distribution = tensor([0.2787, 0.3994, 0.3219]), new_distribution = tensor([0.2795, 0.3994, 0.3212])
2024-12-05 15:44:36,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 343: ref_distribution = tensor([0.2795, 0.3994, 0.3212]), new_distribution = tensor([0.2802, 0.3994, 0.3204])
2024-12-05 15:44:36,624 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 344: ref_distribution = tensor([0.2802, 0.3994, 0.3204]), new_distribution = tensor([0.2810, 0.3994, 0.3197])
2024-12-05 15:44:36,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 345: ref_distribution = tensor([0.2810, 0.3994, 0.3197]), new_distribution = tensor([0.2817, 0.3993, 0.3189])
2024-12-05 15:44:36,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 346: ref_distribution = tensor([0.2817, 0.3993, 0.3189]), new_distribution = tensor([0.2825, 0.3993, 0.3182])
2024-12-05 15:44:36,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 347: ref_distribution = tensor([0.2825, 0.3993, 0.3182]), new_distribution = tensor([0.2832, 0.3993, 0.3175])
2024-12-05 15:44:36,842 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 348: ref_distribution = tensor([0.2832, 0.3993, 0.3175]), new_distribution = tensor([0.2840, 0.3993, 0.3167])
2024-12-05 15:44:36,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 349: ref_distribution = tensor([0.2840, 0.3993, 0.3167]), new_distribution = tensor([0.2848, 0.3993, 0.3160])
2024-12-05 15:44:36,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 350: ref_distribution = tensor([0.2848, 0.3993, 0.3160]), new_distribution = tensor([0.2855, 0.3992, 0.3153])
2024-12-05 15:44:37,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 351: ref_distribution = tensor([0.2855, 0.3992, 0.3153]), new_distribution = tensor([0.2863, 0.3992, 0.3145])
2024-12-05 15:44:37,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 352: ref_distribution = tensor([0.2863, 0.3992, 0.3145]), new_distribution = tensor([0.2870, 0.3992, 0.3138])
2024-12-05 15:44:37,114 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 353: ref_distribution = tensor([0.2870, 0.3992, 0.3138]), new_distribution = tensor([0.2878, 0.3991, 0.3131])
2024-12-05 15:44:37,170 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 354: ref_distribution = tensor([0.2878, 0.3991, 0.3131]), new_distribution = tensor([0.2886, 0.3991, 0.3123])
2024-12-05 15:44:37,224 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 355: ref_distribution = tensor([0.2886, 0.3991, 0.3123]), new_distribution = tensor([0.2893, 0.3991, 0.3116])
2024-12-05 15:44:37,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 356: ref_distribution = tensor([0.2893, 0.3991, 0.3116]), new_distribution = tensor([0.2901, 0.3990, 0.3109])
2024-12-05 15:44:37,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 357: ref_distribution = tensor([0.2901, 0.3990, 0.3109]), new_distribution = tensor([0.2909, 0.3990, 0.3101])
2024-12-05 15:44:37,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 358: ref_distribution = tensor([0.2909, 0.3990, 0.3101]), new_distribution = tensor([0.2916, 0.3989, 0.3094])
2024-12-05 15:44:37,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 359: ref_distribution = tensor([0.2916, 0.3989, 0.3094]), new_distribution = tensor([0.2924, 0.3989, 0.3087])
2024-12-05 15:44:37,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 360: ref_distribution = tensor([0.2924, 0.3989, 0.3087]), new_distribution = tensor([0.2932, 0.3988, 0.3080])
2024-12-05 15:44:37,550 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 361: ref_distribution = tensor([0.2932, 0.3988, 0.3080]), new_distribution = tensor([0.2940, 0.3988, 0.3072])
2024-12-05 15:44:37,604 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 362: ref_distribution = tensor([0.2940, 0.3988, 0.3072]), new_distribution = tensor([0.2947, 0.3987, 0.3065])
2024-12-05 15:44:37,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 363: ref_distribution = tensor([0.2947, 0.3987, 0.3065]), new_distribution = tensor([0.2955, 0.3987, 0.3058])
2024-12-05 15:44:37,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 364: ref_distribution = tensor([0.2955, 0.3987, 0.3058]), new_distribution = tensor([0.2963, 0.3986, 0.3051])
2024-12-05 15:44:37,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 365: ref_distribution = tensor([0.2963, 0.3986, 0.3051]), new_distribution = tensor([0.2971, 0.3986, 0.3044])
2024-12-05 15:44:37,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 366: ref_distribution = tensor([0.2971, 0.3986, 0.3044]), new_distribution = tensor([0.2979, 0.3985, 0.3036])
2024-12-05 15:44:37,875 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 367: ref_distribution = tensor([0.2979, 0.3985, 0.3036]), new_distribution = tensor([0.2986, 0.3984, 0.3029])
2024-12-05 15:44:37,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 368: ref_distribution = tensor([0.2986, 0.3984, 0.3029]), new_distribution = tensor([0.2994, 0.3984, 0.3022])
2024-12-05 15:44:37,983 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 369: ref_distribution = tensor([0.2994, 0.3984, 0.3022]), new_distribution = tensor([0.3002, 0.3983, 0.3015])
2024-12-05 15:44:38,037 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 370: ref_distribution = tensor([0.3002, 0.3983, 0.3015]), new_distribution = tensor([0.3010, 0.3982, 0.3008])
2024-12-05 15:44:38,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 371: ref_distribution = tensor([0.3010, 0.3982, 0.3008]), new_distribution = tensor([0.3018, 0.3982, 0.3001])
2024-12-05 15:44:38,146 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 372: ref_distribution = tensor([0.3018, 0.3982, 0.3001]), new_distribution = tensor([0.3026, 0.3981, 0.2993])
2024-12-05 15:44:38,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 373: ref_distribution = tensor([0.3026, 0.3981, 0.2993]), new_distribution = tensor([0.3034, 0.3980, 0.2986])
2024-12-05 15:44:38,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 374: ref_distribution = tensor([0.3034, 0.3980, 0.2986]), new_distribution = tensor([0.3042, 0.3979, 0.2979])
2024-12-05 15:44:38,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 375: ref_distribution = tensor([0.3042, 0.3979, 0.2979]), new_distribution = tensor([0.3050, 0.3978, 0.2972])
2024-12-05 15:44:38,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 376: ref_distribution = tensor([0.3050, 0.3978, 0.2972]), new_distribution = tensor([0.3057, 0.3978, 0.2965])
2024-12-05 15:44:38,416 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 377: ref_distribution = tensor([0.3057, 0.3978, 0.2965]), new_distribution = tensor([0.3065, 0.3977, 0.2958])
2024-12-05 15:44:38,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 378: ref_distribution = tensor([0.3065, 0.3977, 0.2958]), new_distribution = tensor([0.3073, 0.3976, 0.2951])
2024-12-05 15:44:38,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 379: ref_distribution = tensor([0.3073, 0.3976, 0.2951]), new_distribution = tensor([0.3081, 0.3975, 0.2944])
2024-12-05 15:44:38,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 380: ref_distribution = tensor([0.3081, 0.3975, 0.2944]), new_distribution = tensor([0.3089, 0.3974, 0.2937])
2024-12-05 15:44:38,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 381: ref_distribution = tensor([0.3089, 0.3974, 0.2937]), new_distribution = tensor([0.3097, 0.3973, 0.2930])
2024-12-05 15:44:38,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 382: ref_distribution = tensor([0.3097, 0.3973, 0.2930]), new_distribution = tensor([0.3105, 0.3972, 0.2923])
2024-12-05 15:44:38,742 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 383: ref_distribution = tensor([0.3105, 0.3972, 0.2923]), new_distribution = tensor([0.3113, 0.3971, 0.2916])
2024-12-05 15:44:38,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 384: ref_distribution = tensor([0.3113, 0.3971, 0.2916]), new_distribution = tensor([0.3121, 0.3970, 0.2909])
2024-12-05 15:44:38,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 385: ref_distribution = tensor([0.3121, 0.3970, 0.2909]), new_distribution = tensor([0.3129, 0.3969, 0.2902])
2024-12-05 15:44:38,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 386: ref_distribution = tensor([0.3129, 0.3969, 0.2902]), new_distribution = tensor([0.3137, 0.3968, 0.2895])
2024-12-05 15:44:38,959 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 387: ref_distribution = tensor([0.3137, 0.3968, 0.2895]), new_distribution = tensor([0.3146, 0.3967, 0.2888])
2024-12-05 15:44:39,013 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 388: ref_distribution = tensor([0.3146, 0.3967, 0.2888]), new_distribution = tensor([0.3154, 0.3966, 0.2881])
2024-12-05 15:44:39,067 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 389: ref_distribution = tensor([0.3154, 0.3966, 0.2881]), new_distribution = tensor([0.3162, 0.3965, 0.2874])
2024-12-05 15:44:39,122 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 390: ref_distribution = tensor([0.3162, 0.3965, 0.2874]), new_distribution = tensor([0.3170, 0.3963, 0.2867])
2024-12-05 15:44:39,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 391: ref_distribution = tensor([0.3170, 0.3963, 0.2867]), new_distribution = tensor([0.3178, 0.3962, 0.2860])
2024-12-05 15:44:39,230 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 392: ref_distribution = tensor([0.3178, 0.3962, 0.2860]), new_distribution = tensor([0.3186, 0.3961, 0.2853])
2024-12-05 15:44:39,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 393: ref_distribution = tensor([0.3186, 0.3961, 0.2853]), new_distribution = tensor([0.3194, 0.3960, 0.2846])
2024-12-05 15:44:39,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 394: ref_distribution = tensor([0.3194, 0.3960, 0.2846]), new_distribution = tensor([0.3202, 0.3959, 0.2839])
2024-12-05 15:44:39,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 395: ref_distribution = tensor([0.3202, 0.3959, 0.2839]), new_distribution = tensor([0.3211, 0.3957, 0.2832])
2024-12-05 15:44:39,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 396: ref_distribution = tensor([0.3211, 0.3957, 0.2832]), new_distribution = tensor([0.3219, 0.3956, 0.2825])
2024-12-05 15:44:39,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 397: ref_distribution = tensor([0.3219, 0.3956, 0.2825]), new_distribution = tensor([0.3227, 0.3955, 0.2818])
2024-12-05 15:44:39,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 398: ref_distribution = tensor([0.3227, 0.3955, 0.2818]), new_distribution = tensor([0.3235, 0.3953, 0.2811])
2024-12-05 15:44:39,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 399: ref_distribution = tensor([0.3235, 0.3953, 0.2811]), new_distribution = tensor([0.3243, 0.3952, 0.2805])
2024-12-05 15:44:39,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 400: ref_distribution = tensor([0.3243, 0.3952, 0.2805]), new_distribution = tensor([0.3252, 0.3951, 0.2798])
2024-12-05 15:44:39,718 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 401: ref_distribution = tensor([0.3252, 0.3951, 0.2798]), new_distribution = tensor([0.3260, 0.3949, 0.2791])
2024-12-05 15:44:39,772 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 402: ref_distribution = tensor([0.3260, 0.3949, 0.2791]), new_distribution = tensor([0.3268, 0.3948, 0.2784])
2024-12-05 15:44:39,826 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 403: ref_distribution = tensor([0.3268, 0.3948, 0.2784]), new_distribution = tensor([0.3276, 0.3947, 0.2777])
2024-12-05 15:44:39,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 404: ref_distribution = tensor([0.3276, 0.3947, 0.2777]), new_distribution = tensor([0.3285, 0.3945, 0.2770])
2024-12-05 15:44:39,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 405: ref_distribution = tensor([0.3285, 0.3945, 0.2770]), new_distribution = tensor([0.3293, 0.3944, 0.2764])
2024-12-05 15:44:39,988 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 406: ref_distribution = tensor([0.3293, 0.3944, 0.2764]), new_distribution = tensor([0.3301, 0.3942, 0.2757])
2024-12-05 15:44:40,043 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 407: ref_distribution = tensor([0.3301, 0.3942, 0.2757]), new_distribution = tensor([0.3309, 0.3941, 0.2750])
2024-12-05 15:44:40,097 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 408: ref_distribution = tensor([0.3309, 0.3941, 0.2750]), new_distribution = tensor([0.3318, 0.3939, 0.2743])
2024-12-05 15:44:40,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 409: ref_distribution = tensor([0.3318, 0.3939, 0.2743]), new_distribution = tensor([0.3326, 0.3937, 0.2737])
2024-12-05 15:44:40,205 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 410: ref_distribution = tensor([0.3326, 0.3937, 0.2737]), new_distribution = tensor([0.3334, 0.3936, 0.2730])
2024-12-05 15:44:40,259 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 411: ref_distribution = tensor([0.3334, 0.3936, 0.2730]), new_distribution = tensor([0.3343, 0.3934, 0.2723])
2024-12-05 15:44:40,313 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 412: ref_distribution = tensor([0.3343, 0.3934, 0.2723]), new_distribution = tensor([0.3351, 0.3933, 0.2716])
2024-12-05 15:44:40,367 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 413: ref_distribution = tensor([0.3351, 0.3933, 0.2716]), new_distribution = tensor([0.3359, 0.3931, 0.2710])
2024-12-05 15:44:40,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 414: ref_distribution = tensor([0.3359, 0.3931, 0.2710]), new_distribution = tensor([0.3368, 0.3929, 0.2703])
2024-12-05 15:44:40,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 415: ref_distribution = tensor([0.3368, 0.3929, 0.2703]), new_distribution = tensor([0.3376, 0.3928, 0.2696])
2024-12-05 15:44:40,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 416: ref_distribution = tensor([0.3376, 0.3928, 0.2696]), new_distribution = tensor([0.3385, 0.3926, 0.2690])
2024-12-05 15:44:40,584 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 417: ref_distribution = tensor([0.3385, 0.3926, 0.2690]), new_distribution = tensor([0.3393, 0.3924, 0.2683])
2024-12-05 15:44:40,639 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 418: ref_distribution = tensor([0.3393, 0.3924, 0.2683]), new_distribution = tensor([0.3401, 0.3922, 0.2676])
2024-12-05 15:44:40,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 419: ref_distribution = tensor([0.3401, 0.3922, 0.2676]), new_distribution = tensor([0.3410, 0.3921, 0.2670])
2024-12-05 15:44:40,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 420: ref_distribution = tensor([0.3410, 0.3921, 0.2670]), new_distribution = tensor([0.3418, 0.3919, 0.2663])
2024-12-05 15:44:40,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 421: ref_distribution = tensor([0.3418, 0.3919, 0.2663]), new_distribution = tensor([0.3427, 0.3917, 0.2656])
2024-12-05 15:44:40,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 422: ref_distribution = tensor([0.3427, 0.3917, 0.2656]), new_distribution = tensor([0.3435, 0.3915, 0.2650])
2024-12-05 15:44:40,910 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 423: ref_distribution = tensor([0.3435, 0.3915, 0.2650]), new_distribution = tensor([0.3444, 0.3913, 0.2643])
2024-12-05 15:44:40,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 424: ref_distribution = tensor([0.3444, 0.3913, 0.2643]), new_distribution = tensor([0.3452, 0.3911, 0.2637])
2024-12-05 15:44:41,019 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 425: ref_distribution = tensor([0.3452, 0.3911, 0.2637]), new_distribution = tensor([0.3461, 0.3909, 0.2630])
2024-12-05 15:44:41,073 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 426: ref_distribution = tensor([0.3461, 0.3909, 0.2630]), new_distribution = tensor([0.3469, 0.3907, 0.2623])
2024-12-05 15:44:41,128 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 427: ref_distribution = tensor([0.3469, 0.3907, 0.2623]), new_distribution = tensor([0.3478, 0.3906, 0.2617])
2024-12-05 15:44:41,182 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 428: ref_distribution = tensor([0.3478, 0.3906, 0.2617]), new_distribution = tensor([0.3486, 0.3904, 0.2610])
2024-12-05 15:44:41,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 429: ref_distribution = tensor([0.3486, 0.3904, 0.2610]), new_distribution = tensor([0.3495, 0.3902, 0.2604])
2024-12-05 15:44:41,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 430: ref_distribution = tensor([0.3495, 0.3902, 0.2604]), new_distribution = tensor([0.3503, 0.3900, 0.2597])
2024-12-05 15:44:41,345 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 431: ref_distribution = tensor([0.3503, 0.3900, 0.2597]), new_distribution = tensor([0.3512, 0.3898, 0.2591])
2024-12-05 15:44:41,399 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 432: ref_distribution = tensor([0.3512, 0.3898, 0.2591]), new_distribution = tensor([0.3520, 0.3895, 0.2584])
2024-12-05 15:44:41,453 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 433: ref_distribution = tensor([0.3520, 0.3895, 0.2584]), new_distribution = tensor([0.3529, 0.3893, 0.2578])
2024-12-05 15:44:41,508 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 434: ref_distribution = tensor([0.3529, 0.3893, 0.2578]), new_distribution = tensor([0.3537, 0.3891, 0.2571])
2024-12-05 15:44:41,562 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 435: ref_distribution = tensor([0.3537, 0.3891, 0.2571]), new_distribution = tensor([0.3546, 0.3889, 0.2565])
2024-12-05 15:44:41,617 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 436: ref_distribution = tensor([0.3546, 0.3889, 0.2565]), new_distribution = tensor([0.3555, 0.3887, 0.2558])
2024-12-05 15:44:41,671 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 437: ref_distribution = tensor([0.3555, 0.3887, 0.2558]), new_distribution = tensor([0.3563, 0.3885, 0.2552])
2024-12-05 15:44:41,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 438: ref_distribution = tensor([0.3563, 0.3885, 0.2552]), new_distribution = tensor([0.3572, 0.3883, 0.2545])
2024-12-05 15:44:41,780 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 439: ref_distribution = tensor([0.3572, 0.3883, 0.2545]), new_distribution = tensor([0.3581, 0.3880, 0.2539])
2024-12-05 15:44:41,834 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 440: ref_distribution = tensor([0.3581, 0.3880, 0.2539]), new_distribution = tensor([0.3589, 0.3878, 0.2533])
2024-12-05 15:44:41,888 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 441: ref_distribution = tensor([0.3589, 0.3878, 0.2533]), new_distribution = tensor([0.3598, 0.3876, 0.2526])
2024-12-05 15:44:41,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 442: ref_distribution = tensor([0.3598, 0.3876, 0.2526]), new_distribution = tensor([0.3606, 0.3874, 0.2520])
2024-12-05 15:44:41,996 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 443: ref_distribution = tensor([0.3606, 0.3874, 0.2520]), new_distribution = tensor([0.3615, 0.3871, 0.2513])
2024-12-05 15:44:42,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 444: ref_distribution = tensor([0.3615, 0.3871, 0.2513]), new_distribution = tensor([0.3624, 0.3869, 0.2507])
2024-12-05 15:44:42,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 445: ref_distribution = tensor([0.3624, 0.3869, 0.2507]), new_distribution = tensor([0.3633, 0.3867, 0.2501])
2024-12-05 15:44:42,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 446: ref_distribution = tensor([0.3633, 0.3867, 0.2501]), new_distribution = tensor([0.3641, 0.3864, 0.2494])
2024-12-05 15:44:42,214 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 447: ref_distribution = tensor([0.3641, 0.3864, 0.2494]), new_distribution = tensor([0.3650, 0.3862, 0.2488])
2024-12-05 15:44:42,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 448: ref_distribution = tensor([0.3650, 0.3862, 0.2488]), new_distribution = tensor([0.3659, 0.3860, 0.2482])
2024-12-05 15:44:42,322 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 449: ref_distribution = tensor([0.3659, 0.3860, 0.2482]), new_distribution = tensor([0.3667, 0.3857, 0.2475])
2024-12-05 15:44:42,376 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 450: ref_distribution = tensor([0.3667, 0.3857, 0.2475]), new_distribution = tensor([0.3676, 0.3855, 0.2469])
2024-12-05 15:44:42,431 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 451: ref_distribution = tensor([0.3676, 0.3855, 0.2469]), new_distribution = tensor([0.3685, 0.3852, 0.2463])
2024-12-05 15:44:42,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 452: ref_distribution = tensor([0.3685, 0.3852, 0.2463]), new_distribution = tensor([0.3694, 0.3850, 0.2456])
2024-12-05 15:44:42,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 453: ref_distribution = tensor([0.3694, 0.3850, 0.2456]), new_distribution = tensor([0.3702, 0.3847, 0.2450])
2024-12-05 15:44:42,594 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 454: ref_distribution = tensor([0.3702, 0.3847, 0.2450]), new_distribution = tensor([0.3711, 0.3845, 0.2444])
2024-12-05 15:44:42,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 455: ref_distribution = tensor([0.3711, 0.3845, 0.2444]), new_distribution = tensor([0.3720, 0.3842, 0.2438])
2024-12-05 15:44:42,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 456: ref_distribution = tensor([0.3720, 0.3842, 0.2438]), new_distribution = tensor([0.3729, 0.3840, 0.2431])
2024-12-05 15:44:42,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 457: ref_distribution = tensor([0.3729, 0.3840, 0.2431]), new_distribution = tensor([0.3738, 0.3837, 0.2425])
2024-12-05 15:44:42,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 458: ref_distribution = tensor([0.3738, 0.3837, 0.2425]), new_distribution = tensor([0.3746, 0.3835, 0.2419])
2024-12-05 15:44:42,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 459: ref_distribution = tensor([0.3746, 0.3835, 0.2419]), new_distribution = tensor([0.3755, 0.3832, 0.2413])
2024-12-05 15:44:42,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 460: ref_distribution = tensor([0.3755, 0.3832, 0.2413]), new_distribution = tensor([0.3764, 0.3829, 0.2407])
2024-12-05 15:44:42,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 461: ref_distribution = tensor([0.3764, 0.3829, 0.2407]), new_distribution = tensor([0.3773, 0.3827, 0.2400])
2024-12-05 15:44:43,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 462: ref_distribution = tensor([0.3773, 0.3827, 0.2400]), new_distribution = tensor([0.3782, 0.3824, 0.2394])
2024-12-05 15:44:43,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 463: ref_distribution = tensor([0.3782, 0.3824, 0.2394]), new_distribution = tensor([0.3790, 0.3821, 0.2388])
2024-12-05 15:44:43,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 464: ref_distribution = tensor([0.3790, 0.3821, 0.2388]), new_distribution = tensor([0.3799, 0.3819, 0.2382])
2024-12-05 15:44:43,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 465: ref_distribution = tensor([0.3799, 0.3819, 0.2382]), new_distribution = tensor([0.3808, 0.3816, 0.2376])
2024-12-05 15:44:43,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 466: ref_distribution = tensor([0.3808, 0.3816, 0.2376]), new_distribution = tensor([0.3817, 0.3813, 0.2370])
2024-12-05 15:44:43,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 467: ref_distribution = tensor([0.3817, 0.3813, 0.2370]), new_distribution = tensor([0.3826, 0.3810, 0.2364])
2024-12-05 15:44:43,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 468: ref_distribution = tensor([0.3826, 0.3810, 0.2364]), new_distribution = tensor([0.3835, 0.3808, 0.2358])
2024-12-05 15:44:43,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 469: ref_distribution = tensor([0.3835, 0.3808, 0.2358]), new_distribution = tensor([0.3844, 0.3805, 0.2351])
2024-12-05 15:44:43,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 470: ref_distribution = tensor([0.3844, 0.3805, 0.2351]), new_distribution = tensor([0.3853, 0.3802, 0.2345])
2024-12-05 15:44:43,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 471: ref_distribution = tensor([0.3853, 0.3802, 0.2345]), new_distribution = tensor([0.3862, 0.3799, 0.2339])
2024-12-05 15:44:43,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 472: ref_distribution = tensor([0.3862, 0.3799, 0.2339]), new_distribution = tensor([0.3870, 0.3796, 0.2333])
2024-12-05 15:44:43,624 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 473: ref_distribution = tensor([0.3870, 0.3796, 0.2333]), new_distribution = tensor([0.3879, 0.3793, 0.2327])
2024-12-05 15:44:43,678 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 474: ref_distribution = tensor([0.3879, 0.3793, 0.2327]), new_distribution = tensor([0.3888, 0.3790, 0.2321])
2024-12-05 15:44:43,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 475: ref_distribution = tensor([0.3888, 0.3790, 0.2321]), new_distribution = tensor([0.3897, 0.3788, 0.2315])
2024-12-05 15:44:43,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 476: ref_distribution = tensor([0.3897, 0.3788, 0.2315]), new_distribution = tensor([0.3906, 0.3785, 0.2309])
2024-12-05 15:44:43,841 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 477: ref_distribution = tensor([0.3906, 0.3785, 0.2309]), new_distribution = tensor([0.3915, 0.3782, 0.2303])
2024-12-05 15:44:43,895 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 478: ref_distribution = tensor([0.3915, 0.3782, 0.2303]), new_distribution = tensor([0.3924, 0.3779, 0.2297])
2024-12-05 15:44:43,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 479: ref_distribution = tensor([0.3924, 0.3779, 0.2297]), new_distribution = tensor([0.3933, 0.3776, 0.2291])
2024-12-05 15:44:44,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 480: ref_distribution = tensor([0.3933, 0.3776, 0.2291]), new_distribution = tensor([0.3942, 0.3773, 0.2285])
2024-12-05 15:44:44,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 481: ref_distribution = tensor([0.3942, 0.3773, 0.2285]), new_distribution = tensor([0.3951, 0.3770, 0.2279])
2024-12-05 15:44:44,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 482: ref_distribution = tensor([0.3951, 0.3770, 0.2279]), new_distribution = tensor([0.3960, 0.3766, 0.2273])
2024-12-05 15:44:44,166 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 483: ref_distribution = tensor([0.3960, 0.3766, 0.2273]), new_distribution = tensor([0.3969, 0.3763, 0.2267])
2024-12-05 15:44:44,221 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 484: ref_distribution = tensor([0.3969, 0.3763, 0.2267]), new_distribution = tensor([0.3978, 0.3760, 0.2262])
2024-12-05 15:44:44,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 485: ref_distribution = tensor([0.3978, 0.3760, 0.2262]), new_distribution = tensor([0.3987, 0.3757, 0.2256])
2024-12-05 15:44:44,329 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 486: ref_distribution = tensor([0.3987, 0.3757, 0.2256]), new_distribution = tensor([0.3996, 0.3754, 0.2250])
2024-12-05 15:44:44,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 487: ref_distribution = tensor([0.3996, 0.3754, 0.2250]), new_distribution = tensor([0.4005, 0.3751, 0.2244])
2024-12-05 15:44:44,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 488: ref_distribution = tensor([0.4005, 0.3751, 0.2244]), new_distribution = tensor([0.4014, 0.3748, 0.2238])
2024-12-05 15:44:44,492 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 489: ref_distribution = tensor([0.4014, 0.3748, 0.2238]), new_distribution = tensor([0.4023, 0.3745, 0.2232])
2024-12-05 15:44:44,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 490: ref_distribution = tensor([0.4023, 0.3745, 0.2232]), new_distribution = tensor([0.4032, 0.3741, 0.2226])
2024-12-05 15:44:44,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 491: ref_distribution = tensor([0.4032, 0.3741, 0.2226]), new_distribution = tensor([0.4042, 0.3738, 0.2220])
2024-12-05 15:44:44,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 492: ref_distribution = tensor([0.4042, 0.3738, 0.2220]), new_distribution = tensor([0.4051, 0.3735, 0.2215])
2024-12-05 15:44:44,709 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 493: ref_distribution = tensor([0.4051, 0.3735, 0.2215]), new_distribution = tensor([0.4060, 0.3732, 0.2209])
2024-12-05 15:44:44,763 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 494: ref_distribution = tensor([0.4060, 0.3732, 0.2209]), new_distribution = tensor([0.4069, 0.3728, 0.2203])
2024-12-05 15:44:44,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 495: ref_distribution = tensor([0.4069, 0.3728, 0.2203]), new_distribution = tensor([0.4078, 0.3725, 0.2197])
2024-12-05 15:44:44,872 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 496: ref_distribution = tensor([0.4078, 0.3725, 0.2197]), new_distribution = tensor([0.4087, 0.3722, 0.2191])
2024-12-05 15:44:44,926 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 497: ref_distribution = tensor([0.4087, 0.3722, 0.2191]), new_distribution = tensor([0.4096, 0.3718, 0.2186])
2024-12-05 15:44:44,981 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 498: ref_distribution = tensor([0.4096, 0.3718, 0.2186]), new_distribution = tensor([0.4105, 0.3715, 0.2180])
2024-12-05 15:44:45,035 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 499: ref_distribution = tensor([0.4105, 0.3715, 0.2180]), new_distribution = tensor([0.4114, 0.3712, 0.2174])
2024-12-05 15:44:45,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 500: ref_distribution = tensor([0.4114, 0.3712, 0.2174]), new_distribution = tensor([0.4123, 0.3708, 0.2168])
2024-12-05 15:44:45,143 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 501: ref_distribution = tensor([0.4123, 0.3708, 0.2168]), new_distribution = tensor([0.4133, 0.3705, 0.2163])
2024-12-05 15:44:45,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 502: ref_distribution = tensor([0.4133, 0.3705, 0.2163]), new_distribution = tensor([0.4142, 0.3701, 0.2157])
2024-12-05 15:44:45,252 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 503: ref_distribution = tensor([0.4142, 0.3701, 0.2157]), new_distribution = tensor([0.4151, 0.3698, 0.2151])
2024-12-05 15:44:45,307 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 504: ref_distribution = tensor([0.4151, 0.3698, 0.2151]), new_distribution = tensor([0.4160, 0.3694, 0.2146])
2024-12-05 15:44:45,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 505: ref_distribution = tensor([0.4160, 0.3694, 0.2146]), new_distribution = tensor([0.4169, 0.3691, 0.2140])
2024-12-05 15:44:45,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 506: ref_distribution = tensor([0.4169, 0.3691, 0.2140]), new_distribution = tensor([0.4178, 0.3687, 0.2134])
2024-12-05 15:44:45,470 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 507: ref_distribution = tensor([0.4178, 0.3687, 0.2134]), new_distribution = tensor([0.4187, 0.3684, 0.2129])
2024-12-05 15:44:45,524 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 508: ref_distribution = tensor([0.4187, 0.3684, 0.2129]), new_distribution = tensor([0.4197, 0.3680, 0.2123])
2024-12-05 15:44:45,578 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 509: ref_distribution = tensor([0.4197, 0.3680, 0.2123]), new_distribution = tensor([0.4206, 0.3677, 0.2117])
2024-12-05 15:44:45,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 510: ref_distribution = tensor([0.4206, 0.3677, 0.2117]), new_distribution = tensor([0.4215, 0.3673, 0.2112])
2024-12-05 15:44:45,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 511: ref_distribution = tensor([0.4215, 0.3673, 0.2112]), new_distribution = tensor([0.4224, 0.3670, 0.2106])
2024-12-05 15:44:45,742 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 512: ref_distribution = tensor([0.4224, 0.3670, 0.2106]), new_distribution = tensor([0.4233, 0.3666, 0.2101])
2024-12-05 15:44:45,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 513: ref_distribution = tensor([0.4233, 0.3666, 0.2101]), new_distribution = tensor([0.4243, 0.3662, 0.2095])
2024-12-05 15:44:45,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 514: ref_distribution = tensor([0.4243, 0.3662, 0.2095]), new_distribution = tensor([0.4252, 0.3659, 0.2089])
2024-12-05 15:44:45,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 515: ref_distribution = tensor([0.4252, 0.3659, 0.2089]), new_distribution = tensor([0.4261, 0.3655, 0.2084])
2024-12-05 15:44:45,959 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 516: ref_distribution = tensor([0.4261, 0.3655, 0.2084]), new_distribution = tensor([0.4270, 0.3652, 0.2078])
2024-12-05 15:44:46,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 517: ref_distribution = tensor([0.4270, 0.3652, 0.2078]), new_distribution = tensor([0.4279, 0.3648, 0.2073])
2024-12-05 15:44:46,068 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 518: ref_distribution = tensor([0.4279, 0.3648, 0.2073]), new_distribution = tensor([0.4289, 0.3644, 0.2067])
2024-12-05 15:44:46,122 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 519: ref_distribution = tensor([0.4289, 0.3644, 0.2067]), new_distribution = tensor([0.4298, 0.3640, 0.2062])
2024-12-05 15:44:46,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 520: ref_distribution = tensor([0.4298, 0.3640, 0.2062]), new_distribution = tensor([0.4307, 0.3637, 0.2056])
2024-12-05 15:44:46,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 521: ref_distribution = tensor([0.4307, 0.3637, 0.2056]), new_distribution = tensor([0.4316, 0.3633, 0.2051])
2024-12-05 15:44:46,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 522: ref_distribution = tensor([0.4316, 0.3633, 0.2051]), new_distribution = tensor([0.4326, 0.3629, 0.2045])
2024-12-05 15:44:46,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 523: ref_distribution = tensor([0.4326, 0.3629, 0.2045]), new_distribution = tensor([0.4335, 0.3625, 0.2040])
2024-12-05 15:44:46,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 524: ref_distribution = tensor([0.4335, 0.3625, 0.2040]), new_distribution = tensor([0.4344, 0.3622, 0.2034])
2024-12-05 15:44:46,448 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 525: ref_distribution = tensor([0.4344, 0.3622, 0.2034]), new_distribution = tensor([0.4353, 0.3618, 0.2029])
2024-12-05 15:44:46,502 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 526: ref_distribution = tensor([0.4353, 0.3618, 0.2029]), new_distribution = tensor([0.4363, 0.3614, 0.2023])
2024-12-05 15:44:46,557 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 527: ref_distribution = tensor([0.4363, 0.3614, 0.2023]), new_distribution = tensor([0.4372, 0.3610, 0.2018])
2024-12-05 15:44:46,611 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 528: ref_distribution = tensor([0.4372, 0.3610, 0.2018]), new_distribution = tensor([0.4381, 0.3606, 0.2013])
2024-12-05 15:44:46,665 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 529: ref_distribution = tensor([0.4381, 0.3606, 0.2013]), new_distribution = tensor([0.4391, 0.3602, 0.2007])
2024-12-05 15:44:46,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 530: ref_distribution = tensor([0.4391, 0.3602, 0.2007]), new_distribution = tensor([0.4400, 0.3598, 0.2002])
2024-12-05 15:44:46,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 531: ref_distribution = tensor([0.4400, 0.3598, 0.2002]), new_distribution = tensor([0.4409, 0.3594, 0.1996])
2024-12-05 15:44:46,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 532: ref_distribution = tensor([0.4409, 0.3594, 0.1996]), new_distribution = tensor([0.4418, 0.3591, 0.1991])
2024-12-05 15:44:46,884 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 533: ref_distribution = tensor([0.4418, 0.3591, 0.1991]), new_distribution = tensor([0.4428, 0.3587, 0.1986])
2024-12-05 15:44:46,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 534: ref_distribution = tensor([0.4428, 0.3587, 0.1986]), new_distribution = tensor([0.4437, 0.3583, 0.1980])
2024-12-05 15:44:46,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 535: ref_distribution = tensor([0.4437, 0.3583, 0.1980]), new_distribution = tensor([0.4446, 0.3579, 0.1975])
2024-12-05 15:44:47,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 536: ref_distribution = tensor([0.4446, 0.3579, 0.1975]), new_distribution = tensor([0.4456, 0.3575, 0.1970])
2024-12-05 15:44:47,102 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 537: ref_distribution = tensor([0.4456, 0.3575, 0.1970]), new_distribution = tensor([0.4465, 0.3571, 0.1964])
2024-12-05 15:44:47,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 538: ref_distribution = tensor([0.4465, 0.3571, 0.1964]), new_distribution = tensor([0.4474, 0.3567, 0.1959])
2024-12-05 15:44:47,215 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 539: ref_distribution = tensor([0.4474, 0.3567, 0.1959]), new_distribution = tensor([0.4484, 0.3563, 0.1954])
2024-12-05 15:44:47,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 540: ref_distribution = tensor([0.4484, 0.3563, 0.1954]), new_distribution = tensor([0.4493, 0.3558, 0.1949])
2024-12-05 15:44:47,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 541: ref_distribution = tensor([0.4493, 0.3558, 0.1949]), new_distribution = tensor([0.4502, 0.3554, 0.1943])
2024-12-05 15:44:47,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 542: ref_distribution = tensor([0.4502, 0.3554, 0.1943]), new_distribution = tensor([0.4512, 0.3550, 0.1938])
2024-12-05 15:44:47,433 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 543: ref_distribution = tensor([0.4512, 0.3550, 0.1938]), new_distribution = tensor([0.4521, 0.3546, 0.1933])
2024-12-05 15:44:47,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 544: ref_distribution = tensor([0.4521, 0.3546, 0.1933]), new_distribution = tensor([0.4530, 0.3542, 0.1928])
2024-12-05 15:44:47,542 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 545: ref_distribution = tensor([0.4530, 0.3542, 0.1928]), new_distribution = tensor([0.4540, 0.3538, 0.1922])
2024-12-05 15:44:47,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 546: ref_distribution = tensor([0.4540, 0.3538, 0.1922]), new_distribution = tensor([0.4549, 0.3534, 0.1917])
2024-12-05 15:44:47,650 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 547: ref_distribution = tensor([0.4549, 0.3534, 0.1917]), new_distribution = tensor([0.4558, 0.3530, 0.1912])
2024-12-05 15:44:47,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 548: ref_distribution = tensor([0.4558, 0.3530, 0.1912]), new_distribution = tensor([0.4568, 0.3525, 0.1907])
2024-12-05 15:44:47,759 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 549: ref_distribution = tensor([0.4568, 0.3525, 0.1907]), new_distribution = tensor([0.4577, 0.3521, 0.1902])
2024-12-05 15:44:47,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 550: ref_distribution = tensor([0.4577, 0.3521, 0.1902]), new_distribution = tensor([0.4586, 0.3517, 0.1896])
2024-12-05 15:44:47,867 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 551: ref_distribution = tensor([0.4586, 0.3517, 0.1896]), new_distribution = tensor([0.4596, 0.3513, 0.1891])
2024-12-05 15:44:47,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 552: ref_distribution = tensor([0.4596, 0.3513, 0.1891]), new_distribution = tensor([0.4605, 0.3509, 0.1886])
2024-12-05 15:44:47,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 553: ref_distribution = tensor([0.4605, 0.3509, 0.1886]), new_distribution = tensor([0.4615, 0.3504, 0.1881])
2024-12-05 15:44:48,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 554: ref_distribution = tensor([0.4615, 0.3504, 0.1881]), new_distribution = tensor([0.4624, 0.3500, 0.1876])
2024-12-05 15:44:48,085 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 555: ref_distribution = tensor([0.4624, 0.3500, 0.1876]), new_distribution = tensor([0.4633, 0.3496, 0.1871])
2024-12-05 15:44:48,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 556: ref_distribution = tensor([0.4633, 0.3496, 0.1871]), new_distribution = tensor([0.4643, 0.3492, 0.1866])
2024-12-05 15:44:48,193 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 557: ref_distribution = tensor([0.4643, 0.3492, 0.1866]), new_distribution = tensor([0.4652, 0.3487, 0.1861])
2024-12-05 15:44:48,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 558: ref_distribution = tensor([0.4652, 0.3487, 0.1861]), new_distribution = tensor([0.4662, 0.3483, 0.1856])
2024-12-05 15:44:48,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 559: ref_distribution = tensor([0.4662, 0.3483, 0.1856]), new_distribution = tensor([0.4671, 0.3479, 0.1851])
2024-12-05 15:44:48,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 560: ref_distribution = tensor([0.4671, 0.3479, 0.1851]), new_distribution = tensor([0.4680, 0.3474, 0.1845])
2024-12-05 15:44:48,410 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 561: ref_distribution = tensor([0.4680, 0.3474, 0.1845]), new_distribution = tensor([0.4690, 0.3470, 0.1840])
2024-12-05 15:44:48,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 562: ref_distribution = tensor([0.4690, 0.3470, 0.1840]), new_distribution = tensor([0.4699, 0.3465, 0.1835])
2024-12-05 15:44:48,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 563: ref_distribution = tensor([0.4699, 0.3465, 0.1835]), new_distribution = tensor([0.4708, 0.3461, 0.1830])
2024-12-05 15:44:48,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 564: ref_distribution = tensor([0.4708, 0.3461, 0.1830]), new_distribution = tensor([0.4718, 0.3457, 0.1825])
2024-12-05 15:44:48,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 565: ref_distribution = tensor([0.4718, 0.3457, 0.1825]), new_distribution = tensor([0.4727, 0.3452, 0.1820])
2024-12-05 15:44:48,682 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 566: ref_distribution = tensor([0.4727, 0.3452, 0.1820]), new_distribution = tensor([0.4737, 0.3448, 0.1815])
2024-12-05 15:44:48,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 567: ref_distribution = tensor([0.4737, 0.3448, 0.1815]), new_distribution = tensor([0.4746, 0.3443, 0.1810])
2024-12-05 15:44:48,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 568: ref_distribution = tensor([0.4746, 0.3443, 0.1810]), new_distribution = tensor([0.4756, 0.3439, 0.1806])
2024-12-05 15:44:48,845 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 569: ref_distribution = tensor([0.4756, 0.3439, 0.1806]), new_distribution = tensor([0.4765, 0.3434, 0.1801])
2024-12-05 15:44:48,899 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 570: ref_distribution = tensor([0.4765, 0.3434, 0.1801]), new_distribution = tensor([0.4774, 0.3430, 0.1796])
2024-12-05 15:44:48,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 571: ref_distribution = tensor([0.4774, 0.3430, 0.1796]), new_distribution = tensor([0.4784, 0.3426, 0.1791])
2024-12-05 15:44:49,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 572: ref_distribution = tensor([0.4784, 0.3426, 0.1791]), new_distribution = tensor([0.4793, 0.3421, 0.1786])
2024-12-05 15:44:49,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 573: ref_distribution = tensor([0.4793, 0.3421, 0.1786]), new_distribution = tensor([0.4803, 0.3416, 0.1781])
2024-12-05 15:44:49,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 574: ref_distribution = tensor([0.4803, 0.3416, 0.1781]), new_distribution = tensor([0.4812, 0.3412, 0.1776])
2024-12-05 15:44:49,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 575: ref_distribution = tensor([0.4812, 0.3412, 0.1776]), new_distribution = tensor([0.4821, 0.3407, 0.1771])
2024-12-05 15:44:49,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 576: ref_distribution = tensor([0.4821, 0.3407, 0.1771]), new_distribution = tensor([0.4831, 0.3403, 0.1766])
2024-12-05 15:44:49,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 577: ref_distribution = tensor([0.4831, 0.3403, 0.1766]), new_distribution = tensor([0.4840, 0.3398, 0.1761])
2024-12-05 15:44:49,335 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 578: ref_distribution = tensor([0.4840, 0.3398, 0.1761]), new_distribution = tensor([0.4850, 0.3394, 0.1757])
2024-12-05 15:44:49,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 579: ref_distribution = tensor([0.4850, 0.3394, 0.1757]), new_distribution = tensor([0.4859, 0.3389, 0.1752])
2024-12-05 15:44:49,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 580: ref_distribution = tensor([0.4859, 0.3389, 0.1752]), new_distribution = tensor([0.4869, 0.3384, 0.1747])
2024-12-05 15:44:49,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 581: ref_distribution = tensor([0.4869, 0.3384, 0.1747]), new_distribution = tensor([0.4878, 0.3380, 0.1742])
2024-12-05 15:44:49,552 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 582: ref_distribution = tensor([0.4878, 0.3380, 0.1742]), new_distribution = tensor([0.4887, 0.3375, 0.1737])
2024-12-05 15:44:49,607 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 583: ref_distribution = tensor([0.4887, 0.3375, 0.1737]), new_distribution = tensor([0.4897, 0.3371, 0.1733])
2024-12-05 15:44:49,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 584: ref_distribution = tensor([0.4897, 0.3371, 0.1733]), new_distribution = tensor([0.4906, 0.3366, 0.1728])
2024-12-05 15:44:49,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 585: ref_distribution = tensor([0.4906, 0.3366, 0.1728]), new_distribution = tensor([0.4916, 0.3361, 0.1723])
2024-12-05 15:44:49,770 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 586: ref_distribution = tensor([0.4916, 0.3361, 0.1723]), new_distribution = tensor([0.4925, 0.3357, 0.1718])
2024-12-05 15:44:49,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 587: ref_distribution = tensor([0.4925, 0.3357, 0.1718]), new_distribution = tensor([0.4935, 0.3352, 0.1713])
2024-12-05 15:44:49,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 588: ref_distribution = tensor([0.4935, 0.3352, 0.1713]), new_distribution = tensor([0.4944, 0.3347, 0.1709])
2024-12-05 15:44:49,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 589: ref_distribution = tensor([0.4944, 0.3347, 0.1709]), new_distribution = tensor([0.4953, 0.3342, 0.1704])
2024-12-05 15:44:49,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 590: ref_distribution = tensor([0.4953, 0.3342, 0.1704]), new_distribution = tensor([0.4963, 0.3338, 0.1699])
2024-12-05 15:44:50,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 591: ref_distribution = tensor([0.4963, 0.3338, 0.1699]), new_distribution = tensor([0.4972, 0.3333, 0.1695])
2024-12-05 15:44:50,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 592: ref_distribution = tensor([0.4972, 0.3333, 0.1695]), new_distribution = tensor([0.4982, 0.3328, 0.1690])
2024-12-05 15:44:50,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 593: ref_distribution = tensor([0.4982, 0.3328, 0.1690]), new_distribution = tensor([0.4991, 0.3323, 0.1685])
2024-12-05 15:44:50,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 594: ref_distribution = tensor([0.4991, 0.3323, 0.1685]), new_distribution = tensor([0.5001, 0.3319, 0.1681])
2024-12-05 15:44:50,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 595: ref_distribution = tensor([0.5001, 0.3319, 0.1681]), new_distribution = tensor([0.5010, 0.3314, 0.1676])
2024-12-05 15:44:50,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 596: ref_distribution = tensor([0.5010, 0.3314, 0.1676]), new_distribution = tensor([0.5020, 0.3309, 0.1671])
2024-12-05 15:44:50,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 597: ref_distribution = tensor([0.5020, 0.3309, 0.1671]), new_distribution = tensor([0.5029, 0.3304, 0.1667])
2024-12-05 15:44:50,420 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 598: ref_distribution = tensor([0.5029, 0.3304, 0.1667]), new_distribution = tensor([0.5038, 0.3300, 0.1662])
2024-12-05 15:44:50,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 599: ref_distribution = tensor([0.5038, 0.3300, 0.1662]), new_distribution = tensor([0.5048, 0.3295, 0.1657])
2024-12-05 15:44:50,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 600: ref_distribution = tensor([0.5048, 0.3295, 0.1657]), new_distribution = tensor([0.5057, 0.3290, 0.1653])
2024-12-05 15:44:50,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 601: ref_distribution = tensor([0.5057, 0.3290, 0.1653]), new_distribution = tensor([0.5067, 0.3285, 0.1648])
2024-12-05 15:44:50,637 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 602: ref_distribution = tensor([0.5067, 0.3285, 0.1648]), new_distribution = tensor([0.5076, 0.3280, 0.1644])
2024-12-05 15:44:50,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 603: ref_distribution = tensor([0.5076, 0.3280, 0.1644]), new_distribution = tensor([0.5086, 0.3275, 0.1639])
2024-12-05 15:44:50,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 604: ref_distribution = tensor([0.5086, 0.3275, 0.1639]), new_distribution = tensor([0.5095, 0.3270, 0.1635])
2024-12-05 15:44:50,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 605: ref_distribution = tensor([0.5095, 0.3270, 0.1635]), new_distribution = tensor([0.5104, 0.3266, 0.1630])
2024-12-05 15:44:50,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 606: ref_distribution = tensor([0.5104, 0.3266, 0.1630]), new_distribution = tensor([0.5114, 0.3261, 0.1625])
2024-12-05 15:44:50,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 607: ref_distribution = tensor([0.5114, 0.3261, 0.1625]), new_distribution = tensor([0.5123, 0.3256, 0.1621])
2024-12-05 15:44:50,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 608: ref_distribution = tensor([0.5123, 0.3256, 0.1621]), new_distribution = tensor([0.5133, 0.3251, 0.1616])
2024-12-05 15:44:51,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 609: ref_distribution = tensor([0.5133, 0.3251, 0.1616]), new_distribution = tensor([0.5142, 0.3246, 0.1612])
2024-12-05 15:44:51,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 610: ref_distribution = tensor([0.5142, 0.3246, 0.1612]), new_distribution = tensor([0.5152, 0.3241, 0.1607])
2024-12-05 15:44:51,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 611: ref_distribution = tensor([0.5152, 0.3241, 0.1607]), new_distribution = tensor([0.5161, 0.3236, 0.1603])
2024-12-05 15:44:51,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 612: ref_distribution = tensor([0.5161, 0.3236, 0.1603]), new_distribution = tensor([0.5171, 0.3231, 0.1598])
2024-12-05 15:44:51,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 613: ref_distribution = tensor([0.5171, 0.3231, 0.1598]), new_distribution = tensor([0.5180, 0.3226, 0.1594])
2024-12-05 15:44:51,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 614: ref_distribution = tensor([0.5180, 0.3226, 0.1594]), new_distribution = tensor([0.5189, 0.3221, 0.1590])
2024-12-05 15:44:51,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 615: ref_distribution = tensor([0.5189, 0.3221, 0.1590]), new_distribution = tensor([0.5199, 0.3216, 0.1585])
2024-12-05 15:44:51,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 616: ref_distribution = tensor([0.5199, 0.3216, 0.1585]), new_distribution = tensor([0.5208, 0.3211, 0.1581])
2024-12-05 15:44:51,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 617: ref_distribution = tensor([0.5208, 0.3211, 0.1581]), new_distribution = tensor([0.5218, 0.3206, 0.1576])
2024-12-05 15:44:51,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 618: ref_distribution = tensor([0.5218, 0.3206, 0.1576]), new_distribution = tensor([0.5227, 0.3201, 0.1572])
2024-12-05 15:44:51,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 619: ref_distribution = tensor([0.5227, 0.3201, 0.1572]), new_distribution = tensor([0.5236, 0.3196, 0.1567])
2024-12-05 15:44:51,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 620: ref_distribution = tensor([0.5236, 0.3196, 0.1567]), new_distribution = tensor([0.5246, 0.3191, 0.1563])
2024-12-05 15:44:51,666 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 621: ref_distribution = tensor([0.5246, 0.3191, 0.1563]), new_distribution = tensor([0.5255, 0.3186, 0.1559])
2024-12-05 15:44:51,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 622: ref_distribution = tensor([0.5255, 0.3186, 0.1559]), new_distribution = tensor([0.5265, 0.3181, 0.1554])
2024-12-05 15:44:51,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 623: ref_distribution = tensor([0.5265, 0.3181, 0.1554]), new_distribution = tensor([0.5274, 0.3176, 0.1550])
2024-12-05 15:44:51,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 624: ref_distribution = tensor([0.5274, 0.3176, 0.1550]), new_distribution = tensor([0.5284, 0.3171, 0.1546])
2024-12-05 15:44:51,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 625: ref_distribution = tensor([0.5284, 0.3171, 0.1546]), new_distribution = tensor([0.5293, 0.3166, 0.1541])
2024-12-05 15:44:51,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 626: ref_distribution = tensor([0.5293, 0.3166, 0.1541]), new_distribution = tensor([0.5302, 0.3161, 0.1537])
2024-12-05 15:44:51,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 627: ref_distribution = tensor([0.5302, 0.3161, 0.1537]), new_distribution = tensor([0.5312, 0.3156, 0.1533])
2024-12-05 15:44:52,046 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 628: ref_distribution = tensor([0.5312, 0.3156, 0.1533]), new_distribution = tensor([0.5321, 0.3150, 0.1528])
2024-12-05 15:44:52,101 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 629: ref_distribution = tensor([0.5321, 0.3150, 0.1528]), new_distribution = tensor([0.5331, 0.3145, 0.1524])
2024-12-05 15:44:52,155 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 630: ref_distribution = tensor([0.5331, 0.3145, 0.1524]), new_distribution = tensor([0.5340, 0.3140, 0.1520])
2024-12-05 15:44:52,210 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 631: ref_distribution = tensor([0.5340, 0.3140, 0.1520]), new_distribution = tensor([0.5349, 0.3135, 0.1516])
2024-12-05 15:44:52,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 632: ref_distribution = tensor([0.5349, 0.3135, 0.1516]), new_distribution = tensor([0.5359, 0.3130, 0.1511])
2024-12-05 15:44:52,319 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 633: ref_distribution = tensor([0.5359, 0.3130, 0.1511]), new_distribution = tensor([0.5368, 0.3125, 0.1507])
2024-12-05 15:44:52,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 634: ref_distribution = tensor([0.5368, 0.3125, 0.1507]), new_distribution = tensor([0.5378, 0.3120, 0.1503])
2024-12-05 15:44:52,428 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 635: ref_distribution = tensor([0.5378, 0.3120, 0.1503]), new_distribution = tensor([0.5387, 0.3114, 0.1499])
2024-12-05 15:44:52,482 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 636: ref_distribution = tensor([0.5387, 0.3114, 0.1499]), new_distribution = tensor([0.5396, 0.3109, 0.1494])
2024-12-05 15:44:52,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 637: ref_distribution = tensor([0.5396, 0.3109, 0.1494]), new_distribution = tensor([0.5406, 0.3104, 0.1490])
2024-12-05 15:44:52,591 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 638: ref_distribution = tensor([0.5406, 0.3104, 0.1490]), new_distribution = tensor([0.5415, 0.3099, 0.1486])
2024-12-05 15:44:52,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 639: ref_distribution = tensor([0.5415, 0.3099, 0.1486]), new_distribution = tensor([0.5424, 0.3094, 0.1482])
2024-12-05 15:44:52,699 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 640: ref_distribution = tensor([0.5424, 0.3094, 0.1482]), new_distribution = tensor([0.5434, 0.3089, 0.1478])
2024-12-05 15:44:52,754 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 641: ref_distribution = tensor([0.5434, 0.3089, 0.1478]), new_distribution = tensor([0.5443, 0.3083, 0.1473])
2024-12-05 15:44:52,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 642: ref_distribution = tensor([0.5443, 0.3083, 0.1473]), new_distribution = tensor([0.5453, 0.3078, 0.1469])
2024-12-05 15:44:52,862 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 643: ref_distribution = tensor([0.5453, 0.3078, 0.1469]), new_distribution = tensor([0.5462, 0.3073, 0.1465])
2024-12-05 15:44:52,916 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 644: ref_distribution = tensor([0.5462, 0.3073, 0.1465]), new_distribution = tensor([0.5471, 0.3068, 0.1461])
2024-12-05 15:44:52,971 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 645: ref_distribution = tensor([0.5471, 0.3068, 0.1461]), new_distribution = tensor([0.5481, 0.3062, 0.1457])
2024-12-05 15:44:53,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 646: ref_distribution = tensor([0.5481, 0.3062, 0.1457]), new_distribution = tensor([0.5490, 0.3057, 0.1453])
2024-12-05 15:44:53,081 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 647: ref_distribution = tensor([0.5490, 0.3057, 0.1453]), new_distribution = tensor([0.5499, 0.3052, 0.1449])
2024-12-05 15:44:53,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 648: ref_distribution = tensor([0.5499, 0.3052, 0.1449]), new_distribution = tensor([0.5509, 0.3047, 0.1445])
2024-12-05 15:44:53,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 649: ref_distribution = tensor([0.5509, 0.3047, 0.1445]), new_distribution = tensor([0.5518, 0.3041, 0.1441])
2024-12-05 15:44:53,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 650: ref_distribution = tensor([0.5518, 0.3041, 0.1441]), new_distribution = tensor([0.5527, 0.3036, 0.1436])
2024-12-05 15:44:53,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 651: ref_distribution = tensor([0.5527, 0.3036, 0.1436]), new_distribution = tensor([0.5537, 0.3031, 0.1432])
2024-12-05 15:44:53,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 652: ref_distribution = tensor([0.5537, 0.3031, 0.1432]), new_distribution = tensor([0.5546, 0.3026, 0.1428])
2024-12-05 15:44:53,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 653: ref_distribution = tensor([0.5546, 0.3026, 0.1428]), new_distribution = tensor([0.5555, 0.3020, 0.1424])
2024-12-05 15:44:53,463 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 654: ref_distribution = tensor([0.5555, 0.3020, 0.1424]), new_distribution = tensor([0.5565, 0.3015, 0.1420])
2024-12-05 15:44:53,517 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 655: ref_distribution = tensor([0.5565, 0.3015, 0.1420]), new_distribution = tensor([0.5574, 0.3010, 0.1416])
2024-12-05 15:44:53,571 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 656: ref_distribution = tensor([0.5574, 0.3010, 0.1416]), new_distribution = tensor([0.5583, 0.3004, 0.1412])
2024-12-05 15:44:53,625 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 657: ref_distribution = tensor([0.5583, 0.3004, 0.1412]), new_distribution = tensor([0.5593, 0.2999, 0.1408])
2024-12-05 15:44:53,680 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 658: ref_distribution = tensor([0.5593, 0.2999, 0.1408]), new_distribution = tensor([0.5602, 0.2994, 0.1404])
2024-12-05 15:44:53,734 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 659: ref_distribution = tensor([0.5602, 0.2994, 0.1404]), new_distribution = tensor([0.5611, 0.2989, 0.1400])
2024-12-05 15:44:53,788 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 660: ref_distribution = tensor([0.5611, 0.2989, 0.1400]), new_distribution = tensor([0.5620, 0.2983, 0.1396])
2024-12-05 15:44:53,843 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 661: ref_distribution = tensor([0.5620, 0.2983, 0.1396]), new_distribution = tensor([0.5630, 0.2978, 0.1392])
2024-12-05 15:44:53,897 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 662: ref_distribution = tensor([0.5630, 0.2978, 0.1392]), new_distribution = tensor([0.5639, 0.2973, 0.1388])
2024-12-05 15:44:53,951 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 663: ref_distribution = tensor([0.5639, 0.2973, 0.1388]), new_distribution = tensor([0.5648, 0.2967, 0.1384])
2024-12-05 15:44:54,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 664: ref_distribution = tensor([0.5648, 0.2967, 0.1384]), new_distribution = tensor([0.5658, 0.2962, 0.1381])
2024-12-05 15:44:54,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 665: ref_distribution = tensor([0.5658, 0.2962, 0.1381]), new_distribution = tensor([0.5667, 0.2956, 0.1377])
2024-12-05 15:44:54,114 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 666: ref_distribution = tensor([0.5667, 0.2956, 0.1377]), new_distribution = tensor([0.5676, 0.2951, 0.1373])
2024-12-05 15:44:54,169 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 667: ref_distribution = tensor([0.5676, 0.2951, 0.1373]), new_distribution = tensor([0.5685, 0.2946, 0.1369])
2024-12-05 15:44:54,223 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 668: ref_distribution = tensor([0.5685, 0.2946, 0.1369]), new_distribution = tensor([0.5695, 0.2940, 0.1365])
2024-12-05 15:44:54,277 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 669: ref_distribution = tensor([0.5695, 0.2940, 0.1365]), new_distribution = tensor([0.5704, 0.2935, 0.1361])
2024-12-05 15:44:54,331 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 670: ref_distribution = tensor([0.5704, 0.2935, 0.1361]), new_distribution = tensor([0.5713, 0.2930, 0.1357])
2024-12-05 15:44:54,386 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 671: ref_distribution = tensor([0.5713, 0.2930, 0.1357]), new_distribution = tensor([0.5722, 0.2924, 0.1353])
2024-12-05 15:44:54,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 672: ref_distribution = tensor([0.5722, 0.2924, 0.1353]), new_distribution = tensor([0.5732, 0.2919, 0.1349])
2024-12-05 15:44:54,494 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 673: ref_distribution = tensor([0.5732, 0.2919, 0.1349]), new_distribution = tensor([0.5741, 0.2913, 0.1346])
2024-12-05 15:44:54,549 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 674: ref_distribution = tensor([0.5741, 0.2913, 0.1346]), new_distribution = tensor([0.5750, 0.2908, 0.1342])
2024-12-05 15:44:54,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 675: ref_distribution = tensor([0.5750, 0.2908, 0.1342]), new_distribution = tensor([0.5759, 0.2903, 0.1338])
2024-12-05 15:44:54,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 676: ref_distribution = tensor([0.5759, 0.2903, 0.1338]), new_distribution = tensor([0.5769, 0.2897, 0.1334])
2024-12-05 15:44:54,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 677: ref_distribution = tensor([0.5769, 0.2897, 0.1334]), new_distribution = tensor([0.5778, 0.2892, 0.1330])
2024-12-05 15:44:54,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 678: ref_distribution = tensor([0.5778, 0.2892, 0.1330]), new_distribution = tensor([0.5787, 0.2886, 0.1327])
2024-12-05 15:44:54,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 679: ref_distribution = tensor([0.5787, 0.2886, 0.1327]), new_distribution = tensor([0.5796, 0.2881, 0.1323])
2024-12-05 15:44:54,875 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 680: ref_distribution = tensor([0.5796, 0.2881, 0.1323]), new_distribution = tensor([0.5805, 0.2876, 0.1319])
2024-12-05 15:44:54,930 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 681: ref_distribution = tensor([0.5805, 0.2876, 0.1319]), new_distribution = tensor([0.5815, 0.2870, 0.1315])
2024-12-05 15:44:54,984 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 682: ref_distribution = tensor([0.5815, 0.2870, 0.1315]), new_distribution = tensor([0.5824, 0.2865, 0.1311])
2024-12-05 15:44:55,039 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 683: ref_distribution = tensor([0.5824, 0.2865, 0.1311]), new_distribution = tensor([0.5833, 0.2859, 0.1308])
2024-12-05 15:44:55,093 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 684: ref_distribution = tensor([0.5833, 0.2859, 0.1308]), new_distribution = tensor([0.5842, 0.2854, 0.1304])
2024-12-05 15:44:55,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 685: ref_distribution = tensor([0.5842, 0.2854, 0.1304]), new_distribution = tensor([0.5851, 0.2848, 0.1300])
2024-12-05 15:44:55,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 686: ref_distribution = tensor([0.5851, 0.2848, 0.1300]), new_distribution = tensor([0.5861, 0.2843, 0.1297])
2024-12-05 15:44:55,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 687: ref_distribution = tensor([0.5861, 0.2843, 0.1297]), new_distribution = tensor([0.5870, 0.2837, 0.1293])
2024-12-05 15:44:55,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 688: ref_distribution = tensor([0.5870, 0.2837, 0.1293]), new_distribution = tensor([0.5879, 0.2832, 0.1289])
2024-12-05 15:44:55,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 689: ref_distribution = tensor([0.5879, 0.2832, 0.1289]), new_distribution = tensor([0.5888, 0.2827, 0.1286])
2024-12-05 15:44:55,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 690: ref_distribution = tensor([0.5888, 0.2827, 0.1286]), new_distribution = tensor([0.5897, 0.2821, 0.1282])
2024-12-05 15:44:55,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 691: ref_distribution = tensor([0.5897, 0.2821, 0.1282]), new_distribution = tensor([0.5906, 0.2816, 0.1278])
2024-12-05 15:44:55,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 692: ref_distribution = tensor([0.5906, 0.2816, 0.1278]), new_distribution = tensor([0.5915, 0.2810, 0.1275])
2024-12-05 15:44:55,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 693: ref_distribution = tensor([0.5915, 0.2810, 0.1275]), new_distribution = tensor([0.5924, 0.2805, 0.1271])
2024-12-05 15:44:55,636 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 694: ref_distribution = tensor([0.5924, 0.2805, 0.1271]), new_distribution = tensor([0.5934, 0.2799, 0.1267])
2024-12-05 15:44:55,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 695: ref_distribution = tensor([0.5934, 0.2799, 0.1267]), new_distribution = tensor([0.5943, 0.2794, 0.1264])
2024-12-05 15:44:55,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 696: ref_distribution = tensor([0.5943, 0.2794, 0.1264]), new_distribution = tensor([0.5952, 0.2788, 0.1260])
2024-12-05 15:44:55,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 697: ref_distribution = tensor([0.5952, 0.2788, 0.1260]), new_distribution = tensor([0.5961, 0.2783, 0.1256])
2024-12-05 15:44:55,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 698: ref_distribution = tensor([0.5961, 0.2783, 0.1256]), new_distribution = tensor([0.5970, 0.2777, 0.1253])
2024-12-05 15:44:55,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 699: ref_distribution = tensor([0.5970, 0.2777, 0.1253]), new_distribution = tensor([0.5979, 0.2772, 0.1249])
