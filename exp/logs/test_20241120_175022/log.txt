2024-11-20 17:50:24,123 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 0 loss: 0.6915 acc: 0.52
2024-11-20 17:50:24,130 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 2 loss: 0.6910 acc: 0.52
2024-11-20 17:50:24,136 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 4 loss: 0.6905 acc: 0.52
2024-11-20 17:50:24,141 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 6 loss: 0.6902 acc: 0.52
2024-11-20 17:50:24,146 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 8 loss: 0.6898 acc: 0.55
2024-11-20 17:50:24,151 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 10 loss: 0.6896 acc: 0.55
2024-11-20 17:50:24,156 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 12 loss: 0.6894 acc: 0.55
2024-11-20 17:50:24,161 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 14 loss: 0.6892 acc: 0.55
2024-11-20 17:50:24,166 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 16 loss: 0.6891 acc: 0.55
2024-11-20 17:50:24,172 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 18 loss: 0.6890 acc: 0.55
2024-11-20 17:50:24,325 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 0 loss: -0.2034 reward: 0.2034 ref_reward: 0.1991 improvement: 2.14%
2024-11-20 17:50:24,333 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 2 loss: -0.2066 reward: 0.2066 ref_reward: 0.1991 improvement: 3.75%
2024-11-20 17:50:24,340 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 4 loss: -0.2098 reward: 0.2098 ref_reward: 0.1991 improvement: 5.34%
2024-11-20 17:50:24,347 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 6 loss: -0.2129 reward: 0.2129 ref_reward: 0.1991 improvement: 6.93%
2024-11-20 17:50:24,354 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 8 loss: -0.2162 reward: 0.2162 ref_reward: 0.1991 improvement: 8.55%
2024-11-20 17:50:24,361 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 10 loss: -0.2195 reward: 0.2195 ref_reward: 0.1991 improvement: 10.23%
2024-11-20 17:50:24,368 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 12 loss: -0.2230 reward: 0.2230 ref_reward: 0.1991 improvement: 12.00%
2024-11-20 17:50:24,375 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 14 loss: -0.2267 reward: 0.2267 ref_reward: 0.1991 improvement: 13.86%
2024-11-20 17:50:24,382 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 16 loss: -0.2307 reward: 0.2307 ref_reward: 0.1991 improvement: 15.86%
2024-11-20 17:50:24,389 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 18 loss: -0.2350 reward: 0.2350 ref_reward: 0.1991 improvement: 17.99%
2024-11-20 17:50:24,396 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 20 loss: -0.2395 reward: 0.2395 ref_reward: 0.1991 improvement: 20.26%
2024-11-20 17:50:24,403 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 22 loss: -0.2442 reward: 0.2442 ref_reward: 0.1991 improvement: 22.63%
2024-11-20 17:50:24,410 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 24 loss: -0.2491 reward: 0.2491 ref_reward: 0.1991 improvement: 25.10%
2024-11-20 17:50:24,417 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 26 loss: -0.2541 reward: 0.2541 ref_reward: 0.1991 improvement: 27.62%
2024-11-20 17:50:24,424 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 28 loss: -0.2592 reward: 0.2592 ref_reward: 0.1991 improvement: 30.17%
2024-11-20 17:50:24,431 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 30 loss: -0.2643 reward: 0.2643 ref_reward: 0.1991 improvement: 32.70%
2024-11-20 17:50:24,438 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 32 loss: -0.2692 reward: 0.2692 ref_reward: 0.1991 improvement: 35.17%
2024-11-20 17:50:24,445 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 34 loss: -0.2739 reward: 0.2739 ref_reward: 0.1991 improvement: 37.54%
2024-11-20 17:50:24,452 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 36 loss: -0.2782 reward: 0.2782 ref_reward: 0.1991 improvement: 39.72%
2024-11-20 17:50:24,459 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 38 loss: -0.2823 reward: 0.2823 ref_reward: 0.1991 improvement: 41.74%
2024-11-20 17:50:24,466 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 40 loss: -0.2859 reward: 0.2859 ref_reward: 0.1991 improvement: 43.57%
2024-11-20 17:50:24,473 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 42 loss: -0.2891 reward: 0.2891 ref_reward: 0.1991 improvement: 45.20%
2024-11-20 17:50:24,480 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 44 loss: -0.2920 reward: 0.2920 ref_reward: 0.1991 improvement: 46.63%
2024-11-20 17:50:24,487 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 46 loss: -0.2945 reward: 0.2945 ref_reward: 0.1991 improvement: 47.87%
2024-11-20 17:50:24,494 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 48 loss: -0.2966 reward: 0.2966 ref_reward: 0.1991 improvement: 48.92%
2024-11-20 17:50:24,501 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 50 loss: -0.2984 reward: 0.2984 ref_reward: 0.1991 improvement: 49.82%
2024-11-20 17:50:24,508 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 52 loss: -0.2999 reward: 0.2999 ref_reward: 0.1991 improvement: 50.57%
2024-11-20 17:50:24,516 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 54 loss: -0.3011 reward: 0.3011 ref_reward: 0.1991 improvement: 51.20%
2024-11-20 17:50:24,524 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 56 loss: -0.3021 reward: 0.3021 ref_reward: 0.1991 improvement: 51.73%
2024-11-20 17:50:24,531 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 58 loss: -0.3030 reward: 0.3030 ref_reward: 0.1991 improvement: 52.16%
2024-11-20 17:50:24,538 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 60 loss: -0.3037 reward: 0.3037 ref_reward: 0.1991 improvement: 52.53%
2024-11-20 17:50:24,546 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 62 loss: -0.3043 reward: 0.3043 ref_reward: 0.1991 improvement: 52.83%
2024-11-20 17:50:24,553 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 64 loss: -0.3049 reward: 0.3049 ref_reward: 0.1991 improvement: 53.08%
2024-11-20 17:50:24,561 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 66 loss: -0.3053 reward: 0.3053 ref_reward: 0.1991 improvement: 53.30%
2024-11-20 17:50:24,568 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 68 loss: -0.3056 reward: 0.3056 ref_reward: 0.1991 improvement: 53.48%
2024-11-20 17:50:24,575 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 70 loss: -0.3059 reward: 0.3059 ref_reward: 0.1991 improvement: 53.63%
2024-11-20 17:50:24,582 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 72 loss: -0.3062 reward: 0.3062 ref_reward: 0.1991 improvement: 53.76%
2024-11-20 17:50:24,590 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 74 loss: -0.3064 reward: 0.3064 ref_reward: 0.1991 improvement: 53.87%
2024-11-20 17:50:24,597 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 76 loss: -0.3066 reward: 0.3066 ref_reward: 0.1991 improvement: 53.97%
2024-11-20 17:50:24,604 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 78 loss: -0.3068 reward: 0.3068 ref_reward: 0.1991 improvement: 54.05%
2024-11-20 17:50:24,612 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 80 loss: -0.3069 reward: 0.3069 ref_reward: 0.1991 improvement: 54.12%
2024-11-20 17:50:24,620 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 82 loss: -0.3071 reward: 0.3071 ref_reward: 0.1991 improvement: 54.19%
2024-11-20 17:50:24,627 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 84 loss: -0.3072 reward: 0.3072 ref_reward: 0.1991 improvement: 54.24%
2024-11-20 17:50:24,635 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 86 loss: -0.3073 reward: 0.3073 ref_reward: 0.1991 improvement: 54.29%
2024-11-20 17:50:24,644 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 88 loss: -0.3074 reward: 0.3074 ref_reward: 0.1991 improvement: 54.34%
2024-11-20 17:50:24,653 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 90 loss: -0.3074 reward: 0.3074 ref_reward: 0.1991 improvement: 54.38%
2024-11-20 17:50:24,662 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 92 loss: -0.3075 reward: 0.3075 ref_reward: 0.1991 improvement: 54.42%
2024-11-20 17:50:24,670 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 94 loss: -0.3076 reward: 0.3076 ref_reward: 0.1991 improvement: 54.45%
2024-11-20 17:50:24,679 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 96 loss: -0.3076 reward: 0.3076 ref_reward: 0.1991 improvement: 54.48%
2024-11-20 17:50:24,689 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 98 loss: -0.3077 reward: 0.3077 ref_reward: 0.1991 improvement: 54.51%
2024-11-20 17:50:25,097 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 0 loss: 0.6929 grad norm: 0.0236 
2024-11-20 17:50:25,115 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 5 loss: 0.6916 grad norm: 0.0199 
2024-11-20 17:50:25,132 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 10 loss: 0.6905 grad norm: 0.0164 
2024-11-20 17:50:25,150 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 15 loss: 0.6897 grad norm: 0.0124 
2024-11-20 17:50:25,167 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 20 loss: 0.6891 grad norm: 0.0079 
2024-11-20 17:50:25,183 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 25 loss: 0.6889 grad norm: 0.0034 
2024-11-20 17:50:25,200 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 30 loss: 0.6888 grad norm: 0.0013 
2024-11-20 17:50:25,216 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 35 loss: 0.6888 grad norm: 0.0025 
2024-11-20 17:50:25,231 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 40 loss: 0.6889 grad norm: 0.0030 
2024-11-20 17:50:25,246 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 45 loss: 0.6889 grad norm: 0.0026 
2024-11-20 17:50:25,260 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 50 loss: 0.6888 grad norm: 0.0018 
2024-11-20 17:50:25,274 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 55 loss: 0.6888 grad norm: 0.0009 
2024-11-20 17:50:25,289 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 60 loss: 0.6888 grad norm: 0.0002 
2024-11-20 17:50:25,305 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 65 loss: 0.6888 grad norm: 0.0006 
2024-11-20 17:50:25,322 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 70 loss: 0.6888 grad norm: 0.0008 
2024-11-20 17:50:25,338 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 75 loss: 0.6888 grad norm: 0.0006 
2024-11-20 17:50:25,354 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 80 loss: 0.6888 grad norm: 0.0003 
2024-11-20 17:50:25,370 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 85 loss: 0.6888 grad norm: 0.0001 
2024-11-20 17:50:25,386 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 90 loss: 0.6888 grad norm: 0.0002 
2024-11-20 17:50:25,402 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 95 loss: 0.6888 grad norm: 0.0002 
2024-11-20 17:50:25,679 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 0 loss: 0.1179 grad norm: 0.3486 
2024-11-20 17:50:25,700 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 5 loss: 0.0032 grad norm: 0.0708 
2024-11-20 17:50:25,721 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 10 loss: 0.0008 grad norm: 0.0266 
2024-11-20 17:50:25,743 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 15 loss: 0.0001 grad norm: 0.0100 
2024-11-20 17:50:25,764 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 20 loss: 0.0003 grad norm: 0.0185 
2024-11-20 17:50:25,784 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 25 loss: 0.0001 grad norm: 0.0099 
2024-11-20 17:50:25,804 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 30 loss: 0.0000 grad norm: 0.0061 
2024-11-20 17:50:25,826 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 35 loss: 0.0001 grad norm: 0.0088 
2024-11-20 17:50:25,846 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 40 loss: 0.0000 grad norm: 0.0031 
2024-11-20 17:50:25,866 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 45 loss: 0.0000 grad norm: 0.0032 
2024-11-20 17:50:25,887 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 50 loss: 0.0000 grad norm: 0.0037 
2024-11-20 17:50:25,907 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0015 
2024-11-20 17:50:25,927 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0010 
2024-11-20 17:50:25,947 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0016 
2024-11-20 17:50:25,966 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0011 
2024-11-20 17:50:25,986 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0003 
2024-11-20 17:50:26,007 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0005 
2024-11-20 17:50:26,027 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0006 
2024-11-20 17:50:26,048 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0004 
2024-11-20 17:50:26,069 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0001 
2024-11-20 17:50:26,288 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 0: ref_distribution = tensor([0.7000, 0.2000, 0.1000], device='cuda:0'), new_distribution = tensor([0.7021, 0.1975, 0.1004], device='cuda:0')
2024-11-20 17:50:26,292 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 1: ref_distribution = tensor([0.7021, 0.1975, 0.1004], device='cuda:0'), new_distribution = tensor([0.7042, 0.1949, 0.1009], device='cuda:0')
2024-11-20 17:50:26,297 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 2: ref_distribution = tensor([0.7042, 0.1949, 0.1009], device='cuda:0'), new_distribution = tensor([0.7059, 0.1928, 0.1013], device='cuda:0')
