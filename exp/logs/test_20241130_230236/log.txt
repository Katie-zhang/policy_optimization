2024-11-30 23:02:36,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 0 loss: 0.6777 acc: 0.77
2024-11-30 23:02:36,845 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 2 loss: 0.6746 acc: 0.77
2024-11-30 23:02:36,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 4 loss: 0.6717 acc: 0.77
2024-11-30 23:02:36,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 6 loss: 0.6688 acc: 0.77
2024-11-30 23:02:36,861 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 8 loss: 0.6659 acc: 0.77
2024-11-30 23:02:36,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 10 loss: 0.6632 acc: 0.77
2024-11-30 23:02:36,872 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 12 loss: 0.6605 acc: 0.77
2024-11-30 23:02:36,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 14 loss: 0.6579 acc: 0.77
2024-11-30 23:02:36,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 16 loss: 0.6554 acc: 0.77
2024-11-30 23:02:36,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 18 loss: 0.6529 acc: 0.77
2024-11-30 23:02:37,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 0 loss: -0.2761 reward: 0.2761 ref_reward: 0.2734 improvement: 1.00%
2024-11-30 23:02:37,332 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 2 loss: -0.2869 reward: 0.2869 ref_reward: 0.2734 improvement: 4.95%
2024-11-30 23:02:37,597 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 4 loss: -0.2961 reward: 0.2961 ref_reward: 0.2734 improvement: 8.29%
2024-11-30 23:02:37,863 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 6 loss: -0.3041 reward: 0.3041 ref_reward: 0.2734 improvement: 11.23%
2024-11-30 23:02:38,127 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 8 loss: -0.3114 reward: 0.3114 ref_reward: 0.2734 improvement: 13.89%
2024-11-30 23:02:38,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 10 loss: -0.3181 reward: 0.3181 ref_reward: 0.2734 improvement: 16.34%
2024-11-30 23:02:38,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 12 loss: -0.3242 reward: 0.3242 ref_reward: 0.2734 improvement: 18.58%
2024-11-30 23:02:38,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 14 loss: -0.3298 reward: 0.3298 ref_reward: 0.2734 improvement: 20.64%
2024-11-30 23:02:39,156 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 16 loss: -0.3350 reward: 0.3350 ref_reward: 0.2734 improvement: 22.53%
2024-11-30 23:02:39,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 18 loss: -0.3398 reward: 0.3398 ref_reward: 0.2734 improvement: 24.30%
2024-11-30 23:02:39,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 20 loss: -0.3443 reward: 0.3443 ref_reward: 0.2734 improvement: 25.94%
2024-11-30 23:02:39,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 22 loss: -0.3485 reward: 0.3485 ref_reward: 0.2734 improvement: 27.47%
2024-11-30 23:02:39,918 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 24 loss: -0.3524 reward: 0.3524 ref_reward: 0.2734 improvement: 28.88%
2024-11-30 23:02:40,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 26 loss: -0.3559 reward: 0.3559 ref_reward: 0.2734 improvement: 30.19%
2024-11-30 23:02:40,289 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 28 loss: -0.3592 reward: 0.3592 ref_reward: 0.2734 improvement: 31.38%
2024-11-30 23:02:40,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 30 loss: -0.3622 reward: 0.3622 ref_reward: 0.2734 improvement: 32.46%
2024-11-30 23:02:40,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 32 loss: -0.3649 reward: 0.3649 ref_reward: 0.2734 improvement: 33.45%
2024-11-30 23:02:40,847 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 34 loss: -0.3673 reward: 0.3673 ref_reward: 0.2734 improvement: 34.36%
2024-11-30 23:02:41,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 36 loss: -0.3696 reward: 0.3696 ref_reward: 0.2734 improvement: 35.18%
2024-11-30 23:02:41,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 38 loss: -0.3716 reward: 0.3716 ref_reward: 0.2734 improvement: 35.92%
2024-11-30 23:02:41,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 40 loss: -0.3734 reward: 0.3734 ref_reward: 0.2734 improvement: 36.58%
2024-11-30 23:02:41,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 42 loss: -0.3750 reward: 0.3750 ref_reward: 0.2734 improvement: 37.16%
2024-11-30 23:02:41,778 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 44 loss: -0.3764 reward: 0.3764 ref_reward: 0.2734 improvement: 37.67%
2024-11-30 23:02:41,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 46 loss: -0.3776 reward: 0.3776 ref_reward: 0.2734 improvement: 38.12%
2024-11-30 23:02:42,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 48 loss: -0.3787 reward: 0.3787 ref_reward: 0.2734 improvement: 38.50%
2024-11-30 23:02:42,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 50 loss: -0.3796 reward: 0.3796 ref_reward: 0.2734 improvement: 38.83%
2024-11-30 23:02:42,521 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 52 loss: -0.3803 reward: 0.3803 ref_reward: 0.2734 improvement: 39.11%
2024-11-30 23:02:42,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 54 loss: -0.3810 reward: 0.3810 ref_reward: 0.2734 improvement: 39.36%
2024-11-30 23:02:42,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 56 loss: -0.3816 reward: 0.3816 ref_reward: 0.2734 improvement: 39.56%
2024-11-30 23:02:43,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 58 loss: -0.3820 reward: 0.3820 ref_reward: 0.2734 improvement: 39.74%
2024-11-30 23:02:43,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 60 loss: -0.3825 reward: 0.3825 ref_reward: 0.2734 improvement: 39.89%
2024-11-30 23:02:43,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 62 loss: -0.3828 reward: 0.3828 ref_reward: 0.2734 improvement: 40.02%
2024-11-30 23:02:43,636 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 64 loss: -0.3831 reward: 0.3831 ref_reward: 0.2734 improvement: 40.13%
2024-11-30 23:02:43,822 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 66 loss: -0.3834 reward: 0.3834 ref_reward: 0.2734 improvement: 40.23%
2024-11-30 23:02:44,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 68 loss: -0.3836 reward: 0.3836 ref_reward: 0.2734 improvement: 40.31%
2024-11-30 23:02:44,194 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 70 loss: -0.3838 reward: 0.3838 ref_reward: 0.2734 improvement: 40.39%
2024-11-30 23:02:44,380 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 72 loss: -0.3840 reward: 0.3840 ref_reward: 0.2734 improvement: 40.45%
2024-11-30 23:02:44,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 74 loss: -0.3841 reward: 0.3841 ref_reward: 0.2734 improvement: 40.51%
2024-11-30 23:02:44,751 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 76 loss: -0.3843 reward: 0.3843 ref_reward: 0.2734 improvement: 40.56%
2024-11-30 23:02:44,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 78 loss: -0.3844 reward: 0.3844 ref_reward: 0.2734 improvement: 40.60%
2024-11-30 23:02:45,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 80 loss: -0.3845 reward: 0.3845 ref_reward: 0.2734 improvement: 40.64%
2024-11-30 23:02:45,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 82 loss: -0.3846 reward: 0.3846 ref_reward: 0.2734 improvement: 40.67%
2024-11-30 23:02:45,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 84 loss: -0.3847 reward: 0.3847 ref_reward: 0.2734 improvement: 40.70%
2024-11-30 23:02:45,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 86 loss: -0.3848 reward: 0.3848 ref_reward: 0.2734 improvement: 40.73%
2024-11-30 23:02:45,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 88 loss: -0.3848 reward: 0.3848 ref_reward: 0.2734 improvement: 40.76%
2024-11-30 23:02:46,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 90 loss: -0.3849 reward: 0.3849 ref_reward: 0.2734 improvement: 40.78%
2024-11-30 23:02:46,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 92 loss: -0.3850 reward: 0.3850 ref_reward: 0.2734 improvement: 40.80%
2024-11-30 23:02:46,434 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 94 loss: -0.3850 reward: 0.3850 ref_reward: 0.2734 improvement: 40.82%
2024-11-30 23:02:46,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 96 loss: -0.3851 reward: 0.3851 ref_reward: 0.2734 improvement: 40.84%
2024-11-30 23:02:46,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 98 loss: -0.3851 reward: 0.3851 ref_reward: 0.2734 improvement: 40.86%
2024-11-30 23:02:47,349 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 0 loss: 0.6911 grad norm: 0.1421 
2024-11-30 23:02:47,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 5 loss: 0.6782 grad norm: 0.1153 
2024-11-30 23:02:48,277 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 10 loss: 0.6687 grad norm: 0.0987 
2024-11-30 23:02:48,739 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 15 loss: 0.6615 grad norm: 0.0906 
2024-11-30 23:02:49,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 20 loss: 0.6552 grad norm: 0.0825 
2024-11-30 23:02:49,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 25 loss: 0.6497 grad norm: 0.0735 
2024-11-30 23:02:50,131 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 30 loss: 0.6450 grad norm: 0.0636 
2024-11-30 23:02:50,595 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 35 loss: 0.6412 grad norm: 0.0536 
2024-11-30 23:02:51,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 40 loss: 0.6382 grad norm: 0.0441 
2024-11-30 23:02:51,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 45 loss: 0.6360 grad norm: 0.0358 
2024-11-30 23:02:51,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 50 loss: 0.6344 grad norm: 0.0291 
2024-11-30 23:02:52,453 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 55 loss: 0.6332 grad norm: 0.0239 
2024-11-30 23:02:52,918 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 60 loss: 0.6323 grad norm: 0.0198 
2024-11-30 23:02:53,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 65 loss: 0.6317 grad norm: 0.0166 
2024-11-30 23:02:53,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 70 loss: 0.6312 grad norm: 0.0143 
2024-11-30 23:02:54,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 75 loss: 0.6309 grad norm: 0.0124 
2024-11-30 23:02:54,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 80 loss: 0.6306 grad norm: 0.0107 
2024-11-30 23:02:55,240 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 85 loss: 0.6304 grad norm: 0.0094 
2024-11-30 23:02:55,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 90 loss: 0.6302 grad norm: 0.0084 
2024-11-30 23:02:56,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 95 loss: 0.6301 grad norm: 0.0076 
2024-11-30 23:02:56,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 0 loss: 0.7603 grad norm: 0.2083 
2024-11-30 23:02:57,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 5 loss: 0.7412 grad norm: 0.1822 
2024-11-30 23:02:57,818 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 10 loss: 0.7259 grad norm: 0.1632 
2024-11-30 23:02:58,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 15 loss: 0.7130 grad norm: 0.1466 
2024-11-30 23:02:58,749 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 20 loss: 0.7023 grad norm: 0.1324 
2024-11-30 23:02:59,213 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 25 loss: 0.6933 grad norm: 0.1124 
2024-11-30 23:02:59,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 30 loss: 0.6864 grad norm: 0.0882 
2024-11-30 23:03:00,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 35 loss: 0.6816 grad norm: 0.0652 
2024-11-30 23:03:00,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 40 loss: 0.6785 grad norm: 0.0482 
2024-11-30 23:03:01,067 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 45 loss: 0.6764 grad norm: 0.0373 
2024-11-30 23:03:01,531 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 50 loss: 0.6749 grad norm: 0.0301 
2024-11-30 23:03:01,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 55 loss: 0.6738 grad norm: 0.0248 
2024-11-30 23:03:02,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 60 loss: 0.6730 grad norm: 0.0213 
2024-11-30 23:03:02,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 65 loss: 0.6724 grad norm: 0.0202 
2024-11-30 23:03:03,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 70 loss: 0.6721 grad norm: 0.0190 
2024-11-30 23:03:03,852 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 75 loss: 0.6717 grad norm: 0.0159 
2024-11-30 23:03:04,316 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 80 loss: 0.6715 grad norm: 0.0127 
2024-11-30 23:03:04,780 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 85 loss: 0.6713 grad norm: 0.0108 
2024-11-30 23:03:05,241 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 90 loss: 0.6711 grad norm: 0.0097 
2024-11-30 23:03:05,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 95 loss: 0.6710 grad norm: 0.0092 
2024-11-30 23:03:06,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 0 loss: 0.8616 grad norm: 0.2120 
2024-11-30 23:03:06,863 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 5 loss: 0.8443 grad norm: 0.2016 
2024-11-30 23:03:07,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 10 loss: 0.8298 grad norm: 0.2002 
2024-11-30 23:03:07,792 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 15 loss: 0.8167 grad norm: 0.2135 
2024-11-30 23:03:08,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 20 loss: 0.8035 grad norm: 0.2282 
2024-11-30 23:03:08,723 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 25 loss: 0.7895 grad norm: 0.2421 
2024-11-30 23:03:09,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 30 loss: 0.7744 grad norm: 0.2474 
2024-11-30 23:03:09,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 35 loss: 0.7591 grad norm: 0.2407 
2024-11-30 23:03:10,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 40 loss: 0.7447 grad norm: 0.2215 
2024-11-30 23:03:10,586 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 45 loss: 0.7321 grad norm: 0.1930 
2024-11-30 23:03:11,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 50 loss: 0.7220 grad norm: 0.1608 
2024-11-30 23:03:11,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 55 loss: 0.7144 grad norm: 0.1303 
2024-11-30 23:03:11,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 60 loss: 0.7090 grad norm: 0.1045 
2024-11-30 23:03:12,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 65 loss: 0.7052 grad norm: 0.0842 
2024-11-30 23:03:12,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 70 loss: 0.7025 grad norm: 0.0688 
2024-11-30 23:03:13,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 75 loss: 0.7006 grad norm: 0.0571 
2024-11-30 23:03:13,838 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 80 loss: 0.6993 grad norm: 0.0483 
2024-11-30 23:03:14,305 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 85 loss: 0.6983 grad norm: 0.0416 
2024-11-30 23:03:14,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 90 loss: 0.6975 grad norm: 0.0363 
2024-11-30 23:03:15,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 95 loss: 0.6969 grad norm: 0.0321 
2024-11-30 23:03:15,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 0 loss: 0.6398 grad norm: 0.0956 
2024-11-30 23:03:16,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 5 loss: 0.6320 grad norm: 0.0752 
2024-11-30 23:03:16,843 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 10 loss: 0.6261 grad norm: 0.0640 
2024-11-30 23:03:17,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 15 loss: 0.6216 grad norm: 0.0563 
2024-11-30 23:03:17,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 20 loss: 0.6180 grad norm: 0.0501 
2024-11-30 23:03:18,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 25 loss: 0.6150 grad norm: 0.0444 
2024-11-30 23:03:18,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 30 loss: 0.6125 grad norm: 0.0384 
2024-11-30 23:03:19,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 35 loss: 0.6105 grad norm: 0.0318 
2024-11-30 23:03:19,632 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 40 loss: 0.6090 grad norm: 0.0251 
2024-11-30 23:03:20,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 45 loss: 0.6078 grad norm: 0.0198 
2024-11-30 23:03:20,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 50 loss: 0.6070 grad norm: 0.0162 
2024-11-30 23:03:21,032 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 55 loss: 0.6064 grad norm: 0.0136 
2024-11-30 23:03:21,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 60 loss: 0.6059 grad norm: 0.0122 
2024-11-30 23:03:21,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 65 loss: 0.6056 grad norm: 0.0107 
2024-11-30 23:03:22,428 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 70 loss: 0.6053 grad norm: 0.0086 
2024-11-30 23:03:22,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 75 loss: 0.6051 grad norm: 0.0073 
2024-11-30 23:03:23,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 80 loss: 0.6050 grad norm: 0.0066 
2024-11-30 23:03:23,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 85 loss: 0.6049 grad norm: 0.0062 
2024-11-30 23:03:24,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 90 loss: 0.6048 grad norm: 0.0055 
2024-11-30 23:03:24,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 95 loss: 0.6047 grad norm: 0.0048 
2024-11-30 23:03:26,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 0 loss: 0.0009 grad norm: 0.0368 
2024-11-30 23:03:26,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 5 loss: 0.0009 grad norm: 0.0284 
2024-11-30 23:03:27,484 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 10 loss: 0.0002 grad norm: 0.0155 
2024-11-30 23:03:28,035 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 15 loss: 0.0000 grad norm: 0.0042 
2024-11-30 23:03:28,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 20 loss: 0.0001 grad norm: 0.0091 
2024-11-30 23:03:28,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 25 loss: 0.0001 grad norm: 0.0108 
