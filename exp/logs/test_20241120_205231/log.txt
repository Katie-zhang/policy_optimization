2024-11-20 20:52:31,306 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 0 loss: 0.6915 acc: 0.52
2024-11-20 20:52:31,312 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 2 loss: 0.6910 acc: 0.52
2024-11-20 20:52:31,318 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 4 loss: 0.6905 acc: 0.52
2024-11-20 20:52:31,323 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 6 loss: 0.6902 acc: 0.52
2024-11-20 20:52:31,329 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 8 loss: 0.6898 acc: 0.55
2024-11-20 20:52:31,335 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 10 loss: 0.6896 acc: 0.55
2024-11-20 20:52:31,341 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 12 loss: 0.6894 acc: 0.55
2024-11-20 20:52:31,347 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 14 loss: 0.6892 acc: 0.55
2024-11-20 20:52:31,353 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 16 loss: 0.6891 acc: 0.55
2024-11-20 20:52:31,359 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 18 loss: 0.6890 acc: 0.55
2024-11-20 20:52:31,417 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 0 loss: -0.1953 reward: 0.1953 ref_reward: 0.1991 improvement: -1.95%
2024-11-20 20:52:31,424 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 2 loss: -0.2000 reward: 0.2000 ref_reward: 0.1991 improvement: 0.46%
2024-11-20 20:52:31,432 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 4 loss: -0.2041 reward: 0.2041 ref_reward: 0.1991 improvement: 2.47%
2024-11-20 20:52:31,439 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 6 loss: -0.2077 reward: 0.2077 ref_reward: 0.1991 improvement: 4.29%
2024-11-20 20:52:31,446 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 8 loss: -0.2113 reward: 0.2113 ref_reward: 0.1991 improvement: 6.09%
2024-11-20 20:52:31,453 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 10 loss: -0.2148 reward: 0.2148 ref_reward: 0.1991 improvement: 7.85%
2024-11-20 20:52:31,460 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 12 loss: -0.2185 reward: 0.2185 ref_reward: 0.1991 improvement: 9.73%
2024-11-20 20:52:31,467 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 14 loss: -0.2225 reward: 0.2225 ref_reward: 0.1991 improvement: 11.71%
2024-11-20 20:52:31,474 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 16 loss: -0.2264 reward: 0.2264 ref_reward: 0.1991 improvement: 13.67%
2024-11-20 20:52:31,481 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 18 loss: -0.2303 reward: 0.2303 ref_reward: 0.1991 improvement: 15.64%
2024-11-20 20:52:31,488 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 20 loss: -0.2345 reward: 0.2345 ref_reward: 0.1991 improvement: 17.74%
2024-11-20 20:52:31,495 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 22 loss: -0.2388 reward: 0.2388 ref_reward: 0.1991 improvement: 19.94%
2024-11-20 20:52:31,503 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 24 loss: -0.2434 reward: 0.2434 ref_reward: 0.1991 improvement: 22.23%
2024-11-20 20:52:31,510 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 26 loss: -0.2481 reward: 0.2481 ref_reward: 0.1991 improvement: 24.59%
2024-11-20 20:52:31,517 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 28 loss: -0.2529 reward: 0.2529 ref_reward: 0.1991 improvement: 27.00%
2024-11-20 20:52:31,524 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 30 loss: -0.2577 reward: 0.2577 ref_reward: 0.1991 improvement: 29.42%
2024-11-20 20:52:31,531 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 32 loss: -0.2625 reward: 0.2625 ref_reward: 0.1991 improvement: 31.83%
2024-11-20 20:52:31,538 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 34 loss: -0.2672 reward: 0.2672 ref_reward: 0.1991 improvement: 34.17%
2024-11-20 20:52:31,545 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 36 loss: -0.2717 reward: 0.2717 ref_reward: 0.1991 improvement: 36.43%
2024-11-20 20:52:31,552 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 38 loss: -0.2759 reward: 0.2759 ref_reward: 0.1991 improvement: 38.56%
2024-11-20 20:52:31,559 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 40 loss: -0.2799 reward: 0.2799 ref_reward: 0.1991 improvement: 40.54%
2024-11-20 20:52:31,567 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 42 loss: -0.2835 reward: 0.2835 ref_reward: 0.1991 improvement: 42.36%
2024-11-20 20:52:31,575 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 44 loss: -0.2868 reward: 0.2868 ref_reward: 0.1991 improvement: 43.99%
2024-11-20 20:52:31,583 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 46 loss: -0.2896 reward: 0.2896 ref_reward: 0.1991 improvement: 45.45%
2024-11-20 20:52:31,591 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 48 loss: -0.2922 reward: 0.2922 ref_reward: 0.1991 improvement: 46.72%
2024-11-20 20:52:31,599 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 50 loss: -0.2944 reward: 0.2944 ref_reward: 0.1991 improvement: 47.83%
2024-11-20 20:52:31,607 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 52 loss: -0.2963 reward: 0.2963 ref_reward: 0.1991 improvement: 48.79%
2024-11-20 20:52:31,615 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 54 loss: -0.2979 reward: 0.2979 ref_reward: 0.1991 improvement: 49.60%
2024-11-20 20:52:31,623 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 56 loss: -0.2993 reward: 0.2993 ref_reward: 0.1991 improvement: 50.30%
2024-11-20 20:52:31,631 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 58 loss: -0.3005 reward: 0.3005 ref_reward: 0.1991 improvement: 50.89%
2024-11-20 20:52:31,639 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 60 loss: -0.3015 reward: 0.3015 ref_reward: 0.1991 improvement: 51.39%
2024-11-20 20:52:31,647 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 62 loss: -0.3023 reward: 0.3023 ref_reward: 0.1991 improvement: 51.81%
2024-11-20 20:52:31,655 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 64 loss: -0.3030 reward: 0.3030 ref_reward: 0.1991 improvement: 52.17%
2024-11-20 20:52:31,664 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 66 loss: -0.3036 reward: 0.3036 ref_reward: 0.1991 improvement: 52.47%
2024-11-20 20:52:31,672 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 68 loss: -0.3042 reward: 0.3042 ref_reward: 0.1991 improvement: 52.73%
2024-11-20 20:52:31,680 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 70 loss: -0.3046 reward: 0.3046 ref_reward: 0.1991 improvement: 52.96%
2024-11-20 20:52:31,688 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 72 loss: -0.3050 reward: 0.3050 ref_reward: 0.1991 improvement: 53.15%
2024-11-20 20:52:31,696 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 74 loss: -0.3053 reward: 0.3053 ref_reward: 0.1991 improvement: 53.31%
2024-11-20 20:52:31,704 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 76 loss: -0.3056 reward: 0.3056 ref_reward: 0.1991 improvement: 53.45%
2024-11-20 20:52:31,712 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 78 loss: -0.3058 reward: 0.3058 ref_reward: 0.1991 improvement: 53.58%
2024-11-20 20:52:31,720 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 80 loss: -0.3061 reward: 0.3061 ref_reward: 0.1991 improvement: 53.69%
2024-11-20 20:52:31,727 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 82 loss: -0.3062 reward: 0.3062 ref_reward: 0.1991 improvement: 53.78%
2024-11-20 20:52:31,734 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 84 loss: -0.3064 reward: 0.3064 ref_reward: 0.1991 improvement: 53.87%
2024-11-20 20:52:31,742 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 86 loss: -0.3066 reward: 0.3066 ref_reward: 0.1991 improvement: 53.94%
2024-11-20 20:52:31,749 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 88 loss: -0.3067 reward: 0.3067 ref_reward: 0.1991 improvement: 54.01%
2024-11-20 20:52:31,756 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 90 loss: -0.3068 reward: 0.3068 ref_reward: 0.1991 improvement: 54.07%
2024-11-20 20:52:31,764 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 92 loss: -0.3069 reward: 0.3069 ref_reward: 0.1991 improvement: 54.12%
2024-11-20 20:52:31,771 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 94 loss: -0.3070 reward: 0.3070 ref_reward: 0.1991 improvement: 54.17%
2024-11-20 20:52:31,778 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 96 loss: -0.3071 reward: 0.3071 ref_reward: 0.1991 improvement: 54.22%
2024-11-20 20:52:31,786 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 98 loss: -0.3072 reward: 0.3072 ref_reward: 0.1991 improvement: 54.26%
2024-11-20 20:52:32,021 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 0 loss: 0.6936 grad norm: 0.0358 
2024-11-20 20:52:32,040 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 5 loss: 0.6909 grad norm: 0.0242 
2024-11-20 20:52:32,058 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 10 loss: 0.6894 grad norm: 0.0146 
2024-11-20 20:52:32,078 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 15 loss: 0.6888 grad norm: 0.0037 
2024-11-20 20:52:32,097 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 20 loss: 0.6889 grad norm: 0.0056 
2024-11-20 20:52:32,117 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 25 loss: 0.6890 grad norm: 0.0087 
2024-11-20 20:52:32,137 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 30 loss: 0.6889 grad norm: 0.0062 
2024-11-20 20:52:32,157 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 35 loss: 0.6888 grad norm: 0.0021 
2024-11-20 20:52:32,175 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 40 loss: 0.6888 grad norm: 0.0015 
2024-11-20 20:52:32,193 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 45 loss: 0.6888 grad norm: 0.0025 
2024-11-20 20:52:32,211 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 50 loss: 0.6888 grad norm: 0.0021 
2024-11-20 20:52:32,229 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 55 loss: 0.6888 grad norm: 0.0010 
2024-11-20 20:52:32,247 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 60 loss: 0.6888 grad norm: 0.0005 
2024-11-20 20:52:32,266 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 65 loss: 0.6888 grad norm: 0.0009 
2024-11-20 20:52:32,284 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 70 loss: 0.6888 grad norm: 0.0007 
2024-11-20 20:52:32,302 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 75 loss: 0.6888 grad norm: 0.0003 
2024-11-20 20:52:32,321 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 80 loss: 0.6888 grad norm: 0.0003 
2024-11-20 20:52:32,339 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 85 loss: 0.6888 grad norm: 0.0003 
2024-11-20 20:52:32,356 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 90 loss: 0.6888 grad norm: 0.0002 
2024-11-20 20:52:32,374 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 95 loss: 0.6888 grad norm: 0.0001 
2024-11-20 20:52:32,551 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 0 loss: 0.7295 grad norm: 0.1041 
2024-11-20 20:52:32,569 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 5 loss: 0.7187 grad norm: 0.1026 
2024-11-20 20:52:32,586 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 10 loss: 0.7091 grad norm: 0.0962 
2024-11-20 20:52:32,604 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 15 loss: 0.7007 grad norm: 0.0825 
2024-11-20 20:52:32,621 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 20 loss: 0.6944 grad norm: 0.0594 
2024-11-20 20:52:32,641 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 25 loss: 0.6908 grad norm: 0.0339 
2024-11-20 20:52:32,660 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 30 loss: 0.6892 grad norm: 0.0141 
2024-11-20 20:52:32,679 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 35 loss: 0.6889 grad norm: 0.0027 
2024-11-20 20:52:32,699 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 40 loss: 0.6889 grad norm: 0.0035 
2024-11-20 20:52:32,726 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 45 loss: 0.6890 grad norm: 0.0060 
2024-11-20 20:52:32,744 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 50 loss: 0.6890 grad norm: 0.0068 
2024-11-20 20:52:32,761 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 55 loss: 0.6890 grad norm: 0.0067 
2024-11-20 20:52:32,778 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 60 loss: 0.6890 grad norm: 0.0060 
2024-11-20 20:52:32,795 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 65 loss: 0.6889 grad norm: 0.0049 
2024-11-20 20:52:32,812 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 70 loss: 0.6889 grad norm: 0.0036 
2024-11-20 20:52:32,831 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 75 loss: 0.6888 grad norm: 0.0023 
2024-11-20 20:52:32,849 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 80 loss: 0.6888 grad norm: 0.0011 
2024-11-20 20:52:32,866 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 85 loss: 0.6888 grad norm: 0.0005 
2024-11-20 20:52:32,883 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 90 loss: 0.6888 grad norm: 0.0008 
2024-11-20 20:52:32,901 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 95 loss: 0.6888 grad norm: 0.0010 
2024-11-20 20:52:33,080 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 0 loss: 0.7913 grad norm: 0.1432 
2024-11-20 20:52:33,098 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 5 loss: 0.7775 grad norm: 0.1435 
2024-11-20 20:52:33,115 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 10 loss: 0.7644 grad norm: 0.1459 
2024-11-20 20:52:33,132 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 15 loss: 0.7524 grad norm: 0.1476 
2024-11-20 20:52:33,148 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 20 loss: 0.7409 grad norm: 0.1470 
2024-11-20 20:52:33,163 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 25 loss: 0.7299 grad norm: 0.1382 
2024-11-20 20:52:33,179 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 30 loss: 0.7200 grad norm: 0.1204 
2024-11-20 20:52:33,195 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 35 loss: 0.7120 grad norm: 0.0976 
2024-11-20 20:52:33,210 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 40 loss: 0.7061 grad norm: 0.0751 
2024-11-20 20:52:33,226 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 45 loss: 0.7022 grad norm: 0.0565 
2024-11-20 20:52:33,242 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 50 loss: 0.6996 grad norm: 0.0427 
2024-11-20 20:52:33,257 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 55 loss: 0.6979 grad norm: 0.0330 
2024-11-20 20:52:33,273 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 60 loss: 0.6969 grad norm: 0.0262 
2024-11-20 20:52:33,288 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 65 loss: 0.6961 grad norm: 0.0215 
2024-11-20 20:52:33,304 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 70 loss: 0.6956 grad norm: 0.0182 
2024-11-20 20:52:33,320 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 75 loss: 0.6952 grad norm: 0.0157 
2024-11-20 20:52:33,335 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 80 loss: 0.6950 grad norm: 0.0138 
2024-11-20 20:52:33,351 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 85 loss: 0.6947 grad norm: 0.0123 
2024-11-20 20:52:33,366 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 90 loss: 0.6946 grad norm: 0.0111 
2024-11-20 20:52:33,383 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 95 loss: 0.6944 grad norm: 0.0101 
2024-11-20 20:52:33,563 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 0 loss: 0.6961 grad norm: 0.0517 
2024-11-20 20:52:33,579 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 5 loss: 0.6919 grad norm: 0.0344 
2024-11-20 20:52:33,595 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 10 loss: 0.6898 grad norm: 0.0193 
2024-11-20 20:52:33,611 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 15 loss: 0.6890 grad norm: 0.0063 
2024-11-20 20:52:33,627 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 20 loss: 0.6890 grad norm: 0.0073 
2024-11-20 20:52:33,642 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 25 loss: 0.6890 grad norm: 0.0088 
2024-11-20 20:52:33,659 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 30 loss: 0.6889 grad norm: 0.0054 
2024-11-20 20:52:33,675 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 35 loss: 0.6888 grad norm: 0.0023 
2024-11-20 20:52:33,691 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 40 loss: 0.6889 grad norm: 0.0035 
2024-11-20 20:52:33,706 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 45 loss: 0.6888 grad norm: 0.0028 
2024-11-20 20:52:33,722 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 50 loss: 0.6888 grad norm: 0.0010 
2024-11-20 20:52:33,738 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 55 loss: 0.6888 grad norm: 0.0009 
2024-11-20 20:52:33,756 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 60 loss: 0.6888 grad norm: 0.0012 
2024-11-20 20:52:33,773 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 65 loss: 0.6888 grad norm: 0.0007 
2024-11-20 20:52:33,790 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 70 loss: 0.6888 grad norm: 0.0005 
2024-11-20 20:52:33,806 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 75 loss: 0.6888 grad norm: 0.0007 
2024-11-20 20:52:33,821 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 80 loss: 0.6888 grad norm: 0.0005 
2024-11-20 20:52:33,837 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 85 loss: 0.6888 grad norm: 0.0001 
2024-11-20 20:52:33,853 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 90 loss: 0.6888 grad norm: 0.0003 
2024-11-20 20:52:33,869 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 95 loss: 0.6888 grad norm: 0.0003 
2024-11-20 20:52:34,123 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 0 loss: 0.1316 grad norm: 0.3288 
2024-11-20 20:52:34,143 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 5 loss: 0.0034 grad norm: 0.0638 
2024-11-20 20:52:34,163 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 10 loss: 0.0004 grad norm: 0.0174 
2024-11-20 20:52:34,182 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 15 loss: 0.0004 grad norm: 0.0147 
2024-11-20 20:52:34,202 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 20 loss: 0.0004 grad norm: 0.0147 
2024-11-20 20:52:34,221 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 25 loss: 0.0001 grad norm: 0.0062 
2024-11-20 20:52:34,243 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 30 loss: 0.0000 grad norm: 0.0038 
2024-11-20 20:52:34,264 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 35 loss: 0.0000 grad norm: 0.0035 
2024-11-20 20:52:34,283 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 40 loss: 0.0000 grad norm: 0.0036 
2024-11-20 20:52:34,302 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 45 loss: 0.0000 grad norm: 0.0011 
2024-11-20 20:52:34,322 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 50 loss: 0.0000 grad norm: 0.0015 
2024-11-20 20:52:34,341 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0018 
2024-11-20 20:52:34,362 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0004 
2024-11-20 20:52:34,382 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0009 
2024-11-20 20:52:34,402 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0007 
2024-11-20 20:52:34,421 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0002 
2024-11-20 20:52:34,441 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0004 
2024-11-20 20:52:34,461 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0003 
2024-11-20 20:52:34,480 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0001 
2024-11-20 20:52:34,500 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0001 
2024-11-20 20:52:34,520 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0001 
2024-11-20 20:52:34,539 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,559 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0001 
2024-11-20 20:52:34,578 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,598 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,619 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,643 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,664 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,684 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,704 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,724 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,745 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,765 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,785 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,806 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,827 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,847 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,868 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,888 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,909 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,929 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,950 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,970 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:34,991 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,011 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,031 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,054 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,077 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,098 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,120 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,141 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,161 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,181 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,203 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,224 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,245 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,265 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,285 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,306 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,328 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0000 
2024-11-20 20:52:35,545 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 0: ref_distribution = tensor([0.3333, 0.3333, 0.3333], device='cuda:0'), new_distribution = tensor([0.3338, 0.3339, 0.3323], device='cuda:0')
2024-11-20 20:52:35,549 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 1: ref_distribution = tensor([0.3338, 0.3339, 0.3323], device='cuda:0'), new_distribution = tensor([0.3345, 0.3339, 0.3315], device='cuda:0')
2024-11-20 20:52:35,553 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 2: ref_distribution = tensor([0.3345, 0.3339, 0.3315], device='cuda:0'), new_distribution = tensor([0.3358, 0.3345, 0.3298], device='cuda:0')
2024-11-20 20:52:35,557 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 3: ref_distribution = tensor([0.3358, 0.3345, 0.3298], device='cuda:0'), new_distribution = tensor([0.3372, 0.3338, 0.3290], device='cuda:0')
2024-11-20 20:52:35,561 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 4: ref_distribution = tensor([0.3372, 0.3338, 0.3290], device='cuda:0'), new_distribution = tensor([0.3377, 0.3336, 0.3287], device='cuda:0')
2024-11-20 20:52:35,565 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 5: ref_distribution = tensor([0.3377, 0.3336, 0.3287], device='cuda:0'), new_distribution = tensor([0.3392, 0.3344, 0.3265], device='cuda:0')
2024-11-20 20:52:35,570 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 6: ref_distribution = tensor([0.3392, 0.3344, 0.3265], device='cuda:0'), new_distribution = tensor([0.3397, 0.3341, 0.3262], device='cuda:0')
2024-11-20 20:52:35,574 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 7: ref_distribution = tensor([0.3397, 0.3341, 0.3262], device='cuda:0'), new_distribution = tensor([0.3397, 0.3342, 0.3261], device='cuda:0')
2024-11-20 20:52:35,578 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 8: ref_distribution = tensor([0.3397, 0.3342, 0.3261], device='cuda:0'), new_distribution = tensor([0.3402, 0.3354, 0.3244], device='cuda:0')
2024-11-20 20:52:35,582 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 9: ref_distribution = tensor([0.3402, 0.3354, 0.3244], device='cuda:0'), new_distribution = tensor([0.3405, 0.3364, 0.3231], device='cuda:0')
2024-11-20 20:52:35,586 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 10: ref_distribution = tensor([0.3405, 0.3364, 0.3231], device='cuda:0'), new_distribution = tensor([0.3410, 0.3369, 0.3221], device='cuda:0')
2024-11-20 20:52:35,590 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 11: ref_distribution = tensor([0.3410, 0.3369, 0.3221], device='cuda:0'), new_distribution = tensor([0.3432, 0.3369, 0.3199], device='cuda:0')
2024-11-20 20:52:35,594 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 12: ref_distribution = tensor([0.3432, 0.3369, 0.3199], device='cuda:0'), new_distribution = tensor([0.3435, 0.3371, 0.3194], device='cuda:0')
2024-11-20 20:52:35,599 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 13: ref_distribution = tensor([0.3435, 0.3371, 0.3194], device='cuda:0'), new_distribution = tensor([0.3440, 0.3383, 0.3177], device='cuda:0')
2024-11-20 20:52:35,603 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 14: ref_distribution = tensor([0.3440, 0.3383, 0.3177], device='cuda:0'), new_distribution = tensor([0.3455, 0.3390, 0.3155], device='cuda:0')
2024-11-20 20:52:35,607 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 15: ref_distribution = tensor([0.3455, 0.3390, 0.3155], device='cuda:0'), new_distribution = tensor([0.3463, 0.3390, 0.3148], device='cuda:0')
2024-11-20 20:52:35,611 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 16: ref_distribution = tensor([0.3463, 0.3390, 0.3148], device='cuda:0'), new_distribution = tensor([0.3466, 0.3392, 0.3143], device='cuda:0')
2024-11-20 20:52:35,615 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 17: ref_distribution = tensor([0.3466, 0.3392, 0.3143], device='cuda:0'), new_distribution = tensor([0.3469, 0.3394, 0.3138], device='cuda:0')
2024-11-20 20:52:35,619 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 18: ref_distribution = tensor([0.3469, 0.3394, 0.3138], device='cuda:0'), new_distribution = tensor([0.3475, 0.3384, 0.3142], device='cuda:0')
2024-11-20 20:52:35,624 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 19: ref_distribution = tensor([0.3475, 0.3384, 0.3142], device='cuda:0'), new_distribution = tensor([0.3487, 0.3381, 0.3132], device='cuda:0')
2024-11-20 20:52:35,628 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 20: ref_distribution = tensor([0.3487, 0.3381, 0.3132], device='cuda:0'), new_distribution = tensor([0.3493, 0.3378, 0.3129], device='cuda:0')
2024-11-20 20:52:35,632 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 21: ref_distribution = tensor([0.3493, 0.3378, 0.3129], device='cuda:0'), new_distribution = tensor([0.3503, 0.3373, 0.3124], device='cuda:0')
2024-11-20 20:52:35,636 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 22: ref_distribution = tensor([0.3503, 0.3373, 0.3124], device='cuda:0'), new_distribution = tensor([0.3516, 0.3370, 0.3114], device='cuda:0')
2024-11-20 20:52:35,640 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 23: ref_distribution = tensor([0.3516, 0.3370, 0.3114], device='cuda:0'), new_distribution = tensor([0.3531, 0.3369, 0.3100], device='cuda:0')
2024-11-20 20:52:35,644 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 24: ref_distribution = tensor([0.3531, 0.3369, 0.3100], device='cuda:0'), new_distribution = tensor([0.3529, 0.3380, 0.3090], device='cuda:0')
2024-11-20 20:52:35,648 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 25: ref_distribution = tensor([0.3529, 0.3380, 0.3090], device='cuda:0'), new_distribution = tensor([0.3540, 0.3389, 0.3071], device='cuda:0')
2024-11-20 20:52:35,652 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 26: ref_distribution = tensor([0.3540, 0.3389, 0.3071], device='cuda:0'), new_distribution = tensor([0.3540, 0.3395, 0.3064], device='cuda:0')
2024-11-20 20:52:35,656 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 27: ref_distribution = tensor([0.3540, 0.3395, 0.3064], device='cuda:0'), new_distribution = tensor([0.3541, 0.3394, 0.3064], device='cuda:0')
2024-11-20 20:52:35,660 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 28: ref_distribution = tensor([0.3541, 0.3394, 0.3064], device='cuda:0'), new_distribution = tensor([0.3554, 0.3391, 0.3055], device='cuda:0')
2024-11-20 20:52:35,664 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 29: ref_distribution = tensor([0.3554, 0.3391, 0.3055], device='cuda:0'), new_distribution = tensor([0.3565, 0.3393, 0.3043], device='cuda:0')
2024-11-20 20:52:35,668 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 30: ref_distribution = tensor([0.3565, 0.3393, 0.3043], device='cuda:0'), new_distribution = tensor([0.3571, 0.3389, 0.3040], device='cuda:0')
2024-11-20 20:52:35,673 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 31: ref_distribution = tensor([0.3571, 0.3389, 0.3040], device='cuda:0'), new_distribution = tensor([0.3589, 0.3383, 0.3028], device='cuda:0')
2024-11-20 20:52:35,677 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 32: ref_distribution = tensor([0.3589, 0.3383, 0.3028], device='cuda:0'), new_distribution = tensor([0.3587, 0.3394, 0.3019], device='cuda:0')
2024-11-20 20:52:35,681 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 33: ref_distribution = tensor([0.3587, 0.3394, 0.3019], device='cuda:0'), new_distribution = tensor([0.3588, 0.3400, 0.3012], device='cuda:0')
2024-11-20 20:52:35,685 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 34: ref_distribution = tensor([0.3588, 0.3400, 0.3012], device='cuda:0'), new_distribution = tensor([0.3601, 0.3396, 0.3003], device='cuda:0')
2024-11-20 20:52:35,689 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 35: ref_distribution = tensor([0.3601, 0.3396, 0.3003], device='cuda:0'), new_distribution = tensor([0.3609, 0.3395, 0.2996], device='cuda:0')
2024-11-20 20:52:35,693 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 36: ref_distribution = tensor([0.3609, 0.3395, 0.2996], device='cuda:0'), new_distribution = tensor([0.3630, 0.3391, 0.2979], device='cuda:0')
2024-11-20 20:52:35,697 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 37: ref_distribution = tensor([0.3630, 0.3391, 0.2979], device='cuda:0'), new_distribution = tensor([0.3638, 0.3390, 0.2972], device='cuda:0')
2024-11-20 20:52:35,702 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 38: ref_distribution = tensor([0.3638, 0.3390, 0.2972], device='cuda:0'), new_distribution = tensor([0.3654, 0.3381, 0.2965], device='cuda:0')
2024-11-20 20:52:35,707 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 39: ref_distribution = tensor([0.3654, 0.3381, 0.2965], device='cuda:0'), new_distribution = tensor([0.3663, 0.3372, 0.2965], device='cuda:0')
2024-11-20 20:52:35,711 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 40: ref_distribution = tensor([0.3663, 0.3372, 0.2965], device='cuda:0'), new_distribution = tensor([0.3668, 0.3383, 0.2949], device='cuda:0')
2024-11-20 20:52:35,716 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 41: ref_distribution = tensor([0.3668, 0.3383, 0.2949], device='cuda:0'), new_distribution = tensor([0.3680, 0.3376, 0.2944], device='cuda:0')
2024-11-20 20:52:35,721 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 42: ref_distribution = tensor([0.3680, 0.3376, 0.2944], device='cuda:0'), new_distribution = tensor([0.3686, 0.3372, 0.2942], device='cuda:0')
2024-11-20 20:52:35,725 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 43: ref_distribution = tensor([0.3686, 0.3372, 0.2942], device='cuda:0'), new_distribution = tensor([0.3697, 0.3373, 0.2931], device='cuda:0')
2024-11-20 20:52:35,730 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 44: ref_distribution = tensor([0.3697, 0.3373, 0.2931], device='cuda:0'), new_distribution = tensor([0.3710, 0.3376, 0.2915], device='cuda:0')
2024-11-20 20:52:35,735 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 45: ref_distribution = tensor([0.3710, 0.3376, 0.2915], device='cuda:0'), new_distribution = tensor([0.3721, 0.3369, 0.2910], device='cuda:0')
2024-11-20 20:52:35,739 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 46: ref_distribution = tensor([0.3721, 0.3369, 0.2910], device='cuda:0'), new_distribution = tensor([0.3730, 0.3360, 0.2910], device='cuda:0')
2024-11-20 20:52:35,744 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 47: ref_distribution = tensor([0.3730, 0.3360, 0.2910], device='cuda:0'), new_distribution = tensor([0.3743, 0.3356, 0.2901], device='cuda:0')
2024-11-20 20:52:35,748 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 48: ref_distribution = tensor([0.3743, 0.3356, 0.2901], device='cuda:0'), new_distribution = tensor([0.3752, 0.3361, 0.2888], device='cuda:0')
2024-11-20 20:52:35,753 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 49: ref_distribution = tensor([0.3752, 0.3361, 0.2888], device='cuda:0'), new_distribution = tensor([0.3770, 0.3354, 0.2876], device='cuda:0')
2024-11-20 20:52:35,758 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 50: ref_distribution = tensor([0.3770, 0.3354, 0.2876], device='cuda:0'), new_distribution = tensor([0.3789, 0.3347, 0.2865], device='cuda:0')
2024-11-20 20:52:35,763 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 51: ref_distribution = tensor([0.3789, 0.3347, 0.2865], device='cuda:0'), new_distribution = tensor([0.3812, 0.3337, 0.2851], device='cuda:0')
2024-11-20 20:52:35,767 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 52: ref_distribution = tensor([0.3812, 0.3337, 0.2851], device='cuda:0'), new_distribution = tensor([0.3828, 0.3328, 0.2844], device='cuda:0')
2024-11-20 20:52:35,771 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 53: ref_distribution = tensor([0.3828, 0.3328, 0.2844], device='cuda:0'), new_distribution = tensor([0.3844, 0.3325, 0.2831], device='cuda:0')
2024-11-20 20:52:35,776 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 54: ref_distribution = tensor([0.3844, 0.3325, 0.2831], device='cuda:0'), new_distribution = tensor([0.3851, 0.3320, 0.2829], device='cuda:0')
2024-11-20 20:52:35,780 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 55: ref_distribution = tensor([0.3851, 0.3320, 0.2829], device='cuda:0'), new_distribution = tensor([0.3859, 0.3325, 0.2816], device='cuda:0')
2024-11-20 20:52:35,784 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 56: ref_distribution = tensor([0.3859, 0.3325, 0.2816], device='cuda:0'), new_distribution = tensor([0.3873, 0.3319, 0.2808], device='cuda:0')
2024-11-20 20:52:35,788 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 57: ref_distribution = tensor([0.3873, 0.3319, 0.2808], device='cuda:0'), new_distribution = tensor([0.3885, 0.3305, 0.2810], device='cuda:0')
2024-11-20 20:52:35,792 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 58: ref_distribution = tensor([0.3885, 0.3305, 0.2810], device='cuda:0'), new_distribution = tensor([0.3898, 0.3307, 0.2795], device='cuda:0')
2024-11-20 20:52:35,796 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 59: ref_distribution = tensor([0.3898, 0.3307, 0.2795], device='cuda:0'), new_distribution = tensor([0.3911, 0.3316, 0.2773], device='cuda:0')
2024-11-20 20:52:35,801 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 60: ref_distribution = tensor([0.3911, 0.3316, 0.2773], device='cuda:0'), new_distribution = tensor([0.3930, 0.3308, 0.2762], device='cuda:0')
2024-11-20 20:52:35,805 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 61: ref_distribution = tensor([0.3930, 0.3308, 0.2762], device='cuda:0'), new_distribution = tensor([0.3934, 0.3307, 0.2759], device='cuda:0')
2024-11-20 20:52:35,809 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 62: ref_distribution = tensor([0.3934, 0.3307, 0.2759], device='cuda:0'), new_distribution = tensor([0.3948, 0.3309, 0.2744], device='cuda:0')
2024-11-20 20:52:35,813 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 63: ref_distribution = tensor([0.3948, 0.3309, 0.2744], device='cuda:0'), new_distribution = tensor([0.3959, 0.3308, 0.2733], device='cuda:0')
2024-11-20 20:52:35,817 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 64: ref_distribution = tensor([0.3959, 0.3308, 0.2733], device='cuda:0'), new_distribution = tensor([0.3968, 0.3305, 0.2727], device='cuda:0')
2024-11-20 20:52:35,821 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 65: ref_distribution = tensor([0.3968, 0.3305, 0.2727], device='cuda:0'), new_distribution = tensor([0.3977, 0.3308, 0.2715], device='cuda:0')
2024-11-20 20:52:35,826 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 66: ref_distribution = tensor([0.3977, 0.3308, 0.2715], device='cuda:0'), new_distribution = tensor([0.3988, 0.3307, 0.2705], device='cuda:0')
2024-11-20 20:52:35,830 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 67: ref_distribution = tensor([0.3988, 0.3307, 0.2705], device='cuda:0'), new_distribution = tensor([0.4003, 0.3294, 0.2703], device='cuda:0')
2024-11-20 20:52:35,834 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 68: ref_distribution = tensor([0.4003, 0.3294, 0.2703], device='cuda:0'), new_distribution = tensor([0.4014, 0.3293, 0.2693], device='cuda:0')
2024-11-20 20:52:35,838 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 69: ref_distribution = tensor([0.4014, 0.3293, 0.2693], device='cuda:0'), new_distribution = tensor([0.4023, 0.3290, 0.2687], device='cuda:0')
2024-11-20 20:52:35,843 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 70: ref_distribution = tensor([0.4023, 0.3290, 0.2687], device='cuda:0'), new_distribution = tensor([0.4042, 0.3281, 0.2676], device='cuda:0')
2024-11-20 20:52:35,847 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 71: ref_distribution = tensor([0.4042, 0.3281, 0.2676], device='cuda:0'), new_distribution = tensor([0.4054, 0.3280, 0.2666], device='cuda:0')
2024-11-20 20:52:35,851 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 72: ref_distribution = tensor([0.4054, 0.3280, 0.2666], device='cuda:0'), new_distribution = tensor([0.4066, 0.3264, 0.2669], device='cuda:0')
2024-11-20 20:52:35,855 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 73: ref_distribution = tensor([0.4066, 0.3264, 0.2669], device='cuda:0'), new_distribution = tensor([0.4090, 0.3254, 0.2656], device='cuda:0')
2024-11-20 20:52:35,859 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 74: ref_distribution = tensor([0.4090, 0.3254, 0.2656], device='cuda:0'), new_distribution = tensor([0.4099, 0.3257, 0.2644], device='cuda:0')
2024-11-20 20:52:35,864 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 75: ref_distribution = tensor([0.4099, 0.3257, 0.2644], device='cuda:0'), new_distribution = tensor([0.4113, 0.3250, 0.2637], device='cuda:0')
2024-11-20 20:52:35,868 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 76: ref_distribution = tensor([0.4113, 0.3250, 0.2637], device='cuda:0'), new_distribution = tensor([0.4122, 0.3253, 0.2625], device='cuda:0')
2024-11-20 20:52:35,872 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 77: ref_distribution = tensor([0.4122, 0.3253, 0.2625], device='cuda:0'), new_distribution = tensor([0.4141, 0.3244, 0.2615], device='cuda:0')
2024-11-20 20:52:35,876 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 78: ref_distribution = tensor([0.4141, 0.3244, 0.2615], device='cuda:0'), new_distribution = tensor([0.4155, 0.3238, 0.2607], device='cuda:0')
2024-11-20 20:52:35,880 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 79: ref_distribution = tensor([0.4155, 0.3238, 0.2607], device='cuda:0'), new_distribution = tensor([0.4177, 0.3224, 0.2599], device='cuda:0')
2024-11-20 20:52:35,884 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 80: ref_distribution = tensor([0.4177, 0.3224, 0.2599], device='cuda:0'), new_distribution = tensor([0.4189, 0.3222, 0.2589], device='cuda:0')
2024-11-20 20:52:35,889 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 81: ref_distribution = tensor([0.4189, 0.3222, 0.2589], device='cuda:0'), new_distribution = tensor([0.4201, 0.3213, 0.2586], device='cuda:0')
2024-11-20 20:52:35,893 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 82: ref_distribution = tensor([0.4201, 0.3213, 0.2586], device='cuda:0'), new_distribution = tensor([0.4205, 0.3218, 0.2577], device='cuda:0')
2024-11-20 20:52:35,897 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 83: ref_distribution = tensor([0.4205, 0.3218, 0.2577], device='cuda:0'), new_distribution = tensor([0.4224, 0.3209, 0.2567], device='cuda:0')
2024-11-20 20:52:35,901 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 84: ref_distribution = tensor([0.4224, 0.3209, 0.2567], device='cuda:0'), new_distribution = tensor([0.4245, 0.3202, 0.2553], device='cuda:0')
2024-11-20 20:52:35,906 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 85: ref_distribution = tensor([0.4245, 0.3202, 0.2553], device='cuda:0'), new_distribution = tensor([0.4262, 0.3198, 0.2541], device='cuda:0')
2024-11-20 20:52:35,910 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 86: ref_distribution = tensor([0.4262, 0.3198, 0.2541], device='cuda:0'), new_distribution = tensor([0.4262, 0.3197, 0.2541], device='cuda:0')
2024-11-20 20:52:35,914 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 87: ref_distribution = tensor([0.4262, 0.3197, 0.2541], device='cuda:0'), new_distribution = tensor([0.4271, 0.3176, 0.2552], device='cuda:0')
2024-11-20 20:52:35,919 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 88: ref_distribution = tensor([0.4271, 0.3176, 0.2552], device='cuda:0'), new_distribution = tensor([0.4278, 0.3176, 0.2546], device='cuda:0')
2024-11-20 20:52:35,923 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 89: ref_distribution = tensor([0.4278, 0.3176, 0.2546], device='cuda:0'), new_distribution = tensor([0.4283, 0.3174, 0.2543], device='cuda:0')
2024-11-20 20:52:35,928 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 90: ref_distribution = tensor([0.4283, 0.3174, 0.2543], device='cuda:0'), new_distribution = tensor([0.4298, 0.3160, 0.2542], device='cuda:0')
2024-11-20 20:52:35,932 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 91: ref_distribution = tensor([0.4298, 0.3160, 0.2542], device='cuda:0'), new_distribution = tensor([0.4310, 0.3157, 0.2533], device='cuda:0')
2024-11-20 20:52:35,937 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 92: ref_distribution = tensor([0.4310, 0.3157, 0.2533], device='cuda:0'), new_distribution = tensor([0.4317, 0.3157, 0.2526], device='cuda:0')
2024-11-20 20:52:35,943 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 93: ref_distribution = tensor([0.4317, 0.3157, 0.2526], device='cuda:0'), new_distribution = tensor([0.4321, 0.3161, 0.2518], device='cuda:0')
2024-11-20 20:52:35,948 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 94: ref_distribution = tensor([0.4321, 0.3161, 0.2518], device='cuda:0'), new_distribution = tensor([0.4327, 0.3152, 0.2521], device='cuda:0')
2024-11-20 20:52:35,952 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 95: ref_distribution = tensor([0.4327, 0.3152, 0.2521], device='cuda:0'), new_distribution = tensor([0.4340, 0.3151, 0.2508], device='cuda:0')
2024-11-20 20:52:35,956 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 96: ref_distribution = tensor([0.4340, 0.3151, 0.2508], device='cuda:0'), new_distribution = tensor([0.4356, 0.3153, 0.2491], device='cuda:0')
2024-11-20 20:52:35,960 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 97: ref_distribution = tensor([0.4356, 0.3153, 0.2491], device='cuda:0'), new_distribution = tensor([0.4361, 0.3151, 0.2488], device='cuda:0')
2024-11-20 20:52:35,964 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 98: ref_distribution = tensor([0.4361, 0.3151, 0.2488], device='cuda:0'), new_distribution = tensor([0.4360, 0.3164, 0.2476], device='cuda:0')
2024-11-20 20:52:35,969 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 99: ref_distribution = tensor([0.4360, 0.3164, 0.2476], device='cuda:0'), new_distribution = tensor([0.4370, 0.3159, 0.2472], device='cuda:0')
2024-11-20 20:52:35,974 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 100: ref_distribution = tensor([0.4370, 0.3159, 0.2472], device='cuda:0'), new_distribution = tensor([0.4391, 0.3151, 0.2458], device='cuda:0')
2024-11-20 20:52:35,978 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 101: ref_distribution = tensor([0.4391, 0.3151, 0.2458], device='cuda:0'), new_distribution = tensor([0.4403, 0.3148, 0.2449], device='cuda:0')
2024-11-20 20:52:35,982 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 102: ref_distribution = tensor([0.4403, 0.3148, 0.2449], device='cuda:0'), new_distribution = tensor([0.4405, 0.3150, 0.2445], device='cuda:0')
2024-11-20 20:52:35,986 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 103: ref_distribution = tensor([0.4405, 0.3150, 0.2445], device='cuda:0'), new_distribution = tensor([0.4423, 0.3137, 0.2440], device='cuda:0')
2024-11-20 20:52:35,990 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 104: ref_distribution = tensor([0.4423, 0.3137, 0.2440], device='cuda:0'), new_distribution = tensor([0.4437, 0.3130, 0.2433], device='cuda:0')
2024-11-20 20:52:35,994 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 105: ref_distribution = tensor([0.4437, 0.3130, 0.2433], device='cuda:0'), new_distribution = tensor([0.4454, 0.3124, 0.2422], device='cuda:0')
2024-11-20 20:52:35,998 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 106: ref_distribution = tensor([0.4454, 0.3124, 0.2422], device='cuda:0'), new_distribution = tensor([0.4459, 0.3121, 0.2420], device='cuda:0')
2024-11-20 20:52:36,002 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 107: ref_distribution = tensor([0.4459, 0.3121, 0.2420], device='cuda:0'), new_distribution = tensor([0.4466, 0.3120, 0.2414], device='cuda:0')
2024-11-20 20:52:36,007 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 108: ref_distribution = tensor([0.4466, 0.3120, 0.2414], device='cuda:0'), new_distribution = tensor([0.4473, 0.3109, 0.2418], device='cuda:0')
2024-11-20 20:52:36,011 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 109: ref_distribution = tensor([0.4473, 0.3109, 0.2418], device='cuda:0'), new_distribution = tensor([0.4484, 0.3113, 0.2403], device='cuda:0')
2024-11-20 20:52:36,015 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 110: ref_distribution = tensor([0.4484, 0.3113, 0.2403], device='cuda:0'), new_distribution = tensor([0.4500, 0.3107, 0.2393], device='cuda:0')
2024-11-20 20:52:36,019 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 111: ref_distribution = tensor([0.4500, 0.3107, 0.2393], device='cuda:0'), new_distribution = tensor([0.4522, 0.3092, 0.2385], device='cuda:0')
2024-11-20 20:52:36,023 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 112: ref_distribution = tensor([0.4522, 0.3092, 0.2385], device='cuda:0'), new_distribution = tensor([0.4542, 0.3075, 0.2382], device='cuda:0')
2024-11-20 20:52:36,027 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 113: ref_distribution = tensor([0.4542, 0.3075, 0.2382], device='cuda:0'), new_distribution = tensor([0.4552, 0.3060, 0.2388], device='cuda:0')
2024-11-20 20:52:36,031 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 114: ref_distribution = tensor([0.4552, 0.3060, 0.2388], device='cuda:0'), new_distribution = tensor([0.4564, 0.3056, 0.2380], device='cuda:0')
2024-11-20 20:52:36,035 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 115: ref_distribution = tensor([0.4564, 0.3056, 0.2380], device='cuda:0'), new_distribution = tensor([0.4578, 0.3048, 0.2374], device='cuda:0')
2024-11-20 20:52:36,040 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 116: ref_distribution = tensor([0.4578, 0.3048, 0.2374], device='cuda:0'), new_distribution = tensor([0.4588, 0.3042, 0.2369], device='cuda:0')
2024-11-20 20:52:36,044 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 117: ref_distribution = tensor([0.4588, 0.3042, 0.2369], device='cuda:0'), new_distribution = tensor([0.4606, 0.3039, 0.2355], device='cuda:0')
2024-11-20 20:52:36,048 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 118: ref_distribution = tensor([0.4606, 0.3039, 0.2355], device='cuda:0'), new_distribution = tensor([0.4616, 0.3023, 0.2361], device='cuda:0')
2024-11-20 20:52:36,052 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 119: ref_distribution = tensor([0.4616, 0.3023, 0.2361], device='cuda:0'), new_distribution = tensor([0.4632, 0.3008, 0.2360], device='cuda:0')
2024-11-20 20:52:36,057 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 120: ref_distribution = tensor([0.4632, 0.3008, 0.2360], device='cuda:0'), new_distribution = tensor([0.4637, 0.3004, 0.2359], device='cuda:0')
2024-11-20 20:52:36,061 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 121: ref_distribution = tensor([0.4637, 0.3004, 0.2359], device='cuda:0'), new_distribution = tensor([0.4651, 0.3003, 0.2347], device='cuda:0')
2024-11-20 20:52:36,065 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 122: ref_distribution = tensor([0.4651, 0.3003, 0.2347], device='cuda:0'), new_distribution = tensor([0.4661, 0.2996, 0.2343], device='cuda:0')
2024-11-20 20:52:36,069 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 123: ref_distribution = tensor([0.4661, 0.2996, 0.2343], device='cuda:0'), new_distribution = tensor([0.4668, 0.2995, 0.2337], device='cuda:0')
2024-11-20 20:52:36,073 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 124: ref_distribution = tensor([0.4668, 0.2995, 0.2337], device='cuda:0'), new_distribution = tensor([0.4672, 0.2988, 0.2340], device='cuda:0')
2024-11-20 20:52:36,077 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 125: ref_distribution = tensor([0.4672, 0.2988, 0.2340], device='cuda:0'), new_distribution = tensor([0.4684, 0.2984, 0.2332], device='cuda:0')
2024-11-20 20:52:36,081 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 126: ref_distribution = tensor([0.4684, 0.2984, 0.2332], device='cuda:0'), new_distribution = tensor([0.4703, 0.2974, 0.2324], device='cuda:0')
2024-11-20 20:52:36,086 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 127: ref_distribution = tensor([0.4703, 0.2974, 0.2324], device='cuda:0'), new_distribution = tensor([0.4721, 0.2954, 0.2325], device='cuda:0')
2024-11-20 20:52:36,090 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 128: ref_distribution = tensor([0.4721, 0.2954, 0.2325], device='cuda:0'), new_distribution = tensor([0.4731, 0.2947, 0.2321], device='cuda:0')
2024-11-20 20:52:36,094 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 129: ref_distribution = tensor([0.4731, 0.2947, 0.2321], device='cuda:0'), new_distribution = tensor([0.4748, 0.2941, 0.2311], device='cuda:0')
2024-11-20 20:52:36,098 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 130: ref_distribution = tensor([0.4748, 0.2941, 0.2311], device='cuda:0'), new_distribution = tensor([0.4768, 0.2923, 0.2309], device='cuda:0')
2024-11-20 20:52:36,102 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 131: ref_distribution = tensor([0.4768, 0.2923, 0.2309], device='cuda:0'), new_distribution = tensor([0.4779, 0.2919, 0.2301], device='cuda:0')
2024-11-20 20:52:36,106 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 132: ref_distribution = tensor([0.4779, 0.2919, 0.2301], device='cuda:0'), new_distribution = tensor([0.4794, 0.2910, 0.2296], device='cuda:0')
2024-11-20 20:52:36,110 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 133: ref_distribution = tensor([0.4794, 0.2910, 0.2296], device='cuda:0'), new_distribution = tensor([0.4807, 0.2899, 0.2294], device='cuda:0')
2024-11-20 20:52:36,114 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 134: ref_distribution = tensor([0.4807, 0.2899, 0.2294], device='cuda:0'), new_distribution = tensor([0.4826, 0.2888, 0.2286], device='cuda:0')
2024-11-20 20:52:36,118 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 135: ref_distribution = tensor([0.4826, 0.2888, 0.2286], device='cuda:0'), new_distribution = tensor([0.4833, 0.2886, 0.2281], device='cuda:0')
2024-11-20 20:52:36,122 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 136: ref_distribution = tensor([0.4833, 0.2886, 0.2281], device='cuda:0'), new_distribution = tensor([0.4840, 0.2884, 0.2276], device='cuda:0')
2024-11-20 20:52:36,127 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 137: ref_distribution = tensor([0.4840, 0.2884, 0.2276], device='cuda:0'), new_distribution = tensor([0.4852, 0.2880, 0.2269], device='cuda:0')
2024-11-20 20:52:36,132 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 138: ref_distribution = tensor([0.4852, 0.2880, 0.2269], device='cuda:0'), new_distribution = tensor([0.4855, 0.2879, 0.2266], device='cuda:0')
2024-11-20 20:52:36,136 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 139: ref_distribution = tensor([0.4855, 0.2879, 0.2266], device='cuda:0'), new_distribution = tensor([0.4862, 0.2877, 0.2261], device='cuda:0')
2024-11-20 20:52:36,140 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 140: ref_distribution = tensor([0.4862, 0.2877, 0.2261], device='cuda:0'), new_distribution = tensor([0.4876, 0.2859, 0.2264], device='cuda:0')
2024-11-20 20:52:36,144 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 141: ref_distribution = tensor([0.4876, 0.2859, 0.2264], device='cuda:0'), new_distribution = tensor([0.4886, 0.2843, 0.2270], device='cuda:0')
2024-11-20 20:52:36,149 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 142: ref_distribution = tensor([0.4886, 0.2843, 0.2270], device='cuda:0'), new_distribution = tensor([0.4899, 0.2832, 0.2269], device='cuda:0')
2024-11-20 20:52:36,153 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 143: ref_distribution = tensor([0.4899, 0.2832, 0.2269], device='cuda:0'), new_distribution = tensor([0.4909, 0.2825, 0.2266], device='cuda:0')
2024-11-20 20:52:36,157 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 144: ref_distribution = tensor([0.4909, 0.2825, 0.2266], device='cuda:0'), new_distribution = tensor([0.4928, 0.2805, 0.2267], device='cuda:0')
2024-11-20 20:52:36,162 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 145: ref_distribution = tensor([0.4928, 0.2805, 0.2267], device='cuda:0'), new_distribution = tensor([0.4942, 0.2787, 0.2271], device='cuda:0')
2024-11-20 20:52:36,167 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 146: ref_distribution = tensor([0.4942, 0.2787, 0.2271], device='cuda:0'), new_distribution = tensor([0.4958, 0.2771, 0.2271], device='cuda:0')
2024-11-20 20:52:36,171 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 147: ref_distribution = tensor([0.4958, 0.2771, 0.2271], device='cuda:0'), new_distribution = tensor([0.4962, 0.2764, 0.2274], device='cuda:0')
2024-11-20 20:52:36,176 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 148: ref_distribution = tensor([0.4962, 0.2764, 0.2274], device='cuda:0'), new_distribution = tensor([0.4966, 0.2757, 0.2277], device='cuda:0')
2024-11-20 20:52:36,180 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 149: ref_distribution = tensor([0.4966, 0.2757, 0.2277], device='cuda:0'), new_distribution = tensor([0.4966, 0.2752, 0.2282], device='cuda:0')
2024-11-20 20:52:36,184 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 150: ref_distribution = tensor([0.4966, 0.2752, 0.2282], device='cuda:0'), new_distribution = tensor([0.4973, 0.2741, 0.2286], device='cuda:0')
2024-11-20 20:52:36,188 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 151: ref_distribution = tensor([0.4973, 0.2741, 0.2286], device='cuda:0'), new_distribution = tensor([0.4983, 0.2734, 0.2283], device='cuda:0')
2024-11-20 20:52:36,192 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 152: ref_distribution = tensor([0.4983, 0.2734, 0.2283], device='cuda:0'), new_distribution = tensor([0.4991, 0.2725, 0.2284], device='cuda:0')
2024-11-20 20:52:36,196 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 153: ref_distribution = tensor([0.4991, 0.2725, 0.2284], device='cuda:0'), new_distribution = tensor([0.5000, 0.2716, 0.2285], device='cuda:0')
2024-11-20 20:52:36,200 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 154: ref_distribution = tensor([0.5000, 0.2716, 0.2285], device='cuda:0'), new_distribution = tensor([0.5007, 0.2713, 0.2280], device='cuda:0')
2024-11-20 20:52:36,204 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 155: ref_distribution = tensor([0.5007, 0.2713, 0.2280], device='cuda:0'), new_distribution = tensor([0.5024, 0.2700, 0.2277], device='cuda:0')
2024-11-20 20:52:36,208 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 156: ref_distribution = tensor([0.5024, 0.2700, 0.2277], device='cuda:0'), new_distribution = tensor([0.5032, 0.2700, 0.2268], device='cuda:0')
2024-11-20 20:52:36,212 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 157: ref_distribution = tensor([0.5032, 0.2700, 0.2268], device='cuda:0'), new_distribution = tensor([0.5042, 0.2693, 0.2265], device='cuda:0')
2024-11-20 20:52:36,216 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 158: ref_distribution = tensor([0.5042, 0.2693, 0.2265], device='cuda:0'), new_distribution = tensor([0.5054, 0.2682, 0.2264], device='cuda:0')
2024-11-20 20:52:36,220 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 159: ref_distribution = tensor([0.5054, 0.2682, 0.2264], device='cuda:0'), new_distribution = tensor([0.5057, 0.2681, 0.2262], device='cuda:0')
2024-11-20 20:52:36,224 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 160: ref_distribution = tensor([0.5057, 0.2681, 0.2262], device='cuda:0'), new_distribution = tensor([0.5066, 0.2663, 0.2272], device='cuda:0')
2024-11-20 20:52:36,228 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 161: ref_distribution = tensor([0.5066, 0.2663, 0.2272], device='cuda:0'), new_distribution = tensor([0.5071, 0.2649, 0.2280], device='cuda:0')
2024-11-20 20:52:36,233 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 162: ref_distribution = tensor([0.5071, 0.2649, 0.2280], device='cuda:0'), new_distribution = tensor([0.5077, 0.2635, 0.2288], device='cuda:0')
2024-11-20 20:52:36,237 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 163: ref_distribution = tensor([0.5077, 0.2635, 0.2288], device='cuda:0'), new_distribution = tensor([0.5082, 0.2621, 0.2296], device='cuda:0')
2024-11-20 20:52:36,241 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 164: ref_distribution = tensor([0.5082, 0.2621, 0.2296], device='cuda:0'), new_distribution = tensor([0.5101, 0.2613, 0.2286], device='cuda:0')
2024-11-20 20:52:36,245 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 165: ref_distribution = tensor([0.5101, 0.2613, 0.2286], device='cuda:0'), new_distribution = tensor([0.5107, 0.2599, 0.2294], device='cuda:0')
2024-11-20 20:52:36,249 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 166: ref_distribution = tensor([0.5107, 0.2599, 0.2294], device='cuda:0'), new_distribution = tensor([0.5123, 0.2577, 0.2300], device='cuda:0')
2024-11-20 20:52:36,253 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 167: ref_distribution = tensor([0.5123, 0.2577, 0.2300], device='cuda:0'), new_distribution = tensor([0.5135, 0.2557, 0.2308], device='cuda:0')
2024-11-20 20:52:36,257 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 168: ref_distribution = tensor([0.5135, 0.2557, 0.2308], device='cuda:0'), new_distribution = tensor([0.5144, 0.2539, 0.2317], device='cuda:0')
2024-11-20 20:52:36,261 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 169: ref_distribution = tensor([0.5144, 0.2539, 0.2317], device='cuda:0'), new_distribution = tensor([0.5153, 0.2523, 0.2324], device='cuda:0')
2024-11-20 20:52:36,265 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 170: ref_distribution = tensor([0.5153, 0.2523, 0.2324], device='cuda:0'), new_distribution = tensor([0.5169, 0.2501, 0.2330], device='cuda:0')
2024-11-20 20:52:36,269 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 171: ref_distribution = tensor([0.5169, 0.2501, 0.2330], device='cuda:0'), new_distribution = tensor([0.5181, 0.2491, 0.2329], device='cuda:0')
2024-11-20 20:52:36,274 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 172: ref_distribution = tensor([0.5181, 0.2491, 0.2329], device='cuda:0'), new_distribution = tensor([0.5180, 0.2494, 0.2325], device='cuda:0')
2024-11-20 20:52:36,278 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 173: ref_distribution = tensor([0.5180, 0.2494, 0.2325], device='cuda:0'), new_distribution = tensor([0.5194, 0.2486, 0.2321], device='cuda:0')
2024-11-20 20:52:36,282 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 174: ref_distribution = tensor([0.5194, 0.2486, 0.2321], device='cuda:0'), new_distribution = tensor([0.5195, 0.2483, 0.2322], device='cuda:0')
2024-11-20 20:52:36,286 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 175: ref_distribution = tensor([0.5195, 0.2483, 0.2322], device='cuda:0'), new_distribution = tensor([0.5210, 0.2470, 0.2319], device='cuda:0')
2024-11-20 20:52:36,290 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 176: ref_distribution = tensor([0.5210, 0.2470, 0.2319], device='cuda:0'), new_distribution = tensor([0.5222, 0.2459, 0.2319], device='cuda:0')
2024-11-20 20:52:36,294 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 177: ref_distribution = tensor([0.5222, 0.2459, 0.2319], device='cuda:0'), new_distribution = tensor([0.5235, 0.2442, 0.2323], device='cuda:0')
2024-11-20 20:52:36,298 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 178: ref_distribution = tensor([0.5235, 0.2442, 0.2323], device='cuda:0'), new_distribution = tensor([0.5234, 0.2443, 0.2323], device='cuda:0')
2024-11-20 20:52:36,302 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 179: ref_distribution = tensor([0.5234, 0.2443, 0.2323], device='cuda:0'), new_distribution = tensor([0.5236, 0.2443, 0.2321], device='cuda:0')
2024-11-20 20:52:36,306 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 180: ref_distribution = tensor([0.5236, 0.2443, 0.2321], device='cuda:0'), new_distribution = tensor([0.5245, 0.2427, 0.2327], device='cuda:0')
2024-11-20 20:52:36,310 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 181: ref_distribution = tensor([0.5245, 0.2427, 0.2327], device='cuda:0'), new_distribution = tensor([0.5263, 0.2410, 0.2326], device='cuda:0')
2024-11-20 20:52:36,314 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 182: ref_distribution = tensor([0.5263, 0.2410, 0.2326], device='cuda:0'), new_distribution = tensor([0.5272, 0.2404, 0.2324], device='cuda:0')
2024-11-20 20:52:36,318 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 183: ref_distribution = tensor([0.5272, 0.2404, 0.2324], device='cuda:0'), new_distribution = tensor([0.5289, 0.2384, 0.2327], device='cuda:0')
2024-11-20 20:52:36,322 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 184: ref_distribution = tensor([0.5289, 0.2384, 0.2327], device='cuda:0'), new_distribution = tensor([0.5292, 0.2375, 0.2333], device='cuda:0')
2024-11-20 20:52:36,326 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 185: ref_distribution = tensor([0.5292, 0.2375, 0.2333], device='cuda:0'), new_distribution = tensor([0.5301, 0.2360, 0.2340], device='cuda:0')
2024-11-20 20:52:36,330 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 186: ref_distribution = tensor([0.5301, 0.2360, 0.2340], device='cuda:0'), new_distribution = tensor([0.5308, 0.2351, 0.2341], device='cuda:0')
2024-11-20 20:52:36,334 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 187: ref_distribution = tensor([0.5308, 0.2351, 0.2341], device='cuda:0'), new_distribution = tensor([0.5318, 0.2338, 0.2344], device='cuda:0')
2024-11-20 20:52:36,338 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 188: ref_distribution = tensor([0.5318, 0.2338, 0.2344], device='cuda:0'), new_distribution = tensor([0.5332, 0.2323, 0.2345], device='cuda:0')
2024-11-20 20:52:36,343 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 189: ref_distribution = tensor([0.5332, 0.2323, 0.2345], device='cuda:0'), new_distribution = tensor([0.5343, 0.2303, 0.2353], device='cuda:0')
2024-11-20 20:52:36,347 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 190: ref_distribution = tensor([0.5343, 0.2303, 0.2353], device='cuda:0'), new_distribution = tensor([0.5357, 0.2289, 0.2354], device='cuda:0')
2024-11-20 20:52:36,351 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 191: ref_distribution = tensor([0.5357, 0.2289, 0.2354], device='cuda:0'), new_distribution = tensor([0.5370, 0.2272, 0.2359], device='cuda:0')
2024-11-20 20:52:36,355 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 192: ref_distribution = tensor([0.5370, 0.2272, 0.2359], device='cuda:0'), new_distribution = tensor([0.5380, 0.2261, 0.2359], device='cuda:0')
2024-11-20 20:52:36,359 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 193: ref_distribution = tensor([0.5380, 0.2261, 0.2359], device='cuda:0'), new_distribution = tensor([0.5394, 0.2246, 0.2360], device='cuda:0')
2024-11-20 20:52:36,363 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 194: ref_distribution = tensor([0.5394, 0.2246, 0.2360], device='cuda:0'), new_distribution = tensor([0.5400, 0.2235, 0.2365], device='cuda:0')
2024-11-20 20:52:36,367 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 195: ref_distribution = tensor([0.5400, 0.2235, 0.2365], device='cuda:0'), new_distribution = tensor([0.5414, 0.2223, 0.2363], device='cuda:0')
2024-11-20 20:52:36,371 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 196: ref_distribution = tensor([0.5414, 0.2223, 0.2363], device='cuda:0'), new_distribution = tensor([0.5422, 0.2214, 0.2364], device='cuda:0')
2024-11-20 20:52:36,375 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 197: ref_distribution = tensor([0.5422, 0.2214, 0.2364], device='cuda:0'), new_distribution = tensor([0.5427, 0.2203, 0.2369], device='cuda:0')
2024-11-20 20:52:36,380 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 198: ref_distribution = tensor([0.5427, 0.2203, 0.2369], device='cuda:0'), new_distribution = tensor([0.5433, 0.2192, 0.2374], device='cuda:0')
2024-11-20 20:52:36,384 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 199: ref_distribution = tensor([0.5433, 0.2192, 0.2374], device='cuda:0'), new_distribution = tensor([0.5443, 0.2180, 0.2377], device='cuda:0')
2024-11-20 20:52:36,388 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 200: ref_distribution = tensor([0.5443, 0.2180, 0.2377], device='cuda:0'), new_distribution = tensor([0.5454, 0.2161, 0.2385], device='cuda:0')
2024-11-20 20:52:36,393 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 201: ref_distribution = tensor([0.5454, 0.2161, 0.2385], device='cuda:0'), new_distribution = tensor([0.5463, 0.2157, 0.2381], device='cuda:0')
2024-11-20 20:52:36,397 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 202: ref_distribution = tensor([0.5463, 0.2157, 0.2381], device='cuda:0'), new_distribution = tensor([0.5476, 0.2142, 0.2382], device='cuda:0')
2024-11-20 20:52:36,402 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 203: ref_distribution = tensor([0.5476, 0.2142, 0.2382], device='cuda:0'), new_distribution = tensor([0.5487, 0.2126, 0.2387], device='cuda:0')
2024-11-20 20:52:36,406 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 204: ref_distribution = tensor([0.5487, 0.2126, 0.2387], device='cuda:0'), new_distribution = tensor([0.5504, 0.2110, 0.2386], device='cuda:0')
2024-11-20 20:52:36,411 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 205: ref_distribution = tensor([0.5504, 0.2110, 0.2386], device='cuda:0'), new_distribution = tensor([0.5512, 0.2103, 0.2385], device='cuda:0')
2024-11-20 20:52:36,415 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 206: ref_distribution = tensor([0.5512, 0.2103, 0.2385], device='cuda:0'), new_distribution = tensor([0.5516, 0.2099, 0.2385], device='cuda:0')
2024-11-20 20:52:36,420 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 207: ref_distribution = tensor([0.5516, 0.2099, 0.2385], device='cuda:0'), new_distribution = tensor([0.5513, 0.2098, 0.2389], device='cuda:0')
2024-11-20 20:52:36,424 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 208: ref_distribution = tensor([0.5513, 0.2098, 0.2389], device='cuda:0'), new_distribution = tensor([0.5515, 0.2089, 0.2396], device='cuda:0')
2024-11-20 20:52:36,429 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 209: ref_distribution = tensor([0.5515, 0.2089, 0.2396], device='cuda:0'), new_distribution = tensor([0.5522, 0.2081, 0.2398], device='cuda:0')
2024-11-20 20:52:36,433 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 210: ref_distribution = tensor([0.5522, 0.2081, 0.2398], device='cuda:0'), new_distribution = tensor([0.5532, 0.2070, 0.2398], device='cuda:0')
2024-11-20 20:52:36,437 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 211: ref_distribution = tensor([0.5532, 0.2070, 0.2398], device='cuda:0'), new_distribution = tensor([0.5534, 0.2072, 0.2393], device='cuda:0')
2024-11-20 20:52:36,441 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 212: ref_distribution = tensor([0.5534, 0.2072, 0.2393], device='cuda:0'), new_distribution = tensor([0.5545, 0.2054, 0.2402], device='cuda:0')
2024-11-20 20:52:36,446 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 213: ref_distribution = tensor([0.5545, 0.2054, 0.2402], device='cuda:0'), new_distribution = tensor([0.5552, 0.2047, 0.2400], device='cuda:0')
2024-11-20 20:52:36,450 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 214: ref_distribution = tensor([0.5552, 0.2047, 0.2400], device='cuda:0'), new_distribution = tensor([0.5564, 0.2031, 0.2405], device='cuda:0')
2024-11-20 20:52:36,454 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 215: ref_distribution = tensor([0.5564, 0.2031, 0.2405], device='cuda:0'), new_distribution = tensor([0.5571, 0.2025, 0.2404], device='cuda:0')
2024-11-20 20:52:36,458 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 216: ref_distribution = tensor([0.5571, 0.2025, 0.2404], device='cuda:0'), new_distribution = tensor([0.5583, 0.2019, 0.2398], device='cuda:0')
2024-11-20 20:52:36,462 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 217: ref_distribution = tensor([0.5583, 0.2019, 0.2398], device='cuda:0'), new_distribution = tensor([0.5596, 0.2008, 0.2396], device='cuda:0')
2024-11-20 20:52:36,466 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 218: ref_distribution = tensor([0.5596, 0.2008, 0.2396], device='cuda:0'), new_distribution = tensor([0.5603, 0.1991, 0.2406], device='cuda:0')
2024-11-20 20:52:36,470 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 219: ref_distribution = tensor([0.5603, 0.1991, 0.2406], device='cuda:0'), new_distribution = tensor([0.5614, 0.1975, 0.2411], device='cuda:0')
2024-11-20 20:52:36,474 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 220: ref_distribution = tensor([0.5614, 0.1975, 0.2411], device='cuda:0'), new_distribution = tensor([0.5619, 0.1965, 0.2416], device='cuda:0')
2024-11-20 20:52:36,478 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 221: ref_distribution = tensor([0.5619, 0.1965, 0.2416], device='cuda:0'), new_distribution = tensor([0.5626, 0.1948, 0.2426], device='cuda:0')
2024-11-20 20:52:36,482 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 222: ref_distribution = tensor([0.5626, 0.1948, 0.2426], device='cuda:0'), new_distribution = tensor([0.5634, 0.1936, 0.2430], device='cuda:0')
2024-11-20 20:52:36,486 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 223: ref_distribution = tensor([0.5634, 0.1936, 0.2430], device='cuda:0'), new_distribution = tensor([0.5639, 0.1926, 0.2435], device='cuda:0')
2024-11-20 20:52:36,490 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 224: ref_distribution = tensor([0.5639, 0.1926, 0.2435], device='cuda:0'), new_distribution = tensor([0.5641, 0.1925, 0.2434], device='cuda:0')
2024-11-20 20:52:36,494 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 225: ref_distribution = tensor([0.5641, 0.1925, 0.2434], device='cuda:0'), new_distribution = tensor([0.5647, 0.1920, 0.2433], device='cuda:0')
2024-11-20 20:52:36,499 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 226: ref_distribution = tensor([0.5647, 0.1920, 0.2433], device='cuda:0'), new_distribution = tensor([0.5660, 0.1908, 0.2432], device='cuda:0')
2024-11-20 20:52:36,503 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 227: ref_distribution = tensor([0.5660, 0.1908, 0.2432], device='cuda:0'), new_distribution = tensor([0.5667, 0.1894, 0.2438], device='cuda:0')
2024-11-20 20:52:36,507 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 228: ref_distribution = tensor([0.5667, 0.1894, 0.2438], device='cuda:0'), new_distribution = tensor([0.5675, 0.1880, 0.2445], device='cuda:0')
2024-11-20 20:52:36,511 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 229: ref_distribution = tensor([0.5675, 0.1880, 0.2445], device='cuda:0'), new_distribution = tensor([0.5685, 0.1865, 0.2450], device='cuda:0')
2024-11-20 20:52:36,515 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 230: ref_distribution = tensor([0.5685, 0.1865, 0.2450], device='cuda:0'), new_distribution = tensor([0.5696, 0.1851, 0.2452], device='cuda:0')
2024-11-20 20:52:36,519 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 231: ref_distribution = tensor([0.5696, 0.1851, 0.2452], device='cuda:0'), new_distribution = tensor([0.5707, 0.1836, 0.2457], device='cuda:0')
2024-11-20 20:52:36,523 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 232: ref_distribution = tensor([0.5707, 0.1836, 0.2457], device='cuda:0'), new_distribution = tensor([0.5714, 0.1824, 0.2461], device='cuda:0')
2024-11-20 20:52:36,527 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 233: ref_distribution = tensor([0.5714, 0.1824, 0.2461], device='cuda:0'), new_distribution = tensor([0.5721, 0.1811, 0.2468], device='cuda:0')
2024-11-20 20:52:36,532 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 234: ref_distribution = tensor([0.5721, 0.1811, 0.2468], device='cuda:0'), new_distribution = tensor([0.5726, 0.1801, 0.2473], device='cuda:0')
2024-11-20 20:52:36,536 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 235: ref_distribution = tensor([0.5726, 0.1801, 0.2473], device='cuda:0'), new_distribution = tensor([0.5730, 0.1791, 0.2479], device='cuda:0')
2024-11-20 20:52:36,541 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 236: ref_distribution = tensor([0.5730, 0.1791, 0.2479], device='cuda:0'), new_distribution = tensor([0.5738, 0.1780, 0.2482], device='cuda:0')
2024-11-20 20:52:36,546 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 237: ref_distribution = tensor([0.5738, 0.1780, 0.2482], device='cuda:0'), new_distribution = tensor([0.5740, 0.1773, 0.2486], device='cuda:0')
2024-11-20 20:52:36,550 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 238: ref_distribution = tensor([0.5740, 0.1773, 0.2486], device='cuda:0'), new_distribution = tensor([0.5747, 0.1760, 0.2493], device='cuda:0')
2024-11-20 20:52:36,555 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 239: ref_distribution = tensor([0.5747, 0.1760, 0.2493], device='cuda:0'), new_distribution = tensor([0.5758, 0.1757, 0.2485], device='cuda:0')
2024-11-20 20:52:36,559 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 240: ref_distribution = tensor([0.5758, 0.1757, 0.2485], device='cuda:0'), new_distribution = tensor([0.5763, 0.1749, 0.2487], device='cuda:0')
2024-11-20 20:52:36,564 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 241: ref_distribution = tensor([0.5763, 0.1749, 0.2487], device='cuda:0'), new_distribution = tensor([0.5764, 0.1741, 0.2494], device='cuda:0')
2024-11-20 20:52:36,568 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 242: ref_distribution = tensor([0.5764, 0.1741, 0.2494], device='cuda:0'), new_distribution = tensor([0.5771, 0.1728, 0.2501], device='cuda:0')
2024-11-20 20:52:36,572 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 243: ref_distribution = tensor([0.5771, 0.1728, 0.2501], device='cuda:0'), new_distribution = tensor([0.5779, 0.1711, 0.2509], device='cuda:0')
2024-11-20 20:52:36,577 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 244: ref_distribution = tensor([0.5779, 0.1711, 0.2509], device='cuda:0'), new_distribution = tensor([0.5788, 0.1697, 0.2515], device='cuda:0')
2024-11-20 20:52:36,581 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 245: ref_distribution = tensor([0.5788, 0.1697, 0.2515], device='cuda:0'), new_distribution = tensor([0.5798, 0.1675, 0.2527], device='cuda:0')
2024-11-20 20:52:36,585 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 246: ref_distribution = tensor([0.5798, 0.1675, 0.2527], device='cuda:0'), new_distribution = tensor([0.5806, 0.1666, 0.2528], device='cuda:0')
2024-11-20 20:52:36,589 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 247: ref_distribution = tensor([0.5806, 0.1666, 0.2528], device='cuda:0'), new_distribution = tensor([0.5816, 0.1646, 0.2538], device='cuda:0')
2024-11-20 20:52:36,593 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 248: ref_distribution = tensor([0.5816, 0.1646, 0.2538], device='cuda:0'), new_distribution = tensor([0.5822, 0.1641, 0.2538], device='cuda:0')
2024-11-20 20:52:36,597 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 249: ref_distribution = tensor([0.5822, 0.1641, 0.2538], device='cuda:0'), new_distribution = tensor([0.5827, 0.1628, 0.2545], device='cuda:0')
2024-11-20 20:52:36,601 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 250: ref_distribution = tensor([0.5827, 0.1628, 0.2545], device='cuda:0'), new_distribution = tensor([0.5829, 0.1622, 0.2549], device='cuda:0')
2024-11-20 20:52:36,605 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 251: ref_distribution = tensor([0.5829, 0.1622, 0.2549], device='cuda:0'), new_distribution = tensor([0.5831, 0.1616, 0.2553], device='cuda:0')
2024-11-20 20:52:36,610 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 252: ref_distribution = tensor([0.5831, 0.1616, 0.2553], device='cuda:0'), new_distribution = tensor([0.5839, 0.1610, 0.2551], device='cuda:0')
2024-11-20 20:52:36,614 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 253: ref_distribution = tensor([0.5839, 0.1610, 0.2551], device='cuda:0'), new_distribution = tensor([0.5841, 0.1604, 0.2555], device='cuda:0')
2024-11-20 20:52:36,618 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 254: ref_distribution = tensor([0.5841, 0.1604, 0.2555], device='cuda:0'), new_distribution = tensor([0.5850, 0.1592, 0.2558], device='cuda:0')
2024-11-20 20:52:36,622 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 255: ref_distribution = tensor([0.5850, 0.1592, 0.2558], device='cuda:0'), new_distribution = tensor([0.5853, 0.1581, 0.2566], device='cuda:0')
2024-11-20 20:52:36,626 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 256: ref_distribution = tensor([0.5853, 0.1581, 0.2566], device='cuda:0'), new_distribution = tensor([0.5857, 0.1567, 0.2576], device='cuda:0')
2024-11-20 20:52:36,630 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 257: ref_distribution = tensor([0.5857, 0.1567, 0.2576], device='cuda:0'), new_distribution = tensor([0.5864, 0.1558, 0.2577], device='cuda:0')
2024-11-20 20:52:36,634 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 258: ref_distribution = tensor([0.5864, 0.1558, 0.2577], device='cuda:0'), new_distribution = tensor([0.5867, 0.1547, 0.2586], device='cuda:0')
2024-11-20 20:52:36,638 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 259: ref_distribution = tensor([0.5867, 0.1547, 0.2586], device='cuda:0'), new_distribution = tensor([0.5872, 0.1535, 0.2593], device='cuda:0')
2024-11-20 20:52:36,642 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 260: ref_distribution = tensor([0.5872, 0.1535, 0.2593], device='cuda:0'), new_distribution = tensor([0.5878, 0.1525, 0.2597], device='cuda:0')
2024-11-20 20:52:36,647 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 261: ref_distribution = tensor([0.5878, 0.1525, 0.2597], device='cuda:0'), new_distribution = tensor([0.5884, 0.1515, 0.2601], device='cuda:0')
2024-11-20 20:52:36,651 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 262: ref_distribution = tensor([0.5884, 0.1515, 0.2601], device='cuda:0'), new_distribution = tensor([0.5890, 0.1505, 0.2605], device='cuda:0')
2024-11-20 20:52:36,655 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 263: ref_distribution = tensor([0.5890, 0.1505, 0.2605], device='cuda:0'), new_distribution = tensor([0.5892, 0.1494, 0.2614], device='cuda:0')
2024-11-20 20:52:36,659 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 264: ref_distribution = tensor([0.5892, 0.1494, 0.2614], device='cuda:0'), new_distribution = tensor([0.5894, 0.1491, 0.2615], device='cuda:0')
2024-11-20 20:52:36,663 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 265: ref_distribution = tensor([0.5894, 0.1491, 0.2615], device='cuda:0'), new_distribution = tensor([0.5900, 0.1488, 0.2612], device='cuda:0')
2024-11-20 20:52:36,668 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 266: ref_distribution = tensor([0.5900, 0.1488, 0.2612], device='cuda:0'), new_distribution = tensor([0.5906, 0.1478, 0.2617], device='cuda:0')
2024-11-20 20:52:36,672 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 267: ref_distribution = tensor([0.5906, 0.1478, 0.2617], device='cuda:0'), new_distribution = tensor([0.5915, 0.1461, 0.2623], device='cuda:0')
2024-11-20 20:52:36,676 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 268: ref_distribution = tensor([0.5915, 0.1461, 0.2623], device='cuda:0'), new_distribution = tensor([0.5922, 0.1446, 0.2632], device='cuda:0')
2024-11-20 20:52:36,680 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 269: ref_distribution = tensor([0.5922, 0.1446, 0.2632], device='cuda:0'), new_distribution = tensor([0.5925, 0.1433, 0.2642], device='cuda:0')
2024-11-20 20:52:36,684 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 270: ref_distribution = tensor([0.5925, 0.1433, 0.2642], device='cuda:0'), new_distribution = tensor([0.5932, 0.1425, 0.2643], device='cuda:0')
2024-11-20 20:52:36,688 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 271: ref_distribution = tensor([0.5932, 0.1425, 0.2643], device='cuda:0'), new_distribution = tensor([0.5935, 0.1412, 0.2653], device='cuda:0')
2024-11-20 20:52:36,692 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 272: ref_distribution = tensor([0.5935, 0.1412, 0.2653], device='cuda:0'), new_distribution = tensor([0.5941, 0.1402, 0.2657], device='cuda:0')
2024-11-20 20:52:36,696 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 273: ref_distribution = tensor([0.5941, 0.1402, 0.2657], device='cuda:0'), new_distribution = tensor([0.5946, 0.1386, 0.2668], device='cuda:0')
2024-11-20 20:52:36,701 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 274: ref_distribution = tensor([0.5946, 0.1386, 0.2668], device='cuda:0'), new_distribution = tensor([0.5952, 0.1372, 0.2677], device='cuda:0')
2024-11-20 20:52:36,705 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 275: ref_distribution = tensor([0.5952, 0.1372, 0.2677], device='cuda:0'), new_distribution = tensor([0.5957, 0.1362, 0.2681], device='cuda:0')
2024-11-20 20:52:36,709 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 276: ref_distribution = tensor([0.5957, 0.1362, 0.2681], device='cuda:0'), new_distribution = tensor([0.5962, 0.1353, 0.2685], device='cuda:0')
2024-11-20 20:52:36,713 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 277: ref_distribution = tensor([0.5962, 0.1353, 0.2685], device='cuda:0'), new_distribution = tensor([0.5964, 0.1345, 0.2691], device='cuda:0')
2024-11-20 20:52:36,717 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 278: ref_distribution = tensor([0.5964, 0.1345, 0.2691], device='cuda:0'), new_distribution = tensor([0.5970, 0.1338, 0.2693], device='cuda:0')
2024-11-20 20:52:36,721 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 279: ref_distribution = tensor([0.5970, 0.1338, 0.2693], device='cuda:0'), new_distribution = tensor([0.5973, 0.1333, 0.2693], device='cuda:0')
2024-11-20 20:52:36,725 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 280: ref_distribution = tensor([0.5973, 0.1333, 0.2693], device='cuda:0'), new_distribution = tensor([0.5983, 0.1320, 0.2698], device='cuda:0')
2024-11-20 20:52:36,729 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 281: ref_distribution = tensor([0.5983, 0.1320, 0.2698], device='cuda:0'), new_distribution = tensor([0.5980, 0.1323, 0.2697], device='cuda:0')
2024-11-20 20:52:36,733 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 282: ref_distribution = tensor([0.5980, 0.1323, 0.2697], device='cuda:0'), new_distribution = tensor([0.5983, 0.1310, 0.2707], device='cuda:0')
2024-11-20 20:52:36,737 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 283: ref_distribution = tensor([0.5983, 0.1310, 0.2707], device='cuda:0'), new_distribution = tensor([0.5985, 0.1302, 0.2712], device='cuda:0')
2024-11-20 20:52:36,742 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 284: ref_distribution = tensor([0.5985, 0.1302, 0.2712], device='cuda:0'), new_distribution = tensor([0.5987, 0.1295, 0.2718], device='cuda:0')
2024-11-20 20:52:36,746 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 285: ref_distribution = tensor([0.5987, 0.1295, 0.2718], device='cuda:0'), new_distribution = tensor([0.5983, 0.1294, 0.2723], device='cuda:0')
2024-11-20 20:52:36,750 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 286: ref_distribution = tensor([0.5983, 0.1294, 0.2723], device='cuda:0'), new_distribution = tensor([0.5988, 0.1281, 0.2731], device='cuda:0')
2024-11-20 20:52:36,754 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 287: ref_distribution = tensor([0.5988, 0.1281, 0.2731], device='cuda:0'), new_distribution = tensor([0.5989, 0.1278, 0.2733], device='cuda:0')
2024-11-20 20:52:36,758 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 288: ref_distribution = tensor([0.5989, 0.1278, 0.2733], device='cuda:0'), new_distribution = tensor([0.5990, 0.1269, 0.2742], device='cuda:0')
2024-11-20 20:52:36,762 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 289: ref_distribution = tensor([0.5990, 0.1269, 0.2742], device='cuda:0'), new_distribution = tensor([0.5999, 0.1262, 0.2740], device='cuda:0')
2024-11-20 20:52:36,767 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 290: ref_distribution = tensor([0.5999, 0.1262, 0.2740], device='cuda:0'), new_distribution = tensor([0.5999, 0.1253, 0.2748], device='cuda:0')
2024-11-20 20:52:36,771 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 291: ref_distribution = tensor([0.5999, 0.1253, 0.2748], device='cuda:0'), new_distribution = tensor([0.6005, 0.1241, 0.2754], device='cuda:0')
2024-11-20 20:52:36,775 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 292: ref_distribution = tensor([0.6005, 0.1241, 0.2754], device='cuda:0'), new_distribution = tensor([0.6007, 0.1240, 0.2753], device='cuda:0')
2024-11-20 20:52:36,779 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 293: ref_distribution = tensor([0.6007, 0.1240, 0.2753], device='cuda:0'), new_distribution = tensor([0.6001, 0.1243, 0.2757], device='cuda:0')
2024-11-20 20:52:36,783 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 294: ref_distribution = tensor([0.6001, 0.1243, 0.2757], device='cuda:0'), new_distribution = tensor([0.5998, 0.1239, 0.2762], device='cuda:0')
2024-11-20 20:52:36,787 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 295: ref_distribution = tensor([0.5998, 0.1239, 0.2762], device='cuda:0'), new_distribution = tensor([0.5999, 0.1237, 0.2764], device='cuda:0')
2024-11-20 20:52:36,791 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 296: ref_distribution = tensor([0.5999, 0.1237, 0.2764], device='cuda:0'), new_distribution = tensor([0.6000, 0.1234, 0.2766], device='cuda:0')
2024-11-20 20:52:36,795 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 297: ref_distribution = tensor([0.6000, 0.1234, 0.2766], device='cuda:0'), new_distribution = tensor([0.6007, 0.1226, 0.2767], device='cuda:0')
2024-11-20 20:52:36,799 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 298: ref_distribution = tensor([0.6007, 0.1226, 0.2767], device='cuda:0'), new_distribution = tensor([0.6006, 0.1220, 0.2774], device='cuda:0')
2024-11-20 20:52:36,804 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 299: ref_distribution = tensor([0.6006, 0.1220, 0.2774], device='cuda:0'), new_distribution = tensor([0.6010, 0.1211, 0.2779], device='cuda:0')
