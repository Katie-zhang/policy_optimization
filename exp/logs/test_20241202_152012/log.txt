2024-12-02 15:20:13,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 0 loss: 0.6777 acc: 0.77
2024-12-02 15:20:13,571 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 2 loss: 0.6746 acc: 0.77
2024-12-02 15:20:13,578 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 4 loss: 0.6717 acc: 0.77
2024-12-02 15:20:13,584 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 6 loss: 0.6688 acc: 0.77
2024-12-02 15:20:13,590 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 8 loss: 0.6659 acc: 0.77
2024-12-02 15:20:13,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 10 loss: 0.6632 acc: 0.77
2024-12-02 15:20:13,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 12 loss: 0.6605 acc: 0.77
2024-12-02 15:20:13,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 14 loss: 0.6579 acc: 0.77
2024-12-02 15:20:13,615 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 16 loss: 0.6554 acc: 0.77
2024-12-02 15:20:13,621 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 18 loss: 0.6529 acc: 0.77
2024-12-02 15:20:14,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 0 loss: -0.2946 reward: 0.2946 ref_reward: 0.2734 improvement: 7.77%
2024-12-02 15:20:14,538 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 2 loss: -0.3005 reward: 0.3005 ref_reward: 0.2734 improvement: 9.90%
2024-12-02 15:20:14,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 4 loss: -0.3061 reward: 0.3061 ref_reward: 0.2734 improvement: 11.96%
2024-12-02 15:20:15,192 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 6 loss: -0.3115 reward: 0.3115 ref_reward: 0.2734 improvement: 13.92%
2024-12-02 15:20:15,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 8 loss: -0.3166 reward: 0.3166 ref_reward: 0.2734 improvement: 15.78%
2024-12-02 15:20:15,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 10 loss: -0.3215 reward: 0.3215 ref_reward: 0.2734 improvement: 17.58%
2024-12-02 15:20:16,037 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 12 loss: -0.3261 reward: 0.3261 ref_reward: 0.2734 improvement: 19.28%
2024-12-02 15:20:16,319 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 14 loss: -0.3304 reward: 0.3304 ref_reward: 0.2734 improvement: 20.83%
2024-12-02 15:20:16,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 16 loss: -0.3344 reward: 0.3344 ref_reward: 0.2734 improvement: 22.32%
2024-12-02 15:20:16,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 18 loss: -0.3383 reward: 0.3383 ref_reward: 0.2734 improvement: 23.72%
2024-12-02 15:20:17,170 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 20 loss: -0.3419 reward: 0.3419 ref_reward: 0.2734 improvement: 25.06%
2024-12-02 15:20:17,454 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 22 loss: -0.3454 reward: 0.3454 ref_reward: 0.2734 improvement: 26.33%
2024-12-02 15:20:17,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 24 loss: -0.3487 reward: 0.3487 ref_reward: 0.2734 improvement: 27.53%
2024-12-02 15:20:18,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 26 loss: -0.3518 reward: 0.3518 ref_reward: 0.2734 improvement: 28.67%
2024-12-02 15:20:18,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 28 loss: -0.3547 reward: 0.3547 ref_reward: 0.2734 improvement: 29.74%
2024-12-02 15:20:18,595 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 30 loss: -0.3575 reward: 0.3575 ref_reward: 0.2734 improvement: 30.76%
2024-12-02 15:20:18,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 32 loss: -0.3602 reward: 0.3602 ref_reward: 0.2734 improvement: 31.73%
2024-12-02 15:20:19,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 34 loss: -0.3627 reward: 0.3627 ref_reward: 0.2734 improvement: 32.65%
2024-12-02 15:20:19,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 36 loss: -0.3650 reward: 0.3650 ref_reward: 0.2734 improvement: 33.52%
2024-12-02 15:20:19,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 38 loss: -0.3672 reward: 0.3672 ref_reward: 0.2734 improvement: 34.33%
2024-12-02 15:20:20,003 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 40 loss: -0.3693 reward: 0.3693 ref_reward: 0.2734 improvement: 35.07%
2024-12-02 15:20:20,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 42 loss: -0.3712 reward: 0.3712 ref_reward: 0.2734 improvement: 35.76%
2024-12-02 15:20:20,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 44 loss: -0.3729 reward: 0.3729 ref_reward: 0.2734 improvement: 36.38%
2024-12-02 15:20:20,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 46 loss: -0.3744 reward: 0.3744 ref_reward: 0.2734 improvement: 36.94%
2024-12-02 15:20:21,130 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 48 loss: -0.3758 reward: 0.3758 ref_reward: 0.2734 improvement: 37.44%
2024-12-02 15:20:21,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 50 loss: -0.3770 reward: 0.3770 ref_reward: 0.2734 improvement: 37.88%
2024-12-02 15:20:21,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 52 loss: -0.3780 reward: 0.3780 ref_reward: 0.2734 improvement: 38.27%
2024-12-02 15:20:21,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 54 loss: -0.3789 reward: 0.3789 ref_reward: 0.2734 improvement: 38.61%
2024-12-02 15:20:22,260 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 56 loss: -0.3798 reward: 0.3798 ref_reward: 0.2734 improvement: 38.90%
2024-12-02 15:20:22,550 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 58 loss: -0.3804 reward: 0.3804 ref_reward: 0.2734 improvement: 39.15%
2024-12-02 15:20:22,834 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 60 loss: -0.3810 reward: 0.3810 ref_reward: 0.2734 improvement: 39.37%
2024-12-02 15:20:23,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 62 loss: -0.3816 reward: 0.3816 ref_reward: 0.2734 improvement: 39.56%
2024-12-02 15:20:23,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 64 loss: -0.3820 reward: 0.3820 ref_reward: 0.2734 improvement: 39.73%
2024-12-02 15:20:23,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 66 loss: -0.3824 reward: 0.3824 ref_reward: 0.2734 improvement: 39.87%
2024-12-02 15:20:23,966 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 68 loss: -0.3827 reward: 0.3827 ref_reward: 0.2734 improvement: 39.99%
2024-12-02 15:20:24,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 70 loss: -0.3830 reward: 0.3830 ref_reward: 0.2734 improvement: 40.10%
2024-12-02 15:20:24,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 72 loss: -0.3833 reward: 0.3833 ref_reward: 0.2734 improvement: 40.19%
2024-12-02 15:20:24,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 74 loss: -0.3835 reward: 0.3835 ref_reward: 0.2734 improvement: 40.28%
2024-12-02 15:20:25,103 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 76 loss: -0.3837 reward: 0.3837 ref_reward: 0.2734 improvement: 40.35%
2024-12-02 15:20:25,385 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 78 loss: -0.3839 reward: 0.3839 ref_reward: 0.2734 improvement: 40.41%
2024-12-02 15:20:25,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 80 loss: -0.3840 reward: 0.3840 ref_reward: 0.2734 improvement: 40.47%
2024-12-02 15:20:25,949 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 82 loss: -0.3842 reward: 0.3842 ref_reward: 0.2734 improvement: 40.52%
2024-12-02 15:20:26,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 84 loss: -0.3843 reward: 0.3843 ref_reward: 0.2734 improvement: 40.56%
2024-12-02 15:20:26,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 86 loss: -0.3844 reward: 0.3844 ref_reward: 0.2734 improvement: 40.60%
2024-12-02 15:20:26,794 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 88 loss: -0.3845 reward: 0.3845 ref_reward: 0.2734 improvement: 40.63%
2024-12-02 15:20:27,076 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 90 loss: -0.3846 reward: 0.3846 ref_reward: 0.2734 improvement: 40.67%
2024-12-02 15:20:27,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 92 loss: -0.3847 reward: 0.3847 ref_reward: 0.2734 improvement: 40.70%
2024-12-02 15:20:27,640 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 94 loss: -0.3847 reward: 0.3847 ref_reward: 0.2734 improvement: 40.72%
2024-12-02 15:20:27,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 96 loss: -0.3848 reward: 0.3848 ref_reward: 0.2734 improvement: 40.75%
2024-12-02 15:20:28,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:203] - INFO: [Policy] Epoch 98 loss: -0.3849 reward: 0.3849 ref_reward: 0.2734 improvement: 40.77%
2024-12-02 15:20:29,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 0 loss: 0.7087 grad norm: 0.6002 
2024-12-02 15:20:29,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 5 loss: 0.6571 grad norm: 0.4169 
2024-12-02 15:20:30,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 10 loss: 0.6256 grad norm: 0.2917 
2024-12-02 15:20:31,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 15 loss: 0.6072 grad norm: 0.1682 
2024-12-02 15:20:31,863 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 20 loss: 0.6000 grad norm: 0.0660 
2024-12-02 15:20:32,575 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 25 loss: 0.5994 grad norm: 0.0546 
2024-12-02 15:20:33,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 30 loss: 0.6006 grad norm: 0.0869 
2024-12-02 15:20:33,994 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 35 loss: 0.6007 grad norm: 0.0866 
2024-12-02 15:20:34,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 40 loss: 0.5998 grad norm: 0.0607 
2024-12-02 15:20:35,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 45 loss: 0.5990 grad norm: 0.0269 
2024-12-02 15:20:36,129 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 50 loss: 0.5988 grad norm: 0.0081 
2024-12-02 15:20:36,841 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 55 loss: 0.5989 grad norm: 0.0207 
2024-12-02 15:20:37,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 60 loss: 0.5990 grad norm: 0.0233 
2024-12-02 15:20:38,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 65 loss: 0.5989 grad norm: 0.0163 
2024-12-02 15:20:38,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 70 loss: 0.5988 grad norm: 0.0056 
2024-12-02 15:20:39,683 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 75 loss: 0.5988 grad norm: 0.0036 
2024-12-02 15:20:40,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 80 loss: 0.5988 grad norm: 0.0073 
2024-12-02 15:20:41,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 85 loss: 0.5988 grad norm: 0.0065 
2024-12-02 15:20:41,806 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 90 loss: 0.5988 grad norm: 0.0035 
2024-12-02 15:20:42,511 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 95 loss: 0.5988 grad norm: 0.0010 
2024-12-02 15:20:43,560 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 0 loss: 1.1137 grad norm: 0.8526 
2024-12-02 15:20:44,940 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 5 loss: 1.0296 grad norm: 0.8247 
2024-12-02 15:20:45,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 10 loss: 0.9537 grad norm: 0.8329 
2024-12-02 15:20:46,660 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 15 loss: 0.8816 grad norm: 0.8493 
2024-12-02 15:20:47,413 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 20 loss: 0.8119 grad norm: 0.8401 
2024-12-02 15:20:48,156 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 25 loss: 0.7468 grad norm: 0.7890 
2024-12-02 15:20:48,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 30 loss: 0.6898 grad norm: 0.6923 
2024-12-02 15:20:49,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 35 loss: 0.6441 grad norm: 0.5350 
2024-12-02 15:20:50,418 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 40 loss: 0.6143 grad norm: 0.3336 
2024-12-02 15:20:51,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 45 loss: 0.6012 grad norm: 0.1347 
2024-12-02 15:20:52,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 50 loss: 0.5993 grad norm: 0.0691 
2024-12-02 15:20:52,832 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 55 loss: 0.6009 grad norm: 0.1339 
2024-12-02 15:20:53,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 60 loss: 0.6017 grad norm: 0.1546 
2024-12-02 15:20:54,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 65 loss: 0.6012 grad norm: 0.1373 
2024-12-02 15:20:55,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 70 loss: 0.6001 grad norm: 0.0999 
2024-12-02 15:20:55,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 75 loss: 0.5992 grad norm: 0.0537 
2024-12-02 15:20:56,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 80 loss: 0.5988 grad norm: 0.0117 
2024-12-02 15:20:57,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 85 loss: 0.5988 grad norm: 0.0175 
2024-12-02 15:20:58,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 90 loss: 0.5989 grad norm: 0.0290 
2024-12-02 15:20:58,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 95 loss: 0.5989 grad norm: 0.0284 
2024-12-02 15:21:00,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 0 loss: 9.2191 grad norm: 1.1169 
2024-12-02 15:21:00,759 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 5 loss: 9.1238 grad norm: 0.9929 
2024-12-02 15:21:01,502 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 10 loss: 9.0500 grad norm: 0.9713 
2024-12-02 15:21:02,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 15 loss: 8.9836 grad norm: 1.0354 
2024-12-02 15:21:02,984 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 20 loss: 8.9114 grad norm: 1.1623 
2024-12-02 15:21:03,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 25 loss: 8.8306 grad norm: 1.3151 
2024-12-02 15:21:04,486 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 30 loss: 8.7352 grad norm: 1.4938 
2024-12-02 15:21:05,235 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 35 loss: 8.6247 grad norm: 1.6869 
2024-12-02 15:21:05,983 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 40 loss: 8.4952 grad norm: 1.9013 
2024-12-02 15:21:06,734 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 45 loss: 8.3438 grad norm: 2.1307 
2024-12-02 15:21:07,483 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 50 loss: 8.1682 grad norm: 2.3751 
2024-12-02 15:21:08,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 55 loss: 7.9661 grad norm: 2.6345 
2024-12-02 15:21:08,981 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 60 loss: 7.7352 grad norm: 2.9089 
2024-12-02 15:21:09,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 65 loss: 7.4734 grad norm: 3.1984 
2024-12-02 15:21:10,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 70 loss: 7.1784 grad norm: 3.5028 
2024-12-02 15:21:11,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 75 loss: 6.8482 grad norm: 3.8221 
2024-12-02 15:21:11,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 80 loss: 6.4807 grad norm: 4.1564 
2024-12-02 15:21:12,729 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 85 loss: 6.0739 grad norm: 4.5056 
2024-12-02 15:21:13,481 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 90 loss: 5.6257 grad norm: 4.8697 
2024-12-02 15:21:14,232 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 95 loss: 5.1342 grad norm: 5.2487 
2024-12-02 15:21:15,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 0 loss: 0.6413 grad norm: 0.2434 
2024-12-02 15:21:15,970 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 5 loss: 0.6218 grad norm: 0.1901 
2024-12-02 15:21:16,718 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 10 loss: 0.6089 grad norm: 0.1315 
2024-12-02 15:21:17,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 15 loss: 0.6015 grad norm: 0.0703 
2024-12-02 15:21:18,228 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 20 loss: 0.5990 grad norm: 0.0198 
2024-12-02 15:21:18,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 25 loss: 0.5996 grad norm: 0.0493 
2024-12-02 15:21:19,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 30 loss: 0.6000 grad norm: 0.0577 
2024-12-02 15:21:20,481 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 35 loss: 0.5994 grad norm: 0.0377 
2024-12-02 15:21:21,232 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 40 loss: 0.5989 grad norm: 0.0116 
2024-12-02 15:21:21,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 45 loss: 0.5988 grad norm: 0.0102 
2024-12-02 15:21:22,734 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 50 loss: 0.5989 grad norm: 0.0166 
2024-12-02 15:21:23,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 55 loss: 0.5989 grad norm: 0.0141 
2024-12-02 15:21:24,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 60 loss: 0.5988 grad norm: 0.0065 
2024-12-02 15:21:24,985 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 65 loss: 0.5988 grad norm: 0.0015 
2024-12-02 15:21:25,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 70 loss: 0.5988 grad norm: 0.0057 
2024-12-02 15:21:26,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 75 loss: 0.5988 grad norm: 0.0052 
2024-12-02 15:21:27,228 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 80 loss: 0.5988 grad norm: 0.0021 
2024-12-02 15:21:27,978 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 85 loss: 0.5988 grad norm: 0.0010 
2024-12-02 15:21:28,729 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 90 loss: 0.5988 grad norm: 0.0022 
2024-12-02 15:21:29,477 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:331] - INFO: [Policy] Epoch: 95 loss: 0.5988 grad norm: 0.0018 
2024-12-02 15:21:31,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 0 loss: 0.0276 grad norm: 0.6576 
2024-12-02 15:21:31,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 5 loss: 0.0096 grad norm: 0.3125 
2024-12-02 15:21:32,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 10 loss: 0.0008 grad norm: 0.0973 
2024-12-02 15:21:33,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 15 loss: 0.0004 grad norm: 0.0663 
2024-12-02 15:21:34,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 20 loss: 0.0020 grad norm: 0.1306 
2024-12-02 15:21:34,916 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 25 loss: 0.0005 grad norm: 0.0702 
2024-12-02 15:21:35,670 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 30 loss: 0.0000 grad norm: 0.0172 
2024-12-02 15:21:36,428 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 35 loss: 0.0004 grad norm: 0.0618 
2024-12-02 15:21:37,182 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 40 loss: 0.0001 grad norm: 0.0341 
2024-12-02 15:21:37,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 45 loss: 0.0000 grad norm: 0.0067 
2024-12-02 15:21:38,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 50 loss: 0.0001 grad norm: 0.0248 
2024-12-02 15:21:39,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 55 loss: 0.0001 grad norm: 0.0234 
2024-12-02 15:21:40,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0117 
2024-12-02 15:21:40,953 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0066 
2024-12-02 15:21:41,709 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0054 
2024-12-02 15:21:42,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0027 
2024-12-02 15:21:43,224 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:21:43,981 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0012 
2024-12-02 15:21:44,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0016 
2024-12-02 15:21:45,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0010 
2024-12-02 15:21:46,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0011 
2024-12-02 15:21:47,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0008 
2024-12-02 15:21:47,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0006 
2024-12-02 15:21:48,529 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:21:49,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:21:50,049 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:21:50,806 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:21:51,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:21:52,324 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:21:53,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:21:54,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:21:55,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:21:56,291 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:21:57,019 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:21:57,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:21:59,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0000 
2024-12-02 15:22:00,189 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:00,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:22:01,646 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:02,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:03,901 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:04,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:05,568 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:06,294 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:22:07,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:07,744 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:08,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:09,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:09,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:10,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:22:11,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:12,629 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:13,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:14,385 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:15,156 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:15,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0005 
2024-12-02 15:22:16,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:22:17,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:22:18,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:22:18,988 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:19,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 0 loss: 1.7019 grad norm: 3.9200 
2024-12-02 15:22:20,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 5 loss: 0.0388 grad norm: 0.7232 
2024-12-02 15:22:21,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 10 loss: 0.0087 grad norm: 0.2387 
2024-12-02 15:22:22,295 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 15 loss: 0.0172 grad norm: 0.3197 
2024-12-02 15:22:23,061 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 20 loss: 0.0021 grad norm: 0.1201 
2024-12-02 15:22:23,827 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 25 loss: 0.0027 grad norm: 0.1546 
2024-12-02 15:22:24,595 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 30 loss: 0.0024 grad norm: 0.1450 
2024-12-02 15:22:25,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 35 loss: 0.0010 grad norm: 0.0861 
2024-12-02 15:22:26,130 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 40 loss: 0.0004 grad norm: 0.0556 
2024-12-02 15:22:26,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 45 loss: 0.0001 grad norm: 0.0346 
2024-12-02 15:22:27,665 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 50 loss: 0.0002 grad norm: 0.0439 
2024-12-02 15:22:28,431 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0124 
2024-12-02 15:22:29,199 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 60 loss: 0.0001 grad norm: 0.0271 
2024-12-02 15:22:29,970 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0115 
2024-12-02 15:22:30,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0051 
2024-12-02 15:22:31,510 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0061 
2024-12-02 15:22:32,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0029 
2024-12-02 15:22:33,049 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0042 
2024-12-02 15:22:33,818 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0017 
2024-12-02 15:22:34,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0025 
2024-12-02 15:22:35,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:36,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0015 
2024-12-02 15:22:36,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:22:37,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0008 
2024-12-02 15:22:38,420 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:22:39,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:39,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:22:40,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:22:42,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:43,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:44,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:44,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:45,526 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:22:46,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:47,039 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:47,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:48,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0000 
2024-12-02 15:22:49,309 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:50,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:22:50,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:51,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:52,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:53,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:53,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:54,604 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:22:55,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:56,102 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:56,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:57,594 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:22:58,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:59,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:22:59,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:23:00,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:23:01,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:23:02,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:23:02,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:03,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:04,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:23:05,031 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:05,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0000 
2024-12-02 15:23:06,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 0 loss: 672.4780 grad norm: 63.3320 
2024-12-02 15:23:07,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 5 loss: 0.7335 grad norm: 6.7241 
2024-12-02 15:23:08,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 10 loss: 0.3246 grad norm: 3.8361 
2024-12-02 15:23:08,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 15 loss: 0.0160 grad norm: 0.6194 
2024-12-02 15:23:09,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 20 loss: 0.0466 grad norm: 0.9230 
2024-12-02 15:23:10,488 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 25 loss: 0.0529 grad norm: 0.9367 
2024-12-02 15:23:11,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 30 loss: 0.0294 grad norm: 0.6852 
2024-12-02 15:23:11,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 35 loss: 0.0013 grad norm: 0.1464 
2024-12-02 15:23:12,723 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 40 loss: 0.0016 grad norm: 0.1680 
2024-12-02 15:23:13,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 45 loss: 0.0013 grad norm: 0.1445 
2024-12-02 15:23:14,209 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 50 loss: 0.0005 grad norm: 0.0910 
2024-12-02 15:23:14,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 55 loss: 0.0001 grad norm: 0.0398 
2024-12-02 15:23:15,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0281 
2024-12-02 15:23:16,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0215 
2024-12-02 15:23:17,185 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 70 loss: 0.0001 grad norm: 0.0297 
2024-12-02 15:23:17,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0228 
2024-12-02 15:23:18,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0104 
2024-12-02 15:23:19,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0051 
2024-12-02 15:23:20,162 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0085 
2024-12-02 15:23:20,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0025 
2024-12-02 15:23:21,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0029 
2024-12-02 15:23:22,390 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0017 
2024-12-02 15:23:23,130 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0010 
2024-12-02 15:23:23,873 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0010 
2024-12-02 15:23:24,617 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0007 
2024-12-02 15:23:25,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0009 
2024-12-02 15:23:26,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:23:26,855 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:27,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:23:28,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:29,093 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:23:29,838 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0006 
2024-12-02 15:23:30,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:31,326 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:23:32,069 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:32,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:33,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:23:34,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0005 
2024-12-02 15:23:35,043 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:35,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:23:36,529 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:37,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:38,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:23:38,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0005 
2024-12-02 15:23:39,507 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:40,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:23:41,001 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:41,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:42,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:23:43,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:23:43,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:44,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:23:45,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:46,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:46,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:23:47,708 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:23:48,454 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:23:49,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:23:49,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:23:50,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:23:51,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 0 loss: 1.5558 grad norm: 5.1872 
2024-12-02 15:23:52,423 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 5 loss: 0.0385 grad norm: 0.8681 
2024-12-02 15:23:53,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 10 loss: 0.0244 grad norm: 0.4625 
2024-12-02 15:23:53,926 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 15 loss: 0.0035 grad norm: 0.1975 
2024-12-02 15:23:54,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 20 loss: 0.0085 grad norm: 0.3860 
2024-12-02 15:23:55,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 25 loss: 0.0008 grad norm: 0.1007 
2024-12-02 15:23:56,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 30 loss: 0.0025 grad norm: 0.1756 
2024-12-02 15:23:56,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 35 loss: 0.0008 grad norm: 0.1041 
2024-12-02 15:23:57,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 40 loss: 0.0000 grad norm: 0.0022 
2024-12-02 15:23:58,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 45 loss: 0.0003 grad norm: 0.0603 
2024-12-02 15:23:59,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 50 loss: 0.0000 grad norm: 0.0154 
2024-12-02 15:23:59,949 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 55 loss: 0.0001 grad norm: 0.0327 
2024-12-02 15:24:00,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0209 
2024-12-02 15:24:01,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0092 
2024-12-02 15:24:02,208 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0029 
2024-12-02 15:24:02,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0057 
2024-12-02 15:24:03,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0036 
2024-12-02 15:24:04,464 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0014 
2024-12-02 15:24:05,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0029 
2024-12-02 15:24:05,970 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0012 
2024-12-02 15:24:06,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0008 
2024-12-02 15:24:07,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0006 
2024-12-02 15:24:08,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0007 
2024-12-02 15:24:08,978 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:09,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:24:10,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:24:11,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:11,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:24:12,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:24:13,493 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:24:14,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:24:14,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:24:15,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:16,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:17,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:24:18,001 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:18,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0000 
2024-12-02 15:24:19,511 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:24:20,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:21,020 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:21,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:22,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:23,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:24:24,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:24:24,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:24:25,534 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:24:26,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:27,036 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:27,788 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:28,542 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:24:29,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:24:30,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:24:30,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:24:31,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:32,306 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:33,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:24:33,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:24:34,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0000 
2024-12-02 15:24:35,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:24:36,057 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:24:37,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 0: ref_distribution = tensor([0.3333, 0.3333, 0.3333], device='cuda:0'), new_distribution = tensor([0.3336, 0.3334, 0.3330], device='cuda:0')
2024-12-02 15:24:37,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 1: ref_distribution = tensor([0.3336, 0.3334, 0.3330], device='cuda:0'), new_distribution = tensor([0.3338, 0.3335, 0.3327], device='cuda:0')
2024-12-02 15:24:37,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 2: ref_distribution = tensor([0.3338, 0.3335, 0.3327], device='cuda:0'), new_distribution = tensor([0.3340, 0.3336, 0.3324], device='cuda:0')
2024-12-02 15:24:37,705 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 3: ref_distribution = tensor([0.3340, 0.3336, 0.3324], device='cuda:0'), new_distribution = tensor([0.3342, 0.3337, 0.3321], device='cuda:0')
2024-12-02 15:24:37,770 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 4: ref_distribution = tensor([0.3342, 0.3337, 0.3321], device='cuda:0'), new_distribution = tensor([0.3344, 0.3338, 0.3318], device='cuda:0')
2024-12-02 15:24:37,835 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 5: ref_distribution = tensor([0.3344, 0.3338, 0.3318], device='cuda:0'), new_distribution = tensor([0.3346, 0.3339, 0.3315], device='cuda:0')
2024-12-02 15:24:37,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 6: ref_distribution = tensor([0.3346, 0.3339, 0.3315], device='cuda:0'), new_distribution = tensor([0.3349, 0.3340, 0.3312], device='cuda:0')
2024-12-02 15:24:37,965 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 7: ref_distribution = tensor([0.3349, 0.3340, 0.3312], device='cuda:0'), new_distribution = tensor([0.3351, 0.3341, 0.3309], device='cuda:0')
2024-12-02 15:24:38,029 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 8: ref_distribution = tensor([0.3351, 0.3341, 0.3309], device='cuda:0'), new_distribution = tensor([0.3353, 0.3341, 0.3306], device='cuda:0')
2024-12-02 15:24:38,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 9: ref_distribution = tensor([0.3353, 0.3341, 0.3306], device='cuda:0'), new_distribution = tensor([0.3355, 0.3342, 0.3302], device='cuda:0')
2024-12-02 15:24:38,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 10: ref_distribution = tensor([0.3355, 0.3342, 0.3302], device='cuda:0'), new_distribution = tensor([0.3357, 0.3343, 0.3299], device='cuda:0')
2024-12-02 15:24:38,224 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 11: ref_distribution = tensor([0.3357, 0.3343, 0.3299], device='cuda:0'), new_distribution = tensor([0.3360, 0.3344, 0.3296], device='cuda:0')
2024-12-02 15:24:38,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 12: ref_distribution = tensor([0.3360, 0.3344, 0.3296], device='cuda:0'), new_distribution = tensor([0.3362, 0.3345, 0.3293], device='cuda:0')
2024-12-02 15:24:38,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 13: ref_distribution = tensor([0.3362, 0.3345, 0.3293], device='cuda:0'), new_distribution = tensor([0.3364, 0.3346, 0.3290], device='cuda:0')
2024-12-02 15:24:38,416 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 14: ref_distribution = tensor([0.3364, 0.3346, 0.3290], device='cuda:0'), new_distribution = tensor([0.3366, 0.3347, 0.3287], device='cuda:0')
2024-12-02 15:24:38,482 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 15: ref_distribution = tensor([0.3366, 0.3347, 0.3287], device='cuda:0'), new_distribution = tensor([0.3369, 0.3347, 0.3284], device='cuda:0')
2024-12-02 15:24:38,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 16: ref_distribution = tensor([0.3369, 0.3347, 0.3284], device='cuda:0'), new_distribution = tensor([0.3371, 0.3348, 0.3281], device='cuda:0')
2024-12-02 15:24:38,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 17: ref_distribution = tensor([0.3371, 0.3348, 0.3281], device='cuda:0'), new_distribution = tensor([0.3373, 0.3349, 0.3278], device='cuda:0')
2024-12-02 15:24:38,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 18: ref_distribution = tensor([0.3373, 0.3349, 0.3278], device='cuda:0'), new_distribution = tensor([0.3375, 0.3350, 0.3275], device='cuda:0')
2024-12-02 15:24:38,739 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 19: ref_distribution = tensor([0.3375, 0.3350, 0.3275], device='cuda:0'), new_distribution = tensor([0.3377, 0.3351, 0.3272], device='cuda:0')
2024-12-02 15:24:38,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 20: ref_distribution = tensor([0.3377, 0.3351, 0.3272], device='cuda:0'), new_distribution = tensor([0.3380, 0.3352, 0.3269], device='cuda:0')
2024-12-02 15:24:38,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 21: ref_distribution = tensor([0.3380, 0.3352, 0.3269], device='cuda:0'), new_distribution = tensor([0.3382, 0.3352, 0.3266], device='cuda:0')
2024-12-02 15:24:38,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 22: ref_distribution = tensor([0.3382, 0.3352, 0.3266], device='cuda:0'), new_distribution = tensor([0.3384, 0.3353, 0.3263], device='cuda:0')
2024-12-02 15:24:39,000 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 23: ref_distribution = tensor([0.3384, 0.3353, 0.3263], device='cuda:0'), new_distribution = tensor([0.3386, 0.3354, 0.3260], device='cuda:0')
2024-12-02 15:24:39,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 24: ref_distribution = tensor([0.3386, 0.3354, 0.3260], device='cuda:0'), new_distribution = tensor([0.3389, 0.3355, 0.3257], device='cuda:0')
2024-12-02 15:24:39,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 25: ref_distribution = tensor([0.3389, 0.3355, 0.3257], device='cuda:0'), new_distribution = tensor([0.3391, 0.3356, 0.3253], device='cuda:0')
2024-12-02 15:24:39,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 26: ref_distribution = tensor([0.3391, 0.3356, 0.3253], device='cuda:0'), new_distribution = tensor([0.3393, 0.3356, 0.3250], device='cuda:0')
2024-12-02 15:24:39,255 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 27: ref_distribution = tensor([0.3393, 0.3356, 0.3250], device='cuda:0'), new_distribution = tensor([0.3395, 0.3357, 0.3247], device='cuda:0')
2024-12-02 15:24:39,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 28: ref_distribution = tensor([0.3395, 0.3357, 0.3247], device='cuda:0'), new_distribution = tensor([0.3398, 0.3358, 0.3244], device='cuda:0')
2024-12-02 15:24:39,385 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 29: ref_distribution = tensor([0.3398, 0.3358, 0.3244], device='cuda:0'), new_distribution = tensor([0.3400, 0.3359, 0.3241], device='cuda:0')
2024-12-02 15:24:39,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 30: ref_distribution = tensor([0.3400, 0.3359, 0.3241], device='cuda:0'), new_distribution = tensor([0.3402, 0.3360, 0.3238], device='cuda:0')
2024-12-02 15:24:39,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 31: ref_distribution = tensor([0.3402, 0.3360, 0.3238], device='cuda:0'), new_distribution = tensor([0.3404, 0.3360, 0.3235], device='cuda:0')
2024-12-02 15:24:39,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 32: ref_distribution = tensor([0.3404, 0.3360, 0.3235], device='cuda:0'), new_distribution = tensor([0.3407, 0.3361, 0.3232], device='cuda:0')
2024-12-02 15:24:39,644 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 33: ref_distribution = tensor([0.3407, 0.3361, 0.3232], device='cuda:0'), new_distribution = tensor([0.3409, 0.3362, 0.3229], device='cuda:0')
2024-12-02 15:24:39,709 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 34: ref_distribution = tensor([0.3409, 0.3362, 0.3229], device='cuda:0'), new_distribution = tensor([0.3411, 0.3363, 0.3226], device='cuda:0')
2024-12-02 15:24:39,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 35: ref_distribution = tensor([0.3411, 0.3363, 0.3226], device='cuda:0'), new_distribution = tensor([0.3414, 0.3363, 0.3223], device='cuda:0')
2024-12-02 15:24:39,838 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 36: ref_distribution = tensor([0.3414, 0.3363, 0.3223], device='cuda:0'), new_distribution = tensor([0.3416, 0.3364, 0.3220], device='cuda:0')
2024-12-02 15:24:39,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 37: ref_distribution = tensor([0.3416, 0.3364, 0.3220], device='cuda:0'), new_distribution = tensor([0.3418, 0.3365, 0.3217], device='cuda:0')
2024-12-02 15:24:39,968 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 38: ref_distribution = tensor([0.3418, 0.3365, 0.3217], device='cuda:0'), new_distribution = tensor([0.3420, 0.3365, 0.3214], device='cuda:0')
2024-12-02 15:24:40,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 39: ref_distribution = tensor([0.3420, 0.3365, 0.3214], device='cuda:0'), new_distribution = tensor([0.3423, 0.3366, 0.3211], device='cuda:0')
2024-12-02 15:24:40,097 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 40: ref_distribution = tensor([0.3423, 0.3366, 0.3211], device='cuda:0'), new_distribution = tensor([0.3425, 0.3367, 0.3208], device='cuda:0')
2024-12-02 15:24:40,162 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 41: ref_distribution = tensor([0.3425, 0.3367, 0.3208], device='cuda:0'), new_distribution = tensor([0.3427, 0.3368, 0.3205], device='cuda:0')
2024-12-02 15:24:40,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 42: ref_distribution = tensor([0.3427, 0.3368, 0.3205], device='cuda:0'), new_distribution = tensor([0.3430, 0.3368, 0.3202], device='cuda:0')
2024-12-02 15:24:40,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 43: ref_distribution = tensor([0.3430, 0.3368, 0.3202], device='cuda:0'), new_distribution = tensor([0.3432, 0.3369, 0.3199], device='cuda:0')
2024-12-02 15:24:40,357 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 44: ref_distribution = tensor([0.3432, 0.3369, 0.3199], device='cuda:0'), new_distribution = tensor([0.3434, 0.3370, 0.3196], device='cuda:0')
2024-12-02 15:24:40,421 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 45: ref_distribution = tensor([0.3434, 0.3370, 0.3196], device='cuda:0'), new_distribution = tensor([0.3436, 0.3370, 0.3193], device='cuda:0')
2024-12-02 15:24:40,486 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 46: ref_distribution = tensor([0.3436, 0.3370, 0.3193], device='cuda:0'), new_distribution = tensor([0.3439, 0.3371, 0.3190], device='cuda:0')
2024-12-02 15:24:40,551 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 47: ref_distribution = tensor([0.3439, 0.3371, 0.3190], device='cuda:0'), new_distribution = tensor([0.3441, 0.3372, 0.3187], device='cuda:0')
2024-12-02 15:24:40,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 48: ref_distribution = tensor([0.3441, 0.3372, 0.3187], device='cuda:0'), new_distribution = tensor([0.3443, 0.3372, 0.3184], device='cuda:0')
2024-12-02 15:24:40,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 49: ref_distribution = tensor([0.3443, 0.3372, 0.3184], device='cuda:0'), new_distribution = tensor([0.3446, 0.3373, 0.3181], device='cuda:0')
2024-12-02 15:24:40,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 50: ref_distribution = tensor([0.3446, 0.3373, 0.3181], device='cuda:0'), new_distribution = tensor([0.3448, 0.3374, 0.3178], device='cuda:0')
2024-12-02 15:24:40,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 51: ref_distribution = tensor([0.3448, 0.3374, 0.3178], device='cuda:0'), new_distribution = tensor([0.3450, 0.3374, 0.3175], device='cuda:0')
2024-12-02 15:24:40,875 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 52: ref_distribution = tensor([0.3450, 0.3374, 0.3175], device='cuda:0'), new_distribution = tensor([0.3453, 0.3375, 0.3172], device='cuda:0')
2024-12-02 15:24:40,940 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 53: ref_distribution = tensor([0.3453, 0.3375, 0.3172], device='cuda:0'), new_distribution = tensor([0.3455, 0.3376, 0.3169], device='cuda:0')
2024-12-02 15:24:41,005 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 54: ref_distribution = tensor([0.3455, 0.3376, 0.3169], device='cuda:0'), new_distribution = tensor([0.3457, 0.3376, 0.3166], device='cuda:0')
2024-12-02 15:24:41,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 55: ref_distribution = tensor([0.3457, 0.3376, 0.3166], device='cuda:0'), new_distribution = tensor([0.3460, 0.3377, 0.3163], device='cuda:0')
2024-12-02 15:24:41,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 56: ref_distribution = tensor([0.3460, 0.3377, 0.3163], device='cuda:0'), new_distribution = tensor([0.3462, 0.3378, 0.3160], device='cuda:0')
2024-12-02 15:24:41,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 57: ref_distribution = tensor([0.3462, 0.3378, 0.3160], device='cuda:0'), new_distribution = tensor([0.3464, 0.3378, 0.3157], device='cuda:0')
2024-12-02 15:24:41,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 58: ref_distribution = tensor([0.3464, 0.3378, 0.3157], device='cuda:0'), new_distribution = tensor([0.3467, 0.3379, 0.3154], device='cuda:0')
2024-12-02 15:24:41,329 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 59: ref_distribution = tensor([0.3467, 0.3379, 0.3154], device='cuda:0'), new_distribution = tensor([0.3469, 0.3380, 0.3151], device='cuda:0')
2024-12-02 15:24:41,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 60: ref_distribution = tensor([0.3469, 0.3380, 0.3151], device='cuda:0'), new_distribution = tensor([0.3471, 0.3380, 0.3149], device='cuda:0')
2024-12-02 15:24:41,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 61: ref_distribution = tensor([0.3471, 0.3380, 0.3149], device='cuda:0'), new_distribution = tensor([0.3474, 0.3381, 0.3146], device='cuda:0')
2024-12-02 15:24:41,524 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 62: ref_distribution = tensor([0.3474, 0.3381, 0.3146], device='cuda:0'), new_distribution = tensor([0.3476, 0.3381, 0.3143], device='cuda:0')
2024-12-02 15:24:41,589 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 63: ref_distribution = tensor([0.3476, 0.3381, 0.3143], device='cuda:0'), new_distribution = tensor([0.3478, 0.3382, 0.3140], device='cuda:0')
2024-12-02 15:24:41,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 64: ref_distribution = tensor([0.3478, 0.3382, 0.3140], device='cuda:0'), new_distribution = tensor([0.3481, 0.3383, 0.3137], device='cuda:0')
2024-12-02 15:24:41,718 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 65: ref_distribution = tensor([0.3481, 0.3383, 0.3137], device='cuda:0'), new_distribution = tensor([0.3483, 0.3383, 0.3134], device='cuda:0')
2024-12-02 15:24:41,783 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 66: ref_distribution = tensor([0.3483, 0.3383, 0.3134], device='cuda:0'), new_distribution = tensor([0.3485, 0.3384, 0.3131], device='cuda:0')
2024-12-02 15:24:41,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 67: ref_distribution = tensor([0.3485, 0.3384, 0.3131], device='cuda:0'), new_distribution = tensor([0.3488, 0.3384, 0.3128], device='cuda:0')
2024-12-02 15:24:41,915 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 68: ref_distribution = tensor([0.3488, 0.3384, 0.3128], device='cuda:0'), new_distribution = tensor([0.3490, 0.3385, 0.3125], device='cuda:0')
2024-12-02 15:24:41,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 69: ref_distribution = tensor([0.3490, 0.3385, 0.3125], device='cuda:0'), new_distribution = tensor([0.3493, 0.3385, 0.3122], device='cuda:0')
2024-12-02 15:24:42,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 70: ref_distribution = tensor([0.3493, 0.3385, 0.3122], device='cuda:0'), new_distribution = tensor([0.3495, 0.3386, 0.3119], device='cuda:0')
2024-12-02 15:24:42,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 71: ref_distribution = tensor([0.3495, 0.3386, 0.3119], device='cuda:0'), new_distribution = tensor([0.3497, 0.3386, 0.3116], device='cuda:0')
2024-12-02 15:24:42,174 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 72: ref_distribution = tensor([0.3497, 0.3386, 0.3116], device='cuda:0'), new_distribution = tensor([0.3500, 0.3387, 0.3113], device='cuda:0')
2024-12-02 15:24:42,239 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 73: ref_distribution = tensor([0.3500, 0.3387, 0.3113], device='cuda:0'), new_distribution = tensor([0.3502, 0.3388, 0.3110], device='cuda:0')
2024-12-02 15:24:42,304 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 74: ref_distribution = tensor([0.3502, 0.3388, 0.3110], device='cuda:0'), new_distribution = tensor([0.3504, 0.3388, 0.3107], device='cuda:0')
2024-12-02 15:24:42,368 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 75: ref_distribution = tensor([0.3504, 0.3388, 0.3107], device='cuda:0'), new_distribution = tensor([0.3507, 0.3389, 0.3104], device='cuda:0')
2024-12-02 15:24:42,433 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 76: ref_distribution = tensor([0.3507, 0.3389, 0.3104], device='cuda:0'), new_distribution = tensor([0.3509, 0.3389, 0.3102], device='cuda:0')
2024-12-02 15:24:42,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 77: ref_distribution = tensor([0.3509, 0.3389, 0.3102], device='cuda:0'), new_distribution = tensor([0.3512, 0.3390, 0.3099], device='cuda:0')
2024-12-02 15:24:42,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 78: ref_distribution = tensor([0.3512, 0.3390, 0.3099], device='cuda:0'), new_distribution = tensor([0.3514, 0.3390, 0.3096], device='cuda:0')
2024-12-02 15:24:42,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 79: ref_distribution = tensor([0.3514, 0.3390, 0.3096], device='cuda:0'), new_distribution = tensor([0.3516, 0.3391, 0.3093], device='cuda:0')
2024-12-02 15:24:42,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 80: ref_distribution = tensor([0.3516, 0.3391, 0.3093], device='cuda:0'), new_distribution = tensor([0.3519, 0.3391, 0.3090], device='cuda:0')
2024-12-02 15:24:42,758 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 81: ref_distribution = tensor([0.3519, 0.3391, 0.3090], device='cuda:0'), new_distribution = tensor([0.3521, 0.3392, 0.3087], device='cuda:0')
2024-12-02 15:24:42,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 82: ref_distribution = tensor([0.3521, 0.3392, 0.3087], device='cuda:0'), new_distribution = tensor([0.3524, 0.3392, 0.3084], device='cuda:0')
2024-12-02 15:24:42,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 83: ref_distribution = tensor([0.3524, 0.3392, 0.3084], device='cuda:0'), new_distribution = tensor([0.3526, 0.3393, 0.3081], device='cuda:0')
2024-12-02 15:24:42,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 84: ref_distribution = tensor([0.3526, 0.3393, 0.3081], device='cuda:0'), new_distribution = tensor([0.3528, 0.3393, 0.3078], device='cuda:0')
2024-12-02 15:24:43,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 85: ref_distribution = tensor([0.3528, 0.3393, 0.3078], device='cuda:0'), new_distribution = tensor([0.3531, 0.3394, 0.3075], device='cuda:0')
2024-12-02 15:24:43,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 86: ref_distribution = tensor([0.3531, 0.3394, 0.3075], device='cuda:0'), new_distribution = tensor([0.3533, 0.3394, 0.3073], device='cuda:0')
2024-12-02 15:24:43,147 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 87: ref_distribution = tensor([0.3533, 0.3394, 0.3073], device='cuda:0'), new_distribution = tensor([0.3536, 0.3395, 0.3070], device='cuda:0')
2024-12-02 15:24:43,211 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 88: ref_distribution = tensor([0.3536, 0.3395, 0.3070], device='cuda:0'), new_distribution = tensor([0.3538, 0.3395, 0.3067], device='cuda:0')
2024-12-02 15:24:43,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 89: ref_distribution = tensor([0.3538, 0.3395, 0.3067], device='cuda:0'), new_distribution = tensor([0.3541, 0.3396, 0.3064], device='cuda:0')
2024-12-02 15:24:43,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 90: ref_distribution = tensor([0.3541, 0.3396, 0.3064], device='cuda:0'), new_distribution = tensor([0.3543, 0.3396, 0.3061], device='cuda:0')
2024-12-02 15:24:43,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 91: ref_distribution = tensor([0.3543, 0.3396, 0.3061], device='cuda:0'), new_distribution = tensor([0.3545, 0.3396, 0.3058], device='cuda:0')
2024-12-02 15:24:43,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 92: ref_distribution = tensor([0.3545, 0.3396, 0.3058], device='cuda:0'), new_distribution = tensor([0.3548, 0.3397, 0.3055], device='cuda:0')
2024-12-02 15:24:43,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 93: ref_distribution = tensor([0.3548, 0.3397, 0.3055], device='cuda:0'), new_distribution = tensor([0.3550, 0.3397, 0.3052], device='cuda:0')
2024-12-02 15:24:43,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 94: ref_distribution = tensor([0.3550, 0.3397, 0.3052], device='cuda:0'), new_distribution = tensor([0.3553, 0.3398, 0.3050], device='cuda:0')
2024-12-02 15:24:43,665 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 95: ref_distribution = tensor([0.3553, 0.3398, 0.3050], device='cuda:0'), new_distribution = tensor([0.3555, 0.3398, 0.3047], device='cuda:0')
2024-12-02 15:24:43,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 96: ref_distribution = tensor([0.3555, 0.3398, 0.3047], device='cuda:0'), new_distribution = tensor([0.3558, 0.3399, 0.3044], device='cuda:0')
2024-12-02 15:24:43,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 97: ref_distribution = tensor([0.3558, 0.3399, 0.3044], device='cuda:0'), new_distribution = tensor([0.3560, 0.3399, 0.3041], device='cuda:0')
2024-12-02 15:24:43,860 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 98: ref_distribution = tensor([0.3560, 0.3399, 0.3041], device='cuda:0'), new_distribution = tensor([0.3562, 0.3399, 0.3038], device='cuda:0')
2024-12-02 15:24:43,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 99: ref_distribution = tensor([0.3562, 0.3399, 0.3038], device='cuda:0'), new_distribution = tensor([0.3565, 0.3400, 0.3035], device='cuda:0')
2024-12-02 15:24:43,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 100: ref_distribution = tensor([0.3565, 0.3400, 0.3035], device='cuda:0'), new_distribution = tensor([0.3567, 0.3400, 0.3032], device='cuda:0')
2024-12-02 15:24:44,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 101: ref_distribution = tensor([0.3567, 0.3400, 0.3032], device='cuda:0'), new_distribution = tensor([0.3570, 0.3401, 0.3030], device='cuda:0')
2024-12-02 15:24:44,119 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 102: ref_distribution = tensor([0.3570, 0.3401, 0.3030], device='cuda:0'), new_distribution = tensor([0.3572, 0.3401, 0.3027], device='cuda:0')
2024-12-02 15:24:44,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 103: ref_distribution = tensor([0.3572, 0.3401, 0.3027], device='cuda:0'), new_distribution = tensor([0.3575, 0.3401, 0.3024], device='cuda:0')
2024-12-02 15:24:44,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 104: ref_distribution = tensor([0.3575, 0.3401, 0.3024], device='cuda:0'), new_distribution = tensor([0.3577, 0.3402, 0.3021], device='cuda:0')
2024-12-02 15:24:44,313 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 105: ref_distribution = tensor([0.3577, 0.3402, 0.3021], device='cuda:0'), new_distribution = tensor([0.3580, 0.3402, 0.3018], device='cuda:0')
2024-12-02 15:24:44,378 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 106: ref_distribution = tensor([0.3580, 0.3402, 0.3018], device='cuda:0'), new_distribution = tensor([0.3582, 0.3402, 0.3015], device='cuda:0')
2024-12-02 15:24:44,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 107: ref_distribution = tensor([0.3582, 0.3402, 0.3015], device='cuda:0'), new_distribution = tensor([0.3585, 0.3403, 0.3013], device='cuda:0')
2024-12-02 15:24:44,508 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 108: ref_distribution = tensor([0.3585, 0.3403, 0.3013], device='cuda:0'), new_distribution = tensor([0.3587, 0.3403, 0.3010], device='cuda:0')
2024-12-02 15:24:44,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 109: ref_distribution = tensor([0.3587, 0.3403, 0.3010], device='cuda:0'), new_distribution = tensor([0.3590, 0.3404, 0.3007], device='cuda:0')
2024-12-02 15:24:44,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 110: ref_distribution = tensor([0.3590, 0.3404, 0.3007], device='cuda:0'), new_distribution = tensor([0.3592, 0.3404, 0.3004], device='cuda:0')
2024-12-02 15:24:44,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 111: ref_distribution = tensor([0.3592, 0.3404, 0.3004], device='cuda:0'), new_distribution = tensor([0.3595, 0.3404, 0.3001], device='cuda:0')
2024-12-02 15:24:44,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 112: ref_distribution = tensor([0.3595, 0.3404, 0.3001], device='cuda:0'), new_distribution = tensor([0.3597, 0.3405, 0.2998], device='cuda:0')
2024-12-02 15:24:44,832 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 113: ref_distribution = tensor([0.3597, 0.3405, 0.2998], device='cuda:0'), new_distribution = tensor([0.3600, 0.3405, 0.2996], device='cuda:0')
2024-12-02 15:24:44,897 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 114: ref_distribution = tensor([0.3600, 0.3405, 0.2996], device='cuda:0'), new_distribution = tensor([0.3602, 0.3405, 0.2993], device='cuda:0')
2024-12-02 15:24:44,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 115: ref_distribution = tensor([0.3602, 0.3405, 0.2993], device='cuda:0'), new_distribution = tensor([0.3604, 0.3406, 0.2990], device='cuda:0')
2024-12-02 15:24:45,026 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 116: ref_distribution = tensor([0.3604, 0.3406, 0.2990], device='cuda:0'), new_distribution = tensor([0.3607, 0.3406, 0.2987], device='cuda:0')
2024-12-02 15:24:45,091 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 117: ref_distribution = tensor([0.3607, 0.3406, 0.2987], device='cuda:0'), new_distribution = tensor([0.3609, 0.3406, 0.2984], device='cuda:0')
2024-12-02 15:24:45,156 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 118: ref_distribution = tensor([0.3609, 0.3406, 0.2984], device='cuda:0'), new_distribution = tensor([0.3612, 0.3406, 0.2982], device='cuda:0')
2024-12-02 15:24:45,221 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 119: ref_distribution = tensor([0.3612, 0.3406, 0.2982], device='cuda:0'), new_distribution = tensor([0.3614, 0.3407, 0.2979], device='cuda:0')
2024-12-02 15:24:45,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 120: ref_distribution = tensor([0.3614, 0.3407, 0.2979], device='cuda:0'), new_distribution = tensor([0.3617, 0.3407, 0.2976], device='cuda:0')
2024-12-02 15:24:45,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 121: ref_distribution = tensor([0.3617, 0.3407, 0.2976], device='cuda:0'), new_distribution = tensor([0.3619, 0.3407, 0.2973], device='cuda:0')
2024-12-02 15:24:45,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 122: ref_distribution = tensor([0.3619, 0.3407, 0.2973], device='cuda:0'), new_distribution = tensor([0.3622, 0.3408, 0.2970], device='cuda:0')
2024-12-02 15:24:45,478 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 123: ref_distribution = tensor([0.3622, 0.3408, 0.2970], device='cuda:0'), new_distribution = tensor([0.3625, 0.3408, 0.2968], device='cuda:0')
2024-12-02 15:24:45,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 124: ref_distribution = tensor([0.3625, 0.3408, 0.2968], device='cuda:0'), new_distribution = tensor([0.3627, 0.3408, 0.2965], device='cuda:0')
2024-12-02 15:24:45,607 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 125: ref_distribution = tensor([0.3627, 0.3408, 0.2965], device='cuda:0'), new_distribution = tensor([0.3630, 0.3408, 0.2962], device='cuda:0')
2024-12-02 15:24:45,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 126: ref_distribution = tensor([0.3630, 0.3408, 0.2962], device='cuda:0'), new_distribution = tensor([0.3632, 0.3409, 0.2959], device='cuda:0')
2024-12-02 15:24:45,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 127: ref_distribution = tensor([0.3632, 0.3409, 0.2959], device='cuda:0'), new_distribution = tensor([0.3635, 0.3409, 0.2957], device='cuda:0')
2024-12-02 15:24:45,802 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 128: ref_distribution = tensor([0.3635, 0.3409, 0.2957], device='cuda:0'), new_distribution = tensor([0.3637, 0.3409, 0.2954], device='cuda:0')
2024-12-02 15:24:45,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 129: ref_distribution = tensor([0.3637, 0.3409, 0.2954], device='cuda:0'), new_distribution = tensor([0.3640, 0.3409, 0.2951], device='cuda:0')
2024-12-02 15:24:45,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 130: ref_distribution = tensor([0.3640, 0.3409, 0.2951], device='cuda:0'), new_distribution = tensor([0.3642, 0.3410, 0.2948], device='cuda:0')
2024-12-02 15:24:45,996 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 131: ref_distribution = tensor([0.3642, 0.3410, 0.2948], device='cuda:0'), new_distribution = tensor([0.3645, 0.3410, 0.2945], device='cuda:0')
2024-12-02 15:24:46,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 132: ref_distribution = tensor([0.3645, 0.3410, 0.2945], device='cuda:0'), new_distribution = tensor([0.3647, 0.3410, 0.2943], device='cuda:0')
2024-12-02 15:24:46,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 133: ref_distribution = tensor([0.3647, 0.3410, 0.2943], device='cuda:0'), new_distribution = tensor([0.3650, 0.3410, 0.2940], device='cuda:0')
2024-12-02 15:24:46,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 134: ref_distribution = tensor([0.3650, 0.3410, 0.2940], device='cuda:0'), new_distribution = tensor([0.3652, 0.3411, 0.2937], device='cuda:0')
2024-12-02 15:24:46,255 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 135: ref_distribution = tensor([0.3652, 0.3411, 0.2937], device='cuda:0'), new_distribution = tensor([0.3655, 0.3411, 0.2934], device='cuda:0')
2024-12-02 15:24:46,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 136: ref_distribution = tensor([0.3655, 0.3411, 0.2934], device='cuda:0'), new_distribution = tensor([0.3657, 0.3411, 0.2932], device='cuda:0')
2024-12-02 15:24:46,385 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 137: ref_distribution = tensor([0.3657, 0.3411, 0.2932], device='cuda:0'), new_distribution = tensor([0.3660, 0.3411, 0.2929], device='cuda:0')
2024-12-02 15:24:46,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 138: ref_distribution = tensor([0.3660, 0.3411, 0.2929], device='cuda:0'), new_distribution = tensor([0.3663, 0.3411, 0.2926], device='cuda:0')
2024-12-02 15:24:46,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 139: ref_distribution = tensor([0.3663, 0.3411, 0.2926], device='cuda:0'), new_distribution = tensor([0.3665, 0.3412, 0.2923], device='cuda:0')
2024-12-02 15:24:46,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 140: ref_distribution = tensor([0.3665, 0.3412, 0.2923], device='cuda:0'), new_distribution = tensor([0.3668, 0.3412, 0.2921], device='cuda:0')
2024-12-02 15:24:46,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 141: ref_distribution = tensor([0.3668, 0.3412, 0.2921], device='cuda:0'), new_distribution = tensor([0.3670, 0.3412, 0.2918], device='cuda:0')
2024-12-02 15:24:46,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 142: ref_distribution = tensor([0.3670, 0.3412, 0.2918], device='cuda:0'), new_distribution = tensor([0.3673, 0.3412, 0.2915], device='cuda:0')
2024-12-02 15:24:46,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 143: ref_distribution = tensor([0.3673, 0.3412, 0.2915], device='cuda:0'), new_distribution = tensor([0.3675, 0.3412, 0.2912], device='cuda:0')
2024-12-02 15:24:46,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 144: ref_distribution = tensor([0.3675, 0.3412, 0.2912], device='cuda:0'), new_distribution = tensor([0.3678, 0.3412, 0.2910], device='cuda:0')
2024-12-02 15:24:46,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 145: ref_distribution = tensor([0.3678, 0.3412, 0.2910], device='cuda:0'), new_distribution = tensor([0.3680, 0.3413, 0.2907], device='cuda:0')
2024-12-02 15:24:46,969 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 146: ref_distribution = tensor([0.3680, 0.3413, 0.2907], device='cuda:0'), new_distribution = tensor([0.3683, 0.3413, 0.2904], device='cuda:0')
2024-12-02 15:24:47,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 147: ref_distribution = tensor([0.3683, 0.3413, 0.2904], device='cuda:0'), new_distribution = tensor([0.3686, 0.3413, 0.2902], device='cuda:0')
2024-12-02 15:24:47,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 148: ref_distribution = tensor([0.3686, 0.3413, 0.2902], device='cuda:0'), new_distribution = tensor([0.3688, 0.3413, 0.2899], device='cuda:0')
2024-12-02 15:24:47,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 149: ref_distribution = tensor([0.3688, 0.3413, 0.2899], device='cuda:0'), new_distribution = tensor([0.3691, 0.3413, 0.2896], device='cuda:0')
2024-12-02 15:24:47,228 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 150: ref_distribution = tensor([0.3691, 0.3413, 0.2896], device='cuda:0'), new_distribution = tensor([0.3693, 0.3413, 0.2893], device='cuda:0')
2024-12-02 15:24:47,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 151: ref_distribution = tensor([0.3693, 0.3413, 0.2893], device='cuda:0'), new_distribution = tensor([0.3696, 0.3413, 0.2891], device='cuda:0')
2024-12-02 15:24:47,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 152: ref_distribution = tensor([0.3696, 0.3413, 0.2891], device='cuda:0'), new_distribution = tensor([0.3699, 0.3413, 0.2888], device='cuda:0')
2024-12-02 15:24:47,423 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 153: ref_distribution = tensor([0.3699, 0.3413, 0.2888], device='cuda:0'), new_distribution = tensor([0.3701, 0.3414, 0.2885], device='cuda:0')
2024-12-02 15:24:47,488 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 154: ref_distribution = tensor([0.3701, 0.3414, 0.2885], device='cuda:0'), new_distribution = tensor([0.3704, 0.3414, 0.2883], device='cuda:0')
2024-12-02 15:24:47,553 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 155: ref_distribution = tensor([0.3704, 0.3414, 0.2883], device='cuda:0'), new_distribution = tensor([0.3706, 0.3414, 0.2880], device='cuda:0')
2024-12-02 15:24:47,617 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 156: ref_distribution = tensor([0.3706, 0.3414, 0.2880], device='cuda:0'), new_distribution = tensor([0.3709, 0.3414, 0.2877], device='cuda:0')
2024-12-02 15:24:47,682 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 157: ref_distribution = tensor([0.3709, 0.3414, 0.2877], device='cuda:0'), new_distribution = tensor([0.3711, 0.3414, 0.2875], device='cuda:0')
2024-12-02 15:24:47,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 158: ref_distribution = tensor([0.3711, 0.3414, 0.2875], device='cuda:0'), new_distribution = tensor([0.3714, 0.3414, 0.2872], device='cuda:0')
2024-12-02 15:24:47,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 159: ref_distribution = tensor([0.3714, 0.3414, 0.2872], device='cuda:0'), new_distribution = tensor([0.3717, 0.3414, 0.2869], device='cuda:0')
2024-12-02 15:24:47,876 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 160: ref_distribution = tensor([0.3717, 0.3414, 0.2869], device='cuda:0'), new_distribution = tensor([0.3719, 0.3414, 0.2866], device='cuda:0')
2024-12-02 15:24:47,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 161: ref_distribution = tensor([0.3719, 0.3414, 0.2866], device='cuda:0'), new_distribution = tensor([0.3722, 0.3414, 0.2864], device='cuda:0')
2024-12-02 15:24:48,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 162: ref_distribution = tensor([0.3722, 0.3414, 0.2864], device='cuda:0'), new_distribution = tensor([0.3725, 0.3414, 0.2861], device='cuda:0')
2024-12-02 15:24:48,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 163: ref_distribution = tensor([0.3725, 0.3414, 0.2861], device='cuda:0'), new_distribution = tensor([0.3727, 0.3414, 0.2858], device='cuda:0')
2024-12-02 15:24:48,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 164: ref_distribution = tensor([0.3727, 0.3414, 0.2858], device='cuda:0'), new_distribution = tensor([0.3730, 0.3414, 0.2856], device='cuda:0')
2024-12-02 15:24:48,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 165: ref_distribution = tensor([0.3730, 0.3414, 0.2856], device='cuda:0'), new_distribution = tensor([0.3732, 0.3415, 0.2853], device='cuda:0')
2024-12-02 15:24:48,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 166: ref_distribution = tensor([0.3732, 0.3415, 0.2853], device='cuda:0'), new_distribution = tensor([0.3735, 0.3415, 0.2850], device='cuda:0')
2024-12-02 15:24:48,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 167: ref_distribution = tensor([0.3735, 0.3415, 0.2850], device='cuda:0'), new_distribution = tensor([0.3738, 0.3415, 0.2848], device='cuda:0')
2024-12-02 15:24:48,395 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 168: ref_distribution = tensor([0.3738, 0.3415, 0.2848], device='cuda:0'), new_distribution = tensor([0.3740, 0.3415, 0.2845], device='cuda:0')
2024-12-02 15:24:48,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 169: ref_distribution = tensor([0.3740, 0.3415, 0.2845], device='cuda:0'), new_distribution = tensor([0.3743, 0.3415, 0.2842], device='cuda:0')
2024-12-02 15:24:48,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 170: ref_distribution = tensor([0.3743, 0.3415, 0.2842], device='cuda:0'), new_distribution = tensor([0.3746, 0.3415, 0.2840], device='cuda:0')
2024-12-02 15:24:48,590 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 171: ref_distribution = tensor([0.3746, 0.3415, 0.2840], device='cuda:0'), new_distribution = tensor([0.3748, 0.3415, 0.2837], device='cuda:0')
2024-12-02 15:24:48,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 172: ref_distribution = tensor([0.3748, 0.3415, 0.2837], device='cuda:0'), new_distribution = tensor([0.3751, 0.3415, 0.2835], device='cuda:0')
2024-12-02 15:24:48,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 173: ref_distribution = tensor([0.3751, 0.3415, 0.2835], device='cuda:0'), new_distribution = tensor([0.3753, 0.3415, 0.2832], device='cuda:0')
2024-12-02 15:24:48,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 174: ref_distribution = tensor([0.3753, 0.3415, 0.2832], device='cuda:0'), new_distribution = tensor([0.3756, 0.3415, 0.2829], device='cuda:0')
2024-12-02 15:24:48,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 175: ref_distribution = tensor([0.3756, 0.3415, 0.2829], device='cuda:0'), new_distribution = tensor([0.3759, 0.3415, 0.2827], device='cuda:0')
2024-12-02 15:24:48,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 176: ref_distribution = tensor([0.3759, 0.3415, 0.2827], device='cuda:0'), new_distribution = tensor([0.3761, 0.3415, 0.2824], device='cuda:0')
2024-12-02 15:24:48,978 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 177: ref_distribution = tensor([0.3761, 0.3415, 0.2824], device='cuda:0'), new_distribution = tensor([0.3764, 0.3415, 0.2821], device='cuda:0')
2024-12-02 15:24:49,043 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 178: ref_distribution = tensor([0.3764, 0.3415, 0.2821], device='cuda:0'), new_distribution = tensor([0.3767, 0.3415, 0.2819], device='cuda:0')
2024-12-02 15:24:49,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 179: ref_distribution = tensor([0.3767, 0.3415, 0.2819], device='cuda:0'), new_distribution = tensor([0.3769, 0.3415, 0.2816], device='cuda:0')
2024-12-02 15:24:49,173 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 180: ref_distribution = tensor([0.3769, 0.3415, 0.2816], device='cuda:0'), new_distribution = tensor([0.3772, 0.3415, 0.2813], device='cuda:0')
2024-12-02 15:24:49,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 181: ref_distribution = tensor([0.3772, 0.3415, 0.2813], device='cuda:0'), new_distribution = tensor([0.3775, 0.3415, 0.2811], device='cuda:0')
2024-12-02 15:24:49,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 182: ref_distribution = tensor([0.3775, 0.3415, 0.2811], device='cuda:0'), new_distribution = tensor([0.3777, 0.3415, 0.2808], device='cuda:0')
2024-12-02 15:24:49,367 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 183: ref_distribution = tensor([0.3777, 0.3415, 0.2808], device='cuda:0'), new_distribution = tensor([0.3780, 0.3414, 0.2806], device='cuda:0')
2024-12-02 15:24:49,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 184: ref_distribution = tensor([0.3780, 0.3414, 0.2806], device='cuda:0'), new_distribution = tensor([0.3783, 0.3414, 0.2803], device='cuda:0')
2024-12-02 15:24:49,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 185: ref_distribution = tensor([0.3783, 0.3414, 0.2803], device='cuda:0'), new_distribution = tensor([0.3785, 0.3414, 0.2800], device='cuda:0')
2024-12-02 15:24:49,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 186: ref_distribution = tensor([0.3785, 0.3414, 0.2800], device='cuda:0'), new_distribution = tensor([0.3788, 0.3414, 0.2798], device='cuda:0')
2024-12-02 15:24:49,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 187: ref_distribution = tensor([0.3788, 0.3414, 0.2798], device='cuda:0'), new_distribution = tensor([0.3791, 0.3414, 0.2795], device='cuda:0')
2024-12-02 15:24:49,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 188: ref_distribution = tensor([0.3791, 0.3414, 0.2795], device='cuda:0'), new_distribution = tensor([0.3793, 0.3414, 0.2793], device='cuda:0')
2024-12-02 15:24:49,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 189: ref_distribution = tensor([0.3793, 0.3414, 0.2793], device='cuda:0'), new_distribution = tensor([0.3796, 0.3414, 0.2790], device='cuda:0')
2024-12-02 15:24:49,822 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 190: ref_distribution = tensor([0.3796, 0.3414, 0.2790], device='cuda:0'), new_distribution = tensor([0.3799, 0.3414, 0.2787], device='cuda:0')
2024-12-02 15:24:49,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 191: ref_distribution = tensor([0.3799, 0.3414, 0.2787], device='cuda:0'), new_distribution = tensor([0.3801, 0.3414, 0.2785], device='cuda:0')
2024-12-02 15:24:49,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 192: ref_distribution = tensor([0.3801, 0.3414, 0.2785], device='cuda:0'), new_distribution = tensor([0.3804, 0.3414, 0.2782], device='cuda:0')
2024-12-02 15:24:50,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 193: ref_distribution = tensor([0.3804, 0.3414, 0.2782], device='cuda:0'), new_distribution = tensor([0.3807, 0.3414, 0.2780], device='cuda:0')
2024-12-02 15:24:50,081 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 194: ref_distribution = tensor([0.3807, 0.3414, 0.2780], device='cuda:0'), new_distribution = tensor([0.3809, 0.3414, 0.2777], device='cuda:0')
2024-12-02 15:24:50,146 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 195: ref_distribution = tensor([0.3809, 0.3414, 0.2777], device='cuda:0'), new_distribution = tensor([0.3812, 0.3413, 0.2774], device='cuda:0')
2024-12-02 15:24:50,211 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 196: ref_distribution = tensor([0.3812, 0.3413, 0.2774], device='cuda:0'), new_distribution = tensor([0.3815, 0.3413, 0.2772], device='cuda:0')
2024-12-02 15:24:50,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 197: ref_distribution = tensor([0.3815, 0.3413, 0.2772], device='cuda:0'), new_distribution = tensor([0.3818, 0.3413, 0.2769], device='cuda:0')
2024-12-02 15:24:50,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 198: ref_distribution = tensor([0.3818, 0.3413, 0.2769], device='cuda:0'), new_distribution = tensor([0.3820, 0.3413, 0.2767], device='cuda:0')
2024-12-02 15:24:50,405 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 199: ref_distribution = tensor([0.3820, 0.3413, 0.2767], device='cuda:0'), new_distribution = tensor([0.3823, 0.3413, 0.2764], device='cuda:0')
2024-12-02 15:24:50,470 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 200: ref_distribution = tensor([0.3823, 0.3413, 0.2764], device='cuda:0'), new_distribution = tensor([0.3826, 0.3413, 0.2762], device='cuda:0')
2024-12-02 15:24:50,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 201: ref_distribution = tensor([0.3826, 0.3413, 0.2762], device='cuda:0'), new_distribution = tensor([0.3828, 0.3413, 0.2759], device='cuda:0')
2024-12-02 15:24:50,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 202: ref_distribution = tensor([0.3828, 0.3413, 0.2759], device='cuda:0'), new_distribution = tensor([0.3831, 0.3413, 0.2756], device='cuda:0')
2024-12-02 15:24:50,666 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 203: ref_distribution = tensor([0.3831, 0.3413, 0.2756], device='cuda:0'), new_distribution = tensor([0.3834, 0.3412, 0.2754], device='cuda:0')
2024-12-02 15:24:50,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 204: ref_distribution = tensor([0.3834, 0.3412, 0.2754], device='cuda:0'), new_distribution = tensor([0.3836, 0.3412, 0.2751], device='cuda:0')
2024-12-02 15:24:50,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 205: ref_distribution = tensor([0.3836, 0.3412, 0.2751], device='cuda:0'), new_distribution = tensor([0.3839, 0.3412, 0.2749], device='cuda:0')
2024-12-02 15:24:50,860 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 206: ref_distribution = tensor([0.3839, 0.3412, 0.2749], device='cuda:0'), new_distribution = tensor([0.3842, 0.3412, 0.2746], device='cuda:0')
2024-12-02 15:24:50,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 207: ref_distribution = tensor([0.3842, 0.3412, 0.2746], device='cuda:0'), new_distribution = tensor([0.3845, 0.3412, 0.2744], device='cuda:0')
2024-12-02 15:24:50,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 208: ref_distribution = tensor([0.3845, 0.3412, 0.2744], device='cuda:0'), new_distribution = tensor([0.3847, 0.3412, 0.2741], device='cuda:0')
2024-12-02 15:24:51,055 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 209: ref_distribution = tensor([0.3847, 0.3412, 0.2741], device='cuda:0'), new_distribution = tensor([0.3850, 0.3411, 0.2739], device='cuda:0')
2024-12-02 15:24:51,119 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 210: ref_distribution = tensor([0.3850, 0.3411, 0.2739], device='cuda:0'), new_distribution = tensor([0.3853, 0.3411, 0.2736], device='cuda:0')
2024-12-02 15:24:51,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 211: ref_distribution = tensor([0.3853, 0.3411, 0.2736], device='cuda:0'), new_distribution = tensor([0.3856, 0.3411, 0.2734], device='cuda:0')
2024-12-02 15:24:51,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 212: ref_distribution = tensor([0.3856, 0.3411, 0.2734], device='cuda:0'), new_distribution = tensor([0.3858, 0.3411, 0.2731], device='cuda:0')
2024-12-02 15:24:51,314 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 213: ref_distribution = tensor([0.3858, 0.3411, 0.2731], device='cuda:0'), new_distribution = tensor([0.3861, 0.3411, 0.2728], device='cuda:0')
2024-12-02 15:24:51,378 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 214: ref_distribution = tensor([0.3861, 0.3411, 0.2728], device='cuda:0'), new_distribution = tensor([0.3864, 0.3410, 0.2726], device='cuda:0')
2024-12-02 15:24:51,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 215: ref_distribution = tensor([0.3864, 0.3410, 0.2726], device='cuda:0'), new_distribution = tensor([0.3866, 0.3410, 0.2723], device='cuda:0')
2024-12-02 15:24:51,508 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 216: ref_distribution = tensor([0.3866, 0.3410, 0.2723], device='cuda:0'), new_distribution = tensor([0.3869, 0.3410, 0.2721], device='cuda:0')
2024-12-02 15:24:51,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 217: ref_distribution = tensor([0.3869, 0.3410, 0.2721], device='cuda:0'), new_distribution = tensor([0.3872, 0.3410, 0.2718], device='cuda:0')
2024-12-02 15:24:51,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 218: ref_distribution = tensor([0.3872, 0.3410, 0.2718], device='cuda:0'), new_distribution = tensor([0.3875, 0.3409, 0.2716], device='cuda:0')
2024-12-02 15:24:51,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 219: ref_distribution = tensor([0.3875, 0.3409, 0.2716], device='cuda:0'), new_distribution = tensor([0.3877, 0.3409, 0.2713], device='cuda:0')
2024-12-02 15:24:51,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 220: ref_distribution = tensor([0.3877, 0.3409, 0.2713], device='cuda:0'), new_distribution = tensor([0.3880, 0.3409, 0.2711], device='cuda:0')
2024-12-02 15:24:51,832 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 221: ref_distribution = tensor([0.3880, 0.3409, 0.2711], device='cuda:0'), new_distribution = tensor([0.3883, 0.3409, 0.2708], device='cuda:0')
2024-12-02 15:24:51,897 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 222: ref_distribution = tensor([0.3883, 0.3409, 0.2708], device='cuda:0'), new_distribution = tensor([0.3886, 0.3408, 0.2706], device='cuda:0')
2024-12-02 15:24:51,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 223: ref_distribution = tensor([0.3886, 0.3408, 0.2706], device='cuda:0'), new_distribution = tensor([0.3888, 0.3408, 0.2703], device='cuda:0')
2024-12-02 15:24:52,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 224: ref_distribution = tensor([0.3888, 0.3408, 0.2703], device='cuda:0'), new_distribution = tensor([0.3891, 0.3408, 0.2701], device='cuda:0')
2024-12-02 15:24:52,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 225: ref_distribution = tensor([0.3891, 0.3408, 0.2701], device='cuda:0'), new_distribution = tensor([0.3894, 0.3408, 0.2698], device='cuda:0')
2024-12-02 15:24:52,157 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 226: ref_distribution = tensor([0.3894, 0.3408, 0.2698], device='cuda:0'), new_distribution = tensor([0.3897, 0.3407, 0.2696], device='cuda:0')
2024-12-02 15:24:52,221 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 227: ref_distribution = tensor([0.3897, 0.3407, 0.2696], device='cuda:0'), new_distribution = tensor([0.3900, 0.3407, 0.2693], device='cuda:0')
2024-12-02 15:24:52,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 228: ref_distribution = tensor([0.3900, 0.3407, 0.2693], device='cuda:0'), new_distribution = tensor([0.3902, 0.3407, 0.2691], device='cuda:0')
2024-12-02 15:24:52,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 229: ref_distribution = tensor([0.3902, 0.3407, 0.2691], device='cuda:0'), new_distribution = tensor([0.3905, 0.3407, 0.2688], device='cuda:0')
2024-12-02 15:24:52,416 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 230: ref_distribution = tensor([0.3905, 0.3407, 0.2688], device='cuda:0'), new_distribution = tensor([0.3908, 0.3406, 0.2686], device='cuda:0')
2024-12-02 15:24:52,481 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 231: ref_distribution = tensor([0.3908, 0.3406, 0.2686], device='cuda:0'), new_distribution = tensor([0.3911, 0.3406, 0.2683], device='cuda:0')
2024-12-02 15:24:52,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 232: ref_distribution = tensor([0.3911, 0.3406, 0.2683], device='cuda:0'), new_distribution = tensor([0.3913, 0.3406, 0.2681], device='cuda:0')
2024-12-02 15:24:52,611 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 233: ref_distribution = tensor([0.3913, 0.3406, 0.2681], device='cuda:0'), new_distribution = tensor([0.3916, 0.3405, 0.2679], device='cuda:0')
2024-12-02 15:24:52,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 234: ref_distribution = tensor([0.3916, 0.3405, 0.2679], device='cuda:0'), new_distribution = tensor([0.3919, 0.3405, 0.2676], device='cuda:0')
2024-12-02 15:24:52,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 235: ref_distribution = tensor([0.3919, 0.3405, 0.2676], device='cuda:0'), new_distribution = tensor([0.3922, 0.3405, 0.2674], device='cuda:0')
2024-12-02 15:24:52,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 236: ref_distribution = tensor([0.3922, 0.3405, 0.2674], device='cuda:0'), new_distribution = tensor([0.3925, 0.3404, 0.2671], device='cuda:0')
2024-12-02 15:24:52,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 237: ref_distribution = tensor([0.3925, 0.3404, 0.2671], device='cuda:0'), new_distribution = tensor([0.3927, 0.3404, 0.2669], device='cuda:0')
2024-12-02 15:24:52,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 238: ref_distribution = tensor([0.3927, 0.3404, 0.2669], device='cuda:0'), new_distribution = tensor([0.3930, 0.3404, 0.2666], device='cuda:0')
2024-12-02 15:24:53,000 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 239: ref_distribution = tensor([0.3930, 0.3404, 0.2666], device='cuda:0'), new_distribution = tensor([0.3933, 0.3403, 0.2664], device='cuda:0')
2024-12-02 15:24:53,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 240: ref_distribution = tensor([0.3933, 0.3403, 0.2664], device='cuda:0'), new_distribution = tensor([0.3936, 0.3403, 0.2661], device='cuda:0')
2024-12-02 15:24:53,129 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 241: ref_distribution = tensor([0.3936, 0.3403, 0.2661], device='cuda:0'), new_distribution = tensor([0.3938, 0.3403, 0.2659], device='cuda:0')
2024-12-02 15:24:53,194 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 242: ref_distribution = tensor([0.3938, 0.3403, 0.2659], device='cuda:0'), new_distribution = tensor([0.3941, 0.3402, 0.2656], device='cuda:0')
2024-12-02 15:24:53,259 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 243: ref_distribution = tensor([0.3941, 0.3402, 0.2656], device='cuda:0'), new_distribution = tensor([0.3944, 0.3402, 0.2654], device='cuda:0')
2024-12-02 15:24:53,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 244: ref_distribution = tensor([0.3944, 0.3402, 0.2654], device='cuda:0'), new_distribution = tensor([0.3947, 0.3402, 0.2652], device='cuda:0')
2024-12-02 15:24:53,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 245: ref_distribution = tensor([0.3947, 0.3402, 0.2652], device='cuda:0'), new_distribution = tensor([0.3950, 0.3401, 0.2649], device='cuda:0')
2024-12-02 15:24:53,453 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 246: ref_distribution = tensor([0.3950, 0.3401, 0.2649], device='cuda:0'), new_distribution = tensor([0.3953, 0.3401, 0.2647], device='cuda:0')
2024-12-02 15:24:53,518 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 247: ref_distribution = tensor([0.3953, 0.3401, 0.2647], device='cuda:0'), new_distribution = tensor([0.3955, 0.3400, 0.2644], device='cuda:0')
2024-12-02 15:24:53,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 248: ref_distribution = tensor([0.3955, 0.3400, 0.2644], device='cuda:0'), new_distribution = tensor([0.3958, 0.3400, 0.2642], device='cuda:0')
2024-12-02 15:24:53,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 249: ref_distribution = tensor([0.3958, 0.3400, 0.2642], device='cuda:0'), new_distribution = tensor([0.3961, 0.3400, 0.2639], device='cuda:0')
2024-12-02 15:24:53,713 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 250: ref_distribution = tensor([0.3961, 0.3400, 0.2639], device='cuda:0'), new_distribution = tensor([0.3964, 0.3399, 0.2637], device='cuda:0')
2024-12-02 15:24:53,777 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 251: ref_distribution = tensor([0.3964, 0.3399, 0.2637], device='cuda:0'), new_distribution = tensor([0.3967, 0.3399, 0.2635], device='cuda:0')
2024-12-02 15:24:53,842 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 252: ref_distribution = tensor([0.3967, 0.3399, 0.2635], device='cuda:0'), new_distribution = tensor([0.3969, 0.3398, 0.2632], device='cuda:0')
2024-12-02 15:24:53,907 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 253: ref_distribution = tensor([0.3969, 0.3398, 0.2632], device='cuda:0'), new_distribution = tensor([0.3972, 0.3398, 0.2630], device='cuda:0')
2024-12-02 15:24:53,972 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 254: ref_distribution = tensor([0.3972, 0.3398, 0.2630], device='cuda:0'), new_distribution = tensor([0.3975, 0.3398, 0.2627], device='cuda:0')
2024-12-02 15:24:54,037 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 255: ref_distribution = tensor([0.3975, 0.3398, 0.2627], device='cuda:0'), new_distribution = tensor([0.3978, 0.3397, 0.2625], device='cuda:0')
2024-12-02 15:24:54,102 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 256: ref_distribution = tensor([0.3978, 0.3397, 0.2625], device='cuda:0'), new_distribution = tensor([0.3981, 0.3397, 0.2623], device='cuda:0')
2024-12-02 15:24:54,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 257: ref_distribution = tensor([0.3981, 0.3397, 0.2623], device='cuda:0'), new_distribution = tensor([0.3984, 0.3396, 0.2620], device='cuda:0')
2024-12-02 15:24:54,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 258: ref_distribution = tensor([0.3984, 0.3396, 0.2620], device='cuda:0'), new_distribution = tensor([0.3986, 0.3396, 0.2618], device='cuda:0')
2024-12-02 15:24:54,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 259: ref_distribution = tensor([0.3986, 0.3396, 0.2618], device='cuda:0'), new_distribution = tensor([0.3989, 0.3395, 0.2615], device='cuda:0')
2024-12-02 15:24:54,360 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 260: ref_distribution = tensor([0.3989, 0.3395, 0.2615], device='cuda:0'), new_distribution = tensor([0.3992, 0.3395, 0.2613], device='cuda:0')
2024-12-02 15:24:54,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 261: ref_distribution = tensor([0.3992, 0.3395, 0.2613], device='cuda:0'), new_distribution = tensor([0.3995, 0.3394, 0.2611], device='cuda:0')
2024-12-02 15:24:54,490 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 262: ref_distribution = tensor([0.3995, 0.3394, 0.2611], device='cuda:0'), new_distribution = tensor([0.3998, 0.3394, 0.2608], device='cuda:0')
2024-12-02 15:24:54,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 263: ref_distribution = tensor([0.3998, 0.3394, 0.2608], device='cuda:0'), new_distribution = tensor([0.4001, 0.3394, 0.2606], device='cuda:0')
2024-12-02 15:24:54,620 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 264: ref_distribution = tensor([0.4001, 0.3394, 0.2606], device='cuda:0'), new_distribution = tensor([0.4003, 0.3393, 0.2604], device='cuda:0')
2024-12-02 15:24:54,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 265: ref_distribution = tensor([0.4003, 0.3393, 0.2604], device='cuda:0'), new_distribution = tensor([0.4006, 0.3393, 0.2601], device='cuda:0')
2024-12-02 15:24:54,749 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 266: ref_distribution = tensor([0.4006, 0.3393, 0.2601], device='cuda:0'), new_distribution = tensor([0.4009, 0.3392, 0.2599], device='cuda:0')
2024-12-02 15:24:54,814 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 267: ref_distribution = tensor([0.4009, 0.3392, 0.2599], device='cuda:0'), new_distribution = tensor([0.4012, 0.3392, 0.2596], device='cuda:0')
2024-12-02 15:24:54,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 268: ref_distribution = tensor([0.4012, 0.3392, 0.2596], device='cuda:0'), new_distribution = tensor([0.4015, 0.3391, 0.2594], device='cuda:0')
2024-12-02 15:24:54,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 269: ref_distribution = tensor([0.4015, 0.3391, 0.2594], device='cuda:0'), new_distribution = tensor([0.4018, 0.3391, 0.2592], device='cuda:0')
2024-12-02 15:24:55,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 270: ref_distribution = tensor([0.4018, 0.3391, 0.2592], device='cuda:0'), new_distribution = tensor([0.4021, 0.3390, 0.2589], device='cuda:0')
2024-12-02 15:24:55,073 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 271: ref_distribution = tensor([0.4021, 0.3390, 0.2589], device='cuda:0'), new_distribution = tensor([0.4023, 0.3390, 0.2587], device='cuda:0')
2024-12-02 15:24:55,138 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 272: ref_distribution = tensor([0.4023, 0.3390, 0.2587], device='cuda:0'), new_distribution = tensor([0.4026, 0.3389, 0.2585], device='cuda:0')
2024-12-02 15:24:55,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 273: ref_distribution = tensor([0.4026, 0.3389, 0.2585], device='cuda:0'), new_distribution = tensor([0.4029, 0.3389, 0.2582], device='cuda:0')
2024-12-02 15:24:55,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 274: ref_distribution = tensor([0.4029, 0.3389, 0.2582], device='cuda:0'), new_distribution = tensor([0.4032, 0.3388, 0.2580], device='cuda:0')
2024-12-02 15:24:55,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 275: ref_distribution = tensor([0.4032, 0.3388, 0.2580], device='cuda:0'), new_distribution = tensor([0.4035, 0.3388, 0.2578], device='cuda:0')
2024-12-02 15:24:55,398 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 276: ref_distribution = tensor([0.4035, 0.3388, 0.2578], device='cuda:0'), new_distribution = tensor([0.4038, 0.3387, 0.2575], device='cuda:0')
2024-12-02 15:24:55,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 277: ref_distribution = tensor([0.4038, 0.3387, 0.2575], device='cuda:0'), new_distribution = tensor([0.4041, 0.3386, 0.2573], device='cuda:0')
2024-12-02 15:24:55,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 278: ref_distribution = tensor([0.4041, 0.3386, 0.2573], device='cuda:0'), new_distribution = tensor([0.4044, 0.3386, 0.2571], device='cuda:0')
2024-12-02 15:24:55,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 279: ref_distribution = tensor([0.4044, 0.3386, 0.2571], device='cuda:0'), new_distribution = tensor([0.4046, 0.3385, 0.2568], device='cuda:0')
2024-12-02 15:24:55,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 280: ref_distribution = tensor([0.4046, 0.3385, 0.2568], device='cuda:0'), new_distribution = tensor([0.4049, 0.3385, 0.2566], device='cuda:0')
2024-12-02 15:24:55,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 281: ref_distribution = tensor([0.4049, 0.3385, 0.2566], device='cuda:0'), new_distribution = tensor([0.4052, 0.3384, 0.2564], device='cuda:0')
2024-12-02 15:24:55,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 282: ref_distribution = tensor([0.4052, 0.3384, 0.2564], device='cuda:0'), new_distribution = tensor([0.4055, 0.3384, 0.2561], device='cuda:0')
2024-12-02 15:24:55,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 283: ref_distribution = tensor([0.4055, 0.3384, 0.2561], device='cuda:0'), new_distribution = tensor([0.4058, 0.3383, 0.2559], device='cuda:0')
2024-12-02 15:24:55,916 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 284: ref_distribution = tensor([0.4058, 0.3383, 0.2559], device='cuda:0'), new_distribution = tensor([0.4061, 0.3383, 0.2557], device='cuda:0')
2024-12-02 15:24:55,981 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 285: ref_distribution = tensor([0.4061, 0.3383, 0.2557], device='cuda:0'), new_distribution = tensor([0.4064, 0.3382, 0.2554], device='cuda:0')
2024-12-02 15:24:56,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 286: ref_distribution = tensor([0.4064, 0.3382, 0.2554], device='cuda:0'), new_distribution = tensor([0.4067, 0.3381, 0.2552], device='cuda:0')
2024-12-02 15:24:56,110 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 287: ref_distribution = tensor([0.4067, 0.3381, 0.2552], device='cuda:0'), new_distribution = tensor([0.4069, 0.3381, 0.2550], device='cuda:0')
2024-12-02 15:24:56,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 288: ref_distribution = tensor([0.4069, 0.3381, 0.2550], device='cuda:0'), new_distribution = tensor([0.4072, 0.3380, 0.2547], device='cuda:0')
2024-12-02 15:24:56,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 289: ref_distribution = tensor([0.4072, 0.3380, 0.2547], device='cuda:0'), new_distribution = tensor([0.4075, 0.3380, 0.2545], device='cuda:0')
2024-12-02 15:24:56,303 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 290: ref_distribution = tensor([0.4075, 0.3380, 0.2545], device='cuda:0'), new_distribution = tensor([0.4078, 0.3379, 0.2543], device='cuda:0')
2024-12-02 15:24:56,367 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 291: ref_distribution = tensor([0.4078, 0.3379, 0.2543], device='cuda:0'), new_distribution = tensor([0.4081, 0.3378, 0.2541], device='cuda:0')
2024-12-02 15:24:56,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 292: ref_distribution = tensor([0.4081, 0.3378, 0.2541], device='cuda:0'), new_distribution = tensor([0.4084, 0.3378, 0.2538], device='cuda:0')
2024-12-02 15:24:56,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 293: ref_distribution = tensor([0.4084, 0.3378, 0.2538], device='cuda:0'), new_distribution = tensor([0.4087, 0.3377, 0.2536], device='cuda:0')
2024-12-02 15:24:56,562 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 294: ref_distribution = tensor([0.4087, 0.3377, 0.2536], device='cuda:0'), new_distribution = tensor([0.4090, 0.3377, 0.2534], device='cuda:0')
2024-12-02 15:24:56,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 295: ref_distribution = tensor([0.4090, 0.3377, 0.2534], device='cuda:0'), new_distribution = tensor([0.4093, 0.3376, 0.2531], device='cuda:0')
2024-12-02 15:24:56,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 296: ref_distribution = tensor([0.4093, 0.3376, 0.2531], device='cuda:0'), new_distribution = tensor([0.4096, 0.3375, 0.2529], device='cuda:0')
2024-12-02 15:24:56,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 297: ref_distribution = tensor([0.4096, 0.3375, 0.2529], device='cuda:0'), new_distribution = tensor([0.4099, 0.3375, 0.2527], device='cuda:0')
2024-12-02 15:24:56,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 298: ref_distribution = tensor([0.4099, 0.3375, 0.2527], device='cuda:0'), new_distribution = tensor([0.4101, 0.3374, 0.2525], device='cuda:0')
2024-12-02 15:24:56,886 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 299: ref_distribution = tensor([0.4101, 0.3374, 0.2525], device='cuda:0'), new_distribution = tensor([0.4104, 0.3373, 0.2522], device='cuda:0')
2024-12-02 15:24:57,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 0: ref_distribution = tensor([0.7000, 0.2000, 0.1000], device='cuda:0'), new_distribution = tensor([0.7003, 0.1997, 0.1000], device='cuda:0')
2024-12-02 15:24:57,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 1: ref_distribution = tensor([0.7003, 0.1997, 0.1000], device='cuda:0'), new_distribution = tensor([0.7006, 0.1994, 0.0999], device='cuda:0')
2024-12-02 15:24:57,314 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 2: ref_distribution = tensor([0.7006, 0.1994, 0.0999], device='cuda:0'), new_distribution = tensor([0.7009, 0.1991, 0.0999], device='cuda:0')
2024-12-02 15:24:57,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 3: ref_distribution = tensor([0.7009, 0.1991, 0.0999], device='cuda:0'), new_distribution = tensor([0.7013, 0.1988, 0.0999], device='cuda:0')
2024-12-02 15:24:57,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 4: ref_distribution = tensor([0.7013, 0.1988, 0.0999], device='cuda:0'), new_distribution = tensor([0.7016, 0.1986, 0.0999], device='cuda:0')
2024-12-02 15:24:57,509 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 5: ref_distribution = tensor([0.7016, 0.1986, 0.0999], device='cuda:0'), new_distribution = tensor([0.7019, 0.1983, 0.0998], device='cuda:0')
2024-12-02 15:24:57,574 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 6: ref_distribution = tensor([0.7019, 0.1983, 0.0998], device='cuda:0'), new_distribution = tensor([0.7022, 0.1980, 0.0998], device='cuda:0')
2024-12-02 15:24:57,639 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 7: ref_distribution = tensor([0.7022, 0.1980, 0.0998], device='cuda:0'), new_distribution = tensor([0.7025, 0.1977, 0.0998], device='cuda:0')
2024-12-02 15:24:57,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 8: ref_distribution = tensor([0.7025, 0.1977, 0.0998], device='cuda:0'), new_distribution = tensor([0.7028, 0.1974, 0.0998], device='cuda:0')
2024-12-02 15:24:57,768 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 9: ref_distribution = tensor([0.7028, 0.1974, 0.0998], device='cuda:0'), new_distribution = tensor([0.7031, 0.1971, 0.0997], device='cuda:0')
2024-12-02 15:24:57,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 10: ref_distribution = tensor([0.7031, 0.1971, 0.0997], device='cuda:0'), new_distribution = tensor([0.7035, 0.1968, 0.0997], device='cuda:0')
2024-12-02 15:24:57,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 11: ref_distribution = tensor([0.7035, 0.1968, 0.0997], device='cuda:0'), new_distribution = tensor([0.7038, 0.1965, 0.0997], device='cuda:0')
2024-12-02 15:24:57,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 12: ref_distribution = tensor([0.7038, 0.1965, 0.0997], device='cuda:0'), new_distribution = tensor([0.7041, 0.1963, 0.0997], device='cuda:0')
2024-12-02 15:24:58,029 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 13: ref_distribution = tensor([0.7041, 0.1963, 0.0997], device='cuda:0'), new_distribution = tensor([0.7044, 0.1960, 0.0996], device='cuda:0')
2024-12-02 15:24:58,093 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 14: ref_distribution = tensor([0.7044, 0.1960, 0.0996], device='cuda:0'), new_distribution = tensor([0.7047, 0.1957, 0.0996], device='cuda:0')
2024-12-02 15:24:58,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 15: ref_distribution = tensor([0.7047, 0.1957, 0.0996], device='cuda:0'), new_distribution = tensor([0.7050, 0.1954, 0.0996], device='cuda:0')
2024-12-02 15:24:58,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 16: ref_distribution = tensor([0.7050, 0.1954, 0.0996], device='cuda:0'), new_distribution = tensor([0.7053, 0.1951, 0.0996], device='cuda:0')
2024-12-02 15:24:58,291 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 17: ref_distribution = tensor([0.7053, 0.1951, 0.0996], device='cuda:0'), new_distribution = tensor([0.7056, 0.1948, 0.0995], device='cuda:0')
2024-12-02 15:24:58,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 18: ref_distribution = tensor([0.7056, 0.1948, 0.0995], device='cuda:0'), new_distribution = tensor([0.7059, 0.1945, 0.0995], device='cuda:0')
2024-12-02 15:24:58,421 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 19: ref_distribution = tensor([0.7059, 0.1945, 0.0995], device='cuda:0'), new_distribution = tensor([0.7062, 0.1943, 0.0995], device='cuda:0')
2024-12-02 15:24:58,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 20: ref_distribution = tensor([0.7062, 0.1943, 0.0995], device='cuda:0'), new_distribution = tensor([0.7066, 0.1940, 0.0995], device='cuda:0')
2024-12-02 15:24:58,551 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 21: ref_distribution = tensor([0.7066, 0.1940, 0.0995], device='cuda:0'), new_distribution = tensor([0.7069, 0.1937, 0.0994], device='cuda:0')
2024-12-02 15:24:58,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 22: ref_distribution = tensor([0.7069, 0.1937, 0.0994], device='cuda:0'), new_distribution = tensor([0.7072, 0.1934, 0.0994], device='cuda:0')
2024-12-02 15:24:58,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 23: ref_distribution = tensor([0.7072, 0.1934, 0.0994], device='cuda:0'), new_distribution = tensor([0.7075, 0.1931, 0.0994], device='cuda:0')
2024-12-02 15:24:58,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 24: ref_distribution = tensor([0.7075, 0.1931, 0.0994], device='cuda:0'), new_distribution = tensor([0.7078, 0.1928, 0.0994], device='cuda:0')
2024-12-02 15:24:58,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 25: ref_distribution = tensor([0.7078, 0.1928, 0.0994], device='cuda:0'), new_distribution = tensor([0.7081, 0.1926, 0.0994], device='cuda:0')
2024-12-02 15:24:58,876 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 26: ref_distribution = tensor([0.7081, 0.1926, 0.0994], device='cuda:0'), new_distribution = tensor([0.7084, 0.1923, 0.0993], device='cuda:0')
2024-12-02 15:24:58,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 27: ref_distribution = tensor([0.7084, 0.1923, 0.0993], device='cuda:0'), new_distribution = tensor([0.7087, 0.1920, 0.0993], device='cuda:0')
2024-12-02 15:24:59,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 28: ref_distribution = tensor([0.7087, 0.1920, 0.0993], device='cuda:0'), new_distribution = tensor([0.7090, 0.1917, 0.0993], device='cuda:0')
2024-12-02 15:24:59,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 29: ref_distribution = tensor([0.7090, 0.1917, 0.0993], device='cuda:0'), new_distribution = tensor([0.7093, 0.1914, 0.0993], device='cuda:0')
2024-12-02 15:24:59,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 30: ref_distribution = tensor([0.7093, 0.1914, 0.0993], device='cuda:0'), new_distribution = tensor([0.7096, 0.1912, 0.0992], device='cuda:0')
2024-12-02 15:24:59,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 31: ref_distribution = tensor([0.7096, 0.1912, 0.0992], device='cuda:0'), new_distribution = tensor([0.7099, 0.1909, 0.0992], device='cuda:0')
2024-12-02 15:24:59,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 32: ref_distribution = tensor([0.7099, 0.1909, 0.0992], device='cuda:0'), new_distribution = tensor([0.7102, 0.1906, 0.0992], device='cuda:0')
2024-12-02 15:24:59,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 33: ref_distribution = tensor([0.7102, 0.1906, 0.0992], device='cuda:0'), new_distribution = tensor([0.7105, 0.1903, 0.0992], device='cuda:0')
2024-12-02 15:24:59,395 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 34: ref_distribution = tensor([0.7105, 0.1903, 0.0992], device='cuda:0'), new_distribution = tensor([0.7108, 0.1900, 0.0991], device='cuda:0')
2024-12-02 15:24:59,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 35: ref_distribution = tensor([0.7108, 0.1900, 0.0991], device='cuda:0'), new_distribution = tensor([0.7111, 0.1897, 0.0991], device='cuda:0')
2024-12-02 15:24:59,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 36: ref_distribution = tensor([0.7111, 0.1897, 0.0991], device='cuda:0'), new_distribution = tensor([0.7114, 0.1895, 0.0991], device='cuda:0')
2024-12-02 15:24:59,590 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 37: ref_distribution = tensor([0.7114, 0.1895, 0.0991], device='cuda:0'), new_distribution = tensor([0.7117, 0.1892, 0.0991], device='cuda:0')
2024-12-02 15:24:59,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 38: ref_distribution = tensor([0.7117, 0.1892, 0.0991], device='cuda:0'), new_distribution = tensor([0.7120, 0.1889, 0.0991], device='cuda:0')
2024-12-02 15:24:59,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 39: ref_distribution = tensor([0.7120, 0.1889, 0.0991], device='cuda:0'), new_distribution = tensor([0.7123, 0.1886, 0.0990], device='cuda:0')
2024-12-02 15:24:59,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 40: ref_distribution = tensor([0.7123, 0.1886, 0.0990], device='cuda:0'), new_distribution = tensor([0.7126, 0.1883, 0.0990], device='cuda:0')
2024-12-02 15:24:59,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 41: ref_distribution = tensor([0.7126, 0.1883, 0.0990], device='cuda:0'), new_distribution = tensor([0.7129, 0.1881, 0.0990], device='cuda:0')
2024-12-02 15:24:59,915 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 42: ref_distribution = tensor([0.7129, 0.1881, 0.0990], device='cuda:0'), new_distribution = tensor([0.7132, 0.1878, 0.0990], device='cuda:0')
2024-12-02 15:24:59,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 43: ref_distribution = tensor([0.7132, 0.1878, 0.0990], device='cuda:0'), new_distribution = tensor([0.7135, 0.1875, 0.0990], device='cuda:0')
2024-12-02 15:25:00,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 44: ref_distribution = tensor([0.7135, 0.1875, 0.0990], device='cuda:0'), new_distribution = tensor([0.7138, 0.1872, 0.0989], device='cuda:0')
2024-12-02 15:25:00,111 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 45: ref_distribution = tensor([0.7138, 0.1872, 0.0989], device='cuda:0'), new_distribution = tensor([0.7141, 0.1870, 0.0989], device='cuda:0')
2024-12-02 15:25:00,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 46: ref_distribution = tensor([0.7141, 0.1870, 0.0989], device='cuda:0'), new_distribution = tensor([0.7144, 0.1867, 0.0989], device='cuda:0')
2024-12-02 15:25:00,240 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 47: ref_distribution = tensor([0.7144, 0.1867, 0.0989], device='cuda:0'), new_distribution = tensor([0.7147, 0.1864, 0.0989], device='cuda:0')
2024-12-02 15:25:00,306 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 48: ref_distribution = tensor([0.7147, 0.1864, 0.0989], device='cuda:0'), new_distribution = tensor([0.7150, 0.1861, 0.0988], device='cuda:0')
2024-12-02 15:25:00,371 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 49: ref_distribution = tensor([0.7150, 0.1861, 0.0988], device='cuda:0'), new_distribution = tensor([0.7153, 0.1858, 0.0988], device='cuda:0')
2024-12-02 15:25:00,436 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 50: ref_distribution = tensor([0.7153, 0.1858, 0.0988], device='cuda:0'), new_distribution = tensor([0.7156, 0.1856, 0.0988], device='cuda:0')
2024-12-02 15:25:00,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 51: ref_distribution = tensor([0.7156, 0.1856, 0.0988], device='cuda:0'), new_distribution = tensor([0.7159, 0.1853, 0.0988], device='cuda:0')
2024-12-02 15:25:00,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 52: ref_distribution = tensor([0.7159, 0.1853, 0.0988], device='cuda:0'), new_distribution = tensor([0.7162, 0.1850, 0.0988], device='cuda:0')
2024-12-02 15:25:00,630 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 53: ref_distribution = tensor([0.7162, 0.1850, 0.0988], device='cuda:0'), new_distribution = tensor([0.7165, 0.1847, 0.0987], device='cuda:0')
2024-12-02 15:25:00,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 54: ref_distribution = tensor([0.7165, 0.1847, 0.0987], device='cuda:0'), new_distribution = tensor([0.7168, 0.1845, 0.0987], device='cuda:0')
2024-12-02 15:25:00,763 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 55: ref_distribution = tensor([0.7168, 0.1845, 0.0987], device='cuda:0'), new_distribution = tensor([0.7171, 0.1842, 0.0987], device='cuda:0')
2024-12-02 15:25:00,827 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 56: ref_distribution = tensor([0.7171, 0.1842, 0.0987], device='cuda:0'), new_distribution = tensor([0.7174, 0.1839, 0.0987], device='cuda:0')
2024-12-02 15:25:00,892 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 57: ref_distribution = tensor([0.7174, 0.1839, 0.0987], device='cuda:0'), new_distribution = tensor([0.7177, 0.1836, 0.0987], device='cuda:0')
2024-12-02 15:25:00,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 58: ref_distribution = tensor([0.7177, 0.1836, 0.0987], device='cuda:0'), new_distribution = tensor([0.7180, 0.1834, 0.0986], device='cuda:0')
2024-12-02 15:25:01,022 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 59: ref_distribution = tensor([0.7180, 0.1834, 0.0986], device='cuda:0'), new_distribution = tensor([0.7183, 0.1831, 0.0986], device='cuda:0')
2024-12-02 15:25:01,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 60: ref_distribution = tensor([0.7183, 0.1831, 0.0986], device='cuda:0'), new_distribution = tensor([0.7186, 0.1828, 0.0986], device='cuda:0')
2024-12-02 15:25:01,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 61: ref_distribution = tensor([0.7186, 0.1828, 0.0986], device='cuda:0'), new_distribution = tensor([0.7189, 0.1825, 0.0986], device='cuda:0')
2024-12-02 15:25:01,216 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 62: ref_distribution = tensor([0.7189, 0.1825, 0.0986], device='cuda:0'), new_distribution = tensor([0.7192, 0.1823, 0.0986], device='cuda:0')
2024-12-02 15:25:01,281 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 63: ref_distribution = tensor([0.7192, 0.1823, 0.0986], device='cuda:0'), new_distribution = tensor([0.7195, 0.1820, 0.0985], device='cuda:0')
2024-12-02 15:25:01,346 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 64: ref_distribution = tensor([0.7195, 0.1820, 0.0985], device='cuda:0'), new_distribution = tensor([0.7197, 0.1817, 0.0985], device='cuda:0')
2024-12-02 15:25:01,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 65: ref_distribution = tensor([0.7197, 0.1817, 0.0985], device='cuda:0'), new_distribution = tensor([0.7200, 0.1815, 0.0985], device='cuda:0')
2024-12-02 15:25:01,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 66: ref_distribution = tensor([0.7200, 0.1815, 0.0985], device='cuda:0'), new_distribution = tensor([0.7203, 0.1812, 0.0985], device='cuda:0')
2024-12-02 15:25:01,541 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 67: ref_distribution = tensor([0.7203, 0.1812, 0.0985], device='cuda:0'), new_distribution = tensor([0.7206, 0.1809, 0.0985], device='cuda:0')
2024-12-02 15:25:01,606 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 68: ref_distribution = tensor([0.7206, 0.1809, 0.0985], device='cuda:0'), new_distribution = tensor([0.7209, 0.1806, 0.0985], device='cuda:0')
2024-12-02 15:25:01,670 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 69: ref_distribution = tensor([0.7209, 0.1806, 0.0985], device='cuda:0'), new_distribution = tensor([0.7212, 0.1804, 0.0984], device='cuda:0')
2024-12-02 15:25:01,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 70: ref_distribution = tensor([0.7212, 0.1804, 0.0984], device='cuda:0'), new_distribution = tensor([0.7215, 0.1801, 0.0984], device='cuda:0')
2024-12-02 15:25:01,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 71: ref_distribution = tensor([0.7215, 0.1801, 0.0984], device='cuda:0'), new_distribution = tensor([0.7218, 0.1798, 0.0984], device='cuda:0')
2024-12-02 15:25:01,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 72: ref_distribution = tensor([0.7218, 0.1798, 0.0984], device='cuda:0'), new_distribution = tensor([0.7221, 0.1795, 0.0984], device='cuda:0')
2024-12-02 15:25:01,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 73: ref_distribution = tensor([0.7221, 0.1795, 0.0984], device='cuda:0'), new_distribution = tensor([0.7224, 0.1793, 0.0984], device='cuda:0')
2024-12-02 15:25:01,996 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 74: ref_distribution = tensor([0.7224, 0.1793, 0.0984], device='cuda:0'), new_distribution = tensor([0.7226, 0.1790, 0.0983], device='cuda:0')
2024-12-02 15:25:02,061 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 75: ref_distribution = tensor([0.7226, 0.1790, 0.0983], device='cuda:0'), new_distribution = tensor([0.7229, 0.1787, 0.0983], device='cuda:0')
2024-12-02 15:25:02,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 76: ref_distribution = tensor([0.7229, 0.1787, 0.0983], device='cuda:0'), new_distribution = tensor([0.7232, 0.1785, 0.0983], device='cuda:0')
2024-12-02 15:25:02,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 77: ref_distribution = tensor([0.7232, 0.1785, 0.0983], device='cuda:0'), new_distribution = tensor([0.7235, 0.1782, 0.0983], device='cuda:0')
2024-12-02 15:25:02,255 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 78: ref_distribution = tensor([0.7235, 0.1782, 0.0983], device='cuda:0'), new_distribution = tensor([0.7238, 0.1779, 0.0983], device='cuda:0')
2024-12-02 15:25:02,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 79: ref_distribution = tensor([0.7238, 0.1779, 0.0983], device='cuda:0'), new_distribution = tensor([0.7241, 0.1777, 0.0983], device='cuda:0')
2024-12-02 15:25:02,386 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 80: ref_distribution = tensor([0.7241, 0.1777, 0.0983], device='cuda:0'), new_distribution = tensor([0.7244, 0.1774, 0.0982], device='cuda:0')
2024-12-02 15:25:02,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 81: ref_distribution = tensor([0.7244, 0.1774, 0.0982], device='cuda:0'), new_distribution = tensor([0.7247, 0.1771, 0.0982], device='cuda:0')
2024-12-02 15:25:02,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 82: ref_distribution = tensor([0.7247, 0.1771, 0.0982], device='cuda:0'), new_distribution = tensor([0.7249, 0.1769, 0.0982], device='cuda:0')
2024-12-02 15:25:02,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 83: ref_distribution = tensor([0.7249, 0.1769, 0.0982], device='cuda:0'), new_distribution = tensor([0.7252, 0.1766, 0.0982], device='cuda:0')
2024-12-02 15:25:02,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 84: ref_distribution = tensor([0.7252, 0.1766, 0.0982], device='cuda:0'), new_distribution = tensor([0.7255, 0.1763, 0.0982], device='cuda:0')
2024-12-02 15:25:02,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 85: ref_distribution = tensor([0.7255, 0.1763, 0.0982], device='cuda:0'), new_distribution = tensor([0.7258, 0.1761, 0.0982], device='cuda:0')
2024-12-02 15:25:02,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 86: ref_distribution = tensor([0.7258, 0.1761, 0.0982], device='cuda:0'), new_distribution = tensor([0.7261, 0.1758, 0.0981], device='cuda:0')
2024-12-02 15:25:02,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 87: ref_distribution = tensor([0.7261, 0.1758, 0.0981], device='cuda:0'), new_distribution = tensor([0.7264, 0.1755, 0.0981], device='cuda:0')
2024-12-02 15:25:02,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 88: ref_distribution = tensor([0.7264, 0.1755, 0.0981], device='cuda:0'), new_distribution = tensor([0.7266, 0.1753, 0.0981], device='cuda:0')
2024-12-02 15:25:02,969 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 89: ref_distribution = tensor([0.7266, 0.1753, 0.0981], device='cuda:0'), new_distribution = tensor([0.7269, 0.1750, 0.0981], device='cuda:0')
2024-12-02 15:25:03,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 90: ref_distribution = tensor([0.7269, 0.1750, 0.0981], device='cuda:0'), new_distribution = tensor([0.7272, 0.1747, 0.0981], device='cuda:0')
2024-12-02 15:25:03,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 91: ref_distribution = tensor([0.7272, 0.1747, 0.0981], device='cuda:0'), new_distribution = tensor([0.7275, 0.1745, 0.0981], device='cuda:0')
2024-12-02 15:25:03,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 92: ref_distribution = tensor([0.7275, 0.1745, 0.0981], device='cuda:0'), new_distribution = tensor([0.7278, 0.1742, 0.0980], device='cuda:0')
2024-12-02 15:25:03,228 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 93: ref_distribution = tensor([0.7278, 0.1742, 0.0980], device='cuda:0'), new_distribution = tensor([0.7280, 0.1739, 0.0980], device='cuda:0')
2024-12-02 15:25:03,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 94: ref_distribution = tensor([0.7280, 0.1739, 0.0980], device='cuda:0'), new_distribution = tensor([0.7283, 0.1737, 0.0980], device='cuda:0')
2024-12-02 15:25:03,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 95: ref_distribution = tensor([0.7283, 0.1737, 0.0980], device='cuda:0'), new_distribution = tensor([0.7286, 0.1734, 0.0980], device='cuda:0')
2024-12-02 15:25:03,423 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 96: ref_distribution = tensor([0.7286, 0.1734, 0.0980], device='cuda:0'), new_distribution = tensor([0.7289, 0.1731, 0.0980], device='cuda:0')
2024-12-02 15:25:03,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 97: ref_distribution = tensor([0.7289, 0.1731, 0.0980], device='cuda:0'), new_distribution = tensor([0.7292, 0.1729, 0.0980], device='cuda:0')
2024-12-02 15:25:03,552 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 98: ref_distribution = tensor([0.7292, 0.1729, 0.0980], device='cuda:0'), new_distribution = tensor([0.7294, 0.1726, 0.0980], device='cuda:0')
2024-12-02 15:25:03,617 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 99: ref_distribution = tensor([0.7294, 0.1726, 0.0980], device='cuda:0'), new_distribution = tensor([0.7297, 0.1723, 0.0979], device='cuda:0')
2024-12-02 15:25:03,682 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 100: ref_distribution = tensor([0.7297, 0.1723, 0.0979], device='cuda:0'), new_distribution = tensor([0.7300, 0.1721, 0.0979], device='cuda:0')
2024-12-02 15:25:03,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 101: ref_distribution = tensor([0.7300, 0.1721, 0.0979], device='cuda:0'), new_distribution = tensor([0.7303, 0.1718, 0.0979], device='cuda:0')
2024-12-02 15:25:03,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 102: ref_distribution = tensor([0.7303, 0.1718, 0.0979], device='cuda:0'), new_distribution = tensor([0.7306, 0.1715, 0.0979], device='cuda:0')
2024-12-02 15:25:03,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 103: ref_distribution = tensor([0.7306, 0.1715, 0.0979], device='cuda:0'), new_distribution = tensor([0.7308, 0.1713, 0.0979], device='cuda:0')
2024-12-02 15:25:03,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 104: ref_distribution = tensor([0.7308, 0.1713, 0.0979], device='cuda:0'), new_distribution = tensor([0.7311, 0.1710, 0.0979], device='cuda:0')
2024-12-02 15:25:04,007 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 105: ref_distribution = tensor([0.7311, 0.1710, 0.0979], device='cuda:0'), new_distribution = tensor([0.7314, 0.1708, 0.0978], device='cuda:0')
2024-12-02 15:25:04,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 106: ref_distribution = tensor([0.7314, 0.1708, 0.0978], device='cuda:0'), new_distribution = tensor([0.7317, 0.1705, 0.0978], device='cuda:0')
2024-12-02 15:25:04,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 107: ref_distribution = tensor([0.7317, 0.1705, 0.0978], device='cuda:0'), new_distribution = tensor([0.7319, 0.1702, 0.0978], device='cuda:0')
2024-12-02 15:25:04,201 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 108: ref_distribution = tensor([0.7319, 0.1702, 0.0978], device='cuda:0'), new_distribution = tensor([0.7322, 0.1700, 0.0978], device='cuda:0')
2024-12-02 15:25:04,266 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 109: ref_distribution = tensor([0.7322, 0.1700, 0.0978], device='cuda:0'), new_distribution = tensor([0.7325, 0.1697, 0.0978], device='cuda:0')
2024-12-02 15:25:04,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 110: ref_distribution = tensor([0.7325, 0.1697, 0.0978], device='cuda:0'), new_distribution = tensor([0.7328, 0.1695, 0.0978], device='cuda:0')
2024-12-02 15:25:04,395 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 111: ref_distribution = tensor([0.7328, 0.1695, 0.0978], device='cuda:0'), new_distribution = tensor([0.7330, 0.1692, 0.0978], device='cuda:0')
2024-12-02 15:25:04,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 112: ref_distribution = tensor([0.7330, 0.1692, 0.0978], device='cuda:0'), new_distribution = tensor([0.7333, 0.1689, 0.0977], device='cuda:0')
2024-12-02 15:25:04,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 113: ref_distribution = tensor([0.7333, 0.1689, 0.0977], device='cuda:0'), new_distribution = tensor([0.7336, 0.1687, 0.0977], device='cuda:0')
2024-12-02 15:25:04,590 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 114: ref_distribution = tensor([0.7336, 0.1687, 0.0977], device='cuda:0'), new_distribution = tensor([0.7339, 0.1684, 0.0977], device='cuda:0')
2024-12-02 15:25:04,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 115: ref_distribution = tensor([0.7339, 0.1684, 0.0977], device='cuda:0'), new_distribution = tensor([0.7341, 0.1682, 0.0977], device='cuda:0')
2024-12-02 15:25:04,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 116: ref_distribution = tensor([0.7341, 0.1682, 0.0977], device='cuda:0'), new_distribution = tensor([0.7344, 0.1679, 0.0977], device='cuda:0')
2024-12-02 15:25:04,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 117: ref_distribution = tensor([0.7344, 0.1679, 0.0977], device='cuda:0'), new_distribution = tensor([0.7347, 0.1676, 0.0977], device='cuda:0')
2024-12-02 15:25:04,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 118: ref_distribution = tensor([0.7347, 0.1676, 0.0977], device='cuda:0'), new_distribution = tensor([0.7350, 0.1674, 0.0977], device='cuda:0')
2024-12-02 15:25:04,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 119: ref_distribution = tensor([0.7350, 0.1674, 0.0977], device='cuda:0'), new_distribution = tensor([0.7352, 0.1671, 0.0977], device='cuda:0')
2024-12-02 15:25:04,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 120: ref_distribution = tensor([0.7352, 0.1671, 0.0977], device='cuda:0'), new_distribution = tensor([0.7355, 0.1669, 0.0976], device='cuda:0')
2024-12-02 15:25:05,042 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 121: ref_distribution = tensor([0.7355, 0.1669, 0.0976], device='cuda:0'), new_distribution = tensor([0.7358, 0.1666, 0.0976], device='cuda:0')
2024-12-02 15:25:05,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 122: ref_distribution = tensor([0.7358, 0.1666, 0.0976], device='cuda:0'), new_distribution = tensor([0.7360, 0.1663, 0.0976], device='cuda:0')
2024-12-02 15:25:05,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 123: ref_distribution = tensor([0.7360, 0.1663, 0.0976], device='cuda:0'), new_distribution = tensor([0.7363, 0.1661, 0.0976], device='cuda:0')
2024-12-02 15:25:05,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 124: ref_distribution = tensor([0.7363, 0.1661, 0.0976], device='cuda:0'), new_distribution = tensor([0.7366, 0.1658, 0.0976], device='cuda:0')
2024-12-02 15:25:05,301 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 125: ref_distribution = tensor([0.7366, 0.1658, 0.0976], device='cuda:0'), new_distribution = tensor([0.7368, 0.1656, 0.0976], device='cuda:0')
2024-12-02 15:25:05,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 126: ref_distribution = tensor([0.7368, 0.1656, 0.0976], device='cuda:0'), new_distribution = tensor([0.7371, 0.1653, 0.0976], device='cuda:0')
2024-12-02 15:25:05,428 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 127: ref_distribution = tensor([0.7371, 0.1653, 0.0976], device='cuda:0'), new_distribution = tensor([0.7374, 0.1651, 0.0976], device='cuda:0')
2024-12-02 15:25:05,493 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 128: ref_distribution = tensor([0.7374, 0.1651, 0.0976], device='cuda:0'), new_distribution = tensor([0.7376, 0.1648, 0.0975], device='cuda:0')
2024-12-02 15:25:05,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 129: ref_distribution = tensor([0.7376, 0.1648, 0.0975], device='cuda:0'), new_distribution = tensor([0.7379, 0.1646, 0.0975], device='cuda:0')
2024-12-02 15:25:05,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 130: ref_distribution = tensor([0.7379, 0.1646, 0.0975], device='cuda:0'), new_distribution = tensor([0.7382, 0.1643, 0.0975], device='cuda:0')
2024-12-02 15:25:05,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 131: ref_distribution = tensor([0.7382, 0.1643, 0.0975], device='cuda:0'), new_distribution = tensor([0.7384, 0.1640, 0.0975], device='cuda:0')
2024-12-02 15:25:05,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 132: ref_distribution = tensor([0.7384, 0.1640, 0.0975], device='cuda:0'), new_distribution = tensor([0.7387, 0.1638, 0.0975], device='cuda:0')
2024-12-02 15:25:05,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 133: ref_distribution = tensor([0.7387, 0.1638, 0.0975], device='cuda:0'), new_distribution = tensor([0.7390, 0.1635, 0.0975], device='cuda:0')
2024-12-02 15:25:05,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 134: ref_distribution = tensor([0.7390, 0.1635, 0.0975], device='cuda:0'), new_distribution = tensor([0.7392, 0.1633, 0.0975], device='cuda:0')
2024-12-02 15:25:05,946 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 135: ref_distribution = tensor([0.7392, 0.1633, 0.0975], device='cuda:0'), new_distribution = tensor([0.7395, 0.1630, 0.0975], device='cuda:0')
2024-12-02 15:25:06,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 136: ref_distribution = tensor([0.7395, 0.1630, 0.0975], device='cuda:0'), new_distribution = tensor([0.7398, 0.1628, 0.0974], device='cuda:0')
2024-12-02 15:25:06,077 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 137: ref_distribution = tensor([0.7398, 0.1628, 0.0974], device='cuda:0'), new_distribution = tensor([0.7400, 0.1625, 0.0974], device='cuda:0')
2024-12-02 15:25:06,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 138: ref_distribution = tensor([0.7400, 0.1625, 0.0974], device='cuda:0'), new_distribution = tensor([0.7403, 0.1623, 0.0974], device='cuda:0')
2024-12-02 15:25:06,208 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 139: ref_distribution = tensor([0.7403, 0.1623, 0.0974], device='cuda:0'), new_distribution = tensor([0.7406, 0.1620, 0.0974], device='cuda:0')
2024-12-02 15:25:06,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 140: ref_distribution = tensor([0.7406, 0.1620, 0.0974], device='cuda:0'), new_distribution = tensor([0.7408, 0.1618, 0.0974], device='cuda:0')
2024-12-02 15:25:06,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 141: ref_distribution = tensor([0.7408, 0.1618, 0.0974], device='cuda:0'), new_distribution = tensor([0.7411, 0.1615, 0.0974], device='cuda:0')
2024-12-02 15:25:06,403 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 142: ref_distribution = tensor([0.7411, 0.1615, 0.0974], device='cuda:0'), new_distribution = tensor([0.7414, 0.1613, 0.0974], device='cuda:0')
2024-12-02 15:25:06,467 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 143: ref_distribution = tensor([0.7414, 0.1613, 0.0974], device='cuda:0'), new_distribution = tensor([0.7416, 0.1610, 0.0974], device='cuda:0')
2024-12-02 15:25:06,532 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 144: ref_distribution = tensor([0.7416, 0.1610, 0.0974], device='cuda:0'), new_distribution = tensor([0.7419, 0.1608, 0.0974], device='cuda:0')
2024-12-02 15:25:06,597 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 145: ref_distribution = tensor([0.7419, 0.1608, 0.0974], device='cuda:0'), new_distribution = tensor([0.7421, 0.1605, 0.0974], device='cuda:0')
2024-12-02 15:25:06,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 146: ref_distribution = tensor([0.7421, 0.1605, 0.0974], device='cuda:0'), new_distribution = tensor([0.7424, 0.1603, 0.0973], device='cuda:0')
2024-12-02 15:25:06,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 147: ref_distribution = tensor([0.7424, 0.1603, 0.0973], device='cuda:0'), new_distribution = tensor([0.7427, 0.1600, 0.0973], device='cuda:0')
2024-12-02 15:25:06,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 148: ref_distribution = tensor([0.7427, 0.1600, 0.0973], device='cuda:0'), new_distribution = tensor([0.7429, 0.1598, 0.0973], device='cuda:0')
2024-12-02 15:25:06,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 149: ref_distribution = tensor([0.7429, 0.1598, 0.0973], device='cuda:0'), new_distribution = tensor([0.7432, 0.1595, 0.0973], device='cuda:0')
2024-12-02 15:25:06,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 150: ref_distribution = tensor([0.7432, 0.1595, 0.0973], device='cuda:0'), new_distribution = tensor([0.7434, 0.1593, 0.0973], device='cuda:0')
2024-12-02 15:25:06,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 151: ref_distribution = tensor([0.7434, 0.1593, 0.0973], device='cuda:0'), new_distribution = tensor([0.7437, 0.1590, 0.0973], device='cuda:0')
2024-12-02 15:25:07,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 152: ref_distribution = tensor([0.7437, 0.1590, 0.0973], device='cuda:0'), new_distribution = tensor([0.7440, 0.1588, 0.0973], device='cuda:0')
2024-12-02 15:25:07,116 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 153: ref_distribution = tensor([0.7440, 0.1588, 0.0973], device='cuda:0'), new_distribution = tensor([0.7442, 0.1585, 0.0973], device='cuda:0')
2024-12-02 15:25:07,181 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 154: ref_distribution = tensor([0.7442, 0.1585, 0.0973], device='cuda:0'), new_distribution = tensor([0.7445, 0.1583, 0.0973], device='cuda:0')
2024-12-02 15:25:07,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 155: ref_distribution = tensor([0.7445, 0.1583, 0.0973], device='cuda:0'), new_distribution = tensor([0.7447, 0.1580, 0.0973], device='cuda:0')
2024-12-02 15:25:07,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 156: ref_distribution = tensor([0.7447, 0.1580, 0.0973], device='cuda:0'), new_distribution = tensor([0.7450, 0.1578, 0.0972], device='cuda:0')
2024-12-02 15:25:07,375 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 157: ref_distribution = tensor([0.7450, 0.1578, 0.0972], device='cuda:0'), new_distribution = tensor([0.7453, 0.1575, 0.0972], device='cuda:0')
2024-12-02 15:25:07,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 158: ref_distribution = tensor([0.7453, 0.1575, 0.0972], device='cuda:0'), new_distribution = tensor([0.7455, 0.1573, 0.0972], device='cuda:0')
2024-12-02 15:25:07,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 159: ref_distribution = tensor([0.7455, 0.1573, 0.0972], device='cuda:0'), new_distribution = tensor([0.7458, 0.1570, 0.0972], device='cuda:0')
2024-12-02 15:25:07,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 160: ref_distribution = tensor([0.7458, 0.1570, 0.0972], device='cuda:0'), new_distribution = tensor([0.7460, 0.1568, 0.0972], device='cuda:0')
2024-12-02 15:25:07,635 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 161: ref_distribution = tensor([0.7460, 0.1568, 0.0972], device='cuda:0'), new_distribution = tensor([0.7463, 0.1565, 0.0972], device='cuda:0')
2024-12-02 15:25:07,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 162: ref_distribution = tensor([0.7463, 0.1565, 0.0972], device='cuda:0'), new_distribution = tensor([0.7465, 0.1563, 0.0972], device='cuda:0')
2024-12-02 15:25:07,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 163: ref_distribution = tensor([0.7465, 0.1563, 0.0972], device='cuda:0'), new_distribution = tensor([0.7468, 0.1560, 0.0972], device='cuda:0')
2024-12-02 15:25:07,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 164: ref_distribution = tensor([0.7468, 0.1560, 0.0972], device='cuda:0'), new_distribution = tensor([0.7470, 0.1558, 0.0972], device='cuda:0')
2024-12-02 15:25:07,895 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 165: ref_distribution = tensor([0.7470, 0.1558, 0.0972], device='cuda:0'), new_distribution = tensor([0.7473, 0.1555, 0.0972], device='cuda:0')
2024-12-02 15:25:07,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 166: ref_distribution = tensor([0.7473, 0.1555, 0.0972], device='cuda:0'), new_distribution = tensor([0.7475, 0.1553, 0.0972], device='cuda:0')
2024-12-02 15:25:08,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 167: ref_distribution = tensor([0.7475, 0.1553, 0.0972], device='cuda:0'), new_distribution = tensor([0.7478, 0.1551, 0.0971], device='cuda:0')
2024-12-02 15:25:08,090 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 168: ref_distribution = tensor([0.7478, 0.1551, 0.0971], device='cuda:0'), new_distribution = tensor([0.7481, 0.1548, 0.0971], device='cuda:0')
2024-12-02 15:25:08,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 169: ref_distribution = tensor([0.7481, 0.1548, 0.0971], device='cuda:0'), new_distribution = tensor([0.7483, 0.1546, 0.0971], device='cuda:0')
2024-12-02 15:25:08,219 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 170: ref_distribution = tensor([0.7483, 0.1546, 0.0971], device='cuda:0'), new_distribution = tensor([0.7486, 0.1543, 0.0971], device='cuda:0')
2024-12-02 15:25:08,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 171: ref_distribution = tensor([0.7486, 0.1543, 0.0971], device='cuda:0'), new_distribution = tensor([0.7488, 0.1541, 0.0971], device='cuda:0')
2024-12-02 15:25:08,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 172: ref_distribution = tensor([0.7488, 0.1541, 0.0971], device='cuda:0'), new_distribution = tensor([0.7491, 0.1538, 0.0971], device='cuda:0')
2024-12-02 15:25:08,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 173: ref_distribution = tensor([0.7491, 0.1538, 0.0971], device='cuda:0'), new_distribution = tensor([0.7493, 0.1536, 0.0971], device='cuda:0')
2024-12-02 15:25:08,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 174: ref_distribution = tensor([0.7493, 0.1536, 0.0971], device='cuda:0'), new_distribution = tensor([0.7496, 0.1534, 0.0971], device='cuda:0')
2024-12-02 15:25:08,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 175: ref_distribution = tensor([0.7496, 0.1534, 0.0971], device='cuda:0'), new_distribution = tensor([0.7498, 0.1531, 0.0971], device='cuda:0')
2024-12-02 15:25:08,604 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 176: ref_distribution = tensor([0.7498, 0.1531, 0.0971], device='cuda:0'), new_distribution = tensor([0.7501, 0.1529, 0.0971], device='cuda:0')
2024-12-02 15:25:08,669 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 177: ref_distribution = tensor([0.7501, 0.1529, 0.0971], device='cuda:0'), new_distribution = tensor([0.7503, 0.1526, 0.0971], device='cuda:0')
2024-12-02 15:25:08,734 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 178: ref_distribution = tensor([0.7503, 0.1526, 0.0971], device='cuda:0'), new_distribution = tensor([0.7506, 0.1524, 0.0971], device='cuda:0')
2024-12-02 15:25:08,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 179: ref_distribution = tensor([0.7506, 0.1524, 0.0971], device='cuda:0'), new_distribution = tensor([0.7508, 0.1521, 0.0971], device='cuda:0')
2024-12-02 15:25:08,864 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 180: ref_distribution = tensor([0.7508, 0.1521, 0.0971], device='cuda:0'), new_distribution = tensor([0.7511, 0.1519, 0.0970], device='cuda:0')
2024-12-02 15:25:08,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 181: ref_distribution = tensor([0.7511, 0.1519, 0.0970], device='cuda:0'), new_distribution = tensor([0.7513, 0.1517, 0.0970], device='cuda:0')
2024-12-02 15:25:08,994 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 182: ref_distribution = tensor([0.7513, 0.1517, 0.0970], device='cuda:0'), new_distribution = tensor([0.7515, 0.1514, 0.0970], device='cuda:0')
2024-12-02 15:25:09,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 183: ref_distribution = tensor([0.7515, 0.1514, 0.0970], device='cuda:0'), new_distribution = tensor([0.7518, 0.1512, 0.0970], device='cuda:0')
2024-12-02 15:25:09,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 184: ref_distribution = tensor([0.7518, 0.1512, 0.0970], device='cuda:0'), new_distribution = tensor([0.7520, 0.1509, 0.0970], device='cuda:0')
2024-12-02 15:25:09,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 185: ref_distribution = tensor([0.7520, 0.1509, 0.0970], device='cuda:0'), new_distribution = tensor([0.7523, 0.1507, 0.0970], device='cuda:0')
2024-12-02 15:25:09,252 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 186: ref_distribution = tensor([0.7523, 0.1507, 0.0970], device='cuda:0'), new_distribution = tensor([0.7525, 0.1505, 0.0970], device='cuda:0')
2024-12-02 15:25:09,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 187: ref_distribution = tensor([0.7525, 0.1505, 0.0970], device='cuda:0'), new_distribution = tensor([0.7528, 0.1502, 0.0970], device='cuda:0')
2024-12-02 15:25:09,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 188: ref_distribution = tensor([0.7528, 0.1502, 0.0970], device='cuda:0'), new_distribution = tensor([0.7530, 0.1500, 0.0970], device='cuda:0')
2024-12-02 15:25:09,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 189: ref_distribution = tensor([0.7530, 0.1500, 0.0970], device='cuda:0'), new_distribution = tensor([0.7533, 0.1497, 0.0970], device='cuda:0')
2024-12-02 15:25:09,512 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 190: ref_distribution = tensor([0.7533, 0.1497, 0.0970], device='cuda:0'), new_distribution = tensor([0.7535, 0.1495, 0.0970], device='cuda:0')
2024-12-02 15:25:09,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 191: ref_distribution = tensor([0.7535, 0.1495, 0.0970], device='cuda:0'), new_distribution = tensor([0.7538, 0.1493, 0.0970], device='cuda:0')
2024-12-02 15:25:09,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 192: ref_distribution = tensor([0.7538, 0.1493, 0.0970], device='cuda:0'), new_distribution = tensor([0.7540, 0.1490, 0.0970], device='cuda:0')
2024-12-02 15:25:09,706 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 193: ref_distribution = tensor([0.7540, 0.1490, 0.0970], device='cuda:0'), new_distribution = tensor([0.7542, 0.1488, 0.0970], device='cuda:0')
2024-12-02 15:25:09,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 194: ref_distribution = tensor([0.7542, 0.1488, 0.0970], device='cuda:0'), new_distribution = tensor([0.7545, 0.1486, 0.0970], device='cuda:0')
2024-12-02 15:25:09,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 195: ref_distribution = tensor([0.7545, 0.1486, 0.0970], device='cuda:0'), new_distribution = tensor([0.7547, 0.1483, 0.0970], device='cuda:0')
2024-12-02 15:25:09,901 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 196: ref_distribution = tensor([0.7547, 0.1483, 0.0970], device='cuda:0'), new_distribution = tensor([0.7550, 0.1481, 0.0969], device='cuda:0')
2024-12-02 15:25:09,966 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 197: ref_distribution = tensor([0.7550, 0.1481, 0.0969], device='cuda:0'), new_distribution = tensor([0.7552, 0.1478, 0.0969], device='cuda:0')
2024-12-02 15:25:10,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 198: ref_distribution = tensor([0.7552, 0.1478, 0.0969], device='cuda:0'), new_distribution = tensor([0.7555, 0.1476, 0.0969], device='cuda:0')
2024-12-02 15:25:10,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 199: ref_distribution = tensor([0.7555, 0.1476, 0.0969], device='cuda:0'), new_distribution = tensor([0.7557, 0.1474, 0.0969], device='cuda:0')
2024-12-02 15:25:10,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 200: ref_distribution = tensor([0.7557, 0.1474, 0.0969], device='cuda:0'), new_distribution = tensor([0.7559, 0.1471, 0.0969], device='cuda:0')
2024-12-02 15:25:10,224 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 201: ref_distribution = tensor([0.7559, 0.1471, 0.0969], device='cuda:0'), new_distribution = tensor([0.7562, 0.1469, 0.0969], device='cuda:0')
2024-12-02 15:25:10,289 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 202: ref_distribution = tensor([0.7562, 0.1469, 0.0969], device='cuda:0'), new_distribution = tensor([0.7564, 0.1467, 0.0969], device='cuda:0')
2024-12-02 15:25:10,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 203: ref_distribution = tensor([0.7564, 0.1467, 0.0969], device='cuda:0'), new_distribution = tensor([0.7567, 0.1464, 0.0969], device='cuda:0')
2024-12-02 15:25:10,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 204: ref_distribution = tensor([0.7567, 0.1464, 0.0969], device='cuda:0'), new_distribution = tensor([0.7569, 0.1462, 0.0969], device='cuda:0')
2024-12-02 15:25:10,483 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 205: ref_distribution = tensor([0.7569, 0.1462, 0.0969], device='cuda:0'), new_distribution = tensor([0.7571, 0.1460, 0.0969], device='cuda:0')
2024-12-02 15:25:10,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 206: ref_distribution = tensor([0.7571, 0.1460, 0.0969], device='cuda:0'), new_distribution = tensor([0.7574, 0.1457, 0.0969], device='cuda:0')
2024-12-02 15:25:10,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 207: ref_distribution = tensor([0.7574, 0.1457, 0.0969], device='cuda:0'), new_distribution = tensor([0.7576, 0.1455, 0.0969], device='cuda:0')
2024-12-02 15:25:10,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 208: ref_distribution = tensor([0.7576, 0.1455, 0.0969], device='cuda:0'), new_distribution = tensor([0.7578, 0.1453, 0.0969], device='cuda:0')
2024-12-02 15:25:10,742 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 209: ref_distribution = tensor([0.7578, 0.1453, 0.0969], device='cuda:0'), new_distribution = tensor([0.7581, 0.1450, 0.0969], device='cuda:0')
2024-12-02 15:25:10,807 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 210: ref_distribution = tensor([0.7581, 0.1450, 0.0969], device='cuda:0'), new_distribution = tensor([0.7583, 0.1448, 0.0969], device='cuda:0')
2024-12-02 15:25:10,872 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 211: ref_distribution = tensor([0.7583, 0.1448, 0.0969], device='cuda:0'), new_distribution = tensor([0.7586, 0.1446, 0.0969], device='cuda:0')
2024-12-02 15:25:10,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 212: ref_distribution = tensor([0.7586, 0.1446, 0.0969], device='cuda:0'), new_distribution = tensor([0.7588, 0.1443, 0.0969], device='cuda:0')
2024-12-02 15:25:11,003 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 213: ref_distribution = tensor([0.7588, 0.1443, 0.0969], device='cuda:0'), new_distribution = tensor([0.7590, 0.1441, 0.0969], device='cuda:0')
2024-12-02 15:25:11,068 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 214: ref_distribution = tensor([0.7590, 0.1441, 0.0969], device='cuda:0'), new_distribution = tensor([0.7593, 0.1439, 0.0969], device='cuda:0')
2024-12-02 15:25:11,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 215: ref_distribution = tensor([0.7593, 0.1439, 0.0969], device='cuda:0'), new_distribution = tensor([0.7595, 0.1436, 0.0969], device='cuda:0')
2024-12-02 15:25:11,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 216: ref_distribution = tensor([0.7595, 0.1436, 0.0969], device='cuda:0'), new_distribution = tensor([0.7597, 0.1434, 0.0969], device='cuda:0')
2024-12-02 15:25:11,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 217: ref_distribution = tensor([0.7597, 0.1434, 0.0969], device='cuda:0'), new_distribution = tensor([0.7600, 0.1432, 0.0969], device='cuda:0')
2024-12-02 15:25:11,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 218: ref_distribution = tensor([0.7600, 0.1432, 0.0969], device='cuda:0'), new_distribution = tensor([0.7602, 0.1429, 0.0968], device='cuda:0')
2024-12-02 15:25:11,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 219: ref_distribution = tensor([0.7602, 0.1429, 0.0968], device='cuda:0'), new_distribution = tensor([0.7604, 0.1427, 0.0968], device='cuda:0')
2024-12-02 15:25:11,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 220: ref_distribution = tensor([0.7604, 0.1427, 0.0968], device='cuda:0'), new_distribution = tensor([0.7607, 0.1425, 0.0968], device='cuda:0')
2024-12-02 15:25:11,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 221: ref_distribution = tensor([0.7607, 0.1425, 0.0968], device='cuda:0'), new_distribution = tensor([0.7609, 0.1423, 0.0968], device='cuda:0')
2024-12-02 15:25:11,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 222: ref_distribution = tensor([0.7609, 0.1423, 0.0968], device='cuda:0'), new_distribution = tensor([0.7611, 0.1420, 0.0968], device='cuda:0')
2024-12-02 15:25:11,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 223: ref_distribution = tensor([0.7611, 0.1420, 0.0968], device='cuda:0'), new_distribution = tensor([0.7614, 0.1418, 0.0968], device='cuda:0')
2024-12-02 15:25:11,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 224: ref_distribution = tensor([0.7614, 0.1418, 0.0968], device='cuda:0'), new_distribution = tensor([0.7616, 0.1416, 0.0968], device='cuda:0')
2024-12-02 15:25:11,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 225: ref_distribution = tensor([0.7616, 0.1416, 0.0968], device='cuda:0'), new_distribution = tensor([0.7618, 0.1413, 0.0968], device='cuda:0')
2024-12-02 15:25:11,847 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 226: ref_distribution = tensor([0.7618, 0.1413, 0.0968], device='cuda:0'), new_distribution = tensor([0.7621, 0.1411, 0.0968], device='cuda:0')
2024-12-02 15:25:11,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 227: ref_distribution = tensor([0.7621, 0.1411, 0.0968], device='cuda:0'), new_distribution = tensor([0.7623, 0.1409, 0.0968], device='cuda:0')
2024-12-02 15:25:11,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 228: ref_distribution = tensor([0.7623, 0.1409, 0.0968], device='cuda:0'), new_distribution = tensor([0.7625, 0.1407, 0.0968], device='cuda:0')
2024-12-02 15:25:12,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 229: ref_distribution = tensor([0.7625, 0.1407, 0.0968], device='cuda:0'), new_distribution = tensor([0.7628, 0.1404, 0.0968], device='cuda:0')
2024-12-02 15:25:12,106 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 230: ref_distribution = tensor([0.7628, 0.1404, 0.0968], device='cuda:0'), new_distribution = tensor([0.7630, 0.1402, 0.0968], device='cuda:0')
2024-12-02 15:25:12,170 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 231: ref_distribution = tensor([0.7630, 0.1402, 0.0968], device='cuda:0'), new_distribution = tensor([0.7632, 0.1400, 0.0968], device='cuda:0')
2024-12-02 15:25:12,235 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 232: ref_distribution = tensor([0.7632, 0.1400, 0.0968], device='cuda:0'), new_distribution = tensor([0.7634, 0.1398, 0.0968], device='cuda:0')
2024-12-02 15:25:12,300 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 233: ref_distribution = tensor([0.7634, 0.1398, 0.0968], device='cuda:0'), new_distribution = tensor([0.7637, 0.1395, 0.0968], device='cuda:0')
2024-12-02 15:25:12,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 234: ref_distribution = tensor([0.7637, 0.1395, 0.0968], device='cuda:0'), new_distribution = tensor([0.7639, 0.1393, 0.0968], device='cuda:0')
2024-12-02 15:25:12,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 235: ref_distribution = tensor([0.7639, 0.1393, 0.0968], device='cuda:0'), new_distribution = tensor([0.7641, 0.1391, 0.0968], device='cuda:0')
2024-12-02 15:25:12,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 236: ref_distribution = tensor([0.7641, 0.1391, 0.0968], device='cuda:0'), new_distribution = tensor([0.7644, 0.1388, 0.0968], device='cuda:0')
2024-12-02 15:25:12,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 237: ref_distribution = tensor([0.7644, 0.1388, 0.0968], device='cuda:0'), new_distribution = tensor([0.7646, 0.1386, 0.0968], device='cuda:0')
2024-12-02 15:25:12,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 238: ref_distribution = tensor([0.7646, 0.1386, 0.0968], device='cuda:0'), new_distribution = tensor([0.7648, 0.1384, 0.0968], device='cuda:0')
2024-12-02 15:25:12,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 239: ref_distribution = tensor([0.7648, 0.1384, 0.0968], device='cuda:0'), new_distribution = tensor([0.7650, 0.1382, 0.0968], device='cuda:0')
2024-12-02 15:25:12,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 240: ref_distribution = tensor([0.7650, 0.1382, 0.0968], device='cuda:0'), new_distribution = tensor([0.7653, 0.1380, 0.0968], device='cuda:0')
2024-12-02 15:25:12,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 241: ref_distribution = tensor([0.7653, 0.1380, 0.0968], device='cuda:0'), new_distribution = tensor([0.7655, 0.1377, 0.0968], device='cuda:0')
2024-12-02 15:25:12,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 242: ref_distribution = tensor([0.7655, 0.1377, 0.0968], device='cuda:0'), new_distribution = tensor([0.7657, 0.1375, 0.0968], device='cuda:0')
2024-12-02 15:25:12,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 243: ref_distribution = tensor([0.7657, 0.1375, 0.0968], device='cuda:0'), new_distribution = tensor([0.7659, 0.1373, 0.0968], device='cuda:0')
2024-12-02 15:25:13,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 244: ref_distribution = tensor([0.7659, 0.1373, 0.0968], device='cuda:0'), new_distribution = tensor([0.7662, 0.1371, 0.0968], device='cuda:0')
2024-12-02 15:25:13,076 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 245: ref_distribution = tensor([0.7662, 0.1371, 0.0968], device='cuda:0'), new_distribution = tensor([0.7664, 0.1368, 0.0968], device='cuda:0')
2024-12-02 15:25:13,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 246: ref_distribution = tensor([0.7664, 0.1368, 0.0968], device='cuda:0'), new_distribution = tensor([0.7666, 0.1366, 0.0968], device='cuda:0')
2024-12-02 15:25:13,206 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 247: ref_distribution = tensor([0.7666, 0.1366, 0.0968], device='cuda:0'), new_distribution = tensor([0.7668, 0.1364, 0.0968], device='cuda:0')
2024-12-02 15:25:13,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 248: ref_distribution = tensor([0.7668, 0.1364, 0.0968], device='cuda:0'), new_distribution = tensor([0.7671, 0.1362, 0.0968], device='cuda:0')
2024-12-02 15:25:13,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 249: ref_distribution = tensor([0.7671, 0.1362, 0.0968], device='cuda:0'), new_distribution = tensor([0.7673, 0.1359, 0.0968], device='cuda:0')
2024-12-02 15:25:13,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 250: ref_distribution = tensor([0.7673, 0.1359, 0.0968], device='cuda:0'), new_distribution = tensor([0.7675, 0.1357, 0.0968], device='cuda:0')
2024-12-02 15:25:13,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 251: ref_distribution = tensor([0.7675, 0.1357, 0.0968], device='cuda:0'), new_distribution = tensor([0.7677, 0.1355, 0.0968], device='cuda:0')
2024-12-02 15:25:13,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 252: ref_distribution = tensor([0.7677, 0.1355, 0.0968], device='cuda:0'), new_distribution = tensor([0.7679, 0.1353, 0.0968], device='cuda:0')
2024-12-02 15:25:13,595 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 253: ref_distribution = tensor([0.7679, 0.1353, 0.0968], device='cuda:0'), new_distribution = tensor([0.7682, 0.1351, 0.0968], device='cuda:0')
2024-12-02 15:25:13,660 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 254: ref_distribution = tensor([0.7682, 0.1351, 0.0968], device='cuda:0'), new_distribution = tensor([0.7684, 0.1348, 0.0968], device='cuda:0')
2024-12-02 15:25:13,725 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 255: ref_distribution = tensor([0.7684, 0.1348, 0.0968], device='cuda:0'), new_distribution = tensor([0.7686, 0.1346, 0.0968], device='cuda:0')
2024-12-02 15:25:13,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 256: ref_distribution = tensor([0.7686, 0.1346, 0.0968], device='cuda:0'), new_distribution = tensor([0.7688, 0.1344, 0.0968], device='cuda:0')
2024-12-02 15:25:13,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 257: ref_distribution = tensor([0.7688, 0.1344, 0.0968], device='cuda:0'), new_distribution = tensor([0.7690, 0.1342, 0.0968], device='cuda:0')
2024-12-02 15:25:13,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 258: ref_distribution = tensor([0.7690, 0.1342, 0.0968], device='cuda:0'), new_distribution = tensor([0.7693, 0.1340, 0.0968], device='cuda:0')
2024-12-02 15:25:13,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 259: ref_distribution = tensor([0.7693, 0.1340, 0.0968], device='cuda:0'), new_distribution = tensor([0.7695, 0.1337, 0.0968], device='cuda:0')
2024-12-02 15:25:14,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 260: ref_distribution = tensor([0.7695, 0.1337, 0.0968], device='cuda:0'), new_distribution = tensor([0.7697, 0.1335, 0.0968], device='cuda:0')
2024-12-02 15:25:14,116 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 261: ref_distribution = tensor([0.7697, 0.1335, 0.0968], device='cuda:0'), new_distribution = tensor([0.7699, 0.1333, 0.0968], device='cuda:0')
2024-12-02 15:25:14,181 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 262: ref_distribution = tensor([0.7699, 0.1333, 0.0968], device='cuda:0'), new_distribution = tensor([0.7701, 0.1331, 0.0968], device='cuda:0')
2024-12-02 15:25:14,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 263: ref_distribution = tensor([0.7701, 0.1331, 0.0968], device='cuda:0'), new_distribution = tensor([0.7703, 0.1329, 0.0968], device='cuda:0')
2024-12-02 15:25:14,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 264: ref_distribution = tensor([0.7703, 0.1329, 0.0968], device='cuda:0'), new_distribution = tensor([0.7706, 0.1327, 0.0968], device='cuda:0')
2024-12-02 15:25:14,375 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 265: ref_distribution = tensor([0.7706, 0.1327, 0.0968], device='cuda:0'), new_distribution = tensor([0.7708, 0.1324, 0.0968], device='cuda:0')
2024-12-02 15:25:14,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 266: ref_distribution = tensor([0.7708, 0.1324, 0.0968], device='cuda:0'), new_distribution = tensor([0.7710, 0.1322, 0.0968], device='cuda:0')
2024-12-02 15:25:14,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 267: ref_distribution = tensor([0.7710, 0.1322, 0.0968], device='cuda:0'), new_distribution = tensor([0.7712, 0.1320, 0.0968], device='cuda:0')
2024-12-02 15:25:14,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 268: ref_distribution = tensor([0.7712, 0.1320, 0.0968], device='cuda:0'), new_distribution = tensor([0.7714, 0.1318, 0.0968], device='cuda:0')
2024-12-02 15:25:14,635 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 269: ref_distribution = tensor([0.7714, 0.1318, 0.0968], device='cuda:0'), new_distribution = tensor([0.7716, 0.1316, 0.0968], device='cuda:0')
2024-12-02 15:25:14,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 270: ref_distribution = tensor([0.7716, 0.1316, 0.0968], device='cuda:0'), new_distribution = tensor([0.7719, 0.1314, 0.0968], device='cuda:0')
2024-12-02 15:25:14,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 271: ref_distribution = tensor([0.7719, 0.1314, 0.0968], device='cuda:0'), new_distribution = tensor([0.7721, 0.1311, 0.0968], device='cuda:0')
2024-12-02 15:25:14,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 272: ref_distribution = tensor([0.7721, 0.1311, 0.0968], device='cuda:0'), new_distribution = tensor([0.7723, 0.1309, 0.0968], device='cuda:0')
2024-12-02 15:25:14,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 273: ref_distribution = tensor([0.7723, 0.1309, 0.0968], device='cuda:0'), new_distribution = tensor([0.7725, 0.1307, 0.0968], device='cuda:0')
2024-12-02 15:25:14,959 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 274: ref_distribution = tensor([0.7725, 0.1307, 0.0968], device='cuda:0'), new_distribution = tensor([0.7727, 0.1305, 0.0968], device='cuda:0')
2024-12-02 15:25:15,024 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 275: ref_distribution = tensor([0.7727, 0.1305, 0.0968], device='cuda:0'), new_distribution = tensor([0.7729, 0.1303, 0.0968], device='cuda:0')
2024-12-02 15:25:15,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 276: ref_distribution = tensor([0.7729, 0.1303, 0.0968], device='cuda:0'), new_distribution = tensor([0.7731, 0.1301, 0.0968], device='cuda:0')
2024-12-02 15:25:15,155 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 277: ref_distribution = tensor([0.7731, 0.1301, 0.0968], device='cuda:0'), new_distribution = tensor([0.7734, 0.1299, 0.0968], device='cuda:0')
2024-12-02 15:25:15,219 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 278: ref_distribution = tensor([0.7734, 0.1299, 0.0968], device='cuda:0'), new_distribution = tensor([0.7736, 0.1296, 0.0968], device='cuda:0')
2024-12-02 15:25:15,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 279: ref_distribution = tensor([0.7736, 0.1296, 0.0968], device='cuda:0'), new_distribution = tensor([0.7738, 0.1294, 0.0968], device='cuda:0')
2024-12-02 15:25:15,349 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 280: ref_distribution = tensor([0.7738, 0.1294, 0.0968], device='cuda:0'), new_distribution = tensor([0.7740, 0.1292, 0.0968], device='cuda:0')
2024-12-02 15:25:15,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 281: ref_distribution = tensor([0.7740, 0.1292, 0.0968], device='cuda:0'), new_distribution = tensor([0.7742, 0.1290, 0.0968], device='cuda:0')
2024-12-02 15:25:15,478 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 282: ref_distribution = tensor([0.7742, 0.1290, 0.0968], device='cuda:0'), new_distribution = tensor([0.7744, 0.1288, 0.0968], device='cuda:0')
2024-12-02 15:25:15,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 283: ref_distribution = tensor([0.7744, 0.1288, 0.0968], device='cuda:0'), new_distribution = tensor([0.7746, 0.1286, 0.0968], device='cuda:0')
2024-12-02 15:25:15,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 284: ref_distribution = tensor([0.7746, 0.1286, 0.0968], device='cuda:0'), new_distribution = tensor([0.7748, 0.1284, 0.0968], device='cuda:0')
2024-12-02 15:25:15,673 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 285: ref_distribution = tensor([0.7748, 0.1284, 0.0968], device='cuda:0'), new_distribution = tensor([0.7750, 0.1282, 0.0968], device='cuda:0')
2024-12-02 15:25:15,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 286: ref_distribution = tensor([0.7750, 0.1282, 0.0968], device='cuda:0'), new_distribution = tensor([0.7752, 0.1279, 0.0968], device='cuda:0')
2024-12-02 15:25:15,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 287: ref_distribution = tensor([0.7752, 0.1279, 0.0968], device='cuda:0'), new_distribution = tensor([0.7755, 0.1277, 0.0968], device='cuda:0')
2024-12-02 15:25:15,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 288: ref_distribution = tensor([0.7755, 0.1277, 0.0968], device='cuda:0'), new_distribution = tensor([0.7757, 0.1275, 0.0968], device='cuda:0')
2024-12-02 15:25:15,930 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 289: ref_distribution = tensor([0.7757, 0.1275, 0.0968], device='cuda:0'), new_distribution = tensor([0.7759, 0.1273, 0.0968], device='cuda:0')
2024-12-02 15:25:15,994 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 290: ref_distribution = tensor([0.7759, 0.1273, 0.0968], device='cuda:0'), new_distribution = tensor([0.7761, 0.1271, 0.0968], device='cuda:0')
2024-12-02 15:25:16,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 291: ref_distribution = tensor([0.7761, 0.1271, 0.0968], device='cuda:0'), new_distribution = tensor([0.7763, 0.1269, 0.0968], device='cuda:0')
2024-12-02 15:25:16,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 292: ref_distribution = tensor([0.7763, 0.1269, 0.0968], device='cuda:0'), new_distribution = tensor([0.7765, 0.1267, 0.0968], device='cuda:0')
2024-12-02 15:25:16,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 293: ref_distribution = tensor([0.7765, 0.1267, 0.0968], device='cuda:0'), new_distribution = tensor([0.7767, 0.1265, 0.0968], device='cuda:0')
2024-12-02 15:25:16,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 294: ref_distribution = tensor([0.7767, 0.1265, 0.0968], device='cuda:0'), new_distribution = tensor([0.7769, 0.1263, 0.0968], device='cuda:0')
2024-12-02 15:25:16,316 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 295: ref_distribution = tensor([0.7769, 0.1263, 0.0968], device='cuda:0'), new_distribution = tensor([0.7771, 0.1261, 0.0968], device='cuda:0')
2024-12-02 15:25:16,381 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 296: ref_distribution = tensor([0.7771, 0.1261, 0.0968], device='cuda:0'), new_distribution = tensor([0.7773, 0.1259, 0.0968], device='cuda:0')
2024-12-02 15:25:16,446 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 297: ref_distribution = tensor([0.7773, 0.1259, 0.0968], device='cuda:0'), new_distribution = tensor([0.7775, 0.1256, 0.0968], device='cuda:0')
2024-12-02 15:25:16,511 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 298: ref_distribution = tensor([0.7775, 0.1256, 0.0968], device='cuda:0'), new_distribution = tensor([0.7777, 0.1254, 0.0968], device='cuda:0')
2024-12-02 15:25:16,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 299: ref_distribution = tensor([0.7777, 0.1254, 0.0968], device='cuda:0'), new_distribution = tensor([0.7779, 0.1252, 0.0968], device='cuda:0')
2024-12-02 15:25:16,871 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 0: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:16,936 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 1: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,001 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 2: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 3: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,130 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 4: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 5: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,260 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 6: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 7: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 8: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,456 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 9: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 10: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,585 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 11: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,650 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 12: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 13: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 14: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 15: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 16: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:17,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 17: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 18: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,106 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 19: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 20: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 21: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 22: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,367 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 23: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 24: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 25: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 26: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 27: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 28: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 29: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 30: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,888 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 31: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:18,953 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 32: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 33: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 34: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,147 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 35: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,211 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 36: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 37: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 38: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 39: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,472 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 40: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,537 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 41: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 42: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 43: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 44: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,798 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 45: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,864 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 46: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,928 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 47: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:19,993 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 48: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 49: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 50: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 51: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,252 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 52: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 53: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 54: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,446 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 55: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,512 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 56: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 57: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 58: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,706 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 59: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,772 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 60: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 61: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,902 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 62: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:20,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 63: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 64: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 65: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 66: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,228 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 67: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,294 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 68: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,359 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 69: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,423 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 70: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,488 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 71: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,553 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 72: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 73: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,682 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 74: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 75: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 76: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 77: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:21,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 78: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 79: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,073 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 80: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,138 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 81: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,203 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 82: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 83: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 84: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,399 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 85: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,464 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 86: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,529 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 87: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,594 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 88: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,659 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 89: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,724 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 90: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,789 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 91: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 92: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 93: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:22,984 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 94: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,049 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 95: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 96: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 97: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,243 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 98: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,307 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 99: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 100: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 101: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 102: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,568 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 103: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 104: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,698 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 105: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,763 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 106: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,828 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 107: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 108: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:23,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 109: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,023 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 110: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 111: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 112: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,219 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 113: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 114: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,350 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 115: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 116: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,480 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 117: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,544 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 118: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 119: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 120: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,739 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 121: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 122: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 123: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 124: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:24,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 125: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 126: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,129 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 127: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,193 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 128: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 129: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,324 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 130: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 131: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,453 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 132: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 133: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 134: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 135: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 136: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 137: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 138: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 139: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:25,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 140: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 141: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,106 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 142: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 143: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 144: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 145: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 146: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,428 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 147: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,493 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 148: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 149: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 150: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 151: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 152: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 153: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 154: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:26,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 155: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 156: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,077 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 157: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 158: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,206 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 159: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 160: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 161: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 162: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 163: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,531 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 164: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 165: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 166: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 167: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 168: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 169: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 170: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:27,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 171: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 172: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 173: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,181 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 174: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 175: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 176: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,376 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 177: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 178: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,506 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 179: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,571 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 180: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,635 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 181: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,701 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 182: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 183: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 184: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,895 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 185: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:28,961 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 186: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 187: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,090 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 188: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,155 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 189: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 190: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 191: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,349 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 192: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 193: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,478 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 194: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 195: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 196: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 197: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,738 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 198: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 199: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 200: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 201: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:29,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 202: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 203: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,130 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 204: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 205: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,260 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 206: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,326 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 207: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 208: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 209: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 210: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,585 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 211: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,649 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 212: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,714 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 213: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,779 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 214: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 215: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 216: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:30,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 217: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 218: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 219: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,168 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 220: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 221: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 222: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 223: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,427 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 224: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,492 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 225: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,557 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 226: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 227: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 228: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,753 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 229: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,818 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 230: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 231: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:31,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 232: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 233: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,077 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 234: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 235: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,206 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 236: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 237: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 238: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 239: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 240: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,531 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 241: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 242: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 243: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,725 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 244: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 245: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,855 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 246: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 247: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:32,985 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 248: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,049 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 249: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,114 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 250: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 251: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,243 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 252: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 253: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 254: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 255: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 256: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,568 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 257: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 258: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,698 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 259: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,763 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 260: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,828 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 261: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 262: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:33,959 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 263: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,024 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 264: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 265: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 266: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 267: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 268: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,350 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 269: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 270: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 271: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,544 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 272: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 273: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 274: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,739 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 275: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 276: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 277: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:34,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 278: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,000 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 279: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 280: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,129 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 281: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,194 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 282: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,259 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 283: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,324 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 284: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 285: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 286: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 287: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 288: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 289: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 290: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 291: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 292: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 293: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:35,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 294: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:36,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 295: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:36,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 296: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:36,170 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 297: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:36,235 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 298: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:36,300 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 299: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:25:36,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 0: ref_distribution = tensor([0.1000, 0.3000, 0.6000], device='cuda:0'), new_distribution = tensor([0.1000, 0.3005, 0.5994], device='cuda:0')
2024-12-02 15:25:36,657 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 1: ref_distribution = tensor([0.1000, 0.3005, 0.5994], device='cuda:0'), new_distribution = tensor([0.1001, 0.3011, 0.5989], device='cuda:0')
2024-12-02 15:25:36,723 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 2: ref_distribution = tensor([0.1001, 0.3011, 0.5989], device='cuda:0'), new_distribution = tensor([0.1001, 0.3016, 0.5983], device='cuda:0')
2024-12-02 15:25:36,788 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 3: ref_distribution = tensor([0.1001, 0.3016, 0.5983], device='cuda:0'), new_distribution = tensor([0.1002, 0.3021, 0.5977], device='cuda:0')
2024-12-02 15:25:36,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 4: ref_distribution = tensor([0.1002, 0.3021, 0.5977], device='cuda:0'), new_distribution = tensor([0.1002, 0.3027, 0.5971], device='cuda:0')
2024-12-02 15:25:36,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 5: ref_distribution = tensor([0.1002, 0.3027, 0.5971], device='cuda:0'), new_distribution = tensor([0.1002, 0.3032, 0.5966], device='cuda:0')
2024-12-02 15:25:36,984 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 6: ref_distribution = tensor([0.1002, 0.3032, 0.5966], device='cuda:0'), new_distribution = tensor([0.1003, 0.3037, 0.5960], device='cuda:0')
2024-12-02 15:25:37,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 7: ref_distribution = tensor([0.1003, 0.3037, 0.5960], device='cuda:0'), new_distribution = tensor([0.1003, 0.3043, 0.5954], device='cuda:0')
2024-12-02 15:25:37,115 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 8: ref_distribution = tensor([0.1003, 0.3043, 0.5954], device='cuda:0'), new_distribution = tensor([0.1004, 0.3048, 0.5948], device='cuda:0')
2024-12-02 15:25:37,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 9: ref_distribution = tensor([0.1004, 0.3048, 0.5948], device='cuda:0'), new_distribution = tensor([0.1004, 0.3053, 0.5942], device='cuda:0')
2024-12-02 15:25:37,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 10: ref_distribution = tensor([0.1004, 0.3053, 0.5942], device='cuda:0'), new_distribution = tensor([0.1005, 0.3059, 0.5937], device='cuda:0')
2024-12-02 15:25:37,309 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 11: ref_distribution = tensor([0.1005, 0.3059, 0.5937], device='cuda:0'), new_distribution = tensor([0.1005, 0.3064, 0.5931], device='cuda:0')
2024-12-02 15:25:37,374 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 12: ref_distribution = tensor([0.1005, 0.3064, 0.5931], device='cuda:0'), new_distribution = tensor([0.1005, 0.3069, 0.5925], device='cuda:0')
2024-12-02 15:25:37,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 13: ref_distribution = tensor([0.1005, 0.3069, 0.5925], device='cuda:0'), new_distribution = tensor([0.1006, 0.3075, 0.5919], device='cuda:0')
2024-12-02 15:25:37,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 14: ref_distribution = tensor([0.1006, 0.3075, 0.5919], device='cuda:0'), new_distribution = tensor([0.1006, 0.3080, 0.5913], device='cuda:0')
2024-12-02 15:25:37,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 15: ref_distribution = tensor([0.1006, 0.3080, 0.5913], device='cuda:0'), new_distribution = tensor([0.1007, 0.3086, 0.5908], device='cuda:0')
2024-12-02 15:25:37,635 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 16: ref_distribution = tensor([0.1007, 0.3086, 0.5908], device='cuda:0'), new_distribution = tensor([0.1007, 0.3091, 0.5902], device='cuda:0')
2024-12-02 15:25:37,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 17: ref_distribution = tensor([0.1007, 0.3091, 0.5902], device='cuda:0'), new_distribution = tensor([0.1008, 0.3096, 0.5896], device='cuda:0')
2024-12-02 15:25:37,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 18: ref_distribution = tensor([0.1008, 0.3096, 0.5896], device='cuda:0'), new_distribution = tensor([0.1008, 0.3102, 0.5890], device='cuda:0')
2024-12-02 15:25:37,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 19: ref_distribution = tensor([0.1008, 0.3102, 0.5890], device='cuda:0'), new_distribution = tensor([0.1009, 0.3107, 0.5884], device='cuda:0')
2024-12-02 15:25:37,895 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 20: ref_distribution = tensor([0.1009, 0.3107, 0.5884], device='cuda:0'), new_distribution = tensor([0.1009, 0.3112, 0.5879], device='cuda:0')
2024-12-02 15:25:37,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 21: ref_distribution = tensor([0.1009, 0.3112, 0.5879], device='cuda:0'), new_distribution = tensor([0.1009, 0.3118, 0.5873], device='cuda:0')
2024-12-02 15:25:38,026 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 22: ref_distribution = tensor([0.1009, 0.3118, 0.5873], device='cuda:0'), new_distribution = tensor([0.1010, 0.3123, 0.5867], device='cuda:0')
2024-12-02 15:25:38,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 23: ref_distribution = tensor([0.1010, 0.3123, 0.5867], device='cuda:0'), new_distribution = tensor([0.1010, 0.3129, 0.5861], device='cuda:0')
2024-12-02 15:25:38,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 24: ref_distribution = tensor([0.1010, 0.3129, 0.5861], device='cuda:0'), new_distribution = tensor([0.1011, 0.3134, 0.5855], device='cuda:0')
2024-12-02 15:25:38,223 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 25: ref_distribution = tensor([0.1011, 0.3134, 0.5855], device='cuda:0'), new_distribution = tensor([0.1011, 0.3139, 0.5849], device='cuda:0')
2024-12-02 15:25:38,289 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 26: ref_distribution = tensor([0.1011, 0.3139, 0.5849], device='cuda:0'), new_distribution = tensor([0.1012, 0.3145, 0.5843], device='cuda:0')
2024-12-02 15:25:38,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 27: ref_distribution = tensor([0.1012, 0.3145, 0.5843], device='cuda:0'), new_distribution = tensor([0.1012, 0.3150, 0.5838], device='cuda:0')
2024-12-02 15:25:38,420 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 28: ref_distribution = tensor([0.1012, 0.3150, 0.5838], device='cuda:0'), new_distribution = tensor([0.1013, 0.3156, 0.5832], device='cuda:0')
2024-12-02 15:25:38,483 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 29: ref_distribution = tensor([0.1013, 0.3156, 0.5832], device='cuda:0'), new_distribution = tensor([0.1013, 0.3161, 0.5826], device='cuda:0')
2024-12-02 15:25:38,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 30: ref_distribution = tensor([0.1013, 0.3161, 0.5826], device='cuda:0'), new_distribution = tensor([0.1014, 0.3166, 0.5820], device='cuda:0')
2024-12-02 15:25:38,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 31: ref_distribution = tensor([0.1014, 0.3166, 0.5820], device='cuda:0'), new_distribution = tensor([0.1014, 0.3172, 0.5814], device='cuda:0')
2024-12-02 15:25:38,678 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 32: ref_distribution = tensor([0.1014, 0.3172, 0.5814], device='cuda:0'), new_distribution = tensor([0.1015, 0.3177, 0.5808], device='cuda:0')
2024-12-02 15:25:38,743 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 33: ref_distribution = tensor([0.1015, 0.3177, 0.5808], device='cuda:0'), new_distribution = tensor([0.1015, 0.3183, 0.5802], device='cuda:0')
2024-12-02 15:25:38,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 34: ref_distribution = tensor([0.1015, 0.3183, 0.5802], device='cuda:0'), new_distribution = tensor([0.1016, 0.3188, 0.5796], device='cuda:0')
2024-12-02 15:25:38,873 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 35: ref_distribution = tensor([0.1016, 0.3188, 0.5796], device='cuda:0'), new_distribution = tensor([0.1016, 0.3193, 0.5791], device='cuda:0')
2024-12-02 15:25:38,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 36: ref_distribution = tensor([0.1016, 0.3193, 0.5791], device='cuda:0'), new_distribution = tensor([0.1016, 0.3199, 0.5785], device='cuda:0')
2024-12-02 15:25:39,003 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 37: ref_distribution = tensor([0.1016, 0.3199, 0.5785], device='cuda:0'), new_distribution = tensor([0.1017, 0.3204, 0.5779], device='cuda:0')
2024-12-02 15:25:39,068 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 38: ref_distribution = tensor([0.1017, 0.3204, 0.5779], device='cuda:0'), new_distribution = tensor([0.1017, 0.3210, 0.5773], device='cuda:0')
2024-12-02 15:25:39,134 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 39: ref_distribution = tensor([0.1017, 0.3210, 0.5773], device='cuda:0'), new_distribution = tensor([0.1018, 0.3215, 0.5767], device='cuda:0')
2024-12-02 15:25:39,199 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 40: ref_distribution = tensor([0.1018, 0.3215, 0.5767], device='cuda:0'), new_distribution = tensor([0.1018, 0.3221, 0.5761], device='cuda:0')
2024-12-02 15:25:39,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 41: ref_distribution = tensor([0.1018, 0.3221, 0.5761], device='cuda:0'), new_distribution = tensor([0.1019, 0.3226, 0.5755], device='cuda:0')
2024-12-02 15:25:39,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 42: ref_distribution = tensor([0.1019, 0.3226, 0.5755], device='cuda:0'), new_distribution = tensor([0.1019, 0.3231, 0.5749], device='cuda:0')
2024-12-02 15:25:39,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 43: ref_distribution = tensor([0.1019, 0.3231, 0.5749], device='cuda:0'), new_distribution = tensor([0.1020, 0.3237, 0.5743], device='cuda:0')
2024-12-02 15:25:39,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 44: ref_distribution = tensor([0.1020, 0.3237, 0.5743], device='cuda:0'), new_distribution = tensor([0.1020, 0.3242, 0.5737], device='cuda:0')
2024-12-02 15:25:39,526 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 45: ref_distribution = tensor([0.1020, 0.3242, 0.5737], device='cuda:0'), new_distribution = tensor([0.1021, 0.3248, 0.5731], device='cuda:0')
2024-12-02 15:25:39,591 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 46: ref_distribution = tensor([0.1021, 0.3248, 0.5731], device='cuda:0'), new_distribution = tensor([0.1021, 0.3253, 0.5725], device='cuda:0')
2024-12-02 15:25:39,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 47: ref_distribution = tensor([0.1021, 0.3253, 0.5725], device='cuda:0'), new_distribution = tensor([0.1022, 0.3259, 0.5719], device='cuda:0')
2024-12-02 15:25:39,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 48: ref_distribution = tensor([0.1022, 0.3259, 0.5719], device='cuda:0'), new_distribution = tensor([0.1022, 0.3264, 0.5713], device='cuda:0')
2024-12-02 15:25:39,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 49: ref_distribution = tensor([0.1022, 0.3264, 0.5713], device='cuda:0'), new_distribution = tensor([0.1023, 0.3270, 0.5707], device='cuda:0')
2024-12-02 15:25:39,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 50: ref_distribution = tensor([0.1023, 0.3270, 0.5707], device='cuda:0'), new_distribution = tensor([0.1023, 0.3275, 0.5702], device='cuda:0')
2024-12-02 15:25:39,916 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 51: ref_distribution = tensor([0.1023, 0.3275, 0.5702], device='cuda:0'), new_distribution = tensor([0.1024, 0.3281, 0.5696], device='cuda:0')
2024-12-02 15:25:39,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 52: ref_distribution = tensor([0.1024, 0.3281, 0.5696], device='cuda:0'), new_distribution = tensor([0.1024, 0.3286, 0.5690], device='cuda:0')
2024-12-02 15:25:40,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 53: ref_distribution = tensor([0.1024, 0.3286, 0.5690], device='cuda:0'), new_distribution = tensor([0.1025, 0.3291, 0.5684], device='cuda:0')
2024-12-02 15:25:40,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 54: ref_distribution = tensor([0.1025, 0.3291, 0.5684], device='cuda:0'), new_distribution = tensor([0.1025, 0.3297, 0.5678], device='cuda:0')
2024-12-02 15:25:40,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 55: ref_distribution = tensor([0.1025, 0.3297, 0.5678], device='cuda:0'), new_distribution = tensor([0.1026, 0.3302, 0.5672], device='cuda:0')
2024-12-02 15:25:40,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 56: ref_distribution = tensor([0.1026, 0.3302, 0.5672], device='cuda:0'), new_distribution = tensor([0.1027, 0.3308, 0.5666], device='cuda:0')
2024-12-02 15:25:40,307 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 57: ref_distribution = tensor([0.1027, 0.3308, 0.5666], device='cuda:0'), new_distribution = tensor([0.1027, 0.3313, 0.5660], device='cuda:0')
2024-12-02 15:25:40,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 58: ref_distribution = tensor([0.1027, 0.3313, 0.5660], device='cuda:0'), new_distribution = tensor([0.1028, 0.3319, 0.5654], device='cuda:0')
2024-12-02 15:25:40,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 59: ref_distribution = tensor([0.1028, 0.3319, 0.5654], device='cuda:0'), new_distribution = tensor([0.1028, 0.3324, 0.5648], device='cuda:0')
2024-12-02 15:25:40,502 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 60: ref_distribution = tensor([0.1028, 0.3324, 0.5648], device='cuda:0'), new_distribution = tensor([0.1029, 0.3330, 0.5642], device='cuda:0')
2024-12-02 15:25:40,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 61: ref_distribution = tensor([0.1029, 0.3330, 0.5642], device='cuda:0'), new_distribution = tensor([0.1029, 0.3335, 0.5636], device='cuda:0')
2024-12-02 15:25:40,635 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 62: ref_distribution = tensor([0.1029, 0.3335, 0.5636], device='cuda:0'), new_distribution = tensor([0.1030, 0.3341, 0.5630], device='cuda:0')
2024-12-02 15:25:40,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 63: ref_distribution = tensor([0.1030, 0.3341, 0.5630], device='cuda:0'), new_distribution = tensor([0.1030, 0.3346, 0.5624], device='cuda:0')
2024-12-02 15:25:40,770 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 64: ref_distribution = tensor([0.1030, 0.3346, 0.5624], device='cuda:0'), new_distribution = tensor([0.1031, 0.3352, 0.5618], device='cuda:0')
2024-12-02 15:25:40,835 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 65: ref_distribution = tensor([0.1031, 0.3352, 0.5618], device='cuda:0'), new_distribution = tensor([0.1031, 0.3357, 0.5612], device='cuda:0')
2024-12-02 15:25:40,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 66: ref_distribution = tensor([0.1031, 0.3357, 0.5612], device='cuda:0'), new_distribution = tensor([0.1032, 0.3363, 0.5606], device='cuda:0')
2024-12-02 15:25:40,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 67: ref_distribution = tensor([0.1032, 0.3363, 0.5606], device='cuda:0'), new_distribution = tensor([0.1032, 0.3368, 0.5600], device='cuda:0')
2024-12-02 15:25:41,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 68: ref_distribution = tensor([0.1032, 0.3368, 0.5600], device='cuda:0'), new_distribution = tensor([0.1033, 0.3374, 0.5593], device='cuda:0')
2024-12-02 15:25:41,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 69: ref_distribution = tensor([0.1033, 0.3374, 0.5593], device='cuda:0'), new_distribution = tensor([0.1033, 0.3379, 0.5587], device='cuda:0')
2024-12-02 15:25:41,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 70: ref_distribution = tensor([0.1033, 0.3379, 0.5587], device='cuda:0'), new_distribution = tensor([0.1034, 0.3385, 0.5581], device='cuda:0')
2024-12-02 15:25:41,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 71: ref_distribution = tensor([0.1034, 0.3385, 0.5581], device='cuda:0'), new_distribution = tensor([0.1035, 0.3390, 0.5575], device='cuda:0')
2024-12-02 15:25:41,294 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 72: ref_distribution = tensor([0.1035, 0.3390, 0.5575], device='cuda:0'), new_distribution = tensor([0.1035, 0.3396, 0.5569], device='cuda:0')
2024-12-02 15:25:41,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 73: ref_distribution = tensor([0.1035, 0.3396, 0.5569], device='cuda:0'), new_distribution = tensor([0.1036, 0.3401, 0.5563], device='cuda:0')
2024-12-02 15:25:41,423 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 74: ref_distribution = tensor([0.1036, 0.3401, 0.5563], device='cuda:0'), new_distribution = tensor([0.1036, 0.3407, 0.5557], device='cuda:0')
2024-12-02 15:25:41,488 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 75: ref_distribution = tensor([0.1036, 0.3407, 0.5557], device='cuda:0'), new_distribution = tensor([0.1037, 0.3412, 0.5551], device='cuda:0')
2024-12-02 15:25:41,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 76: ref_distribution = tensor([0.1037, 0.3412, 0.5551], device='cuda:0'), new_distribution = tensor([0.1037, 0.3418, 0.5545], device='cuda:0')
2024-12-02 15:25:41,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 77: ref_distribution = tensor([0.1037, 0.3418, 0.5545], device='cuda:0'), new_distribution = tensor([0.1038, 0.3423, 0.5539], device='cuda:0')
2024-12-02 15:25:41,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 78: ref_distribution = tensor([0.1038, 0.3423, 0.5539], device='cuda:0'), new_distribution = tensor([0.1038, 0.3429, 0.5533], device='cuda:0')
2024-12-02 15:25:41,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 79: ref_distribution = tensor([0.1038, 0.3429, 0.5533], device='cuda:0'), new_distribution = tensor([0.1039, 0.3434, 0.5527], device='cuda:0')
2024-12-02 15:25:41,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 80: ref_distribution = tensor([0.1039, 0.3434, 0.5527], device='cuda:0'), new_distribution = tensor([0.1040, 0.3440, 0.5521], device='cuda:0')
2024-12-02 15:25:41,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 81: ref_distribution = tensor([0.1040, 0.3440, 0.5521], device='cuda:0'), new_distribution = tensor([0.1040, 0.3445, 0.5515], device='cuda:0')
2024-12-02 15:25:41,945 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 82: ref_distribution = tensor([0.1040, 0.3445, 0.5515], device='cuda:0'), new_distribution = tensor([0.1041, 0.3451, 0.5509], device='cuda:0')
2024-12-02 15:25:42,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 83: ref_distribution = tensor([0.1041, 0.3451, 0.5509], device='cuda:0'), new_distribution = tensor([0.1041, 0.3456, 0.5503], device='cuda:0')
2024-12-02 15:25:42,076 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 84: ref_distribution = tensor([0.1041, 0.3456, 0.5503], device='cuda:0'), new_distribution = tensor([0.1042, 0.3462, 0.5496], device='cuda:0')
2024-12-02 15:25:42,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 85: ref_distribution = tensor([0.1042, 0.3462, 0.5496], device='cuda:0'), new_distribution = tensor([0.1043, 0.3467, 0.5490], device='cuda:0')
2024-12-02 15:25:42,206 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 86: ref_distribution = tensor([0.1043, 0.3467, 0.5490], device='cuda:0'), new_distribution = tensor([0.1043, 0.3473, 0.5484], device='cuda:0')
2024-12-02 15:25:42,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 87: ref_distribution = tensor([0.1043, 0.3473, 0.5484], device='cuda:0'), new_distribution = tensor([0.1044, 0.3478, 0.5478], device='cuda:0')
2024-12-02 15:25:42,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 88: ref_distribution = tensor([0.1044, 0.3478, 0.5478], device='cuda:0'), new_distribution = tensor([0.1044, 0.3484, 0.5472], device='cuda:0')
2024-12-02 15:25:42,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 89: ref_distribution = tensor([0.1044, 0.3484, 0.5472], device='cuda:0'), new_distribution = tensor([0.1045, 0.3489, 0.5466], device='cuda:0')
2024-12-02 15:25:42,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 90: ref_distribution = tensor([0.1045, 0.3489, 0.5466], device='cuda:0'), new_distribution = tensor([0.1045, 0.3495, 0.5460], device='cuda:0')
2024-12-02 15:25:42,531 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 91: ref_distribution = tensor([0.1045, 0.3495, 0.5460], device='cuda:0'), new_distribution = tensor([0.1046, 0.3500, 0.5454], device='cuda:0')
2024-12-02 15:25:42,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 92: ref_distribution = tensor([0.1046, 0.3500, 0.5454], device='cuda:0'), new_distribution = tensor([0.1047, 0.3506, 0.5448], device='cuda:0')
2024-12-02 15:25:42,660 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 93: ref_distribution = tensor([0.1047, 0.3506, 0.5448], device='cuda:0'), new_distribution = tensor([0.1047, 0.3511, 0.5441], device='cuda:0')
2024-12-02 15:25:42,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 94: ref_distribution = tensor([0.1047, 0.3511, 0.5441], device='cuda:0'), new_distribution = tensor([0.1048, 0.3517, 0.5435], device='cuda:0')
2024-12-02 15:25:42,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 95: ref_distribution = tensor([0.1048, 0.3517, 0.5435], device='cuda:0'), new_distribution = tensor([0.1048, 0.3522, 0.5429], device='cuda:0')
2024-12-02 15:25:42,855 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 96: ref_distribution = tensor([0.1048, 0.3522, 0.5429], device='cuda:0'), new_distribution = tensor([0.1049, 0.3528, 0.5423], device='cuda:0')
2024-12-02 15:25:42,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 97: ref_distribution = tensor([0.1049, 0.3528, 0.5423], device='cuda:0'), new_distribution = tensor([0.1050, 0.3533, 0.5417], device='cuda:0')
2024-12-02 15:25:42,985 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 98: ref_distribution = tensor([0.1050, 0.3533, 0.5417], device='cuda:0'), new_distribution = tensor([0.1050, 0.3539, 0.5411], device='cuda:0')
2024-12-02 15:25:43,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 99: ref_distribution = tensor([0.1050, 0.3539, 0.5411], device='cuda:0'), new_distribution = tensor([0.1051, 0.3544, 0.5405], device='cuda:0')
2024-12-02 15:25:43,116 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 100: ref_distribution = tensor([0.1051, 0.3544, 0.5405], device='cuda:0'), new_distribution = tensor([0.1052, 0.3550, 0.5399], device='cuda:0')
2024-12-02 15:25:43,181 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 101: ref_distribution = tensor([0.1052, 0.3550, 0.5399], device='cuda:0'), new_distribution = tensor([0.1052, 0.3555, 0.5392], device='cuda:0')
2024-12-02 15:25:43,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 102: ref_distribution = tensor([0.1052, 0.3555, 0.5392], device='cuda:0'), new_distribution = tensor([0.1053, 0.3561, 0.5386], device='cuda:0')
2024-12-02 15:25:43,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 103: ref_distribution = tensor([0.1053, 0.3561, 0.5386], device='cuda:0'), new_distribution = tensor([0.1053, 0.3567, 0.5380], device='cuda:0')
2024-12-02 15:25:43,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 104: ref_distribution = tensor([0.1053, 0.3567, 0.5380], device='cuda:0'), new_distribution = tensor([0.1054, 0.3572, 0.5374], device='cuda:0')
2024-12-02 15:25:43,442 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 105: ref_distribution = tensor([0.1054, 0.3572, 0.5374], device='cuda:0'), new_distribution = tensor([0.1055, 0.3578, 0.5368], device='cuda:0')
2024-12-02 15:25:43,507 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 106: ref_distribution = tensor([0.1055, 0.3578, 0.5368], device='cuda:0'), new_distribution = tensor([0.1055, 0.3583, 0.5362], device='cuda:0')
2024-12-02 15:25:43,572 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 107: ref_distribution = tensor([0.1055, 0.3583, 0.5362], device='cuda:0'), new_distribution = tensor([0.1056, 0.3589, 0.5355], device='cuda:0')
2024-12-02 15:25:43,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 108: ref_distribution = tensor([0.1056, 0.3589, 0.5355], device='cuda:0'), new_distribution = tensor([0.1057, 0.3594, 0.5349], device='cuda:0')
2024-12-02 15:25:43,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 109: ref_distribution = tensor([0.1057, 0.3594, 0.5349], device='cuda:0'), new_distribution = tensor([0.1057, 0.3600, 0.5343], device='cuda:0')
2024-12-02 15:25:43,768 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 110: ref_distribution = tensor([0.1057, 0.3600, 0.5343], device='cuda:0'), new_distribution = tensor([0.1058, 0.3605, 0.5337], device='cuda:0')
2024-12-02 15:25:43,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 111: ref_distribution = tensor([0.1058, 0.3605, 0.5337], device='cuda:0'), new_distribution = tensor([0.1058, 0.3611, 0.5331], device='cuda:0')
2024-12-02 15:25:43,899 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 112: ref_distribution = tensor([0.1058, 0.3611, 0.5331], device='cuda:0'), new_distribution = tensor([0.1059, 0.3616, 0.5325], device='cuda:0')
2024-12-02 15:25:43,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 113: ref_distribution = tensor([0.1059, 0.3616, 0.5325], device='cuda:0'), new_distribution = tensor([0.1060, 0.3622, 0.5318], device='cuda:0')
2024-12-02 15:25:44,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 114: ref_distribution = tensor([0.1060, 0.3622, 0.5318], device='cuda:0'), new_distribution = tensor([0.1060, 0.3627, 0.5312], device='cuda:0')
2024-12-02 15:25:44,093 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 115: ref_distribution = tensor([0.1060, 0.3627, 0.5312], device='cuda:0'), new_distribution = tensor([0.1061, 0.3633, 0.5306], device='cuda:0')
2024-12-02 15:25:44,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 116: ref_distribution = tensor([0.1061, 0.3633, 0.5306], device='cuda:0'), new_distribution = tensor([0.1062, 0.3638, 0.5300], device='cuda:0')
2024-12-02 15:25:44,224 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 117: ref_distribution = tensor([0.1062, 0.3638, 0.5300], device='cuda:0'), new_distribution = tensor([0.1062, 0.3644, 0.5294], device='cuda:0')
2024-12-02 15:25:44,289 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 118: ref_distribution = tensor([0.1062, 0.3644, 0.5294], device='cuda:0'), new_distribution = tensor([0.1063, 0.3650, 0.5288], device='cuda:0')
2024-12-02 15:25:44,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 119: ref_distribution = tensor([0.1063, 0.3650, 0.5288], device='cuda:0'), new_distribution = tensor([0.1064, 0.3655, 0.5281], device='cuda:0')
2024-12-02 15:25:44,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 120: ref_distribution = tensor([0.1064, 0.3655, 0.5281], device='cuda:0'), new_distribution = tensor([0.1064, 0.3661, 0.5275], device='cuda:0')
2024-12-02 15:25:44,484 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 121: ref_distribution = tensor([0.1064, 0.3661, 0.5275], device='cuda:0'), new_distribution = tensor([0.1065, 0.3666, 0.5269], device='cuda:0')
2024-12-02 15:25:44,549 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 122: ref_distribution = tensor([0.1065, 0.3666, 0.5269], device='cuda:0'), new_distribution = tensor([0.1066, 0.3672, 0.5263], device='cuda:0')
2024-12-02 15:25:44,614 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 123: ref_distribution = tensor([0.1066, 0.3672, 0.5263], device='cuda:0'), new_distribution = tensor([0.1066, 0.3677, 0.5257], device='cuda:0')
2024-12-02 15:25:44,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 124: ref_distribution = tensor([0.1066, 0.3677, 0.5257], device='cuda:0'), new_distribution = tensor([0.1067, 0.3683, 0.5250], device='cuda:0')
2024-12-02 15:25:44,744 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 125: ref_distribution = tensor([0.1067, 0.3683, 0.5250], device='cuda:0'), new_distribution = tensor([0.1068, 0.3688, 0.5244], device='cuda:0')
2024-12-02 15:25:44,809 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 126: ref_distribution = tensor([0.1068, 0.3688, 0.5244], device='cuda:0'), new_distribution = tensor([0.1068, 0.3694, 0.5238], device='cuda:0')
2024-12-02 15:25:44,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 127: ref_distribution = tensor([0.1068, 0.3694, 0.5238], device='cuda:0'), new_distribution = tensor([0.1069, 0.3699, 0.5232], device='cuda:0')
2024-12-02 15:25:44,939 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 128: ref_distribution = tensor([0.1069, 0.3699, 0.5232], device='cuda:0'), new_distribution = tensor([0.1070, 0.3705, 0.5226], device='cuda:0')
2024-12-02 15:25:45,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 129: ref_distribution = tensor([0.1070, 0.3705, 0.5226], device='cuda:0'), new_distribution = tensor([0.1070, 0.3710, 0.5219], device='cuda:0')
2024-12-02 15:25:45,069 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 130: ref_distribution = tensor([0.1070, 0.3710, 0.5219], device='cuda:0'), new_distribution = tensor([0.1071, 0.3716, 0.5213], device='cuda:0')
2024-12-02 15:25:45,133 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 131: ref_distribution = tensor([0.1071, 0.3716, 0.5213], device='cuda:0'), new_distribution = tensor([0.1072, 0.3721, 0.5207], device='cuda:0')
2024-12-02 15:25:45,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 132: ref_distribution = tensor([0.1072, 0.3721, 0.5207], device='cuda:0'), new_distribution = tensor([0.1072, 0.3727, 0.5201], device='cuda:0')
2024-12-02 15:25:45,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 133: ref_distribution = tensor([0.1072, 0.3727, 0.5201], device='cuda:0'), new_distribution = tensor([0.1073, 0.3733, 0.5194], device='cuda:0')
2024-12-02 15:25:45,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 134: ref_distribution = tensor([0.1073, 0.3733, 0.5194], device='cuda:0'), new_distribution = tensor([0.1074, 0.3738, 0.5188], device='cuda:0')
2024-12-02 15:25:45,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 135: ref_distribution = tensor([0.1074, 0.3738, 0.5188], device='cuda:0'), new_distribution = tensor([0.1074, 0.3744, 0.5182], device='cuda:0')
2024-12-02 15:25:45,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 136: ref_distribution = tensor([0.1074, 0.3744, 0.5182], device='cuda:0'), new_distribution = tensor([0.1075, 0.3749, 0.5176], device='cuda:0')
2024-12-02 15:25:45,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 137: ref_distribution = tensor([0.1075, 0.3749, 0.5176], device='cuda:0'), new_distribution = tensor([0.1076, 0.3755, 0.5170], device='cuda:0')
2024-12-02 15:25:45,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 138: ref_distribution = tensor([0.1076, 0.3755, 0.5170], device='cuda:0'), new_distribution = tensor([0.1077, 0.3760, 0.5163], device='cuda:0')
2024-12-02 15:25:45,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 139: ref_distribution = tensor([0.1077, 0.3760, 0.5163], device='cuda:0'), new_distribution = tensor([0.1077, 0.3766, 0.5157], device='cuda:0')
2024-12-02 15:25:45,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 140: ref_distribution = tensor([0.1077, 0.3766, 0.5157], device='cuda:0'), new_distribution = tensor([0.1078, 0.3771, 0.5151], device='cuda:0')
2024-12-02 15:25:45,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 141: ref_distribution = tensor([0.1078, 0.3771, 0.5151], device='cuda:0'), new_distribution = tensor([0.1079, 0.3777, 0.5145], device='cuda:0')
2024-12-02 15:25:45,847 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 142: ref_distribution = tensor([0.1079, 0.3777, 0.5145], device='cuda:0'), new_distribution = tensor([0.1079, 0.3782, 0.5138], device='cuda:0')
2024-12-02 15:25:45,912 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 143: ref_distribution = tensor([0.1079, 0.3782, 0.5138], device='cuda:0'), new_distribution = tensor([0.1080, 0.3788, 0.5132], device='cuda:0')
2024-12-02 15:25:45,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 144: ref_distribution = tensor([0.1080, 0.3788, 0.5132], device='cuda:0'), new_distribution = tensor([0.1081, 0.3793, 0.5126], device='cuda:0')
2024-12-02 15:25:46,042 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 145: ref_distribution = tensor([0.1081, 0.3793, 0.5126], device='cuda:0'), new_distribution = tensor([0.1082, 0.3799, 0.5120], device='cuda:0')
2024-12-02 15:25:46,106 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 146: ref_distribution = tensor([0.1082, 0.3799, 0.5120], device='cuda:0'), new_distribution = tensor([0.1082, 0.3804, 0.5113], device='cuda:0')
2024-12-02 15:25:46,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 147: ref_distribution = tensor([0.1082, 0.3804, 0.5113], device='cuda:0'), new_distribution = tensor([0.1083, 0.3810, 0.5107], device='cuda:0')
2024-12-02 15:25:46,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 148: ref_distribution = tensor([0.1083, 0.3810, 0.5107], device='cuda:0'), new_distribution = tensor([0.1084, 0.3815, 0.5101], device='cuda:0')
2024-12-02 15:25:46,301 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 149: ref_distribution = tensor([0.1084, 0.3815, 0.5101], device='cuda:0'), new_distribution = tensor([0.1084, 0.3821, 0.5095], device='cuda:0')
2024-12-02 15:25:46,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 150: ref_distribution = tensor([0.1084, 0.3821, 0.5095], device='cuda:0'), new_distribution = tensor([0.1085, 0.3827, 0.5088], device='cuda:0')
2024-12-02 15:25:46,431 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 151: ref_distribution = tensor([0.1085, 0.3827, 0.5088], device='cuda:0'), new_distribution = tensor([0.1086, 0.3832, 0.5082], device='cuda:0')
2024-12-02 15:25:46,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 152: ref_distribution = tensor([0.1086, 0.3832, 0.5082], device='cuda:0'), new_distribution = tensor([0.1087, 0.3838, 0.5076], device='cuda:0')
2024-12-02 15:25:46,562 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 153: ref_distribution = tensor([0.1087, 0.3838, 0.5076], device='cuda:0'), new_distribution = tensor([0.1087, 0.3843, 0.5070], device='cuda:0')
2024-12-02 15:25:46,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 154: ref_distribution = tensor([0.1087, 0.3843, 0.5070], device='cuda:0'), new_distribution = tensor([0.1088, 0.3849, 0.5063], device='cuda:0')
2024-12-02 15:25:46,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 155: ref_distribution = tensor([0.1088, 0.3849, 0.5063], device='cuda:0'), new_distribution = tensor([0.1089, 0.3854, 0.5057], device='cuda:0')
2024-12-02 15:25:46,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 156: ref_distribution = tensor([0.1089, 0.3854, 0.5057], device='cuda:0'), new_distribution = tensor([0.1090, 0.3860, 0.5051], device='cuda:0')
2024-12-02 15:25:46,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 157: ref_distribution = tensor([0.1090, 0.3860, 0.5051], device='cuda:0'), new_distribution = tensor([0.1090, 0.3865, 0.5045], device='cuda:0')
2024-12-02 15:25:46,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 158: ref_distribution = tensor([0.1090, 0.3865, 0.5045], device='cuda:0'), new_distribution = tensor([0.1091, 0.3871, 0.5038], device='cuda:0')
2024-12-02 15:25:46,951 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 159: ref_distribution = tensor([0.1091, 0.3871, 0.5038], device='cuda:0'), new_distribution = tensor([0.1092, 0.3876, 0.5032], device='cuda:0')
2024-12-02 15:25:47,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 160: ref_distribution = tensor([0.1092, 0.3876, 0.5032], device='cuda:0'), new_distribution = tensor([0.1093, 0.3882, 0.5026], device='cuda:0')
2024-12-02 15:25:47,081 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 161: ref_distribution = tensor([0.1093, 0.3882, 0.5026], device='cuda:0'), new_distribution = tensor([0.1093, 0.3887, 0.5019], device='cuda:0')
2024-12-02 15:25:47,146 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 162: ref_distribution = tensor([0.1093, 0.3887, 0.5019], device='cuda:0'), new_distribution = tensor([0.1094, 0.3893, 0.5013], device='cuda:0')
2024-12-02 15:25:47,211 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 163: ref_distribution = tensor([0.1094, 0.3893, 0.5013], device='cuda:0'), new_distribution = tensor([0.1095, 0.3898, 0.5007], device='cuda:0')
2024-12-02 15:25:47,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 164: ref_distribution = tensor([0.1095, 0.3898, 0.5007], device='cuda:0'), new_distribution = tensor([0.1096, 0.3904, 0.5001], device='cuda:0')
2024-12-02 15:25:47,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 165: ref_distribution = tensor([0.1096, 0.3904, 0.5001], device='cuda:0'), new_distribution = tensor([0.1096, 0.3909, 0.4994], device='cuda:0')
2024-12-02 15:25:47,405 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 166: ref_distribution = tensor([0.1096, 0.3909, 0.4994], device='cuda:0'), new_distribution = tensor([0.1097, 0.3915, 0.4988], device='cuda:0')
2024-12-02 15:25:47,470 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 167: ref_distribution = tensor([0.1097, 0.3915, 0.4988], device='cuda:0'), new_distribution = tensor([0.1098, 0.3920, 0.4982], device='cuda:0')
2024-12-02 15:25:47,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 168: ref_distribution = tensor([0.1098, 0.3920, 0.4982], device='cuda:0'), new_distribution = tensor([0.1099, 0.3926, 0.4976], device='cuda:0')
2024-12-02 15:25:47,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 169: ref_distribution = tensor([0.1099, 0.3926, 0.4976], device='cuda:0'), new_distribution = tensor([0.1100, 0.3931, 0.4969], device='cuda:0')
2024-12-02 15:25:47,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 170: ref_distribution = tensor([0.1100, 0.3931, 0.4969], device='cuda:0'), new_distribution = tensor([0.1100, 0.3937, 0.4963], device='cuda:0')
2024-12-02 15:25:47,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 171: ref_distribution = tensor([0.1100, 0.3937, 0.4963], device='cuda:0'), new_distribution = tensor([0.1101, 0.3942, 0.4957], device='cuda:0')
2024-12-02 15:25:47,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 172: ref_distribution = tensor([0.1101, 0.3942, 0.4957], device='cuda:0'), new_distribution = tensor([0.1102, 0.3948, 0.4950], device='cuda:0')
2024-12-02 15:25:47,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 173: ref_distribution = tensor([0.1102, 0.3948, 0.4950], device='cuda:0'), new_distribution = tensor([0.1103, 0.3953, 0.4944], device='cuda:0')
2024-12-02 15:25:47,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 174: ref_distribution = tensor([0.1103, 0.3953, 0.4944], device='cuda:0'), new_distribution = tensor([0.1103, 0.3959, 0.4938], device='cuda:0')
2024-12-02 15:25:47,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 175: ref_distribution = tensor([0.1103, 0.3959, 0.4938], device='cuda:0'), new_distribution = tensor([0.1104, 0.3964, 0.4932], device='cuda:0')
2024-12-02 15:25:48,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 176: ref_distribution = tensor([0.1104, 0.3964, 0.4932], device='cuda:0'), new_distribution = tensor([0.1105, 0.3970, 0.4925], device='cuda:0')
2024-12-02 15:25:48,119 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 177: ref_distribution = tensor([0.1105, 0.3970, 0.4925], device='cuda:0'), new_distribution = tensor([0.1106, 0.3975, 0.4919], device='cuda:0')
2024-12-02 15:25:48,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 178: ref_distribution = tensor([0.1106, 0.3975, 0.4919], device='cuda:0'), new_distribution = tensor([0.1107, 0.3981, 0.4913], device='cuda:0')
2024-12-02 15:25:48,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 179: ref_distribution = tensor([0.1107, 0.3981, 0.4913], device='cuda:0'), new_distribution = tensor([0.1107, 0.3986, 0.4906], device='cuda:0')
2024-12-02 15:25:48,313 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 180: ref_distribution = tensor([0.1107, 0.3986, 0.4906], device='cuda:0'), new_distribution = tensor([0.1108, 0.3992, 0.4900], device='cuda:0')
2024-12-02 15:25:48,376 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 181: ref_distribution = tensor([0.1108, 0.3992, 0.4900], device='cuda:0'), new_distribution = tensor([0.1109, 0.3997, 0.4894], device='cuda:0')
2024-12-02 15:25:48,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 182: ref_distribution = tensor([0.1109, 0.3997, 0.4894], device='cuda:0'), new_distribution = tensor([0.1110, 0.4003, 0.4888], device='cuda:0')
2024-12-02 15:25:48,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 183: ref_distribution = tensor([0.1110, 0.4003, 0.4888], device='cuda:0'), new_distribution = tensor([0.1111, 0.4008, 0.4881], device='cuda:0')
2024-12-02 15:25:48,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 184: ref_distribution = tensor([0.1111, 0.4008, 0.4881], device='cuda:0'), new_distribution = tensor([0.1111, 0.4014, 0.4875], device='cuda:0')
2024-12-02 15:25:48,634 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 185: ref_distribution = tensor([0.1111, 0.4014, 0.4875], device='cuda:0'), new_distribution = tensor([0.1112, 0.4019, 0.4869], device='cuda:0')
2024-12-02 15:25:48,699 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 186: ref_distribution = tensor([0.1112, 0.4019, 0.4869], device='cuda:0'), new_distribution = tensor([0.1113, 0.4025, 0.4862], device='cuda:0')
2024-12-02 15:25:48,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 187: ref_distribution = tensor([0.1113, 0.4025, 0.4862], device='cuda:0'), new_distribution = tensor([0.1114, 0.4030, 0.4856], device='cuda:0')
2024-12-02 15:25:48,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 188: ref_distribution = tensor([0.1114, 0.4030, 0.4856], device='cuda:0'), new_distribution = tensor([0.1115, 0.4035, 0.4850], device='cuda:0')
2024-12-02 15:25:48,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 189: ref_distribution = tensor([0.1115, 0.4035, 0.4850], device='cuda:0'), new_distribution = tensor([0.1116, 0.4041, 0.4843], device='cuda:0')
2024-12-02 15:25:48,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 190: ref_distribution = tensor([0.1116, 0.4041, 0.4843], device='cuda:0'), new_distribution = tensor([0.1116, 0.4046, 0.4837], device='cuda:0')
2024-12-02 15:25:49,023 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 191: ref_distribution = tensor([0.1116, 0.4046, 0.4837], device='cuda:0'), new_distribution = tensor([0.1117, 0.4052, 0.4831], device='cuda:0')
2024-12-02 15:25:49,088 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 192: ref_distribution = tensor([0.1117, 0.4052, 0.4831], device='cuda:0'), new_distribution = tensor([0.1118, 0.4057, 0.4825], device='cuda:0')
2024-12-02 15:25:49,152 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 193: ref_distribution = tensor([0.1118, 0.4057, 0.4825], device='cuda:0'), new_distribution = tensor([0.1119, 0.4063, 0.4818], device='cuda:0')
2024-12-02 15:25:49,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 194: ref_distribution = tensor([0.1119, 0.4063, 0.4818], device='cuda:0'), new_distribution = tensor([0.1120, 0.4068, 0.4812], device='cuda:0')
2024-12-02 15:25:49,282 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 195: ref_distribution = tensor([0.1120, 0.4068, 0.4812], device='cuda:0'), new_distribution = tensor([0.1121, 0.4074, 0.4806], device='cuda:0')
2024-12-02 15:25:49,346 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 196: ref_distribution = tensor([0.1121, 0.4074, 0.4806], device='cuda:0'), new_distribution = tensor([0.1121, 0.4079, 0.4799], device='cuda:0')
2024-12-02 15:25:49,412 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 197: ref_distribution = tensor([0.1121, 0.4079, 0.4799], device='cuda:0'), new_distribution = tensor([0.1122, 0.4085, 0.4793], device='cuda:0')
2024-12-02 15:25:49,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 198: ref_distribution = tensor([0.1122, 0.4085, 0.4793], device='cuda:0'), new_distribution = tensor([0.1123, 0.4090, 0.4787], device='cuda:0')
2024-12-02 15:25:49,541 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 199: ref_distribution = tensor([0.1123, 0.4090, 0.4787], device='cuda:0'), new_distribution = tensor([0.1124, 0.4096, 0.4780], device='cuda:0')
2024-12-02 15:25:49,606 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 200: ref_distribution = tensor([0.1124, 0.4096, 0.4780], device='cuda:0'), new_distribution = tensor([0.1125, 0.4101, 0.4774], device='cuda:0')
2024-12-02 15:25:49,671 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 201: ref_distribution = tensor([0.1125, 0.4101, 0.4774], device='cuda:0'), new_distribution = tensor([0.1126, 0.4106, 0.4768], device='cuda:0')
2024-12-02 15:25:49,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 202: ref_distribution = tensor([0.1126, 0.4106, 0.4768], device='cuda:0'), new_distribution = tensor([0.1127, 0.4112, 0.4762], device='cuda:0')
2024-12-02 15:25:49,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 203: ref_distribution = tensor([0.1127, 0.4112, 0.4762], device='cuda:0'), new_distribution = tensor([0.1127, 0.4117, 0.4755], device='cuda:0')
2024-12-02 15:25:49,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 204: ref_distribution = tensor([0.1127, 0.4117, 0.4755], device='cuda:0'), new_distribution = tensor([0.1128, 0.4123, 0.4749], device='cuda:0')
2024-12-02 15:25:49,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 205: ref_distribution = tensor([0.1128, 0.4123, 0.4749], device='cuda:0'), new_distribution = tensor([0.1129, 0.4128, 0.4743], device='cuda:0')
2024-12-02 15:25:49,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 206: ref_distribution = tensor([0.1129, 0.4128, 0.4743], device='cuda:0'), new_distribution = tensor([0.1130, 0.4134, 0.4736], device='cuda:0')
2024-12-02 15:25:50,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 207: ref_distribution = tensor([0.1130, 0.4134, 0.4736], device='cuda:0'), new_distribution = tensor([0.1131, 0.4139, 0.4730], device='cuda:0')
2024-12-02 15:25:50,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 208: ref_distribution = tensor([0.1131, 0.4139, 0.4730], device='cuda:0'), new_distribution = tensor([0.1132, 0.4144, 0.4724], device='cuda:0')
2024-12-02 15:25:50,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 209: ref_distribution = tensor([0.1132, 0.4144, 0.4724], device='cuda:0'), new_distribution = tensor([0.1133, 0.4150, 0.4717], device='cuda:0')
2024-12-02 15:25:50,255 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 210: ref_distribution = tensor([0.1133, 0.4150, 0.4717], device='cuda:0'), new_distribution = tensor([0.1134, 0.4155, 0.4711], device='cuda:0')
2024-12-02 15:25:50,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 211: ref_distribution = tensor([0.1134, 0.4155, 0.4711], device='cuda:0'), new_distribution = tensor([0.1134, 0.4161, 0.4705], device='cuda:0')
2024-12-02 15:25:50,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 212: ref_distribution = tensor([0.1134, 0.4161, 0.4705], device='cuda:0'), new_distribution = tensor([0.1135, 0.4166, 0.4699], device='cuda:0')
2024-12-02 15:25:50,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 213: ref_distribution = tensor([0.1135, 0.4166, 0.4699], device='cuda:0'), new_distribution = tensor([0.1136, 0.4172, 0.4692], device='cuda:0')
2024-12-02 15:25:50,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 214: ref_distribution = tensor([0.1136, 0.4172, 0.4692], device='cuda:0'), new_distribution = tensor([0.1137, 0.4177, 0.4686], device='cuda:0')
2024-12-02 15:25:50,578 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 215: ref_distribution = tensor([0.1137, 0.4177, 0.4686], device='cuda:0'), new_distribution = tensor([0.1138, 0.4182, 0.4680], device='cuda:0')
2024-12-02 15:25:50,644 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 216: ref_distribution = tensor([0.1138, 0.4182, 0.4680], device='cuda:0'), new_distribution = tensor([0.1139, 0.4188, 0.4673], device='cuda:0')
2024-12-02 15:25:50,708 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 217: ref_distribution = tensor([0.1139, 0.4188, 0.4673], device='cuda:0'), new_distribution = tensor([0.1140, 0.4193, 0.4667], device='cuda:0')
2024-12-02 15:25:50,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 218: ref_distribution = tensor([0.1140, 0.4193, 0.4667], device='cuda:0'), new_distribution = tensor([0.1141, 0.4199, 0.4661], device='cuda:0')
2024-12-02 15:25:50,838 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 219: ref_distribution = tensor([0.1141, 0.4199, 0.4661], device='cuda:0'), new_distribution = tensor([0.1142, 0.4204, 0.4654], device='cuda:0')
2024-12-02 15:25:50,902 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 220: ref_distribution = tensor([0.1142, 0.4204, 0.4654], device='cuda:0'), new_distribution = tensor([0.1143, 0.4209, 0.4648], device='cuda:0')
2024-12-02 15:25:50,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 221: ref_distribution = tensor([0.1143, 0.4209, 0.4648], device='cuda:0'), new_distribution = tensor([0.1143, 0.4215, 0.4642], device='cuda:0')
2024-12-02 15:25:51,032 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 222: ref_distribution = tensor([0.1143, 0.4215, 0.4642], device='cuda:0'), new_distribution = tensor([0.1144, 0.4220, 0.4636], device='cuda:0')
2024-12-02 15:25:51,096 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 223: ref_distribution = tensor([0.1144, 0.4220, 0.4636], device='cuda:0'), new_distribution = tensor([0.1145, 0.4225, 0.4629], device='cuda:0')
2024-12-02 15:25:51,161 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 224: ref_distribution = tensor([0.1145, 0.4225, 0.4629], device='cuda:0'), new_distribution = tensor([0.1146, 0.4231, 0.4623], device='cuda:0')
2024-12-02 15:25:51,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 225: ref_distribution = tensor([0.1146, 0.4231, 0.4623], device='cuda:0'), new_distribution = tensor([0.1147, 0.4236, 0.4617], device='cuda:0')
2024-12-02 15:25:51,291 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 226: ref_distribution = tensor([0.1147, 0.4236, 0.4617], device='cuda:0'), new_distribution = tensor([0.1148, 0.4242, 0.4610], device='cuda:0')
2024-12-02 15:25:51,355 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 227: ref_distribution = tensor([0.1148, 0.4242, 0.4610], device='cuda:0'), new_distribution = tensor([0.1149, 0.4247, 0.4604], device='cuda:0')
2024-12-02 15:25:51,420 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 228: ref_distribution = tensor([0.1149, 0.4247, 0.4604], device='cuda:0'), new_distribution = tensor([0.1150, 0.4252, 0.4598], device='cuda:0')
2024-12-02 15:25:51,486 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 229: ref_distribution = tensor([0.1150, 0.4252, 0.4598], device='cuda:0'), new_distribution = tensor([0.1151, 0.4258, 0.4591], device='cuda:0')
2024-12-02 15:25:51,550 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 230: ref_distribution = tensor([0.1151, 0.4258, 0.4591], device='cuda:0'), new_distribution = tensor([0.1152, 0.4263, 0.4585], device='cuda:0')
2024-12-02 15:25:51,615 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 231: ref_distribution = tensor([0.1152, 0.4263, 0.4585], device='cuda:0'), new_distribution = tensor([0.1153, 0.4268, 0.4579], device='cuda:0')
2024-12-02 15:25:51,680 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 232: ref_distribution = tensor([0.1153, 0.4268, 0.4579], device='cuda:0'), new_distribution = tensor([0.1154, 0.4274, 0.4573], device='cuda:0')
2024-12-02 15:25:51,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 233: ref_distribution = tensor([0.1154, 0.4274, 0.4573], device='cuda:0'), new_distribution = tensor([0.1155, 0.4279, 0.4566], device='cuda:0')
2024-12-02 15:25:51,810 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 234: ref_distribution = tensor([0.1155, 0.4279, 0.4566], device='cuda:0'), new_distribution = tensor([0.1156, 0.4284, 0.4560], device='cuda:0')
2024-12-02 15:25:51,875 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 235: ref_distribution = tensor([0.1156, 0.4284, 0.4560], device='cuda:0'), new_distribution = tensor([0.1157, 0.4290, 0.4554], device='cuda:0')
2024-12-02 15:25:51,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 236: ref_distribution = tensor([0.1157, 0.4290, 0.4554], device='cuda:0'), new_distribution = tensor([0.1157, 0.4295, 0.4547], device='cuda:0')
2024-12-02 15:25:52,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 237: ref_distribution = tensor([0.1157, 0.4295, 0.4547], device='cuda:0'), new_distribution = tensor([0.1158, 0.4300, 0.4541], device='cuda:0')
2024-12-02 15:25:52,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 238: ref_distribution = tensor([0.1158, 0.4300, 0.4541], device='cuda:0'), new_distribution = tensor([0.1159, 0.4306, 0.4535], device='cuda:0')
2024-12-02 15:25:52,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 239: ref_distribution = tensor([0.1159, 0.4306, 0.4535], device='cuda:0'), new_distribution = tensor([0.1160, 0.4311, 0.4529], device='cuda:0')
2024-12-02 15:25:52,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 240: ref_distribution = tensor([0.1160, 0.4311, 0.4529], device='cuda:0'), new_distribution = tensor([0.1161, 0.4316, 0.4522], device='cuda:0')
2024-12-02 15:25:52,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 241: ref_distribution = tensor([0.1161, 0.4316, 0.4522], device='cuda:0'), new_distribution = tensor([0.1162, 0.4322, 0.4516], device='cuda:0')
2024-12-02 15:25:52,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 242: ref_distribution = tensor([0.1162, 0.4322, 0.4516], device='cuda:0'), new_distribution = tensor([0.1163, 0.4327, 0.4510], device='cuda:0')
2024-12-02 15:25:52,395 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 243: ref_distribution = tensor([0.1163, 0.4327, 0.4510], device='cuda:0'), new_distribution = tensor([0.1164, 0.4332, 0.4503], device='cuda:0')
2024-12-02 15:25:52,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 244: ref_distribution = tensor([0.1164, 0.4332, 0.4503], device='cuda:0'), new_distribution = tensor([0.1165, 0.4338, 0.4497], device='cuda:0')
2024-12-02 15:25:52,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 245: ref_distribution = tensor([0.1165, 0.4338, 0.4497], device='cuda:0'), new_distribution = tensor([0.1166, 0.4343, 0.4491], device='cuda:0')
2024-12-02 15:25:52,588 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 246: ref_distribution = tensor([0.1166, 0.4343, 0.4491], device='cuda:0'), new_distribution = tensor([0.1167, 0.4348, 0.4485], device='cuda:0')
2024-12-02 15:25:52,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 247: ref_distribution = tensor([0.1167, 0.4348, 0.4485], device='cuda:0'), new_distribution = tensor([0.1168, 0.4354, 0.4478], device='cuda:0')
2024-12-02 15:25:52,718 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 248: ref_distribution = tensor([0.1168, 0.4354, 0.4478], device='cuda:0'), new_distribution = tensor([0.1169, 0.4359, 0.4472], device='cuda:0')
2024-12-02 15:25:52,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 249: ref_distribution = tensor([0.1169, 0.4359, 0.4472], device='cuda:0'), new_distribution = tensor([0.1170, 0.4364, 0.4466], device='cuda:0')
2024-12-02 15:25:52,847 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 250: ref_distribution = tensor([0.1170, 0.4364, 0.4466], device='cuda:0'), new_distribution = tensor([0.1171, 0.4369, 0.4459], device='cuda:0')
2024-12-02 15:25:52,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 251: ref_distribution = tensor([0.1171, 0.4369, 0.4459], device='cuda:0'), new_distribution = tensor([0.1172, 0.4375, 0.4453], device='cuda:0')
2024-12-02 15:25:52,976 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 252: ref_distribution = tensor([0.1172, 0.4375, 0.4453], device='cuda:0'), new_distribution = tensor([0.1173, 0.4380, 0.4447], device='cuda:0')
2024-12-02 15:25:53,042 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 253: ref_distribution = tensor([0.1173, 0.4380, 0.4447], device='cuda:0'), new_distribution = tensor([0.1174, 0.4385, 0.4441], device='cuda:0')
2024-12-02 15:25:53,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 254: ref_distribution = tensor([0.1174, 0.4385, 0.4441], device='cuda:0'), new_distribution = tensor([0.1175, 0.4391, 0.4434], device='cuda:0')
2024-12-02 15:25:53,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 255: ref_distribution = tensor([0.1175, 0.4391, 0.4434], device='cuda:0'), new_distribution = tensor([0.1176, 0.4396, 0.4428], device='cuda:0')
2024-12-02 15:25:53,237 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 256: ref_distribution = tensor([0.1176, 0.4396, 0.4428], device='cuda:0'), new_distribution = tensor([0.1177, 0.4401, 0.4422], device='cuda:0')
2024-12-02 15:25:53,301 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 257: ref_distribution = tensor([0.1177, 0.4401, 0.4422], device='cuda:0'), new_distribution = tensor([0.1178, 0.4406, 0.4416], device='cuda:0')
2024-12-02 15:25:53,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 258: ref_distribution = tensor([0.1178, 0.4406, 0.4416], device='cuda:0'), new_distribution = tensor([0.1179, 0.4412, 0.4409], device='cuda:0')
2024-12-02 15:25:53,431 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 259: ref_distribution = tensor([0.1179, 0.4412, 0.4409], device='cuda:0'), new_distribution = tensor([0.1180, 0.4417, 0.4403], device='cuda:0')
2024-12-02 15:25:53,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 260: ref_distribution = tensor([0.1180, 0.4417, 0.4403], device='cuda:0'), new_distribution = tensor([0.1181, 0.4422, 0.4397], device='cuda:0')
2024-12-02 15:25:53,562 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 261: ref_distribution = tensor([0.1181, 0.4422, 0.4397], device='cuda:0'), new_distribution = tensor([0.1182, 0.4427, 0.4390], device='cuda:0')
2024-12-02 15:25:53,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 262: ref_distribution = tensor([0.1182, 0.4427, 0.4390], device='cuda:0'), new_distribution = tensor([0.1183, 0.4433, 0.4384], device='cuda:0')
2024-12-02 15:25:53,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 263: ref_distribution = tensor([0.1183, 0.4433, 0.4384], device='cuda:0'), new_distribution = tensor([0.1184, 0.4438, 0.4378], device='cuda:0')
2024-12-02 15:25:53,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 264: ref_distribution = tensor([0.1184, 0.4438, 0.4378], device='cuda:0'), new_distribution = tensor([0.1185, 0.4443, 0.4372], device='cuda:0')
2024-12-02 15:25:53,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 265: ref_distribution = tensor([0.1185, 0.4443, 0.4372], device='cuda:0'), new_distribution = tensor([0.1186, 0.4448, 0.4365], device='cuda:0')
2024-12-02 15:25:53,886 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 266: ref_distribution = tensor([0.1186, 0.4448, 0.4365], device='cuda:0'), new_distribution = tensor([0.1187, 0.4453, 0.4359], device='cuda:0')
2024-12-02 15:25:53,951 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 267: ref_distribution = tensor([0.1187, 0.4453, 0.4359], device='cuda:0'), new_distribution = tensor([0.1188, 0.4459, 0.4353], device='cuda:0')
2024-12-02 15:25:54,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 268: ref_distribution = tensor([0.1188, 0.4459, 0.4353], device='cuda:0'), new_distribution = tensor([0.1190, 0.4464, 0.4347], device='cuda:0')
2024-12-02 15:25:54,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 269: ref_distribution = tensor([0.1190, 0.4464, 0.4347], device='cuda:0'), new_distribution = tensor([0.1191, 0.4469, 0.4340], device='cuda:0')
2024-12-02 15:25:54,147 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 270: ref_distribution = tensor([0.1191, 0.4469, 0.4340], device='cuda:0'), new_distribution = tensor([0.1192, 0.4474, 0.4334], device='cuda:0')
2024-12-02 15:25:54,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 271: ref_distribution = tensor([0.1192, 0.4474, 0.4334], device='cuda:0'), new_distribution = tensor([0.1193, 0.4479, 0.4328], device='cuda:0')
2024-12-02 15:25:54,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 272: ref_distribution = tensor([0.1193, 0.4479, 0.4328], device='cuda:0'), new_distribution = tensor([0.1194, 0.4485, 0.4322], device='cuda:0')
2024-12-02 15:25:54,342 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 273: ref_distribution = tensor([0.1194, 0.4485, 0.4322], device='cuda:0'), new_distribution = tensor([0.1195, 0.4490, 0.4315], device='cuda:0')
2024-12-02 15:25:54,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 274: ref_distribution = tensor([0.1195, 0.4490, 0.4315], device='cuda:0'), new_distribution = tensor([0.1196, 0.4495, 0.4309], device='cuda:0')
2024-12-02 15:25:54,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 275: ref_distribution = tensor([0.1196, 0.4495, 0.4309], device='cuda:0'), new_distribution = tensor([0.1197, 0.4500, 0.4303], device='cuda:0')
2024-12-02 15:25:54,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 276: ref_distribution = tensor([0.1197, 0.4500, 0.4303], device='cuda:0'), new_distribution = tensor([0.1198, 0.4505, 0.4297], device='cuda:0')
2024-12-02 15:25:54,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 277: ref_distribution = tensor([0.1198, 0.4505, 0.4297], device='cuda:0'), new_distribution = tensor([0.1199, 0.4510, 0.4290], device='cuda:0')
2024-12-02 15:25:54,666 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 278: ref_distribution = tensor([0.1199, 0.4510, 0.4290], device='cuda:0'), new_distribution = tensor([0.1200, 0.4516, 0.4284], device='cuda:0')
2024-12-02 15:25:54,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 279: ref_distribution = tensor([0.1200, 0.4516, 0.4284], device='cuda:0'), new_distribution = tensor([0.1201, 0.4521, 0.4278], device='cuda:0')
2024-12-02 15:25:54,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 280: ref_distribution = tensor([0.1201, 0.4521, 0.4278], device='cuda:0'), new_distribution = tensor([0.1202, 0.4526, 0.4272], device='cuda:0')
2024-12-02 15:25:54,860 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 281: ref_distribution = tensor([0.1202, 0.4526, 0.4272], device='cuda:0'), new_distribution = tensor([0.1203, 0.4531, 0.4266], device='cuda:0')
2024-12-02 15:25:54,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 282: ref_distribution = tensor([0.1203, 0.4531, 0.4266], device='cuda:0'), new_distribution = tensor([0.1204, 0.4536, 0.4259], device='cuda:0')
2024-12-02 15:25:54,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 283: ref_distribution = tensor([0.1204, 0.4536, 0.4259], device='cuda:0'), new_distribution = tensor([0.1206, 0.4541, 0.4253], device='cuda:0')
2024-12-02 15:25:55,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 284: ref_distribution = tensor([0.1206, 0.4541, 0.4253], device='cuda:0'), new_distribution = tensor([0.1207, 0.4547, 0.4247], device='cuda:0')
2024-12-02 15:25:55,119 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 285: ref_distribution = tensor([0.1207, 0.4547, 0.4247], device='cuda:0'), new_distribution = tensor([0.1208, 0.4552, 0.4241], device='cuda:0')
2024-12-02 15:25:55,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 286: ref_distribution = tensor([0.1208, 0.4552, 0.4241], device='cuda:0'), new_distribution = tensor([0.1209, 0.4557, 0.4234], device='cuda:0')
2024-12-02 15:25:55,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 287: ref_distribution = tensor([0.1209, 0.4557, 0.4234], device='cuda:0'), new_distribution = tensor([0.1210, 0.4562, 0.4228], device='cuda:0')
2024-12-02 15:25:55,314 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 288: ref_distribution = tensor([0.1210, 0.4562, 0.4228], device='cuda:0'), new_distribution = tensor([0.1211, 0.4567, 0.4222], device='cuda:0')
2024-12-02 15:25:55,378 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 289: ref_distribution = tensor([0.1211, 0.4567, 0.4222], device='cuda:0'), new_distribution = tensor([0.1212, 0.4572, 0.4216], device='cuda:0')
2024-12-02 15:25:55,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 290: ref_distribution = tensor([0.1212, 0.4572, 0.4216], device='cuda:0'), new_distribution = tensor([0.1213, 0.4577, 0.4210], device='cuda:0')
2024-12-02 15:25:55,507 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 291: ref_distribution = tensor([0.1213, 0.4577, 0.4210], device='cuda:0'), new_distribution = tensor([0.1214, 0.4582, 0.4203], device='cuda:0')
2024-12-02 15:25:55,572 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 292: ref_distribution = tensor([0.1214, 0.4582, 0.4203], device='cuda:0'), new_distribution = tensor([0.1216, 0.4587, 0.4197], device='cuda:0')
2024-12-02 15:25:55,637 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 293: ref_distribution = tensor([0.1216, 0.4587, 0.4197], device='cuda:0'), new_distribution = tensor([0.1217, 0.4592, 0.4191], device='cuda:0')
2024-12-02 15:25:55,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 294: ref_distribution = tensor([0.1217, 0.4592, 0.4191], device='cuda:0'), new_distribution = tensor([0.1218, 0.4598, 0.4185], device='cuda:0')
2024-12-02 15:25:55,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 295: ref_distribution = tensor([0.1218, 0.4598, 0.4185], device='cuda:0'), new_distribution = tensor([0.1219, 0.4603, 0.4178], device='cuda:0')
2024-12-02 15:25:55,831 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 296: ref_distribution = tensor([0.1219, 0.4603, 0.4178], device='cuda:0'), new_distribution = tensor([0.1220, 0.4608, 0.4172], device='cuda:0')
2024-12-02 15:25:55,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 297: ref_distribution = tensor([0.1220, 0.4608, 0.4172], device='cuda:0'), new_distribution = tensor([0.1221, 0.4613, 0.4166], device='cuda:0')
2024-12-02 15:25:55,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 298: ref_distribution = tensor([0.1221, 0.4613, 0.4166], device='cuda:0'), new_distribution = tensor([0.1222, 0.4618, 0.4160], device='cuda:0')
2024-12-02 15:25:56,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 299: ref_distribution = tensor([0.1222, 0.4618, 0.4160], device='cuda:0'), new_distribution = tensor([0.1223, 0.4623, 0.4154], device='cuda:0')
2024-12-02 15:26:52,185 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 0 loss: 0.0023 grad norm: 0.1341 
2024-12-02 15:26:53,237 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 5 loss: 0.0055 grad norm: 0.1716 
2024-12-02 15:26:54,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 10 loss: 0.0001 grad norm: 0.0274 
2024-12-02 15:26:55,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 15 loss: 0.0002 grad norm: 0.0331 
2024-12-02 15:26:55,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 20 loss: 0.0006 grad norm: 0.0457 
2024-12-02 15:26:56,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 25 loss: 0.0000 grad norm: 0.0120 
2024-12-02 15:26:57,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 30 loss: 0.0002 grad norm: 0.0309 
2024-12-02 15:26:58,020 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 35 loss: 0.0000 grad norm: 0.0057 
2024-12-02 15:26:58,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 40 loss: 0.0000 grad norm: 0.0031 
2024-12-02 15:26:59,510 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 45 loss: 0.0000 grad norm: 0.0040 
2024-12-02 15:27:00,255 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 50 loss: 0.0000 grad norm: 0.0018 
2024-12-02 15:27:00,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0020 
2024-12-02 15:27:01,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0017 
2024-12-02 15:27:02,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0007 
2024-12-02 15:27:03,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0006 
2024-12-02 15:27:03,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0005 
2024-12-02 15:27:04,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0002 
2024-12-02 15:27:05,478 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:27:06,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:27:06,971 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0001 
2024-12-02 15:27:07,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 0 loss: 1.8549 grad norm: 3.8212 
2024-12-02 15:27:08,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 5 loss: 0.0376 grad norm: 0.6428 
2024-12-02 15:27:09,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 10 loss: 0.0007 grad norm: 0.0726 
2024-12-02 15:27:10,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 15 loss: 0.0074 grad norm: 0.2006 
2024-12-02 15:27:10,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 20 loss: 0.0042 grad norm: 0.1365 
2024-12-02 15:27:11,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 25 loss: 0.0011 grad norm: 0.0783 
2024-12-02 15:27:12,402 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 30 loss: 0.0005 grad norm: 0.0590 
2024-12-02 15:27:13,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 35 loss: 0.0003 grad norm: 0.0411 
2024-12-02 15:27:13,895 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 40 loss: 0.0002 grad norm: 0.0363 
2024-12-02 15:27:14,639 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 45 loss: 0.0000 grad norm: 0.0117 
2024-12-02 15:27:15,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 50 loss: 0.0001 grad norm: 0.0163 
2024-12-02 15:27:16,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 55 loss: 0.0001 grad norm: 0.0166 
2024-12-02 15:27:16,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0065 
2024-12-02 15:27:17,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0085 
2024-12-02 15:27:18,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0075 
2024-12-02 15:27:19,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0004 
2024-12-02 15:27:19,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0044 
2024-12-02 15:27:20,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0031 
2024-12-02 15:27:21,344 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0009 
2024-12-02 15:27:22,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0014 
2024-12-02 15:27:23,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 0 loss: 672.2272 grad norm: 57.5506 
2024-12-02 15:27:23,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 5 loss: 0.5467 grad norm: 4.9993 
2024-12-02 15:27:24,562 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 10 loss: 0.4581 grad norm: 4.4087 
2024-12-02 15:27:25,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 15 loss: 0.0689 grad norm: 1.2834 
2024-12-02 15:27:26,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 20 loss: 0.0001 grad norm: 0.0415 
2024-12-02 15:27:26,814 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 25 loss: 0.0168 grad norm: 0.4507 
2024-12-02 15:27:27,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 30 loss: 0.0293 grad norm: 0.5695 
2024-12-02 15:27:28,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 35 loss: 0.0000 grad norm: 0.0232 
2024-12-02 15:27:29,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 40 loss: 0.0001 grad norm: 0.0354 
2024-12-02 15:27:29,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 45 loss: 0.0001 grad norm: 0.0340 
2024-12-02 15:27:30,551 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 50 loss: 0.0001 grad norm: 0.0250 
2024-12-02 15:27:31,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0138 
2024-12-02 15:27:32,049 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0054 
2024-12-02 15:27:32,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0053 
2024-12-02 15:27:33,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0080 
2024-12-02 15:27:34,294 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0074 
2024-12-02 15:27:35,042 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0050 
2024-12-02 15:27:35,788 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0025 
2024-12-02 15:27:36,531 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0013 
2024-12-02 15:27:37,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0012 
2024-12-02 15:27:38,247 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 0 loss: 1.0241 grad norm: 4.1638 
2024-12-02 15:27:38,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 5 loss: 0.0117 grad norm: 0.5408 
2024-12-02 15:27:39,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 10 loss: 0.0422 grad norm: 0.8213 
2024-12-02 15:27:40,482 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 15 loss: 0.0032 grad norm: 0.2584 
2024-12-02 15:27:41,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 20 loss: 0.0064 grad norm: 0.3605 
2024-12-02 15:27:41,972 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 25 loss: 0.0049 grad norm: 0.2710 
2024-12-02 15:27:42,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 30 loss: 0.0015 grad norm: 0.1529 
2024-12-02 15:27:43,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 35 loss: 0.0024 grad norm: 0.2056 
2024-12-02 15:27:44,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 40 loss: 0.0000 grad norm: 0.0149 
2024-12-02 15:27:44,959 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 45 loss: 0.0008 grad norm: 0.1110 
2024-12-02 15:27:45,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 50 loss: 0.0001 grad norm: 0.0445 
2024-12-02 15:27:46,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 55 loss: 0.0001 grad norm: 0.0485 
2024-12-02 15:27:47,197 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 60 loss: 0.0002 grad norm: 0.0499 
2024-12-02 15:27:47,943 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0039 
2024-12-02 15:27:48,686 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0008 
2024-12-02 15:27:49,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0020 
2024-12-02 15:27:50,173 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0017 
2024-12-02 15:27:50,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0003 
2024-12-02 15:27:51,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0010 
2024-12-02 15:27:52,409 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:455] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0007 
2024-12-02 15:39:43,262 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 0: ref_distribution = tensor([0.3333, 0.3333, 0.3333], device='cuda:0'), new_distribution = tensor([0.3336, 0.3334, 0.3330], device='cuda:0')
2024-12-02 15:39:43,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 1: ref_distribution = tensor([0.3336, 0.3334, 0.3330], device='cuda:0'), new_distribution = tensor([0.3338, 0.3335, 0.3327], device='cuda:0')
2024-12-02 15:39:43,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 2: ref_distribution = tensor([0.3338, 0.3335, 0.3327], device='cuda:0'), new_distribution = tensor([0.3340, 0.3336, 0.3324], device='cuda:0')
2024-12-02 15:39:43,534 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 3: ref_distribution = tensor([0.3340, 0.3336, 0.3324], device='cuda:0'), new_distribution = tensor([0.3342, 0.3337, 0.3321], device='cuda:0')
2024-12-02 15:39:43,629 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 4: ref_distribution = tensor([0.3342, 0.3337, 0.3321], device='cuda:0'), new_distribution = tensor([0.3344, 0.3338, 0.3318], device='cuda:0')
2024-12-02 15:39:43,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 5: ref_distribution = tensor([0.3344, 0.3338, 0.3318], device='cuda:0'), new_distribution = tensor([0.3346, 0.3339, 0.3315], device='cuda:0')
2024-12-02 15:39:43,814 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 6: ref_distribution = tensor([0.3346, 0.3339, 0.3315], device='cuda:0'), new_distribution = tensor([0.3349, 0.3340, 0.3312], device='cuda:0')
2024-12-02 15:39:43,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 7: ref_distribution = tensor([0.3349, 0.3340, 0.3312], device='cuda:0'), new_distribution = tensor([0.3351, 0.3341, 0.3309], device='cuda:0')
2024-12-02 15:39:43,998 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 8: ref_distribution = tensor([0.3351, 0.3341, 0.3309], device='cuda:0'), new_distribution = tensor([0.3353, 0.3341, 0.3306], device='cuda:0')
2024-12-02 15:39:44,088 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 9: ref_distribution = tensor([0.3353, 0.3341, 0.3306], device='cuda:0'), new_distribution = tensor([0.3355, 0.3342, 0.3302], device='cuda:0')
2024-12-02 15:39:44,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 10: ref_distribution = tensor([0.3355, 0.3342, 0.3302], device='cuda:0'), new_distribution = tensor([0.3357, 0.3343, 0.3299], device='cuda:0')
2024-12-02 15:39:44,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 11: ref_distribution = tensor([0.3357, 0.3343, 0.3299], device='cuda:0'), new_distribution = tensor([0.3360, 0.3344, 0.3296], device='cuda:0')
2024-12-02 15:39:44,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 12: ref_distribution = tensor([0.3360, 0.3344, 0.3296], device='cuda:0'), new_distribution = tensor([0.3362, 0.3345, 0.3293], device='cuda:0')
2024-12-02 15:39:44,456 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 13: ref_distribution = tensor([0.3362, 0.3345, 0.3293], device='cuda:0'), new_distribution = tensor([0.3364, 0.3346, 0.3290], device='cuda:0')
2024-12-02 15:39:44,550 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 14: ref_distribution = tensor([0.3364, 0.3346, 0.3290], device='cuda:0'), new_distribution = tensor([0.3366, 0.3347, 0.3287], device='cuda:0')
2024-12-02 15:39:44,646 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 15: ref_distribution = tensor([0.3366, 0.3347, 0.3287], device='cuda:0'), new_distribution = tensor([0.3369, 0.3347, 0.3284], device='cuda:0')
2024-12-02 15:39:44,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 16: ref_distribution = tensor([0.3369, 0.3347, 0.3284], device='cuda:0'), new_distribution = tensor([0.3371, 0.3348, 0.3281], device='cuda:0')
2024-12-02 15:39:44,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 17: ref_distribution = tensor([0.3371, 0.3348, 0.3281], device='cuda:0'), new_distribution = tensor([0.3373, 0.3349, 0.3278], device='cuda:0')
2024-12-02 15:39:44,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 18: ref_distribution = tensor([0.3373, 0.3349, 0.3278], device='cuda:0'), new_distribution = tensor([0.3375, 0.3350, 0.3275], device='cuda:0')
2024-12-02 15:39:45,015 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 19: ref_distribution = tensor([0.3375, 0.3350, 0.3275], device='cuda:0'), new_distribution = tensor([0.3377, 0.3351, 0.3272], device='cuda:0')
2024-12-02 15:39:45,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 20: ref_distribution = tensor([0.3377, 0.3351, 0.3272], device='cuda:0'), new_distribution = tensor([0.3380, 0.3352, 0.3269], device='cuda:0')
2024-12-02 15:39:45,199 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 21: ref_distribution = tensor([0.3380, 0.3352, 0.3269], device='cuda:0'), new_distribution = tensor([0.3382, 0.3352, 0.3266], device='cuda:0')
2024-12-02 15:39:45,295 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 22: ref_distribution = tensor([0.3382, 0.3352, 0.3266], device='cuda:0'), new_distribution = tensor([0.3384, 0.3353, 0.3263], device='cuda:0')
2024-12-02 15:39:45,385 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 23: ref_distribution = tensor([0.3384, 0.3353, 0.3263], device='cuda:0'), new_distribution = tensor([0.3386, 0.3354, 0.3260], device='cuda:0')
2024-12-02 15:39:45,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 24: ref_distribution = tensor([0.3386, 0.3354, 0.3260], device='cuda:0'), new_distribution = tensor([0.3389, 0.3355, 0.3257], device='cuda:0')
2024-12-02 15:39:45,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 25: ref_distribution = tensor([0.3389, 0.3355, 0.3257], device='cuda:0'), new_distribution = tensor([0.3391, 0.3356, 0.3253], device='cuda:0')
2024-12-02 15:39:45,625 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 26: ref_distribution = tensor([0.3391, 0.3356, 0.3253], device='cuda:0'), new_distribution = tensor([0.3393, 0.3356, 0.3250], device='cuda:0')
2024-12-02 15:39:45,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 27: ref_distribution = tensor([0.3393, 0.3356, 0.3250], device='cuda:0'), new_distribution = tensor([0.3395, 0.3357, 0.3247], device='cuda:0')
2024-12-02 15:39:45,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 28: ref_distribution = tensor([0.3395, 0.3357, 0.3247], device='cuda:0'), new_distribution = tensor([0.3398, 0.3358, 0.3244], device='cuda:0')
2024-12-02 15:39:45,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 29: ref_distribution = tensor([0.3398, 0.3358, 0.3244], device='cuda:0'), new_distribution = tensor([0.3400, 0.3359, 0.3241], device='cuda:0')
2024-12-02 15:39:45,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 30: ref_distribution = tensor([0.3400, 0.3359, 0.3241], device='cuda:0'), new_distribution = tensor([0.3402, 0.3360, 0.3238], device='cuda:0')
2024-12-02 15:39:45,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 31: ref_distribution = tensor([0.3402, 0.3360, 0.3238], device='cuda:0'), new_distribution = tensor([0.3404, 0.3360, 0.3235], device='cuda:0')
2024-12-02 15:39:46,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 32: ref_distribution = tensor([0.3404, 0.3360, 0.3235], device='cuda:0'), new_distribution = tensor([0.3407, 0.3361, 0.3232], device='cuda:0')
2024-12-02 15:39:46,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 33: ref_distribution = tensor([0.3407, 0.3361, 0.3232], device='cuda:0'), new_distribution = tensor([0.3409, 0.3362, 0.3229], device='cuda:0')
2024-12-02 15:39:46,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 34: ref_distribution = tensor([0.3409, 0.3362, 0.3229], device='cuda:0'), new_distribution = tensor([0.3411, 0.3363, 0.3226], device='cuda:0')
2024-12-02 15:39:46,223 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 35: ref_distribution = tensor([0.3411, 0.3363, 0.3226], device='cuda:0'), new_distribution = tensor([0.3414, 0.3363, 0.3223], device='cuda:0')
2024-12-02 15:39:46,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 36: ref_distribution = tensor([0.3414, 0.3363, 0.3223], device='cuda:0'), new_distribution = tensor([0.3416, 0.3364, 0.3220], device='cuda:0')
2024-12-02 15:39:46,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 37: ref_distribution = tensor([0.3416, 0.3364, 0.3220], device='cuda:0'), new_distribution = tensor([0.3418, 0.3365, 0.3217], device='cuda:0')
2024-12-02 15:39:46,418 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 38: ref_distribution = tensor([0.3418, 0.3365, 0.3217], device='cuda:0'), new_distribution = tensor([0.3420, 0.3365, 0.3214], device='cuda:0')
2024-12-02 15:39:46,482 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 39: ref_distribution = tensor([0.3420, 0.3365, 0.3214], device='cuda:0'), new_distribution = tensor([0.3423, 0.3366, 0.3211], device='cuda:0')
2024-12-02 15:39:46,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 40: ref_distribution = tensor([0.3423, 0.3366, 0.3211], device='cuda:0'), new_distribution = tensor([0.3425, 0.3367, 0.3208], device='cuda:0')
2024-12-02 15:39:46,617 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 41: ref_distribution = tensor([0.3425, 0.3367, 0.3208], device='cuda:0'), new_distribution = tensor([0.3427, 0.3368, 0.3205], device='cuda:0')
2024-12-02 15:39:46,686 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 42: ref_distribution = tensor([0.3427, 0.3368, 0.3205], device='cuda:0'), new_distribution = tensor([0.3430, 0.3368, 0.3202], device='cuda:0')
2024-12-02 15:39:46,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 43: ref_distribution = tensor([0.3430, 0.3368, 0.3202], device='cuda:0'), new_distribution = tensor([0.3432, 0.3369, 0.3199], device='cuda:0')
2024-12-02 15:39:46,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 44: ref_distribution = tensor([0.3432, 0.3369, 0.3199], device='cuda:0'), new_distribution = tensor([0.3434, 0.3370, 0.3196], device='cuda:0')
2024-12-02 15:39:46,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 45: ref_distribution = tensor([0.3434, 0.3370, 0.3196], device='cuda:0'), new_distribution = tensor([0.3436, 0.3370, 0.3193], device='cuda:0')
2024-12-02 15:39:46,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 46: ref_distribution = tensor([0.3436, 0.3370, 0.3193], device='cuda:0'), new_distribution = tensor([0.3439, 0.3371, 0.3190], device='cuda:0')
2024-12-02 15:39:47,019 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 47: ref_distribution = tensor([0.3439, 0.3371, 0.3190], device='cuda:0'), new_distribution = tensor([0.3441, 0.3372, 0.3187], device='cuda:0')
2024-12-02 15:39:47,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 48: ref_distribution = tensor([0.3441, 0.3372, 0.3187], device='cuda:0'), new_distribution = tensor([0.3443, 0.3372, 0.3184], device='cuda:0')
2024-12-02 15:39:47,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 49: ref_distribution = tensor([0.3443, 0.3372, 0.3184], device='cuda:0'), new_distribution = tensor([0.3446, 0.3373, 0.3181], device='cuda:0')
2024-12-02 15:39:47,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 50: ref_distribution = tensor([0.3446, 0.3373, 0.3181], device='cuda:0'), new_distribution = tensor([0.3448, 0.3374, 0.3178], device='cuda:0')
2024-12-02 15:39:47,282 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 51: ref_distribution = tensor([0.3448, 0.3374, 0.3178], device='cuda:0'), new_distribution = tensor([0.3450, 0.3374, 0.3175], device='cuda:0')
2024-12-02 15:39:47,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 52: ref_distribution = tensor([0.3450, 0.3374, 0.3175], device='cuda:0'), new_distribution = tensor([0.3453, 0.3375, 0.3172], device='cuda:0')
2024-12-02 15:39:47,416 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 53: ref_distribution = tensor([0.3453, 0.3375, 0.3172], device='cuda:0'), new_distribution = tensor([0.3455, 0.3376, 0.3169], device='cuda:0')
2024-12-02 15:39:47,484 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 54: ref_distribution = tensor([0.3455, 0.3376, 0.3169], device='cuda:0'), new_distribution = tensor([0.3457, 0.3376, 0.3166], device='cuda:0')
2024-12-02 15:39:47,550 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 55: ref_distribution = tensor([0.3457, 0.3376, 0.3166], device='cuda:0'), new_distribution = tensor([0.3460, 0.3377, 0.3163], device='cuda:0')
2024-12-02 15:39:47,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 56: ref_distribution = tensor([0.3460, 0.3377, 0.3163], device='cuda:0'), new_distribution = tensor([0.3462, 0.3378, 0.3160], device='cuda:0')
2024-12-02 15:39:47,683 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 57: ref_distribution = tensor([0.3462, 0.3378, 0.3160], device='cuda:0'), new_distribution = tensor([0.3464, 0.3378, 0.3157], device='cuda:0')
2024-12-02 15:39:47,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 58: ref_distribution = tensor([0.3464, 0.3378, 0.3157], device='cuda:0'), new_distribution = tensor([0.3467, 0.3379, 0.3154], device='cuda:0')
2024-12-02 15:39:47,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 59: ref_distribution = tensor([0.3467, 0.3379, 0.3154], device='cuda:0'), new_distribution = tensor([0.3469, 0.3380, 0.3151], device='cuda:0')
2024-12-02 15:39:47,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 60: ref_distribution = tensor([0.3469, 0.3380, 0.3151], device='cuda:0'), new_distribution = tensor([0.3471, 0.3380, 0.3149], device='cuda:0')
2024-12-02 15:39:47,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 61: ref_distribution = tensor([0.3471, 0.3380, 0.3149], device='cuda:0'), new_distribution = tensor([0.3474, 0.3381, 0.3146], device='cuda:0')
2024-12-02 15:39:48,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 62: ref_distribution = tensor([0.3474, 0.3381, 0.3146], device='cuda:0'), new_distribution = tensor([0.3476, 0.3381, 0.3143], device='cuda:0')
2024-12-02 15:39:48,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 63: ref_distribution = tensor([0.3476, 0.3381, 0.3143], device='cuda:0'), new_distribution = tensor([0.3478, 0.3382, 0.3140], device='cuda:0')
2024-12-02 15:39:48,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 64: ref_distribution = tensor([0.3478, 0.3382, 0.3140], device='cuda:0'), new_distribution = tensor([0.3481, 0.3383, 0.3137], device='cuda:0')
2024-12-02 15:39:48,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 65: ref_distribution = tensor([0.3481, 0.3383, 0.3137], device='cuda:0'), new_distribution = tensor([0.3483, 0.3383, 0.3134], device='cuda:0')
2024-12-02 15:39:48,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 66: ref_distribution = tensor([0.3483, 0.3383, 0.3134], device='cuda:0'), new_distribution = tensor([0.3485, 0.3384, 0.3131], device='cuda:0')
2024-12-02 15:39:48,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 67: ref_distribution = tensor([0.3485, 0.3384, 0.3131], device='cuda:0'), new_distribution = tensor([0.3488, 0.3384, 0.3128], device='cuda:0')
2024-12-02 15:39:48,418 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 68: ref_distribution = tensor([0.3488, 0.3384, 0.3128], device='cuda:0'), new_distribution = tensor([0.3490, 0.3385, 0.3125], device='cuda:0')
2024-12-02 15:39:48,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 69: ref_distribution = tensor([0.3490, 0.3385, 0.3125], device='cuda:0'), new_distribution = tensor([0.3493, 0.3385, 0.3122], device='cuda:0')
2024-12-02 15:39:48,550 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 70: ref_distribution = tensor([0.3493, 0.3385, 0.3122], device='cuda:0'), new_distribution = tensor([0.3495, 0.3386, 0.3119], device='cuda:0')
2024-12-02 15:39:48,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 71: ref_distribution = tensor([0.3495, 0.3386, 0.3119], device='cuda:0'), new_distribution = tensor([0.3497, 0.3386, 0.3116], device='cuda:0')
2024-12-02 15:39:48,686 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 72: ref_distribution = tensor([0.3497, 0.3386, 0.3116], device='cuda:0'), new_distribution = tensor([0.3500, 0.3387, 0.3113], device='cuda:0')
2024-12-02 15:39:48,751 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 73: ref_distribution = tensor([0.3500, 0.3387, 0.3113], device='cuda:0'), new_distribution = tensor([0.3502, 0.3388, 0.3110], device='cuda:0')
2024-12-02 15:39:48,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 74: ref_distribution = tensor([0.3502, 0.3388, 0.3110], device='cuda:0'), new_distribution = tensor([0.3504, 0.3388, 0.3107], device='cuda:0')
2024-12-02 15:39:48,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 75: ref_distribution = tensor([0.3504, 0.3388, 0.3107], device='cuda:0'), new_distribution = tensor([0.3507, 0.3389, 0.3104], device='cuda:0')
2024-12-02 15:39:48,945 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 76: ref_distribution = tensor([0.3507, 0.3389, 0.3104], device='cuda:0'), new_distribution = tensor([0.3509, 0.3389, 0.3102], device='cuda:0')
2024-12-02 15:39:49,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 77: ref_distribution = tensor([0.3509, 0.3389, 0.3102], device='cuda:0'), new_distribution = tensor([0.3512, 0.3390, 0.3099], device='cuda:0')
2024-12-02 15:39:49,075 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 78: ref_distribution = tensor([0.3512, 0.3390, 0.3099], device='cuda:0'), new_distribution = tensor([0.3514, 0.3390, 0.3096], device='cuda:0')
2024-12-02 15:39:49,140 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 79: ref_distribution = tensor([0.3514, 0.3390, 0.3096], device='cuda:0'), new_distribution = tensor([0.3516, 0.3391, 0.3093], device='cuda:0')
2024-12-02 15:39:49,205 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 80: ref_distribution = tensor([0.3516, 0.3391, 0.3093], device='cuda:0'), new_distribution = tensor([0.3519, 0.3391, 0.3090], device='cuda:0')
2024-12-02 15:39:49,269 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 81: ref_distribution = tensor([0.3519, 0.3391, 0.3090], device='cuda:0'), new_distribution = tensor([0.3521, 0.3392, 0.3087], device='cuda:0')
2024-12-02 15:39:49,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 82: ref_distribution = tensor([0.3521, 0.3392, 0.3087], device='cuda:0'), new_distribution = tensor([0.3524, 0.3392, 0.3084], device='cuda:0')
2024-12-02 15:39:49,399 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 83: ref_distribution = tensor([0.3524, 0.3392, 0.3084], device='cuda:0'), new_distribution = tensor([0.3526, 0.3393, 0.3081], device='cuda:0')
2024-12-02 15:39:49,463 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 84: ref_distribution = tensor([0.3526, 0.3393, 0.3081], device='cuda:0'), new_distribution = tensor([0.3528, 0.3393, 0.3078], device='cuda:0')
2024-12-02 15:39:49,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 85: ref_distribution = tensor([0.3528, 0.3393, 0.3078], device='cuda:0'), new_distribution = tensor([0.3531, 0.3394, 0.3075], device='cuda:0')
2024-12-02 15:39:49,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 86: ref_distribution = tensor([0.3531, 0.3394, 0.3075], device='cuda:0'), new_distribution = tensor([0.3533, 0.3394, 0.3073], device='cuda:0')
2024-12-02 15:39:49,657 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 87: ref_distribution = tensor([0.3533, 0.3394, 0.3073], device='cuda:0'), new_distribution = tensor([0.3536, 0.3395, 0.3070], device='cuda:0')
2024-12-02 15:39:49,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 88: ref_distribution = tensor([0.3536, 0.3395, 0.3070], device='cuda:0'), new_distribution = tensor([0.3538, 0.3395, 0.3067], device='cuda:0')
2024-12-02 15:39:49,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 89: ref_distribution = tensor([0.3538, 0.3395, 0.3067], device='cuda:0'), new_distribution = tensor([0.3541, 0.3396, 0.3064], device='cuda:0')
2024-12-02 15:39:49,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 90: ref_distribution = tensor([0.3541, 0.3396, 0.3064], device='cuda:0'), new_distribution = tensor([0.3543, 0.3396, 0.3061], device='cuda:0')
2024-12-02 15:39:49,915 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 91: ref_distribution = tensor([0.3543, 0.3396, 0.3061], device='cuda:0'), new_distribution = tensor([0.3545, 0.3396, 0.3058], device='cuda:0')
2024-12-02 15:39:49,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 92: ref_distribution = tensor([0.3545, 0.3396, 0.3058], device='cuda:0'), new_distribution = tensor([0.3548, 0.3397, 0.3055], device='cuda:0')
2024-12-02 15:39:50,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 93: ref_distribution = tensor([0.3548, 0.3397, 0.3055], device='cuda:0'), new_distribution = tensor([0.3550, 0.3397, 0.3052], device='cuda:0')
2024-12-02 15:39:50,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 94: ref_distribution = tensor([0.3550, 0.3397, 0.3052], device='cuda:0'), new_distribution = tensor([0.3553, 0.3398, 0.3050], device='cuda:0')
2024-12-02 15:39:50,174 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 95: ref_distribution = tensor([0.3553, 0.3398, 0.3050], device='cuda:0'), new_distribution = tensor([0.3555, 0.3398, 0.3047], device='cuda:0')
2024-12-02 15:39:50,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 96: ref_distribution = tensor([0.3555, 0.3398, 0.3047], device='cuda:0'), new_distribution = tensor([0.3558, 0.3399, 0.3044], device='cuda:0')
2024-12-02 15:39:50,303 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 97: ref_distribution = tensor([0.3558, 0.3399, 0.3044], device='cuda:0'), new_distribution = tensor([0.3560, 0.3399, 0.3041], device='cuda:0')
2024-12-02 15:39:50,368 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 98: ref_distribution = tensor([0.3560, 0.3399, 0.3041], device='cuda:0'), new_distribution = tensor([0.3562, 0.3399, 0.3038], device='cuda:0')
2024-12-02 15:39:50,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 99: ref_distribution = tensor([0.3562, 0.3399, 0.3038], device='cuda:0'), new_distribution = tensor([0.3565, 0.3400, 0.3035], device='cuda:0')
2024-12-02 15:39:50,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 0: ref_distribution = tensor([0.7000, 0.2000, 0.1000], device='cuda:0'), new_distribution = tensor([0.7003, 0.1997, 0.1000], device='cuda:0')
2024-12-02 15:39:50,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 1: ref_distribution = tensor([0.7003, 0.1997, 0.1000], device='cuda:0'), new_distribution = tensor([0.7006, 0.1994, 0.0999], device='cuda:0')
2024-12-02 15:39:50,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 2: ref_distribution = tensor([0.7006, 0.1994, 0.0999], device='cuda:0'), new_distribution = tensor([0.7009, 0.1991, 0.0999], device='cuda:0')
2024-12-02 15:39:50,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 3: ref_distribution = tensor([0.7009, 0.1991, 0.0999], device='cuda:0'), new_distribution = tensor([0.7013, 0.1988, 0.0999], device='cuda:0')
2024-12-02 15:39:50,978 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 4: ref_distribution = tensor([0.7013, 0.1988, 0.0999], device='cuda:0'), new_distribution = tensor([0.7016, 0.1986, 0.0999], device='cuda:0')
2024-12-02 15:39:51,043 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 5: ref_distribution = tensor([0.7016, 0.1986, 0.0999], device='cuda:0'), new_distribution = tensor([0.7019, 0.1983, 0.0998], device='cuda:0')
2024-12-02 15:39:51,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 6: ref_distribution = tensor([0.7019, 0.1983, 0.0998], device='cuda:0'), new_distribution = tensor([0.7022, 0.1980, 0.0998], device='cuda:0')
2024-12-02 15:39:51,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 7: ref_distribution = tensor([0.7022, 0.1980, 0.0998], device='cuda:0'), new_distribution = tensor([0.7025, 0.1977, 0.0998], device='cuda:0')
2024-12-02 15:39:51,237 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 8: ref_distribution = tensor([0.7025, 0.1977, 0.0998], device='cuda:0'), new_distribution = tensor([0.7028, 0.1974, 0.0998], device='cuda:0')
2024-12-02 15:39:51,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 9: ref_distribution = tensor([0.7028, 0.1974, 0.0998], device='cuda:0'), new_distribution = tensor([0.7031, 0.1971, 0.0997], device='cuda:0')
2024-12-02 15:39:51,367 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 10: ref_distribution = tensor([0.7031, 0.1971, 0.0997], device='cuda:0'), new_distribution = tensor([0.7035, 0.1968, 0.0997], device='cuda:0')
2024-12-02 15:39:51,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 11: ref_distribution = tensor([0.7035, 0.1968, 0.0997], device='cuda:0'), new_distribution = tensor([0.7038, 0.1965, 0.0997], device='cuda:0')
2024-12-02 15:39:51,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 12: ref_distribution = tensor([0.7038, 0.1965, 0.0997], device='cuda:0'), new_distribution = tensor([0.7041, 0.1963, 0.0997], device='cuda:0')
2024-12-02 15:39:51,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 13: ref_distribution = tensor([0.7041, 0.1963, 0.0997], device='cuda:0'), new_distribution = tensor([0.7044, 0.1960, 0.0996], device='cuda:0')
2024-12-02 15:39:51,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 14: ref_distribution = tensor([0.7044, 0.1960, 0.0996], device='cuda:0'), new_distribution = tensor([0.7047, 0.1957, 0.0996], device='cuda:0')
2024-12-02 15:39:51,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 15: ref_distribution = tensor([0.7047, 0.1957, 0.0996], device='cuda:0'), new_distribution = tensor([0.7050, 0.1954, 0.0996], device='cuda:0')
2024-12-02 15:39:51,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 16: ref_distribution = tensor([0.7050, 0.1954, 0.0996], device='cuda:0'), new_distribution = tensor([0.7053, 0.1951, 0.0996], device='cuda:0')
2024-12-02 15:39:51,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 17: ref_distribution = tensor([0.7053, 0.1951, 0.0996], device='cuda:0'), new_distribution = tensor([0.7056, 0.1948, 0.0995], device='cuda:0')
2024-12-02 15:39:51,886 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 18: ref_distribution = tensor([0.7056, 0.1948, 0.0995], device='cuda:0'), new_distribution = tensor([0.7059, 0.1945, 0.0995], device='cuda:0')
2024-12-02 15:39:51,951 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 19: ref_distribution = tensor([0.7059, 0.1945, 0.0995], device='cuda:0'), new_distribution = tensor([0.7062, 0.1943, 0.0995], device='cuda:0')
2024-12-02 15:39:52,015 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 20: ref_distribution = tensor([0.7062, 0.1943, 0.0995], device='cuda:0'), new_distribution = tensor([0.7066, 0.1940, 0.0995], device='cuda:0')
2024-12-02 15:39:52,080 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 21: ref_distribution = tensor([0.7066, 0.1940, 0.0995], device='cuda:0'), new_distribution = tensor([0.7069, 0.1937, 0.0994], device='cuda:0')
2024-12-02 15:39:52,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 22: ref_distribution = tensor([0.7069, 0.1937, 0.0994], device='cuda:0'), new_distribution = tensor([0.7072, 0.1934, 0.0994], device='cuda:0')
2024-12-02 15:39:52,213 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 23: ref_distribution = tensor([0.7072, 0.1934, 0.0994], device='cuda:0'), new_distribution = tensor([0.7075, 0.1931, 0.0994], device='cuda:0')
2024-12-02 15:39:52,278 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 24: ref_distribution = tensor([0.7075, 0.1931, 0.0994], device='cuda:0'), new_distribution = tensor([0.7078, 0.1928, 0.0994], device='cuda:0')
2024-12-02 15:39:52,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 25: ref_distribution = tensor([0.7078, 0.1928, 0.0994], device='cuda:0'), new_distribution = tensor([0.7081, 0.1926, 0.0994], device='cuda:0')
2024-12-02 15:39:52,408 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 26: ref_distribution = tensor([0.7081, 0.1926, 0.0994], device='cuda:0'), new_distribution = tensor([0.7084, 0.1923, 0.0993], device='cuda:0')
2024-12-02 15:39:52,472 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 27: ref_distribution = tensor([0.7084, 0.1923, 0.0993], device='cuda:0'), new_distribution = tensor([0.7087, 0.1920, 0.0993], device='cuda:0')
2024-12-02 15:39:52,537 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 28: ref_distribution = tensor([0.7087, 0.1920, 0.0993], device='cuda:0'), new_distribution = tensor([0.7090, 0.1917, 0.0993], device='cuda:0')
2024-12-02 15:39:52,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 29: ref_distribution = tensor([0.7090, 0.1917, 0.0993], device='cuda:0'), new_distribution = tensor([0.7093, 0.1914, 0.0993], device='cuda:0')
2024-12-02 15:39:52,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 30: ref_distribution = tensor([0.7093, 0.1914, 0.0993], device='cuda:0'), new_distribution = tensor([0.7096, 0.1912, 0.0992], device='cuda:0')
2024-12-02 15:39:52,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 31: ref_distribution = tensor([0.7096, 0.1912, 0.0992], device='cuda:0'), new_distribution = tensor([0.7099, 0.1909, 0.0992], device='cuda:0')
2024-12-02 15:39:52,798 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 32: ref_distribution = tensor([0.7099, 0.1909, 0.0992], device='cuda:0'), new_distribution = tensor([0.7102, 0.1906, 0.0992], device='cuda:0')
2024-12-02 15:39:52,863 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 33: ref_distribution = tensor([0.7102, 0.1906, 0.0992], device='cuda:0'), new_distribution = tensor([0.7105, 0.1903, 0.0992], device='cuda:0')
2024-12-02 15:39:52,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 34: ref_distribution = tensor([0.7105, 0.1903, 0.0992], device='cuda:0'), new_distribution = tensor([0.7108, 0.1900, 0.0991], device='cuda:0')
2024-12-02 15:39:52,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 35: ref_distribution = tensor([0.7108, 0.1900, 0.0991], device='cuda:0'), new_distribution = tensor([0.7111, 0.1897, 0.0991], device='cuda:0')
2024-12-02 15:39:53,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 36: ref_distribution = tensor([0.7111, 0.1897, 0.0991], device='cuda:0'), new_distribution = tensor([0.7114, 0.1895, 0.0991], device='cuda:0')
2024-12-02 15:39:53,121 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 37: ref_distribution = tensor([0.7114, 0.1895, 0.0991], device='cuda:0'), new_distribution = tensor([0.7117, 0.1892, 0.0991], device='cuda:0')
2024-12-02 15:39:53,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 38: ref_distribution = tensor([0.7117, 0.1892, 0.0991], device='cuda:0'), new_distribution = tensor([0.7120, 0.1889, 0.0991], device='cuda:0')
2024-12-02 15:39:53,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 39: ref_distribution = tensor([0.7120, 0.1889, 0.0991], device='cuda:0'), new_distribution = tensor([0.7123, 0.1886, 0.0990], device='cuda:0')
2024-12-02 15:39:53,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 40: ref_distribution = tensor([0.7123, 0.1886, 0.0990], device='cuda:0'), new_distribution = tensor([0.7126, 0.1883, 0.0990], device='cuda:0')
2024-12-02 15:39:53,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 41: ref_distribution = tensor([0.7126, 0.1883, 0.0990], device='cuda:0'), new_distribution = tensor([0.7129, 0.1881, 0.0990], device='cuda:0')
2024-12-02 15:39:53,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 42: ref_distribution = tensor([0.7129, 0.1881, 0.0990], device='cuda:0'), new_distribution = tensor([0.7132, 0.1878, 0.0990], device='cuda:0')
2024-12-02 15:39:53,509 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 43: ref_distribution = tensor([0.7132, 0.1878, 0.0990], device='cuda:0'), new_distribution = tensor([0.7135, 0.1875, 0.0990], device='cuda:0')
2024-12-02 15:39:53,574 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 44: ref_distribution = tensor([0.7135, 0.1875, 0.0990], device='cuda:0'), new_distribution = tensor([0.7138, 0.1872, 0.0989], device='cuda:0')
2024-12-02 15:39:53,638 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 45: ref_distribution = tensor([0.7138, 0.1872, 0.0989], device='cuda:0'), new_distribution = tensor([0.7141, 0.1870, 0.0989], device='cuda:0')
2024-12-02 15:39:53,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 46: ref_distribution = tensor([0.7141, 0.1870, 0.0989], device='cuda:0'), new_distribution = tensor([0.7144, 0.1867, 0.0989], device='cuda:0')
2024-12-02 15:39:53,768 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 47: ref_distribution = tensor([0.7144, 0.1867, 0.0989], device='cuda:0'), new_distribution = tensor([0.7147, 0.1864, 0.0989], device='cuda:0')
2024-12-02 15:39:53,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 48: ref_distribution = tensor([0.7147, 0.1864, 0.0989], device='cuda:0'), new_distribution = tensor([0.7150, 0.1861, 0.0988], device='cuda:0')
2024-12-02 15:39:53,897 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 49: ref_distribution = tensor([0.7150, 0.1861, 0.0988], device='cuda:0'), new_distribution = tensor([0.7153, 0.1858, 0.0988], device='cuda:0')
2024-12-02 15:39:53,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 50: ref_distribution = tensor([0.7153, 0.1858, 0.0988], device='cuda:0'), new_distribution = tensor([0.7156, 0.1856, 0.0988], device='cuda:0')
2024-12-02 15:39:54,026 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 51: ref_distribution = tensor([0.7156, 0.1856, 0.0988], device='cuda:0'), new_distribution = tensor([0.7159, 0.1853, 0.0988], device='cuda:0')
2024-12-02 15:39:54,091 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 52: ref_distribution = tensor([0.7159, 0.1853, 0.0988], device='cuda:0'), new_distribution = tensor([0.7162, 0.1850, 0.0988], device='cuda:0')
2024-12-02 15:39:54,156 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 53: ref_distribution = tensor([0.7162, 0.1850, 0.0988], device='cuda:0'), new_distribution = tensor([0.7165, 0.1847, 0.0987], device='cuda:0')
2024-12-02 15:39:54,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 54: ref_distribution = tensor([0.7165, 0.1847, 0.0987], device='cuda:0'), new_distribution = tensor([0.7168, 0.1845, 0.0987], device='cuda:0')
2024-12-02 15:39:54,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 55: ref_distribution = tensor([0.7168, 0.1845, 0.0987], device='cuda:0'), new_distribution = tensor([0.7171, 0.1842, 0.0987], device='cuda:0')
2024-12-02 15:39:54,350 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 56: ref_distribution = tensor([0.7171, 0.1842, 0.0987], device='cuda:0'), new_distribution = tensor([0.7174, 0.1839, 0.0987], device='cuda:0')
2024-12-02 15:39:54,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 57: ref_distribution = tensor([0.7174, 0.1839, 0.0987], device='cuda:0'), new_distribution = tensor([0.7177, 0.1836, 0.0987], device='cuda:0')
2024-12-02 15:39:54,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 58: ref_distribution = tensor([0.7177, 0.1836, 0.0987], device='cuda:0'), new_distribution = tensor([0.7180, 0.1834, 0.0986], device='cuda:0')
2024-12-02 15:39:54,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 59: ref_distribution = tensor([0.7180, 0.1834, 0.0986], device='cuda:0'), new_distribution = tensor([0.7183, 0.1831, 0.0986], device='cuda:0')
2024-12-02 15:39:54,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 60: ref_distribution = tensor([0.7183, 0.1831, 0.0986], device='cuda:0'), new_distribution = tensor([0.7186, 0.1828, 0.0986], device='cuda:0')
2024-12-02 15:39:54,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 61: ref_distribution = tensor([0.7186, 0.1828, 0.0986], device='cuda:0'), new_distribution = tensor([0.7189, 0.1825, 0.0986], device='cuda:0')
2024-12-02 15:39:54,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 62: ref_distribution = tensor([0.7189, 0.1825, 0.0986], device='cuda:0'), new_distribution = tensor([0.7192, 0.1823, 0.0986], device='cuda:0')
2024-12-02 15:39:54,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 63: ref_distribution = tensor([0.7192, 0.1823, 0.0986], device='cuda:0'), new_distribution = tensor([0.7195, 0.1820, 0.0985], device='cuda:0')
2024-12-02 15:39:54,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 64: ref_distribution = tensor([0.7195, 0.1820, 0.0985], device='cuda:0'), new_distribution = tensor([0.7197, 0.1817, 0.0985], device='cuda:0')
2024-12-02 15:39:54,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 65: ref_distribution = tensor([0.7197, 0.1817, 0.0985], device='cuda:0'), new_distribution = tensor([0.7200, 0.1815, 0.0985], device='cuda:0')
2024-12-02 15:39:54,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 66: ref_distribution = tensor([0.7200, 0.1815, 0.0985], device='cuda:0'), new_distribution = tensor([0.7203, 0.1812, 0.0985], device='cuda:0')
2024-12-02 15:39:55,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 67: ref_distribution = tensor([0.7203, 0.1812, 0.0985], device='cuda:0'), new_distribution = tensor([0.7206, 0.1809, 0.0985], device='cuda:0')
2024-12-02 15:39:55,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 68: ref_distribution = tensor([0.7206, 0.1809, 0.0985], device='cuda:0'), new_distribution = tensor([0.7209, 0.1806, 0.0985], device='cuda:0')
2024-12-02 15:39:55,189 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 69: ref_distribution = tensor([0.7209, 0.1806, 0.0985], device='cuda:0'), new_distribution = tensor([0.7212, 0.1804, 0.0984], device='cuda:0')
2024-12-02 15:39:55,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 70: ref_distribution = tensor([0.7212, 0.1804, 0.0984], device='cuda:0'), new_distribution = tensor([0.7215, 0.1801, 0.0984], device='cuda:0')
2024-12-02 15:39:55,319 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 71: ref_distribution = tensor([0.7215, 0.1801, 0.0984], device='cuda:0'), new_distribution = tensor([0.7218, 0.1798, 0.0984], device='cuda:0')
2024-12-02 15:39:55,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 72: ref_distribution = tensor([0.7218, 0.1798, 0.0984], device='cuda:0'), new_distribution = tensor([0.7221, 0.1795, 0.0984], device='cuda:0')
2024-12-02 15:39:55,448 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 73: ref_distribution = tensor([0.7221, 0.1795, 0.0984], device='cuda:0'), new_distribution = tensor([0.7224, 0.1793, 0.0984], device='cuda:0')
2024-12-02 15:39:55,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 74: ref_distribution = tensor([0.7224, 0.1793, 0.0984], device='cuda:0'), new_distribution = tensor([0.7226, 0.1790, 0.0983], device='cuda:0')
2024-12-02 15:39:55,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 75: ref_distribution = tensor([0.7226, 0.1790, 0.0983], device='cuda:0'), new_distribution = tensor([0.7229, 0.1787, 0.0983], device='cuda:0')
2024-12-02 15:39:55,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 76: ref_distribution = tensor([0.7229, 0.1787, 0.0983], device='cuda:0'), new_distribution = tensor([0.7232, 0.1785, 0.0983], device='cuda:0')
2024-12-02 15:39:55,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 77: ref_distribution = tensor([0.7232, 0.1785, 0.0983], device='cuda:0'), new_distribution = tensor([0.7235, 0.1782, 0.0983], device='cuda:0')
2024-12-02 15:39:55,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 78: ref_distribution = tensor([0.7235, 0.1782, 0.0983], device='cuda:0'), new_distribution = tensor([0.7238, 0.1779, 0.0983], device='cuda:0')
2024-12-02 15:39:55,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 79: ref_distribution = tensor([0.7238, 0.1779, 0.0983], device='cuda:0'), new_distribution = tensor([0.7241, 0.1777, 0.0983], device='cuda:0')
2024-12-02 15:39:55,901 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 80: ref_distribution = tensor([0.7241, 0.1777, 0.0983], device='cuda:0'), new_distribution = tensor([0.7244, 0.1774, 0.0982], device='cuda:0')
2024-12-02 15:39:55,965 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 81: ref_distribution = tensor([0.7244, 0.1774, 0.0982], device='cuda:0'), new_distribution = tensor([0.7247, 0.1771, 0.0982], device='cuda:0')
2024-12-02 15:39:56,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 82: ref_distribution = tensor([0.7247, 0.1771, 0.0982], device='cuda:0'), new_distribution = tensor([0.7249, 0.1769, 0.0982], device='cuda:0')
2024-12-02 15:39:56,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 83: ref_distribution = tensor([0.7249, 0.1769, 0.0982], device='cuda:0'), new_distribution = tensor([0.7252, 0.1766, 0.0982], device='cuda:0')
2024-12-02 15:39:56,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 84: ref_distribution = tensor([0.7252, 0.1766, 0.0982], device='cuda:0'), new_distribution = tensor([0.7255, 0.1763, 0.0982], device='cuda:0')
2024-12-02 15:39:56,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 85: ref_distribution = tensor([0.7255, 0.1763, 0.0982], device='cuda:0'), new_distribution = tensor([0.7258, 0.1761, 0.0982], device='cuda:0')
2024-12-02 15:39:56,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 86: ref_distribution = tensor([0.7258, 0.1761, 0.0982], device='cuda:0'), new_distribution = tensor([0.7261, 0.1758, 0.0981], device='cuda:0')
2024-12-02 15:39:56,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 87: ref_distribution = tensor([0.7261, 0.1758, 0.0981], device='cuda:0'), new_distribution = tensor([0.7264, 0.1755, 0.0981], device='cuda:0')
2024-12-02 15:39:56,416 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 88: ref_distribution = tensor([0.7264, 0.1755, 0.0981], device='cuda:0'), new_distribution = tensor([0.7266, 0.1753, 0.0981], device='cuda:0')
2024-12-02 15:39:56,480 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 89: ref_distribution = tensor([0.7266, 0.1753, 0.0981], device='cuda:0'), new_distribution = tensor([0.7269, 0.1750, 0.0981], device='cuda:0')
2024-12-02 15:39:56,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 90: ref_distribution = tensor([0.7269, 0.1750, 0.0981], device='cuda:0'), new_distribution = tensor([0.7272, 0.1747, 0.0981], device='cuda:0')
2024-12-02 15:39:56,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 91: ref_distribution = tensor([0.7272, 0.1747, 0.0981], device='cuda:0'), new_distribution = tensor([0.7275, 0.1745, 0.0981], device='cuda:0')
2024-12-02 15:39:56,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 92: ref_distribution = tensor([0.7275, 0.1745, 0.0981], device='cuda:0'), new_distribution = tensor([0.7278, 0.1742, 0.0980], device='cuda:0')
2024-12-02 15:39:56,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 93: ref_distribution = tensor([0.7278, 0.1742, 0.0980], device='cuda:0'), new_distribution = tensor([0.7280, 0.1739, 0.0980], device='cuda:0')
2024-12-02 15:39:56,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 94: ref_distribution = tensor([0.7280, 0.1739, 0.0980], device='cuda:0'), new_distribution = tensor([0.7283, 0.1737, 0.0980], device='cuda:0')
2024-12-02 15:39:56,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 95: ref_distribution = tensor([0.7283, 0.1737, 0.0980], device='cuda:0'), new_distribution = tensor([0.7286, 0.1734, 0.0980], device='cuda:0')
2024-12-02 15:39:56,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 96: ref_distribution = tensor([0.7286, 0.1734, 0.0980], device='cuda:0'), new_distribution = tensor([0.7289, 0.1731, 0.0980], device='cuda:0')
2024-12-02 15:39:56,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 97: ref_distribution = tensor([0.7289, 0.1731, 0.0980], device='cuda:0'), new_distribution = tensor([0.7292, 0.1729, 0.0980], device='cuda:0')
2024-12-02 15:39:57,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 98: ref_distribution = tensor([0.7292, 0.1729, 0.0980], device='cuda:0'), new_distribution = tensor([0.7294, 0.1726, 0.0980], device='cuda:0')
2024-12-02 15:39:57,128 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 99: ref_distribution = tensor([0.7294, 0.1726, 0.0980], device='cuda:0'), new_distribution = tensor([0.7297, 0.1723, 0.0979], device='cuda:0')
2024-12-02 15:39:57,413 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 0: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:57,477 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 1: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:57,542 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 2: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:57,606 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 3: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:57,671 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 4: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:57,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 5: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:57,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 6: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:57,864 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 7: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:57,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 8: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:57,993 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 9: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 10: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,122 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 11: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 12: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 13: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 14: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 15: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 16: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,509 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 17: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 18: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,637 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 19: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,699 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 20: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,763 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 21: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,827 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 22: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,892 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 23: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:58,956 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 24: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,020 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 25: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,088 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 26: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,152 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 27: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 28: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,281 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 29: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,345 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 30: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,410 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 31: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 32: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,538 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 33: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 34: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 35: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 36: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,797 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 37: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,861 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 38: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 39: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:39:59,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 40: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 41: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,119 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 42: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 43: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 44: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,313 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 45: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 46: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,442 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 47: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,506 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 48: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,571 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 49: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,635 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 50: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 51: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 52: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 53: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,894 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 54: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:00,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 55: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,022 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 56: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 57: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 58: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,216 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 59: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 60: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,344 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 61: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,409 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 62: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 63: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,538 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 64: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 65: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 66: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 67: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 68: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,860 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 69: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 70: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:01,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 71: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 72: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,119 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 73: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 74: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 75: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 76: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 77: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 78: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,506 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 79: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 80: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,632 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 81: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 82: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,763 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 83: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,828 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 84: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 85: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:02,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 86: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:03,024 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 87: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:03,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 88: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:03,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 89: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:03,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 90: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:03,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 91: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:03,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 92: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:03,412 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 93: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:03,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 94: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:03,541 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 95: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:03,605 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 96: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:03,670 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 97: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:03,734 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 98: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:03,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 99: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-02 15:40:04,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 0: ref_distribution = tensor([0.1000, 0.3000, 0.6000], device='cuda:0'), new_distribution = tensor([0.1000, 0.3005, 0.5994], device='cuda:0')
2024-12-02 15:40:04,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 1: ref_distribution = tensor([0.1000, 0.3005, 0.5994], device='cuda:0'), new_distribution = tensor([0.1001, 0.3011, 0.5989], device='cuda:0')
2024-12-02 15:40:04,215 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 2: ref_distribution = tensor([0.1001, 0.3011, 0.5989], device='cuda:0'), new_distribution = tensor([0.1001, 0.3016, 0.5983], device='cuda:0')
2024-12-02 15:40:04,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 3: ref_distribution = tensor([0.1001, 0.3016, 0.5983], device='cuda:0'), new_distribution = tensor([0.1002, 0.3021, 0.5977], device='cuda:0')
2024-12-02 15:40:04,345 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 4: ref_distribution = tensor([0.1002, 0.3021, 0.5977], device='cuda:0'), new_distribution = tensor([0.1002, 0.3027, 0.5971], device='cuda:0')
2024-12-02 15:40:04,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 5: ref_distribution = tensor([0.1002, 0.3027, 0.5971], device='cuda:0'), new_distribution = tensor([0.1002, 0.3032, 0.5966], device='cuda:0')
2024-12-02 15:40:04,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 6: ref_distribution = tensor([0.1002, 0.3032, 0.5966], device='cuda:0'), new_distribution = tensor([0.1003, 0.3037, 0.5960], device='cuda:0')
2024-12-02 15:40:04,540 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 7: ref_distribution = tensor([0.1003, 0.3037, 0.5960], device='cuda:0'), new_distribution = tensor([0.1003, 0.3043, 0.5954], device='cuda:0')
2024-12-02 15:40:04,605 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 8: ref_distribution = tensor([0.1003, 0.3043, 0.5954], device='cuda:0'), new_distribution = tensor([0.1004, 0.3048, 0.5948], device='cuda:0')
2024-12-02 15:40:04,670 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 9: ref_distribution = tensor([0.1004, 0.3048, 0.5948], device='cuda:0'), new_distribution = tensor([0.1004, 0.3053, 0.5942], device='cuda:0')
2024-12-02 15:40:04,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 10: ref_distribution = tensor([0.1004, 0.3053, 0.5942], device='cuda:0'), new_distribution = tensor([0.1005, 0.3059, 0.5937], device='cuda:0')
2024-12-02 15:40:04,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 11: ref_distribution = tensor([0.1005, 0.3059, 0.5937], device='cuda:0'), new_distribution = tensor([0.1005, 0.3064, 0.5931], device='cuda:0')
2024-12-02 15:40:04,864 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 12: ref_distribution = tensor([0.1005, 0.3064, 0.5931], device='cuda:0'), new_distribution = tensor([0.1005, 0.3069, 0.5925], device='cuda:0')
2024-12-02 15:40:04,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 13: ref_distribution = tensor([0.1005, 0.3069, 0.5925], device='cuda:0'), new_distribution = tensor([0.1006, 0.3075, 0.5919], device='cuda:0')
2024-12-02 15:40:04,993 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 14: ref_distribution = tensor([0.1006, 0.3075, 0.5919], device='cuda:0'), new_distribution = tensor([0.1006, 0.3080, 0.5913], device='cuda:0')
2024-12-02 15:40:05,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 15: ref_distribution = tensor([0.1006, 0.3080, 0.5913], device='cuda:0'), new_distribution = tensor([0.1007, 0.3086, 0.5908], device='cuda:0')
2024-12-02 15:40:05,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 16: ref_distribution = tensor([0.1007, 0.3086, 0.5908], device='cuda:0'), new_distribution = tensor([0.1007, 0.3091, 0.5902], device='cuda:0')
2024-12-02 15:40:05,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 17: ref_distribution = tensor([0.1007, 0.3091, 0.5902], device='cuda:0'), new_distribution = tensor([0.1008, 0.3096, 0.5896], device='cuda:0')
2024-12-02 15:40:05,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 18: ref_distribution = tensor([0.1008, 0.3096, 0.5896], device='cuda:0'), new_distribution = tensor([0.1008, 0.3102, 0.5890], device='cuda:0')
2024-12-02 15:40:05,322 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 19: ref_distribution = tensor([0.1008, 0.3102, 0.5890], device='cuda:0'), new_distribution = tensor([0.1009, 0.3107, 0.5884], device='cuda:0')
2024-12-02 15:40:05,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 20: ref_distribution = tensor([0.1009, 0.3107, 0.5884], device='cuda:0'), new_distribution = tensor([0.1009, 0.3112, 0.5879], device='cuda:0')
2024-12-02 15:40:05,452 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 21: ref_distribution = tensor([0.1009, 0.3112, 0.5879], device='cuda:0'), new_distribution = tensor([0.1009, 0.3118, 0.5873], device='cuda:0')
2024-12-02 15:40:05,517 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 22: ref_distribution = tensor([0.1009, 0.3118, 0.5873], device='cuda:0'), new_distribution = tensor([0.1010, 0.3123, 0.5867], device='cuda:0')
2024-12-02 15:40:05,581 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 23: ref_distribution = tensor([0.1010, 0.3123, 0.5867], device='cuda:0'), new_distribution = tensor([0.1010, 0.3129, 0.5861], device='cuda:0')
2024-12-02 15:40:05,646 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 24: ref_distribution = tensor([0.1010, 0.3129, 0.5861], device='cuda:0'), new_distribution = tensor([0.1011, 0.3134, 0.5855], device='cuda:0')
2024-12-02 15:40:05,711 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 25: ref_distribution = tensor([0.1011, 0.3134, 0.5855], device='cuda:0'), new_distribution = tensor([0.1011, 0.3139, 0.5849], device='cuda:0')
2024-12-02 15:40:05,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 26: ref_distribution = tensor([0.1011, 0.3139, 0.5849], device='cuda:0'), new_distribution = tensor([0.1012, 0.3145, 0.5843], device='cuda:0')
2024-12-02 15:40:05,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 27: ref_distribution = tensor([0.1012, 0.3145, 0.5843], device='cuda:0'), new_distribution = tensor([0.1012, 0.3150, 0.5838], device='cuda:0')
2024-12-02 15:40:05,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 28: ref_distribution = tensor([0.1012, 0.3150, 0.5838], device='cuda:0'), new_distribution = tensor([0.1013, 0.3156, 0.5832], device='cuda:0')
2024-12-02 15:40:05,970 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 29: ref_distribution = tensor([0.1013, 0.3156, 0.5832], device='cuda:0'), new_distribution = tensor([0.1013, 0.3161, 0.5826], device='cuda:0')
2024-12-02 15:40:06,035 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 30: ref_distribution = tensor([0.1013, 0.3161, 0.5826], device='cuda:0'), new_distribution = tensor([0.1014, 0.3166, 0.5820], device='cuda:0')
2024-12-02 15:40:06,100 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 31: ref_distribution = tensor([0.1014, 0.3166, 0.5820], device='cuda:0'), new_distribution = tensor([0.1014, 0.3172, 0.5814], device='cuda:0')
2024-12-02 15:40:06,165 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 32: ref_distribution = tensor([0.1014, 0.3172, 0.5814], device='cuda:0'), new_distribution = tensor([0.1015, 0.3177, 0.5808], device='cuda:0')
2024-12-02 15:40:06,230 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 33: ref_distribution = tensor([0.1015, 0.3177, 0.5808], device='cuda:0'), new_distribution = tensor([0.1015, 0.3183, 0.5802], device='cuda:0')
2024-12-02 15:40:06,294 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 34: ref_distribution = tensor([0.1015, 0.3183, 0.5802], device='cuda:0'), new_distribution = tensor([0.1016, 0.3188, 0.5796], device='cuda:0')
2024-12-02 15:40:06,359 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 35: ref_distribution = tensor([0.1016, 0.3188, 0.5796], device='cuda:0'), new_distribution = tensor([0.1016, 0.3193, 0.5791], device='cuda:0')
2024-12-02 15:40:06,423 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 36: ref_distribution = tensor([0.1016, 0.3193, 0.5791], device='cuda:0'), new_distribution = tensor([0.1016, 0.3199, 0.5785], device='cuda:0')
2024-12-02 15:40:06,488 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 37: ref_distribution = tensor([0.1016, 0.3199, 0.5785], device='cuda:0'), new_distribution = tensor([0.1017, 0.3204, 0.5779], device='cuda:0')
2024-12-02 15:40:06,553 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 38: ref_distribution = tensor([0.1017, 0.3204, 0.5779], device='cuda:0'), new_distribution = tensor([0.1017, 0.3210, 0.5773], device='cuda:0')
2024-12-02 15:40:06,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 39: ref_distribution = tensor([0.1017, 0.3210, 0.5773], device='cuda:0'), new_distribution = tensor([0.1018, 0.3215, 0.5767], device='cuda:0')
2024-12-02 15:40:06,682 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 40: ref_distribution = tensor([0.1018, 0.3215, 0.5767], device='cuda:0'), new_distribution = tensor([0.1018, 0.3221, 0.5761], device='cuda:0')
2024-12-02 15:40:06,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 41: ref_distribution = tensor([0.1018, 0.3221, 0.5761], device='cuda:0'), new_distribution = tensor([0.1019, 0.3226, 0.5755], device='cuda:0')
2024-12-02 15:40:06,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 42: ref_distribution = tensor([0.1019, 0.3226, 0.5755], device='cuda:0'), new_distribution = tensor([0.1019, 0.3231, 0.5749], device='cuda:0')
2024-12-02 15:40:06,876 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 43: ref_distribution = tensor([0.1019, 0.3231, 0.5749], device='cuda:0'), new_distribution = tensor([0.1020, 0.3237, 0.5743], device='cuda:0')
2024-12-02 15:40:06,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 44: ref_distribution = tensor([0.1020, 0.3237, 0.5743], device='cuda:0'), new_distribution = tensor([0.1020, 0.3242, 0.5737], device='cuda:0')
2024-12-02 15:40:07,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 45: ref_distribution = tensor([0.1020, 0.3242, 0.5737], device='cuda:0'), new_distribution = tensor([0.1021, 0.3248, 0.5731], device='cuda:0')
2024-12-02 15:40:07,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 46: ref_distribution = tensor([0.1021, 0.3248, 0.5731], device='cuda:0'), new_distribution = tensor([0.1021, 0.3253, 0.5725], device='cuda:0')
2024-12-02 15:40:07,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 47: ref_distribution = tensor([0.1021, 0.3253, 0.5725], device='cuda:0'), new_distribution = tensor([0.1022, 0.3259, 0.5719], device='cuda:0')
2024-12-02 15:40:07,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 48: ref_distribution = tensor([0.1022, 0.3259, 0.5719], device='cuda:0'), new_distribution = tensor([0.1022, 0.3264, 0.5713], device='cuda:0')
2024-12-02 15:40:07,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 49: ref_distribution = tensor([0.1022, 0.3264, 0.5713], device='cuda:0'), new_distribution = tensor([0.1023, 0.3270, 0.5707], device='cuda:0')
2024-12-02 15:40:07,329 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 50: ref_distribution = tensor([0.1023, 0.3270, 0.5707], device='cuda:0'), new_distribution = tensor([0.1023, 0.3275, 0.5702], device='cuda:0')
2024-12-02 15:40:07,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 51: ref_distribution = tensor([0.1023, 0.3275, 0.5702], device='cuda:0'), new_distribution = tensor([0.1024, 0.3281, 0.5696], device='cuda:0')
2024-12-02 15:40:07,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 52: ref_distribution = tensor([0.1024, 0.3281, 0.5696], device='cuda:0'), new_distribution = tensor([0.1024, 0.3286, 0.5690], device='cuda:0')
2024-12-02 15:40:07,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 53: ref_distribution = tensor([0.1024, 0.3286, 0.5690], device='cuda:0'), new_distribution = tensor([0.1025, 0.3291, 0.5684], device='cuda:0')
2024-12-02 15:40:07,588 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 54: ref_distribution = tensor([0.1025, 0.3291, 0.5684], device='cuda:0'), new_distribution = tensor([0.1025, 0.3297, 0.5678], device='cuda:0')
2024-12-02 15:40:07,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 55: ref_distribution = tensor([0.1025, 0.3297, 0.5678], device='cuda:0'), new_distribution = tensor([0.1026, 0.3302, 0.5672], device='cuda:0')
2024-12-02 15:40:07,718 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 56: ref_distribution = tensor([0.1026, 0.3302, 0.5672], device='cuda:0'), new_distribution = tensor([0.1027, 0.3308, 0.5666], device='cuda:0')
2024-12-02 15:40:07,783 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 57: ref_distribution = tensor([0.1027, 0.3308, 0.5666], device='cuda:0'), new_distribution = tensor([0.1027, 0.3313, 0.5660], device='cuda:0')
2024-12-02 15:40:07,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 58: ref_distribution = tensor([0.1027, 0.3313, 0.5660], device='cuda:0'), new_distribution = tensor([0.1028, 0.3319, 0.5654], device='cuda:0')
2024-12-02 15:40:07,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 59: ref_distribution = tensor([0.1028, 0.3319, 0.5654], device='cuda:0'), new_distribution = tensor([0.1028, 0.3324, 0.5648], device='cuda:0')
2024-12-02 15:40:07,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 60: ref_distribution = tensor([0.1028, 0.3324, 0.5648], device='cuda:0'), new_distribution = tensor([0.1029, 0.3330, 0.5642], device='cuda:0')
2024-12-02 15:40:08,043 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 61: ref_distribution = tensor([0.1029, 0.3330, 0.5642], device='cuda:0'), new_distribution = tensor([0.1029, 0.3335, 0.5636], device='cuda:0')
2024-12-02 15:40:08,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 62: ref_distribution = tensor([0.1029, 0.3335, 0.5636], device='cuda:0'), new_distribution = tensor([0.1030, 0.3341, 0.5630], device='cuda:0')
2024-12-02 15:40:08,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 63: ref_distribution = tensor([0.1030, 0.3341, 0.5630], device='cuda:0'), new_distribution = tensor([0.1030, 0.3346, 0.5624], device='cuda:0')
2024-12-02 15:40:08,237 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 64: ref_distribution = tensor([0.1030, 0.3346, 0.5624], device='cuda:0'), new_distribution = tensor([0.1031, 0.3352, 0.5618], device='cuda:0')
2024-12-02 15:40:08,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 65: ref_distribution = tensor([0.1031, 0.3352, 0.5618], device='cuda:0'), new_distribution = tensor([0.1031, 0.3357, 0.5612], device='cuda:0')
2024-12-02 15:40:08,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 66: ref_distribution = tensor([0.1031, 0.3357, 0.5612], device='cuda:0'), new_distribution = tensor([0.1032, 0.3363, 0.5606], device='cuda:0')
2024-12-02 15:40:08,431 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 67: ref_distribution = tensor([0.1032, 0.3363, 0.5606], device='cuda:0'), new_distribution = tensor([0.1032, 0.3368, 0.5600], device='cuda:0')
2024-12-02 15:40:08,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 68: ref_distribution = tensor([0.1032, 0.3368, 0.5600], device='cuda:0'), new_distribution = tensor([0.1033, 0.3374, 0.5593], device='cuda:0')
2024-12-02 15:40:08,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 69: ref_distribution = tensor([0.1033, 0.3374, 0.5593], device='cuda:0'), new_distribution = tensor([0.1033, 0.3379, 0.5587], device='cuda:0')
2024-12-02 15:40:08,625 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 70: ref_distribution = tensor([0.1033, 0.3379, 0.5587], device='cuda:0'), new_distribution = tensor([0.1034, 0.3385, 0.5581], device='cuda:0')
2024-12-02 15:40:08,690 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 71: ref_distribution = tensor([0.1034, 0.3385, 0.5581], device='cuda:0'), new_distribution = tensor([0.1035, 0.3390, 0.5575], device='cuda:0')
2024-12-02 15:40:08,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 72: ref_distribution = tensor([0.1035, 0.3390, 0.5575], device='cuda:0'), new_distribution = tensor([0.1035, 0.3396, 0.5569], device='cuda:0')
2024-12-02 15:40:08,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 73: ref_distribution = tensor([0.1035, 0.3396, 0.5569], device='cuda:0'), new_distribution = tensor([0.1036, 0.3401, 0.5563], device='cuda:0')
2024-12-02 15:40:08,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 74: ref_distribution = tensor([0.1036, 0.3401, 0.5563], device='cuda:0'), new_distribution = tensor([0.1036, 0.3407, 0.5557], device='cuda:0')
2024-12-02 15:40:08,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 75: ref_distribution = tensor([0.1036, 0.3407, 0.5557], device='cuda:0'), new_distribution = tensor([0.1037, 0.3412, 0.5551], device='cuda:0')
2024-12-02 15:40:09,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 76: ref_distribution = tensor([0.1037, 0.3412, 0.5551], device='cuda:0'), new_distribution = tensor([0.1037, 0.3418, 0.5545], device='cuda:0')
2024-12-02 15:40:09,076 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 77: ref_distribution = tensor([0.1037, 0.3418, 0.5545], device='cuda:0'), new_distribution = tensor([0.1038, 0.3423, 0.5539], device='cuda:0')
2024-12-02 15:40:09,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 78: ref_distribution = tensor([0.1038, 0.3423, 0.5539], device='cuda:0'), new_distribution = tensor([0.1038, 0.3429, 0.5533], device='cuda:0')
2024-12-02 15:40:09,206 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 79: ref_distribution = tensor([0.1038, 0.3429, 0.5533], device='cuda:0'), new_distribution = tensor([0.1039, 0.3434, 0.5527], device='cuda:0')
2024-12-02 15:40:09,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 80: ref_distribution = tensor([0.1039, 0.3434, 0.5527], device='cuda:0'), new_distribution = tensor([0.1040, 0.3440, 0.5521], device='cuda:0')
2024-12-02 15:40:09,335 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 81: ref_distribution = tensor([0.1040, 0.3440, 0.5521], device='cuda:0'), new_distribution = tensor([0.1040, 0.3445, 0.5515], device='cuda:0')
2024-12-02 15:40:09,399 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 82: ref_distribution = tensor([0.1040, 0.3445, 0.5515], device='cuda:0'), new_distribution = tensor([0.1041, 0.3451, 0.5509], device='cuda:0')
2024-12-02 15:40:09,464 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 83: ref_distribution = tensor([0.1041, 0.3451, 0.5509], device='cuda:0'), new_distribution = tensor([0.1041, 0.3456, 0.5503], device='cuda:0')
2024-12-02 15:40:09,529 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 84: ref_distribution = tensor([0.1041, 0.3456, 0.5503], device='cuda:0'), new_distribution = tensor([0.1042, 0.3462, 0.5496], device='cuda:0')
2024-12-02 15:40:09,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 85: ref_distribution = tensor([0.1042, 0.3462, 0.5496], device='cuda:0'), new_distribution = tensor([0.1043, 0.3467, 0.5490], device='cuda:0')
2024-12-02 15:40:09,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 86: ref_distribution = tensor([0.1043, 0.3467, 0.5490], device='cuda:0'), new_distribution = tensor([0.1043, 0.3473, 0.5484], device='cuda:0')
2024-12-02 15:40:09,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 87: ref_distribution = tensor([0.1043, 0.3473, 0.5484], device='cuda:0'), new_distribution = tensor([0.1044, 0.3478, 0.5478], device='cuda:0')
2024-12-02 15:40:09,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 88: ref_distribution = tensor([0.1044, 0.3478, 0.5478], device='cuda:0'), new_distribution = tensor([0.1044, 0.3484, 0.5472], device='cuda:0')
2024-12-02 15:40:09,852 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 89: ref_distribution = tensor([0.1044, 0.3484, 0.5472], device='cuda:0'), new_distribution = tensor([0.1045, 0.3489, 0.5466], device='cuda:0')
2024-12-02 15:40:09,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 90: ref_distribution = tensor([0.1045, 0.3489, 0.5466], device='cuda:0'), new_distribution = tensor([0.1045, 0.3495, 0.5460], device='cuda:0')
2024-12-02 15:40:09,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 91: ref_distribution = tensor([0.1045, 0.3495, 0.5460], device='cuda:0'), new_distribution = tensor([0.1046, 0.3500, 0.5454], device='cuda:0')
2024-12-02 15:40:10,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 92: ref_distribution = tensor([0.1046, 0.3500, 0.5454], device='cuda:0'), new_distribution = tensor([0.1047, 0.3506, 0.5448], device='cuda:0')
2024-12-02 15:40:10,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 93: ref_distribution = tensor([0.1047, 0.3506, 0.5448], device='cuda:0'), new_distribution = tensor([0.1047, 0.3511, 0.5441], device='cuda:0')
2024-12-02 15:40:10,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 94: ref_distribution = tensor([0.1047, 0.3511, 0.5441], device='cuda:0'), new_distribution = tensor([0.1048, 0.3517, 0.5435], device='cuda:0')
2024-12-02 15:40:10,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 95: ref_distribution = tensor([0.1048, 0.3517, 0.5435], device='cuda:0'), new_distribution = tensor([0.1048, 0.3522, 0.5429], device='cuda:0')
2024-12-02 15:40:10,307 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 96: ref_distribution = tensor([0.1048, 0.3522, 0.5429], device='cuda:0'), new_distribution = tensor([0.1049, 0.3528, 0.5423], device='cuda:0')
2024-12-02 15:40:10,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 97: ref_distribution = tensor([0.1049, 0.3528, 0.5423], device='cuda:0'), new_distribution = tensor([0.1050, 0.3533, 0.5417], device='cuda:0')
2024-12-02 15:40:10,436 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 98: ref_distribution = tensor([0.1050, 0.3533, 0.5417], device='cuda:0'), new_distribution = tensor([0.1050, 0.3539, 0.5411], device='cuda:0')
2024-12-02 15:40:10,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:537] - INFO: Iteration 99: ref_distribution = tensor([0.1050, 0.3539, 0.5411], device='cuda:0'), new_distribution = tensor([0.1051, 0.3544, 0.5405], device='cuda:0')
