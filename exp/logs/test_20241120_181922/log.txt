2024-11-20 18:19:22,420 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 0 loss: 0.6915 acc: 0.52
2024-11-20 18:19:22,426 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 2 loss: 0.6910 acc: 0.52
2024-11-20 18:19:22,433 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 4 loss: 0.6905 acc: 0.52
2024-11-20 18:19:22,439 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 6 loss: 0.6902 acc: 0.52
2024-11-20 18:19:22,446 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 8 loss: 0.6898 acc: 0.55
2024-11-20 18:19:22,452 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 10 loss: 0.6896 acc: 0.55
2024-11-20 18:19:22,458 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 12 loss: 0.6894 acc: 0.55
2024-11-20 18:19:22,464 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 14 loss: 0.6892 acc: 0.55
2024-11-20 18:19:22,470 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 16 loss: 0.6891 acc: 0.55
2024-11-20 18:19:22,476 - /home/hanwen/policy_optimization/exp/algorithm.py[line:124] - INFO: [Reward] Epoch 18 loss: 0.6890 acc: 0.55
2024-11-20 18:19:22,526 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 0 loss: -0.2085 reward: 0.2085 ref_reward: 0.1991 improvement: 4.69%
2024-11-20 18:19:22,537 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 2 loss: -0.2143 reward: 0.2143 ref_reward: 0.1991 improvement: 7.63%
2024-11-20 18:19:22,546 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 4 loss: -0.2201 reward: 0.2201 ref_reward: 0.1991 improvement: 10.53%
2024-11-20 18:19:22,554 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 6 loss: -0.2258 reward: 0.2258 ref_reward: 0.1991 improvement: 13.39%
2024-11-20 18:19:22,561 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 8 loss: -0.2313 reward: 0.2313 ref_reward: 0.1991 improvement: 16.16%
2024-11-20 18:19:22,569 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 10 loss: -0.2366 reward: 0.2366 ref_reward: 0.1991 improvement: 18.79%
2024-11-20 18:19:22,576 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 12 loss: -0.2417 reward: 0.2417 ref_reward: 0.1991 improvement: 21.36%
2024-11-20 18:19:22,583 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 14 loss: -0.2467 reward: 0.2467 ref_reward: 0.1991 improvement: 23.88%
2024-11-20 18:19:22,590 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 16 loss: -0.2517 reward: 0.2517 ref_reward: 0.1991 improvement: 26.39%
2024-11-20 18:19:22,597 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 18 loss: -0.2567 reward: 0.2567 ref_reward: 0.1991 improvement: 28.90%
2024-11-20 18:19:22,605 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 20 loss: -0.2616 reward: 0.2616 ref_reward: 0.1991 improvement: 31.34%
2024-11-20 18:19:22,613 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 22 loss: -0.2661 reward: 0.2661 ref_reward: 0.1991 improvement: 33.61%
2024-11-20 18:19:22,621 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 24 loss: -0.2705 reward: 0.2705 ref_reward: 0.1991 improvement: 35.82%
2024-11-20 18:19:22,628 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 26 loss: -0.2747 reward: 0.2747 ref_reward: 0.1991 improvement: 37.95%
2024-11-20 18:19:22,636 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 28 loss: -0.2787 reward: 0.2787 ref_reward: 0.1991 improvement: 39.95%
2024-11-20 18:19:22,643 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 30 loss: -0.2824 reward: 0.2824 ref_reward: 0.1991 improvement: 41.82%
2024-11-20 18:19:22,651 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 32 loss: -0.2858 reward: 0.2858 ref_reward: 0.1991 improvement: 43.53%
2024-11-20 18:19:22,658 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 34 loss: -0.2889 reward: 0.2889 ref_reward: 0.1991 improvement: 45.08%
2024-11-20 18:19:22,666 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 36 loss: -0.2916 reward: 0.2916 ref_reward: 0.1991 improvement: 46.44%
2024-11-20 18:19:22,673 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 38 loss: -0.2940 reward: 0.2940 ref_reward: 0.1991 improvement: 47.64%
2024-11-20 18:19:22,681 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 40 loss: -0.2961 reward: 0.2961 ref_reward: 0.1991 improvement: 48.68%
2024-11-20 18:19:22,689 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 42 loss: -0.2979 reward: 0.2979 ref_reward: 0.1991 improvement: 49.57%
2024-11-20 18:19:22,696 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 44 loss: -0.2994 reward: 0.2994 ref_reward: 0.1991 improvement: 50.33%
2024-11-20 18:19:22,704 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 46 loss: -0.3007 reward: 0.3007 ref_reward: 0.1991 improvement: 50.97%
2024-11-20 18:19:22,711 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 48 loss: -0.3017 reward: 0.3017 ref_reward: 0.1991 improvement: 51.51%
2024-11-20 18:19:22,719 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 50 loss: -0.3026 reward: 0.3026 ref_reward: 0.1991 improvement: 51.97%
2024-11-20 18:19:22,727 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 52 loss: -0.3034 reward: 0.3034 ref_reward: 0.1991 improvement: 52.35%
2024-11-20 18:19:22,734 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 54 loss: -0.3040 reward: 0.3040 ref_reward: 0.1991 improvement: 52.67%
2024-11-20 18:19:22,742 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 56 loss: -0.3046 reward: 0.3046 ref_reward: 0.1991 improvement: 52.95%
2024-11-20 18:19:22,749 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 58 loss: -0.3050 reward: 0.3050 ref_reward: 0.1991 improvement: 53.17%
2024-11-20 18:19:22,757 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 60 loss: -0.3054 reward: 0.3054 ref_reward: 0.1991 improvement: 53.37%
2024-11-20 18:19:22,765 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 62 loss: -0.3058 reward: 0.3058 ref_reward: 0.1991 improvement: 53.53%
2024-11-20 18:19:22,773 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 64 loss: -0.3060 reward: 0.3060 ref_reward: 0.1991 improvement: 53.68%
2024-11-20 18:19:22,783 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 66 loss: -0.3063 reward: 0.3063 ref_reward: 0.1991 improvement: 53.80%
2024-11-20 18:19:22,792 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 68 loss: -0.3065 reward: 0.3065 ref_reward: 0.1991 improvement: 53.90%
2024-11-20 18:19:22,799 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 70 loss: -0.3067 reward: 0.3067 ref_reward: 0.1991 improvement: 53.99%
2024-11-20 18:19:22,807 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 72 loss: -0.3068 reward: 0.3068 ref_reward: 0.1991 improvement: 54.07%
2024-11-20 18:19:22,814 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 74 loss: -0.3070 reward: 0.3070 ref_reward: 0.1991 improvement: 54.14%
2024-11-20 18:19:22,821 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 76 loss: -0.3071 reward: 0.3071 ref_reward: 0.1991 improvement: 54.21%
2024-11-20 18:19:22,829 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 78 loss: -0.3072 reward: 0.3072 ref_reward: 0.1991 improvement: 54.26%
2024-11-20 18:19:22,837 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 80 loss: -0.3073 reward: 0.3073 ref_reward: 0.1991 improvement: 54.31%
2024-11-20 18:19:22,845 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 82 loss: -0.3074 reward: 0.3074 ref_reward: 0.1991 improvement: 54.35%
2024-11-20 18:19:22,852 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 84 loss: -0.3075 reward: 0.3075 ref_reward: 0.1991 improvement: 54.39%
2024-11-20 18:19:22,860 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 86 loss: -0.3075 reward: 0.3075 ref_reward: 0.1991 improvement: 54.43%
2024-11-20 18:19:22,867 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 88 loss: -0.3076 reward: 0.3076 ref_reward: 0.1991 improvement: 54.46%
2024-11-20 18:19:22,874 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 90 loss: -0.3077 reward: 0.3077 ref_reward: 0.1991 improvement: 54.49%
2024-11-20 18:19:22,881 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 92 loss: -0.3077 reward: 0.3077 ref_reward: 0.1991 improvement: 54.52%
2024-11-20 18:19:22,889 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 94 loss: -0.3078 reward: 0.3078 ref_reward: 0.1991 improvement: 54.54%
2024-11-20 18:19:22,896 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 96 loss: -0.3078 reward: 0.3078 ref_reward: 0.1991 improvement: 54.56%
2024-11-20 18:19:22,904 - /home/hanwen/policy_optimization/exp/algorithm.py[line:193] - INFO: [Policy] Epoch 98 loss: -0.3078 reward: 0.3078 ref_reward: 0.1991 improvement: 54.59%
2024-11-20 18:19:23,173 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 0 loss: 0.6917 grad norm: 0.0253 
2024-11-20 18:19:23,198 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 5 loss: 0.6898 grad norm: 0.0152 
2024-11-20 18:19:23,220 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 10 loss: 0.6890 grad norm: 0.0061 
2024-11-20 18:19:23,239 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 15 loss: 0.6888 grad norm: 0.0027 
2024-11-20 18:19:23,258 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 20 loss: 0.6889 grad norm: 0.0050 
2024-11-20 18:19:23,277 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 25 loss: 0.6889 grad norm: 0.0040 
2024-11-20 18:19:23,296 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 30 loss: 0.6888 grad norm: 0.0024 
2024-11-20 18:19:23,314 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 35 loss: 0.6888 grad norm: 0.0017 
2024-11-20 18:19:23,333 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 40 loss: 0.6888 grad norm: 0.0008 
2024-11-20 18:19:23,352 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 45 loss: 0.6888 grad norm: 0.0007 
2024-11-20 18:19:23,370 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 50 loss: 0.6888 grad norm: 0.0010 
2024-11-20 18:19:23,390 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 55 loss: 0.6888 grad norm: 0.0007 
2024-11-20 18:19:23,409 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 60 loss: 0.6888 grad norm: 0.0002 
2024-11-20 18:19:23,428 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 65 loss: 0.6888 grad norm: 0.0003 
2024-11-20 18:19:23,447 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 70 loss: 0.6888 grad norm: 0.0003 
2024-11-20 18:19:23,466 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 75 loss: 0.6888 grad norm: 0.0003 
2024-11-20 18:19:23,485 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 80 loss: 0.6888 grad norm: 0.0002 
2024-11-20 18:19:23,504 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 85 loss: 0.6888 grad norm: 0.0001 
2024-11-20 18:19:23,523 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 90 loss: 0.6888 grad norm: 0.0001 
2024-11-20 18:19:23,542 - /home/hanwen/policy_optimization/exp/algorithm.py[line:315] - INFO: [Policy] Epoch: 95 loss: 0.6888 grad norm: 0.0001 
2024-11-20 18:19:23,823 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 0 loss: 0.1343 grad norm: 0.4753 
2024-11-20 18:19:23,851 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 5 loss: 0.0032 grad norm: 0.0781 
2024-11-20 18:19:23,876 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 10 loss: 0.0016 grad norm: 0.0436 
2024-11-20 18:19:23,901 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 15 loss: 0.0010 grad norm: 0.0327 
2024-11-20 18:19:23,926 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 20 loss: 0.0005 grad norm: 0.0214 
2024-11-20 18:19:23,950 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 25 loss: 0.0001 grad norm: 0.0091 
2024-11-20 18:19:23,976 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 30 loss: 0.0003 grad norm: 0.0141 
2024-11-20 18:19:24,002 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 35 loss: 0.0000 grad norm: 0.0061 
2024-11-20 18:19:24,026 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 40 loss: 0.0000 grad norm: 0.0027 
2024-11-20 18:19:24,050 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 45 loss: 0.0000 grad norm: 0.0035 
2024-11-20 18:19:24,075 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 50 loss: 0.0000 grad norm: 0.0027 
2024-11-20 18:19:24,100 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 55 loss: 0.0000 grad norm: 0.0015 
2024-11-20 18:19:24,125 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 60 loss: 0.0000 grad norm: 0.0018 
2024-11-20 18:19:24,151 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 65 loss: 0.0000 grad norm: 0.0006 
2024-11-20 18:19:24,176 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 70 loss: 0.0000 grad norm: 0.0004 
2024-11-20 18:19:24,200 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 75 loss: 0.0000 grad norm: 0.0001 
2024-11-20 18:19:24,225 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 80 loss: 0.0000 grad norm: 0.0004 
2024-11-20 18:19:24,251 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 85 loss: 0.0000 grad norm: 0.0001 
2024-11-20 18:19:24,275 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 90 loss: 0.0000 grad norm: 0.0002 
2024-11-20 18:19:24,302 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 95 loss: 0.0000 grad norm: 0.0001 
2024-11-20 18:19:24,333 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 100 loss: 0.0000 grad norm: 0.0001 
2024-11-20 18:19:24,361 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 105 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,387 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 110 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,411 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 115 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,435 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 120 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,461 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 125 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,485 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 130 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,509 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 135 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,534 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 140 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,556 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 145 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,577 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 150 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,600 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 155 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,622 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 160 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,644 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 165 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,666 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 170 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,688 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 175 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,709 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 180 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,732 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 185 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,754 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 190 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,776 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 195 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,798 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 200 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,819 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 205 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,841 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 210 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,864 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 215 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,886 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 220 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,908 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 225 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,931 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 230 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,954 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 235 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,976 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 240 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:24,998 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 245 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:25,020 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 250 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:25,042 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 255 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:25,064 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 260 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:25,086 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 265 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:25,108 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 270 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:25,132 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 275 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:25,155 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 280 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:25,177 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 285 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:25,200 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 290 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:25,222 - /home/hanwen/policy_optimization/exp/algorithm.py[line:433] - INFO: [Policy] Epoch: 295 loss: 0.0000 grad norm: 0.0000 
2024-11-20 18:19:25,470 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 0: ref_distribution = tensor([0.3333, 0.3333, 0.3333], device='cuda:0'), new_distribution = tensor([0.3353, 0.3339, 0.3309], device='cuda:0')
2024-11-20 18:19:25,475 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 1: ref_distribution = tensor([0.3353, 0.3339, 0.3309], device='cuda:0'), new_distribution = tensor([0.3365, 0.3330, 0.3305], device='cuda:0')
2024-11-20 18:19:25,479 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 2: ref_distribution = tensor([0.3365, 0.3330, 0.3305], device='cuda:0'), new_distribution = tensor([0.3377, 0.3335, 0.3288], device='cuda:0')
2024-11-20 18:19:25,484 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 3: ref_distribution = tensor([0.3377, 0.3335, 0.3288], device='cuda:0'), new_distribution = tensor([0.3370, 0.3343, 0.3288], device='cuda:0')
2024-11-20 18:19:25,488 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 4: ref_distribution = tensor([0.3370, 0.3343, 0.3288], device='cuda:0'), new_distribution = tensor([0.3375, 0.3348, 0.3277], device='cuda:0')
2024-11-20 18:19:25,493 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 5: ref_distribution = tensor([0.3375, 0.3348, 0.3277], device='cuda:0'), new_distribution = tensor([0.3387, 0.3346, 0.3267], device='cuda:0')
2024-11-20 18:19:25,497 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 6: ref_distribution = tensor([0.3387, 0.3346, 0.3267], device='cuda:0'), new_distribution = tensor([0.3392, 0.3351, 0.3257], device='cuda:0')
2024-11-20 18:19:25,502 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 7: ref_distribution = tensor([0.3392, 0.3351, 0.3257], device='cuda:0'), new_distribution = tensor([0.3400, 0.3351, 0.3249], device='cuda:0')
2024-11-20 18:19:25,506 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 8: ref_distribution = tensor([0.3400, 0.3351, 0.3249], device='cuda:0'), new_distribution = tensor([0.3412, 0.3356, 0.3232], device='cuda:0')
2024-11-20 18:19:25,511 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 9: ref_distribution = tensor([0.3412, 0.3356, 0.3232], device='cuda:0'), new_distribution = tensor([0.3427, 0.3349, 0.3224], device='cuda:0')
2024-11-20 18:19:25,515 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 10: ref_distribution = tensor([0.3427, 0.3349, 0.3224], device='cuda:0'), new_distribution = tensor([0.3432, 0.3346, 0.3221], device='cuda:0')
2024-11-20 18:19:25,519 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 11: ref_distribution = tensor([0.3432, 0.3346, 0.3221], device='cuda:0'), new_distribution = tensor([0.3447, 0.3354, 0.3199], device='cuda:0')
2024-11-20 18:19:25,524 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 12: ref_distribution = tensor([0.3447, 0.3354, 0.3199], device='cuda:0'), new_distribution = tensor([0.3452, 0.3351, 0.3197], device='cuda:0')
2024-11-20 18:19:25,528 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 13: ref_distribution = tensor([0.3452, 0.3351, 0.3197], device='cuda:0'), new_distribution = tensor([0.3453, 0.3351, 0.3196], device='cuda:0')
2024-11-20 18:19:25,533 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 14: ref_distribution = tensor([0.3453, 0.3351, 0.3196], device='cuda:0'), new_distribution = tensor([0.3458, 0.3363, 0.3179], device='cuda:0')
2024-11-20 18:19:25,537 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 15: ref_distribution = tensor([0.3458, 0.3363, 0.3179], device='cuda:0'), new_distribution = tensor([0.3461, 0.3372, 0.3167], device='cuda:0')
2024-11-20 18:19:25,542 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 16: ref_distribution = tensor([0.3461, 0.3372, 0.3167], device='cuda:0'), new_distribution = tensor([0.3466, 0.3377, 0.3157], device='cuda:0')
2024-11-20 18:19:25,546 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 17: ref_distribution = tensor([0.3466, 0.3377, 0.3157], device='cuda:0'), new_distribution = tensor([0.3486, 0.3374, 0.3140], device='cuda:0')
2024-11-20 18:19:25,551 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 18: ref_distribution = tensor([0.3486, 0.3374, 0.3140], device='cuda:0'), new_distribution = tensor([0.3489, 0.3376, 0.3135], device='cuda:0')
2024-11-20 18:19:25,556 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 19: ref_distribution = tensor([0.3489, 0.3376, 0.3135], device='cuda:0'), new_distribution = tensor([0.3492, 0.3385, 0.3123], device='cuda:0')
2024-11-20 18:19:25,560 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 20: ref_distribution = tensor([0.3492, 0.3385, 0.3123], device='cuda:0'), new_distribution = tensor([0.3507, 0.3392, 0.3102], device='cuda:0')
2024-11-20 18:19:25,565 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 21: ref_distribution = tensor([0.3507, 0.3392, 0.3102], device='cuda:0'), new_distribution = tensor([0.3515, 0.3391, 0.3094], device='cuda:0')
2024-11-20 18:19:25,570 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 22: ref_distribution = tensor([0.3515, 0.3391, 0.3094], device='cuda:0'), new_distribution = tensor([0.3523, 0.3390, 0.3087], device='cuda:0')
2024-11-20 18:19:25,574 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 23: ref_distribution = tensor([0.3523, 0.3390, 0.3087], device='cuda:0'), new_distribution = tensor([0.3531, 0.3389, 0.3080], device='cuda:0')
2024-11-20 18:19:25,579 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 24: ref_distribution = tensor([0.3531, 0.3389, 0.3080], device='cuda:0'), new_distribution = tensor([0.3537, 0.3379, 0.3084], device='cuda:0')
2024-11-20 18:19:25,583 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 25: ref_distribution = tensor([0.3537, 0.3379, 0.3084], device='cuda:0'), new_distribution = tensor([0.3550, 0.3376, 0.3074], device='cuda:0')
2024-11-20 18:19:25,587 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 26: ref_distribution = tensor([0.3550, 0.3376, 0.3074], device='cuda:0'), new_distribution = tensor([0.3556, 0.3373, 0.3072], device='cuda:0')
2024-11-20 18:19:25,592 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 27: ref_distribution = tensor([0.3556, 0.3373, 0.3072], device='cuda:0'), new_distribution = tensor([0.3566, 0.3367, 0.3067], device='cuda:0')
2024-11-20 18:19:25,596 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 28: ref_distribution = tensor([0.3566, 0.3367, 0.3067], device='cuda:0'), new_distribution = tensor([0.3577, 0.3361, 0.3062], device='cuda:0')
2024-11-20 18:19:25,601 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 29: ref_distribution = tensor([0.3577, 0.3361, 0.3062], device='cuda:0'), new_distribution = tensor([0.3592, 0.3360, 0.3048], device='cuda:0')
2024-11-20 18:19:25,605 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 30: ref_distribution = tensor([0.3592, 0.3360, 0.3048], device='cuda:0'), new_distribution = tensor([0.3590, 0.3371, 0.3039], device='cuda:0')
2024-11-20 18:19:25,610 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 31: ref_distribution = tensor([0.3590, 0.3371, 0.3039], device='cuda:0'), new_distribution = tensor([0.3601, 0.3379, 0.3020], device='cuda:0')
2024-11-20 18:19:25,614 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 32: ref_distribution = tensor([0.3601, 0.3379, 0.3020], device='cuda:0'), new_distribution = tensor([0.3602, 0.3385, 0.3013], device='cuda:0')
2024-11-20 18:19:25,619 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 33: ref_distribution = tensor([0.3602, 0.3385, 0.3013], device='cuda:0'), new_distribution = tensor([0.3603, 0.3384, 0.3013], device='cuda:0')
2024-11-20 18:19:25,623 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 34: ref_distribution = tensor([0.3603, 0.3384, 0.3013], device='cuda:0'), new_distribution = tensor([0.3614, 0.3378, 0.3009], device='cuda:0')
2024-11-20 18:19:25,628 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 35: ref_distribution = tensor([0.3614, 0.3378, 0.3009], device='cuda:0'), new_distribution = tensor([0.3624, 0.3379, 0.2997], device='cuda:0')
2024-11-20 18:19:25,632 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 36: ref_distribution = tensor([0.3624, 0.3379, 0.2997], device='cuda:0'), new_distribution = tensor([0.3630, 0.3375, 0.2995], device='cuda:0')
2024-11-20 18:19:25,636 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 37: ref_distribution = tensor([0.3630, 0.3375, 0.2995], device='cuda:0'), new_distribution = tensor([0.3653, 0.3367, 0.2980], device='cuda:0')
2024-11-20 18:19:25,641 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 38: ref_distribution = tensor([0.3653, 0.3367, 0.2980], device='cuda:0'), new_distribution = tensor([0.3652, 0.3377, 0.2971], device='cuda:0')
2024-11-20 18:19:25,645 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 39: ref_distribution = tensor([0.3652, 0.3377, 0.2971], device='cuda:0'), new_distribution = tensor([0.3657, 0.3380, 0.2962], device='cuda:0')
2024-11-20 18:19:25,650 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 40: ref_distribution = tensor([0.3657, 0.3380, 0.2962], device='cuda:0'), new_distribution = tensor([0.3669, 0.3374, 0.2958], device='cuda:0')
2024-11-20 18:19:25,654 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 41: ref_distribution = tensor([0.3669, 0.3374, 0.2958], device='cuda:0'), new_distribution = tensor([0.3682, 0.3370, 0.2948], device='cuda:0')
2024-11-20 18:19:25,659 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 42: ref_distribution = tensor([0.3682, 0.3370, 0.2948], device='cuda:0'), new_distribution = tensor([0.3702, 0.3366, 0.2932], device='cuda:0')
2024-11-20 18:19:25,663 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 43: ref_distribution = tensor([0.3702, 0.3366, 0.2932], device='cuda:0'), new_distribution = tensor([0.3711, 0.3364, 0.2925], device='cuda:0')
2024-11-20 18:19:25,668 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 44: ref_distribution = tensor([0.3711, 0.3364, 0.2925], device='cuda:0'), new_distribution = tensor([0.3725, 0.3352, 0.2923], device='cuda:0')
2024-11-20 18:19:25,673 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 45: ref_distribution = tensor([0.3725, 0.3352, 0.2923], device='cuda:0'), new_distribution = tensor([0.3734, 0.3343, 0.2923], device='cuda:0')
2024-11-20 18:19:25,677 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 46: ref_distribution = tensor([0.3734, 0.3343, 0.2923], device='cuda:0'), new_distribution = tensor([0.3739, 0.3353, 0.2907], device='cuda:0')
2024-11-20 18:19:25,682 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 47: ref_distribution = tensor([0.3739, 0.3353, 0.2907], device='cuda:0'), new_distribution = tensor([0.3750, 0.3347, 0.2903], device='cuda:0')
2024-11-20 18:19:25,687 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 48: ref_distribution = tensor([0.3750, 0.3347, 0.2903], device='cuda:0'), new_distribution = tensor([0.3757, 0.3342, 0.2901], device='cuda:0')
2024-11-20 18:19:25,691 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 49: ref_distribution = tensor([0.3757, 0.3342, 0.2901], device='cuda:0'), new_distribution = tensor([0.3768, 0.3342, 0.2890], device='cuda:0')
2024-11-20 18:19:25,696 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 50: ref_distribution = tensor([0.3768, 0.3342, 0.2890], device='cuda:0'), new_distribution = tensor([0.3781, 0.3345, 0.2874], device='cuda:0')
2024-11-20 18:19:25,700 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 51: ref_distribution = tensor([0.3781, 0.3345, 0.2874], device='cuda:0'), new_distribution = tensor([0.3792, 0.3338, 0.2870], device='cuda:0')
2024-11-20 18:19:25,705 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 52: ref_distribution = tensor([0.3792, 0.3338, 0.2870], device='cuda:0'), new_distribution = tensor([0.3801, 0.3328, 0.2870], device='cuda:0')
2024-11-20 18:19:25,709 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 53: ref_distribution = tensor([0.3801, 0.3328, 0.2870], device='cuda:0'), new_distribution = tensor([0.3815, 0.3324, 0.2861], device='cuda:0')
2024-11-20 18:19:25,713 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 54: ref_distribution = tensor([0.3815, 0.3324, 0.2861], device='cuda:0'), new_distribution = tensor([0.3823, 0.3328, 0.2848], device='cuda:0')
2024-11-20 18:19:25,718 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 55: ref_distribution = tensor([0.3823, 0.3328, 0.2848], device='cuda:0'), new_distribution = tensor([0.3842, 0.3321, 0.2837], device='cuda:0')
2024-11-20 18:19:25,722 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 56: ref_distribution = tensor([0.3842, 0.3321, 0.2837], device='cuda:0'), new_distribution = tensor([0.3860, 0.3314, 0.2826], device='cuda:0')
2024-11-20 18:19:25,727 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 57: ref_distribution = tensor([0.3860, 0.3314, 0.2826], device='cuda:0'), new_distribution = tensor([0.3882, 0.3302, 0.2817], device='cuda:0')
2024-11-20 18:19:25,732 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 58: ref_distribution = tensor([0.3882, 0.3302, 0.2817], device='cuda:0'), new_distribution = tensor([0.3898, 0.3292, 0.2810], device='cuda:0')
2024-11-20 18:19:25,736 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 59: ref_distribution = tensor([0.3898, 0.3292, 0.2810], device='cuda:0'), new_distribution = tensor([0.3912, 0.3287, 0.2802], device='cuda:0')
2024-11-20 18:19:25,741 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 60: ref_distribution = tensor([0.3912, 0.3287, 0.2802], device='cuda:0'), new_distribution = tensor([0.3918, 0.3281, 0.2800], device='cuda:0')
2024-11-20 18:19:25,745 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 61: ref_distribution = tensor([0.3918, 0.3281, 0.2800], device='cuda:0'), new_distribution = tensor([0.3927, 0.3285, 0.2788], device='cuda:0')
2024-11-20 18:19:25,750 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 62: ref_distribution = tensor([0.3927, 0.3285, 0.2788], device='cuda:0'), new_distribution = tensor([0.3941, 0.3280, 0.2779], device='cuda:0')
2024-11-20 18:19:25,754 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 63: ref_distribution = tensor([0.3941, 0.3280, 0.2779], device='cuda:0'), new_distribution = tensor([0.3953, 0.3265, 0.2782], device='cuda:0')
2024-11-20 18:19:25,759 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 64: ref_distribution = tensor([0.3953, 0.3265, 0.2782], device='cuda:0'), new_distribution = tensor([0.3966, 0.3267, 0.2767], device='cuda:0')
2024-11-20 18:19:25,763 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 65: ref_distribution = tensor([0.3966, 0.3267, 0.2767], device='cuda:0'), new_distribution = tensor([0.3979, 0.3275, 0.2746], device='cuda:0')
2024-11-20 18:19:25,768 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 66: ref_distribution = tensor([0.3979, 0.3275, 0.2746], device='cuda:0'), new_distribution = tensor([0.3998, 0.3267, 0.2735], device='cuda:0')
2024-11-20 18:19:25,772 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 67: ref_distribution = tensor([0.3998, 0.3267, 0.2735], device='cuda:0'), new_distribution = tensor([0.4002, 0.3266, 0.2732], device='cuda:0')
2024-11-20 18:19:25,777 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 68: ref_distribution = tensor([0.4002, 0.3266, 0.2732], device='cuda:0'), new_distribution = tensor([0.4020, 0.3265, 0.2715], device='cuda:0')
2024-11-20 18:19:25,782 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 69: ref_distribution = tensor([0.4020, 0.3265, 0.2715], device='cuda:0'), new_distribution = tensor([0.4032, 0.3264, 0.2704], device='cuda:0')
2024-11-20 18:19:25,786 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 70: ref_distribution = tensor([0.4032, 0.3264, 0.2704], device='cuda:0'), new_distribution = tensor([0.4041, 0.3261, 0.2699], device='cuda:0')
2024-11-20 18:19:25,791 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 71: ref_distribution = tensor([0.4041, 0.3261, 0.2699], device='cuda:0'), new_distribution = tensor([0.4049, 0.3264, 0.2687], device='cuda:0')
2024-11-20 18:19:25,795 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 72: ref_distribution = tensor([0.4049, 0.3264, 0.2687], device='cuda:0'), new_distribution = tensor([0.4061, 0.3263, 0.2677], device='cuda:0')
2024-11-20 18:19:25,800 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 73: ref_distribution = tensor([0.4061, 0.3263, 0.2677], device='cuda:0'), new_distribution = tensor([0.4076, 0.3249, 0.2675], device='cuda:0')
2024-11-20 18:19:25,804 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 74: ref_distribution = tensor([0.4076, 0.3249, 0.2675], device='cuda:0'), new_distribution = tensor([0.4092, 0.3246, 0.2663], device='cuda:0')
2024-11-20 18:19:25,809 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 75: ref_distribution = tensor([0.4092, 0.3246, 0.2663], device='cuda:0'), new_distribution = tensor([0.4101, 0.3242, 0.2657], device='cuda:0')
2024-11-20 18:19:25,813 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 76: ref_distribution = tensor([0.4101, 0.3242, 0.2657], device='cuda:0'), new_distribution = tensor([0.4120, 0.3233, 0.2647], device='cuda:0')
2024-11-20 18:19:25,818 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 77: ref_distribution = tensor([0.4120, 0.3233, 0.2647], device='cuda:0'), new_distribution = tensor([0.4131, 0.3231, 0.2637], device='cuda:0')
2024-11-20 18:19:25,822 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 78: ref_distribution = tensor([0.4131, 0.3231, 0.2637], device='cuda:0'), new_distribution = tensor([0.4144, 0.3216, 0.2640], device='cuda:0')
2024-11-20 18:19:25,827 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 79: ref_distribution = tensor([0.4144, 0.3216, 0.2640], device='cuda:0'), new_distribution = tensor([0.4168, 0.3205, 0.2627], device='cuda:0')
2024-11-20 18:19:25,831 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 80: ref_distribution = tensor([0.4168, 0.3205, 0.2627], device='cuda:0'), new_distribution = tensor([0.4177, 0.3207, 0.2616], device='cuda:0')
2024-11-20 18:19:25,836 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 81: ref_distribution = tensor([0.4177, 0.3207, 0.2616], device='cuda:0'), new_distribution = tensor([0.4191, 0.3201, 0.2608], device='cuda:0')
2024-11-20 18:19:25,840 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 82: ref_distribution = tensor([0.4191, 0.3201, 0.2608], device='cuda:0'), new_distribution = tensor([0.4198, 0.3201, 0.2601], device='cuda:0')
2024-11-20 18:19:25,845 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 83: ref_distribution = tensor([0.4198, 0.3201, 0.2601], device='cuda:0'), new_distribution = tensor([0.4217, 0.3192, 0.2591], device='cuda:0')
2024-11-20 18:19:25,849 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 84: ref_distribution = tensor([0.4217, 0.3192, 0.2591], device='cuda:0'), new_distribution = tensor([0.4231, 0.3185, 0.2584], device='cuda:0')
2024-11-20 18:19:25,854 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 85: ref_distribution = tensor([0.4231, 0.3185, 0.2584], device='cuda:0'), new_distribution = tensor([0.4253, 0.3172, 0.2576], device='cuda:0')
2024-11-20 18:19:25,858 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 86: ref_distribution = tensor([0.4253, 0.3172, 0.2576], device='cuda:0'), new_distribution = tensor([0.4264, 0.3169, 0.2567], device='cuda:0')
2024-11-20 18:19:25,863 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 87: ref_distribution = tensor([0.4264, 0.3169, 0.2567], device='cuda:0'), new_distribution = tensor([0.4276, 0.3160, 0.2564], device='cuda:0')
2024-11-20 18:19:25,867 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 88: ref_distribution = tensor([0.4276, 0.3160, 0.2564], device='cuda:0'), new_distribution = tensor([0.4281, 0.3165, 0.2555], device='cuda:0')
2024-11-20 18:19:25,872 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 89: ref_distribution = tensor([0.4281, 0.3165, 0.2555], device='cuda:0'), new_distribution = tensor([0.4300, 0.3155, 0.2545], device='cuda:0')
2024-11-20 18:19:25,876 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 90: ref_distribution = tensor([0.4300, 0.3155, 0.2545], device='cuda:0'), new_distribution = tensor([0.4320, 0.3148, 0.2531], device='cuda:0')
2024-11-20 18:19:25,881 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 91: ref_distribution = tensor([0.4320, 0.3148, 0.2531], device='cuda:0'), new_distribution = tensor([0.4337, 0.3143, 0.2520], device='cuda:0')
2024-11-20 18:19:25,885 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 92: ref_distribution = tensor([0.4337, 0.3143, 0.2520], device='cuda:0'), new_distribution = tensor([0.4337, 0.3143, 0.2520], device='cuda:0')
2024-11-20 18:19:25,890 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 93: ref_distribution = tensor([0.4337, 0.3143, 0.2520], device='cuda:0'), new_distribution = tensor([0.4347, 0.3122, 0.2532], device='cuda:0')
2024-11-20 18:19:25,894 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 94: ref_distribution = tensor([0.4347, 0.3122, 0.2532], device='cuda:0'), new_distribution = tensor([0.4354, 0.3121, 0.2525], device='cuda:0')
2024-11-20 18:19:25,899 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 95: ref_distribution = tensor([0.4354, 0.3121, 0.2525], device='cuda:0'), new_distribution = tensor([0.4359, 0.3119, 0.2523], device='cuda:0')
2024-11-20 18:19:25,903 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 96: ref_distribution = tensor([0.4359, 0.3119, 0.2523], device='cuda:0'), new_distribution = tensor([0.4374, 0.3105, 0.2522], device='cuda:0')
2024-11-20 18:19:25,908 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 97: ref_distribution = tensor([0.4374, 0.3105, 0.2522], device='cuda:0'), new_distribution = tensor([0.4385, 0.3102, 0.2513], device='cuda:0')
2024-11-20 18:19:25,912 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 98: ref_distribution = tensor([0.4385, 0.3102, 0.2513], device='cuda:0'), new_distribution = tensor([0.4392, 0.3101, 0.2506], device='cuda:0')
2024-11-20 18:19:25,917 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 99: ref_distribution = tensor([0.4392, 0.3101, 0.2506], device='cuda:0'), new_distribution = tensor([0.4396, 0.3105, 0.2498], device='cuda:0')
2024-11-20 18:19:25,921 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 100: ref_distribution = tensor([0.4396, 0.3105, 0.2498], device='cuda:0'), new_distribution = tensor([0.4402, 0.3096, 0.2502], device='cuda:0')
2024-11-20 18:19:25,926 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 101: ref_distribution = tensor([0.4402, 0.3096, 0.2502], device='cuda:0'), new_distribution = tensor([0.4414, 0.3093, 0.2493], device='cuda:0')
2024-11-20 18:19:25,930 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 102: ref_distribution = tensor([0.4414, 0.3093, 0.2493], device='cuda:0'), new_distribution = tensor([0.4429, 0.3094, 0.2476], device='cuda:0')
2024-11-20 18:19:25,935 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 103: ref_distribution = tensor([0.4429, 0.3094, 0.2476], device='cuda:0'), new_distribution = tensor([0.4435, 0.3091, 0.2474], device='cuda:0')
2024-11-20 18:19:25,939 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 104: ref_distribution = tensor([0.4435, 0.3091, 0.2474], device='cuda:0'), new_distribution = tensor([0.4433, 0.3104, 0.2462], device='cuda:0')
2024-11-20 18:19:25,944 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 105: ref_distribution = tensor([0.4433, 0.3104, 0.2462], device='cuda:0'), new_distribution = tensor([0.4441, 0.3097, 0.2462], device='cuda:0')
2024-11-20 18:19:25,948 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 106: ref_distribution = tensor([0.4441, 0.3097, 0.2462], device='cuda:0'), new_distribution = tensor([0.4462, 0.3089, 0.2449], device='cuda:0')
2024-11-20 18:19:25,953 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 107: ref_distribution = tensor([0.4462, 0.3089, 0.2449], device='cuda:0'), new_distribution = tensor([0.4474, 0.3086, 0.2440], device='cuda:0')
2024-11-20 18:19:25,957 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 108: ref_distribution = tensor([0.4474, 0.3086, 0.2440], device='cuda:0'), new_distribution = tensor([0.4476, 0.3087, 0.2436], device='cuda:0')
2024-11-20 18:19:25,962 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 109: ref_distribution = tensor([0.4476, 0.3087, 0.2436], device='cuda:0'), new_distribution = tensor([0.4494, 0.3075, 0.2431], device='cuda:0')
2024-11-20 18:19:25,966 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 110: ref_distribution = tensor([0.4494, 0.3075, 0.2431], device='cuda:0'), new_distribution = tensor([0.4508, 0.3067, 0.2425], device='cuda:0')
2024-11-20 18:19:25,971 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 111: ref_distribution = tensor([0.4508, 0.3067, 0.2425], device='cuda:0'), new_distribution = tensor([0.4525, 0.3061, 0.2414], device='cuda:0')
2024-11-20 18:19:25,975 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 112: ref_distribution = tensor([0.4525, 0.3061, 0.2414], device='cuda:0'), new_distribution = tensor([0.4530, 0.3058, 0.2412], device='cuda:0')
2024-11-20 18:19:25,980 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 113: ref_distribution = tensor([0.4530, 0.3058, 0.2412], device='cuda:0'), new_distribution = tensor([0.4537, 0.3057, 0.2406], device='cuda:0')
2024-11-20 18:19:25,984 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 114: ref_distribution = tensor([0.4537, 0.3057, 0.2406], device='cuda:0'), new_distribution = tensor([0.4544, 0.3046, 0.2410], device='cuda:0')
2024-11-20 18:19:25,989 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 115: ref_distribution = tensor([0.4544, 0.3046, 0.2410], device='cuda:0'), new_distribution = tensor([0.4554, 0.3050, 0.2396], device='cuda:0')
2024-11-20 18:19:25,993 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 116: ref_distribution = tensor([0.4554, 0.3050, 0.2396], device='cuda:0'), new_distribution = tensor([0.4569, 0.3042, 0.2390], device='cuda:0')
2024-11-20 18:19:25,998 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 117: ref_distribution = tensor([0.4569, 0.3042, 0.2390], device='cuda:0'), new_distribution = tensor([0.4591, 0.3027, 0.2383], device='cuda:0')
2024-11-20 18:19:26,002 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 118: ref_distribution = tensor([0.4591, 0.3027, 0.2383], device='cuda:0'), new_distribution = tensor([0.4611, 0.3009, 0.2380], device='cuda:0')
2024-11-20 18:19:26,007 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 119: ref_distribution = tensor([0.4611, 0.3009, 0.2380], device='cuda:0'), new_distribution = tensor([0.4620, 0.2994, 0.2386], device='cuda:0')
2024-11-20 18:19:26,012 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 120: ref_distribution = tensor([0.4620, 0.2994, 0.2386], device='cuda:0'), new_distribution = tensor([0.4632, 0.2990, 0.2378], device='cuda:0')
2024-11-20 18:19:26,016 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 121: ref_distribution = tensor([0.4632, 0.2990, 0.2378], device='cuda:0'), new_distribution = tensor([0.4646, 0.2982, 0.2372], device='cuda:0')
2024-11-20 18:19:26,021 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 122: ref_distribution = tensor([0.4646, 0.2982, 0.2372], device='cuda:0'), new_distribution = tensor([0.4656, 0.2976, 0.2368], device='cuda:0')
2024-11-20 18:19:26,025 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 123: ref_distribution = tensor([0.4656, 0.2976, 0.2368], device='cuda:0'), new_distribution = tensor([0.4674, 0.2972, 0.2354], device='cuda:0')
2024-11-20 18:19:26,030 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 124: ref_distribution = tensor([0.4674, 0.2972, 0.2354], device='cuda:0'), new_distribution = tensor([0.4684, 0.2957, 0.2359], device='cuda:0')
2024-11-20 18:19:26,034 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 125: ref_distribution = tensor([0.4684, 0.2957, 0.2359], device='cuda:0'), new_distribution = tensor([0.4699, 0.2942, 0.2359], device='cuda:0')
2024-11-20 18:19:26,039 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 126: ref_distribution = tensor([0.4699, 0.2942, 0.2359], device='cuda:0'), new_distribution = tensor([0.4705, 0.2938, 0.2358], device='cuda:0')
2024-11-20 18:19:26,043 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 127: ref_distribution = tensor([0.4705, 0.2938, 0.2358], device='cuda:0'), new_distribution = tensor([0.4718, 0.2936, 0.2346], device='cuda:0')
2024-11-20 18:19:26,048 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 128: ref_distribution = tensor([0.4718, 0.2936, 0.2346], device='cuda:0'), new_distribution = tensor([0.4728, 0.2930, 0.2342], device='cuda:0')
2024-11-20 18:19:26,052 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 129: ref_distribution = tensor([0.4728, 0.2930, 0.2342], device='cuda:0'), new_distribution = tensor([0.4735, 0.2928, 0.2337], device='cuda:0')
2024-11-20 18:19:26,057 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 130: ref_distribution = tensor([0.4735, 0.2928, 0.2337], device='cuda:0'), new_distribution = tensor([0.4739, 0.2922, 0.2339], device='cuda:0')
2024-11-20 18:19:26,061 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 131: ref_distribution = tensor([0.4739, 0.2922, 0.2339], device='cuda:0'), new_distribution = tensor([0.4751, 0.2918, 0.2332], device='cuda:0')
2024-11-20 18:19:26,066 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 132: ref_distribution = tensor([0.4751, 0.2918, 0.2332], device='cuda:0'), new_distribution = tensor([0.4769, 0.2907, 0.2324], device='cuda:0')
2024-11-20 18:19:26,070 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 133: ref_distribution = tensor([0.4769, 0.2907, 0.2324], device='cuda:0'), new_distribution = tensor([0.4788, 0.2887, 0.2325], device='cuda:0')
2024-11-20 18:19:26,075 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 134: ref_distribution = tensor([0.4788, 0.2887, 0.2325], device='cuda:0'), new_distribution = tensor([0.4798, 0.2880, 0.2322], device='cuda:0')
2024-11-20 18:19:26,079 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 135: ref_distribution = tensor([0.4798, 0.2880, 0.2322], device='cuda:0'), new_distribution = tensor([0.4814, 0.2874, 0.2312], device='cuda:0')
2024-11-20 18:19:26,083 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 136: ref_distribution = tensor([0.4814, 0.2874, 0.2312], device='cuda:0'), new_distribution = tensor([0.4834, 0.2856, 0.2310], device='cuda:0')
2024-11-20 18:19:26,088 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 137: ref_distribution = tensor([0.4834, 0.2856, 0.2310], device='cuda:0'), new_distribution = tensor([0.4845, 0.2852, 0.2303], device='cuda:0')
2024-11-20 18:19:26,093 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 138: ref_distribution = tensor([0.4845, 0.2852, 0.2303], device='cuda:0'), new_distribution = tensor([0.4859, 0.2843, 0.2297], device='cuda:0')
2024-11-20 18:19:26,097 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 139: ref_distribution = tensor([0.4859, 0.2843, 0.2297], device='cuda:0'), new_distribution = tensor([0.4872, 0.2832, 0.2295], device='cuda:0')
2024-11-20 18:19:26,102 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 140: ref_distribution = tensor([0.4872, 0.2832, 0.2295], device='cuda:0'), new_distribution = tensor([0.4891, 0.2821, 0.2288], device='cuda:0')
2024-11-20 18:19:26,106 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 141: ref_distribution = tensor([0.4891, 0.2821, 0.2288], device='cuda:0'), new_distribution = tensor([0.4898, 0.2819, 0.2283], device='cuda:0')
2024-11-20 18:19:26,111 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 142: ref_distribution = tensor([0.4898, 0.2819, 0.2283], device='cuda:0'), new_distribution = tensor([0.4905, 0.2817, 0.2278], device='cuda:0')
2024-11-20 18:19:26,116 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 143: ref_distribution = tensor([0.4905, 0.2817, 0.2278], device='cuda:0'), new_distribution = tensor([0.4917, 0.2812, 0.2271], device='cuda:0')
2024-11-20 18:19:26,120 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 144: ref_distribution = tensor([0.4917, 0.2812, 0.2271], device='cuda:0'), new_distribution = tensor([0.4920, 0.2812, 0.2268], device='cuda:0')
2024-11-20 18:19:26,125 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 145: ref_distribution = tensor([0.4920, 0.2812, 0.2268], device='cuda:0'), new_distribution = tensor([0.4927, 0.2810, 0.2263], device='cuda:0')
2024-11-20 18:19:26,129 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 146: ref_distribution = tensor([0.4927, 0.2810, 0.2263], device='cuda:0'), new_distribution = tensor([0.4941, 0.2792, 0.2267], device='cuda:0')
2024-11-20 18:19:26,134 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 147: ref_distribution = tensor([0.4941, 0.2792, 0.2267], device='cuda:0'), new_distribution = tensor([0.4951, 0.2776, 0.2273], device='cuda:0')
2024-11-20 18:19:26,138 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 148: ref_distribution = tensor([0.4951, 0.2776, 0.2273], device='cuda:0'), new_distribution = tensor([0.4964, 0.2764, 0.2272], device='cuda:0')
2024-11-20 18:19:26,143 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 149: ref_distribution = tensor([0.4964, 0.2764, 0.2272], device='cuda:0'), new_distribution = tensor([0.4974, 0.2758, 0.2269], device='cuda:0')
2024-11-20 18:19:26,147 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 150: ref_distribution = tensor([0.4974, 0.2758, 0.2269], device='cuda:0'), new_distribution = tensor([0.4992, 0.2738, 0.2271], device='cuda:0')
2024-11-20 18:19:26,152 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 151: ref_distribution = tensor([0.4992, 0.2738, 0.2271], device='cuda:0'), new_distribution = tensor([0.5006, 0.2720, 0.2275], device='cuda:0')
2024-11-20 18:19:26,156 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 152: ref_distribution = tensor([0.5006, 0.2720, 0.2275], device='cuda:0'), new_distribution = tensor([0.5021, 0.2704, 0.2275], device='cuda:0')
2024-11-20 18:19:26,161 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 153: ref_distribution = tensor([0.5021, 0.2704, 0.2275], device='cuda:0'), new_distribution = tensor([0.5025, 0.2697, 0.2278], device='cuda:0')
2024-11-20 18:19:26,165 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 154: ref_distribution = tensor([0.5025, 0.2697, 0.2278], device='cuda:0'), new_distribution = tensor([0.5030, 0.2690, 0.2281], device='cuda:0')
2024-11-20 18:19:26,169 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 155: ref_distribution = tensor([0.5030, 0.2690, 0.2281], device='cuda:0'), new_distribution = tensor([0.5030, 0.2685, 0.2286], device='cuda:0')
2024-11-20 18:19:26,174 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 156: ref_distribution = tensor([0.5030, 0.2685, 0.2286], device='cuda:0'), new_distribution = tensor([0.5037, 0.2673, 0.2290], device='cuda:0')
2024-11-20 18:19:26,178 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 157: ref_distribution = tensor([0.5037, 0.2673, 0.2290], device='cuda:0'), new_distribution = tensor([0.5046, 0.2666, 0.2287], device='cuda:0')
2024-11-20 18:19:26,183 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 158: ref_distribution = tensor([0.5046, 0.2666, 0.2287], device='cuda:0'), new_distribution = tensor([0.5055, 0.2657, 0.2288], device='cuda:0')
2024-11-20 18:19:26,187 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 159: ref_distribution = tensor([0.5055, 0.2657, 0.2288], device='cuda:0'), new_distribution = tensor([0.5063, 0.2648, 0.2289], device='cuda:0')
2024-11-20 18:19:26,192 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 160: ref_distribution = tensor([0.5063, 0.2648, 0.2289], device='cuda:0'), new_distribution = tensor([0.5070, 0.2646, 0.2285], device='cuda:0')
2024-11-20 18:19:26,196 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 161: ref_distribution = tensor([0.5070, 0.2646, 0.2285], device='cuda:0'), new_distribution = tensor([0.5086, 0.2633, 0.2281], device='cuda:0')
2024-11-20 18:19:26,201 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 162: ref_distribution = tensor([0.5086, 0.2633, 0.2281], device='cuda:0'), new_distribution = tensor([0.5094, 0.2632, 0.2273], device='cuda:0')
2024-11-20 18:19:26,205 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 163: ref_distribution = tensor([0.5094, 0.2632, 0.2273], device='cuda:0'), new_distribution = tensor([0.5104, 0.2626, 0.2271], device='cuda:0')
2024-11-20 18:19:26,210 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 164: ref_distribution = tensor([0.5104, 0.2626, 0.2271], device='cuda:0'), new_distribution = tensor([0.5116, 0.2614, 0.2269], device='cuda:0')
2024-11-20 18:19:26,214 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 165: ref_distribution = tensor([0.5116, 0.2614, 0.2269], device='cuda:0'), new_distribution = tensor([0.5119, 0.2614, 0.2267], device='cuda:0')
2024-11-20 18:19:26,219 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 166: ref_distribution = tensor([0.5119, 0.2614, 0.2267], device='cuda:0'), new_distribution = tensor([0.5127, 0.2596, 0.2277], device='cuda:0')
2024-11-20 18:19:26,223 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 167: ref_distribution = tensor([0.5127, 0.2596, 0.2277], device='cuda:0'), new_distribution = tensor([0.5133, 0.2582, 0.2285], device='cuda:0')
2024-11-20 18:19:26,228 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 168: ref_distribution = tensor([0.5133, 0.2582, 0.2285], device='cuda:0'), new_distribution = tensor([0.5139, 0.2568, 0.2294], device='cuda:0')
2024-11-20 18:19:26,232 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 169: ref_distribution = tensor([0.5139, 0.2568, 0.2294], device='cuda:0'), new_distribution = tensor([0.5144, 0.2554, 0.2302], device='cuda:0')
2024-11-20 18:19:26,237 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 170: ref_distribution = tensor([0.5144, 0.2554, 0.2302], device='cuda:0'), new_distribution = tensor([0.5161, 0.2543, 0.2295], device='cuda:0')
2024-11-20 18:19:26,242 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 171: ref_distribution = tensor([0.5161, 0.2543, 0.2295], device='cuda:0'), new_distribution = tensor([0.5167, 0.2530, 0.2303], device='cuda:0')
2024-11-20 18:19:26,246 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 172: ref_distribution = tensor([0.5167, 0.2530, 0.2303], device='cuda:0'), new_distribution = tensor([0.5183, 0.2508, 0.2309], device='cuda:0')
2024-11-20 18:19:26,251 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 173: ref_distribution = tensor([0.5183, 0.2508, 0.2309], device='cuda:0'), new_distribution = tensor([0.5195, 0.2488, 0.2317], device='cuda:0')
2024-11-20 18:19:26,255 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 174: ref_distribution = tensor([0.5195, 0.2488, 0.2317], device='cuda:0'), new_distribution = tensor([0.5203, 0.2470, 0.2327], device='cuda:0')
2024-11-20 18:19:26,260 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 175: ref_distribution = tensor([0.5203, 0.2470, 0.2327], device='cuda:0'), new_distribution = tensor([0.5212, 0.2454, 0.2333], device='cuda:0')
2024-11-20 18:19:26,264 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 176: ref_distribution = tensor([0.5212, 0.2454, 0.2333], device='cuda:0'), new_distribution = tensor([0.5228, 0.2433, 0.2339], device='cuda:0')
2024-11-20 18:19:26,269 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 177: ref_distribution = tensor([0.5228, 0.2433, 0.2339], device='cuda:0'), new_distribution = tensor([0.5240, 0.2422, 0.2339], device='cuda:0')
2024-11-20 18:19:26,273 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 178: ref_distribution = tensor([0.5240, 0.2422, 0.2339], device='cuda:0'), new_distribution = tensor([0.5239, 0.2426, 0.2335], device='cuda:0')
2024-11-20 18:19:26,278 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 179: ref_distribution = tensor([0.5239, 0.2426, 0.2335], device='cuda:0'), new_distribution = tensor([0.5252, 0.2417, 0.2331], device='cuda:0')
2024-11-20 18:19:26,282 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 180: ref_distribution = tensor([0.5252, 0.2417, 0.2331], device='cuda:0'), new_distribution = tensor([0.5253, 0.2414, 0.2333], device='cuda:0')
2024-11-20 18:19:26,287 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 181: ref_distribution = tensor([0.5253, 0.2414, 0.2333], device='cuda:0'), new_distribution = tensor([0.5268, 0.2402, 0.2330], device='cuda:0')
2024-11-20 18:19:26,291 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 182: ref_distribution = tensor([0.5268, 0.2402, 0.2330], device='cuda:0'), new_distribution = tensor([0.5280, 0.2391, 0.2329], device='cuda:0')
2024-11-20 18:19:26,296 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 183: ref_distribution = tensor([0.5280, 0.2391, 0.2329], device='cuda:0'), new_distribution = tensor([0.5293, 0.2373, 0.2334], device='cuda:0')
2024-11-20 18:19:26,300 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 184: ref_distribution = tensor([0.5293, 0.2373, 0.2334], device='cuda:0'), new_distribution = tensor([0.5291, 0.2375, 0.2334], device='cuda:0')
2024-11-20 18:19:26,304 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 185: ref_distribution = tensor([0.5291, 0.2375, 0.2334], device='cuda:0'), new_distribution = tensor([0.5293, 0.2374, 0.2332], device='cuda:0')
2024-11-20 18:19:26,309 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 186: ref_distribution = tensor([0.5293, 0.2374, 0.2332], device='cuda:0'), new_distribution = tensor([0.5302, 0.2359, 0.2339], device='cuda:0')
2024-11-20 18:19:26,313 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 187: ref_distribution = tensor([0.5302, 0.2359, 0.2339], device='cuda:0'), new_distribution = tensor([0.5320, 0.2342, 0.2338], device='cuda:0')
2024-11-20 18:19:26,318 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 188: ref_distribution = tensor([0.5320, 0.2342, 0.2338], device='cuda:0'), new_distribution = tensor([0.5329, 0.2336, 0.2336], device='cuda:0')
2024-11-20 18:19:26,322 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 189: ref_distribution = tensor([0.5329, 0.2336, 0.2336], device='cuda:0'), new_distribution = tensor([0.5345, 0.2317, 0.2338], device='cuda:0')
2024-11-20 18:19:26,327 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 190: ref_distribution = tensor([0.5345, 0.2317, 0.2338], device='cuda:0'), new_distribution = tensor([0.5348, 0.2307, 0.2345], device='cuda:0')
2024-11-20 18:19:26,332 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 191: ref_distribution = tensor([0.5348, 0.2307, 0.2345], device='cuda:0'), new_distribution = tensor([0.5357, 0.2292, 0.2351], device='cuda:0')
2024-11-20 18:19:26,336 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 192: ref_distribution = tensor([0.5357, 0.2292, 0.2351], device='cuda:0'), new_distribution = tensor([0.5364, 0.2283, 0.2353], device='cuda:0')
2024-11-20 18:19:26,341 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 193: ref_distribution = tensor([0.5364, 0.2283, 0.2353], device='cuda:0'), new_distribution = tensor([0.5374, 0.2270, 0.2356], device='cuda:0')
2024-11-20 18:19:26,345 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 194: ref_distribution = tensor([0.5374, 0.2270, 0.2356], device='cuda:0'), new_distribution = tensor([0.5387, 0.2256, 0.2357], device='cuda:0')
2024-11-20 18:19:26,350 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 195: ref_distribution = tensor([0.5387, 0.2256, 0.2357], device='cuda:0'), new_distribution = tensor([0.5398, 0.2236, 0.2365], device='cuda:0')
2024-11-20 18:19:26,354 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 196: ref_distribution = tensor([0.5398, 0.2236, 0.2365], device='cuda:0'), new_distribution = tensor([0.5411, 0.2220, 0.2370], device='cuda:0')
2024-11-20 18:19:26,359 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 197: ref_distribution = tensor([0.5411, 0.2220, 0.2370], device='cuda:0'), new_distribution = tensor([0.5423, 0.2203, 0.2375], device='cuda:0')
2024-11-20 18:19:26,363 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 198: ref_distribution = tensor([0.5423, 0.2203, 0.2375], device='cuda:0'), new_distribution = tensor([0.5433, 0.2192, 0.2374], device='cuda:0')
2024-11-20 18:19:26,368 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 199: ref_distribution = tensor([0.5433, 0.2192, 0.2374], device='cuda:0'), new_distribution = tensor([0.5446, 0.2178, 0.2376], device='cuda:0')
2024-11-20 18:19:26,372 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 200: ref_distribution = tensor([0.5446, 0.2178, 0.2376], device='cuda:0'), new_distribution = tensor([0.5452, 0.2167, 0.2381], device='cuda:0')
2024-11-20 18:19:26,377 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 201: ref_distribution = tensor([0.5452, 0.2167, 0.2381], device='cuda:0'), new_distribution = tensor([0.5465, 0.2153, 0.2382], device='cuda:0')
2024-11-20 18:19:26,381 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 202: ref_distribution = tensor([0.5465, 0.2153, 0.2382], device='cuda:0'), new_distribution = tensor([0.5472, 0.2144, 0.2384], device='cuda:0')
2024-11-20 18:19:26,386 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 203: ref_distribution = tensor([0.5472, 0.2144, 0.2384], device='cuda:0'), new_distribution = tensor([0.5478, 0.2133, 0.2389], device='cuda:0')
2024-11-20 18:19:26,390 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 204: ref_distribution = tensor([0.5478, 0.2133, 0.2389], device='cuda:0'), new_distribution = tensor([0.5483, 0.2122, 0.2394], device='cuda:0')
2024-11-20 18:19:26,395 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 205: ref_distribution = tensor([0.5483, 0.2122, 0.2394], device='cuda:0'), new_distribution = tensor([0.5493, 0.2110, 0.2397], device='cuda:0')
2024-11-20 18:19:26,399 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 206: ref_distribution = tensor([0.5493, 0.2110, 0.2397], device='cuda:0'), new_distribution = tensor([0.5503, 0.2091, 0.2405], device='cuda:0')
2024-11-20 18:19:26,404 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 207: ref_distribution = tensor([0.5503, 0.2091, 0.2405], device='cuda:0'), new_distribution = tensor([0.5512, 0.2087, 0.2401], device='cuda:0')
2024-11-20 18:19:26,408 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 208: ref_distribution = tensor([0.5512, 0.2087, 0.2401], device='cuda:0'), new_distribution = tensor([0.5524, 0.2073, 0.2402], device='cuda:0')
2024-11-20 18:19:26,413 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 209: ref_distribution = tensor([0.5524, 0.2073, 0.2402], device='cuda:0'), new_distribution = tensor([0.5536, 0.2057, 0.2407], device='cuda:0')
2024-11-20 18:19:26,417 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 210: ref_distribution = tensor([0.5536, 0.2057, 0.2407], device='cuda:0'), new_distribution = tensor([0.5552, 0.2041, 0.2407], device='cuda:0')
2024-11-20 18:19:26,422 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 211: ref_distribution = tensor([0.5552, 0.2041, 0.2407], device='cuda:0'), new_distribution = tensor([0.5559, 0.2035, 0.2406], device='cuda:0')
2024-11-20 18:19:26,426 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 212: ref_distribution = tensor([0.5559, 0.2035, 0.2406], device='cuda:0'), new_distribution = tensor([0.5563, 0.2031, 0.2406], device='cuda:0')
2024-11-20 18:19:26,431 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 213: ref_distribution = tensor([0.5563, 0.2031, 0.2406], device='cuda:0'), new_distribution = tensor([0.5560, 0.2030, 0.2410], device='cuda:0')
2024-11-20 18:19:26,435 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 214: ref_distribution = tensor([0.5560, 0.2030, 0.2410], device='cuda:0'), new_distribution = tensor([0.5562, 0.2021, 0.2417], device='cuda:0')
2024-11-20 18:19:26,440 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 215: ref_distribution = tensor([0.5562, 0.2021, 0.2417], device='cuda:0'), new_distribution = tensor([0.5569, 0.2013, 0.2419], device='cuda:0')
2024-11-20 18:19:26,445 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 216: ref_distribution = tensor([0.5569, 0.2013, 0.2419], device='cuda:0'), new_distribution = tensor([0.5578, 0.2003, 0.2419], device='cuda:0')
2024-11-20 18:19:26,449 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 217: ref_distribution = tensor([0.5578, 0.2003, 0.2419], device='cuda:0'), new_distribution = tensor([0.5581, 0.2004, 0.2415], device='cuda:0')
2024-11-20 18:19:26,454 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 218: ref_distribution = tensor([0.5581, 0.2004, 0.2415], device='cuda:0'), new_distribution = tensor([0.5591, 0.1986, 0.2423], device='cuda:0')
2024-11-20 18:19:26,458 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 219: ref_distribution = tensor([0.5591, 0.1986, 0.2423], device='cuda:0'), new_distribution = tensor([0.5598, 0.1980, 0.2422], device='cuda:0')
2024-11-20 18:19:26,463 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 220: ref_distribution = tensor([0.5598, 0.1980, 0.2422], device='cuda:0'), new_distribution = tensor([0.5609, 0.1964, 0.2427], device='cuda:0')
2024-11-20 18:19:26,467 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 221: ref_distribution = tensor([0.5609, 0.1964, 0.2427], device='cuda:0'), new_distribution = tensor([0.5616, 0.1958, 0.2426], device='cuda:0')
2024-11-20 18:19:26,472 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 222: ref_distribution = tensor([0.5616, 0.1958, 0.2426], device='cuda:0'), new_distribution = tensor([0.5628, 0.1953, 0.2420], device='cuda:0')
2024-11-20 18:19:26,476 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 223: ref_distribution = tensor([0.5628, 0.1953, 0.2420], device='cuda:0'), new_distribution = tensor([0.5641, 0.1941, 0.2418], device='cuda:0')
2024-11-20 18:19:26,481 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 224: ref_distribution = tensor([0.5641, 0.1941, 0.2418], device='cuda:0'), new_distribution = tensor([0.5647, 0.1925, 0.2428], device='cuda:0')
2024-11-20 18:19:26,486 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 225: ref_distribution = tensor([0.5647, 0.1925, 0.2428], device='cuda:0'), new_distribution = tensor([0.5658, 0.1909, 0.2433], device='cuda:0')
2024-11-20 18:19:26,490 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 226: ref_distribution = tensor([0.5658, 0.1909, 0.2433], device='cuda:0'), new_distribution = tensor([0.5663, 0.1899, 0.2439], device='cuda:0')
2024-11-20 18:19:26,495 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 227: ref_distribution = tensor([0.5663, 0.1899, 0.2439], device='cuda:0'), new_distribution = tensor([0.5669, 0.1883, 0.2448], device='cuda:0')
2024-11-20 18:19:26,499 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 228: ref_distribution = tensor([0.5669, 0.1883, 0.2448], device='cuda:0'), new_distribution = tensor([0.5677, 0.1871, 0.2452], device='cuda:0')
2024-11-20 18:19:26,503 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 229: ref_distribution = tensor([0.5677, 0.1871, 0.2452], device='cuda:0'), new_distribution = tensor([0.5681, 0.1859, 0.2461], device='cuda:0')
2024-11-20 18:19:26,507 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 230: ref_distribution = tensor([0.5681, 0.1859, 0.2461], device='cuda:0'), new_distribution = tensor([0.5682, 0.1858, 0.2460], device='cuda:0')
2024-11-20 18:19:26,511 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 231: ref_distribution = tensor([0.5682, 0.1858, 0.2460], device='cuda:0'), new_distribution = tensor([0.5688, 0.1853, 0.2459], device='cuda:0')
2024-11-20 18:19:26,515 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 232: ref_distribution = tensor([0.5688, 0.1853, 0.2459], device='cuda:0'), new_distribution = tensor([0.5697, 0.1843, 0.2459], device='cuda:0')
2024-11-20 18:19:26,519 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 233: ref_distribution = tensor([0.5697, 0.1843, 0.2459], device='cuda:0'), new_distribution = tensor([0.5704, 0.1829, 0.2466], device='cuda:0')
2024-11-20 18:19:26,523 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 234: ref_distribution = tensor([0.5704, 0.1829, 0.2466], device='cuda:0'), new_distribution = tensor([0.5711, 0.1816, 0.2473], device='cuda:0')
2024-11-20 18:19:26,527 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 235: ref_distribution = tensor([0.5711, 0.1816, 0.2473], device='cuda:0'), new_distribution = tensor([0.5721, 0.1801, 0.2478], device='cuda:0')
2024-11-20 18:19:26,531 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 236: ref_distribution = tensor([0.5721, 0.1801, 0.2478], device='cuda:0'), new_distribution = tensor([0.5732, 0.1788, 0.2480], device='cuda:0')
2024-11-20 18:19:26,535 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 237: ref_distribution = tensor([0.5732, 0.1788, 0.2480], device='cuda:0'), new_distribution = tensor([0.5742, 0.1773, 0.2486], device='cuda:0')
2024-11-20 18:19:26,539 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 238: ref_distribution = tensor([0.5742, 0.1773, 0.2486], device='cuda:0'), new_distribution = tensor([0.5749, 0.1761, 0.2489], device='cuda:0')
2024-11-20 18:19:26,543 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 239: ref_distribution = tensor([0.5749, 0.1761, 0.2489], device='cuda:0'), new_distribution = tensor([0.5756, 0.1748, 0.2496], device='cuda:0')
2024-11-20 18:19:26,547 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 240: ref_distribution = tensor([0.5756, 0.1748, 0.2496], device='cuda:0'), new_distribution = tensor([0.5760, 0.1738, 0.2502], device='cuda:0')
2024-11-20 18:19:26,550 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 241: ref_distribution = tensor([0.5760, 0.1738, 0.2502], device='cuda:0'), new_distribution = tensor([0.5764, 0.1729, 0.2507], device='cuda:0')
2024-11-20 18:19:26,554 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 242: ref_distribution = tensor([0.5764, 0.1729, 0.2507], device='cuda:0'), new_distribution = tensor([0.5772, 0.1718, 0.2511], device='cuda:0')
2024-11-20 18:19:26,558 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 243: ref_distribution = tensor([0.5772, 0.1718, 0.2511], device='cuda:0'), new_distribution = tensor([0.5773, 0.1712, 0.2515], device='cuda:0')
2024-11-20 18:19:26,562 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 244: ref_distribution = tensor([0.5773, 0.1712, 0.2515], device='cuda:0'), new_distribution = tensor([0.5780, 0.1698, 0.2522], device='cuda:0')
2024-11-20 18:19:26,566 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 245: ref_distribution = tensor([0.5780, 0.1698, 0.2522], device='cuda:0'), new_distribution = tensor([0.5790, 0.1696, 0.2514], device='cuda:0')
2024-11-20 18:19:26,570 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 246: ref_distribution = tensor([0.5790, 0.1696, 0.2514], device='cuda:0'), new_distribution = tensor([0.5795, 0.1688, 0.2516], device='cuda:0')
2024-11-20 18:19:26,574 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 247: ref_distribution = tensor([0.5795, 0.1688, 0.2516], device='cuda:0'), new_distribution = tensor([0.5796, 0.1680, 0.2523], device='cuda:0')
2024-11-20 18:19:26,578 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 248: ref_distribution = tensor([0.5796, 0.1680, 0.2523], device='cuda:0'), new_distribution = tensor([0.5802, 0.1667, 0.2530], device='cuda:0')
2024-11-20 18:19:26,582 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 249: ref_distribution = tensor([0.5802, 0.1667, 0.2530], device='cuda:0'), new_distribution = tensor([0.5810, 0.1651, 0.2539], device='cuda:0')
2024-11-20 18:19:26,585 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 250: ref_distribution = tensor([0.5810, 0.1651, 0.2539], device='cuda:0'), new_distribution = tensor([0.5819, 0.1637, 0.2544], device='cuda:0')
2024-11-20 18:19:26,589 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 251: ref_distribution = tensor([0.5819, 0.1637, 0.2544], device='cuda:0'), new_distribution = tensor([0.5828, 0.1615, 0.2557], device='cuda:0')
2024-11-20 18:19:26,593 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 252: ref_distribution = tensor([0.5828, 0.1615, 0.2557], device='cuda:0'), new_distribution = tensor([0.5836, 0.1607, 0.2558], device='cuda:0')
2024-11-20 18:19:26,597 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 253: ref_distribution = tensor([0.5836, 0.1607, 0.2558], device='cuda:0'), new_distribution = tensor([0.5845, 0.1587, 0.2567], device='cuda:0')
2024-11-20 18:19:26,601 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 254: ref_distribution = tensor([0.5845, 0.1587, 0.2567], device='cuda:0'), new_distribution = tensor([0.5851, 0.1582, 0.2567], device='cuda:0')
2024-11-20 18:19:26,605 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 255: ref_distribution = tensor([0.5851, 0.1582, 0.2567], device='cuda:0'), new_distribution = tensor([0.5856, 0.1570, 0.2574], device='cuda:0')
2024-11-20 18:19:26,609 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 256: ref_distribution = tensor([0.5856, 0.1570, 0.2574], device='cuda:0'), new_distribution = tensor([0.5858, 0.1564, 0.2578], device='cuda:0')
2024-11-20 18:19:26,613 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 257: ref_distribution = tensor([0.5858, 0.1564, 0.2578], device='cuda:0'), new_distribution = tensor([0.5859, 0.1559, 0.2583], device='cuda:0')
2024-11-20 18:19:26,617 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 258: ref_distribution = tensor([0.5859, 0.1559, 0.2583], device='cuda:0'), new_distribution = tensor([0.5866, 0.1550, 0.2584], device='cuda:0')
2024-11-20 18:19:26,621 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 259: ref_distribution = tensor([0.5866, 0.1550, 0.2584], device='cuda:0'), new_distribution = tensor([0.5867, 0.1545, 0.2588], device='cuda:0')
2024-11-20 18:19:26,625 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 260: ref_distribution = tensor([0.5867, 0.1545, 0.2588], device='cuda:0'), new_distribution = tensor([0.5875, 0.1531, 0.2593], device='cuda:0')
2024-11-20 18:19:26,629 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 261: ref_distribution = tensor([0.5875, 0.1531, 0.2593], device='cuda:0'), new_distribution = tensor([0.5878, 0.1520, 0.2602], device='cuda:0')
2024-11-20 18:19:26,632 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 262: ref_distribution = tensor([0.5878, 0.1520, 0.2602], device='cuda:0'), new_distribution = tensor([0.5882, 0.1506, 0.2612], device='cuda:0')
2024-11-20 18:19:26,636 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 263: ref_distribution = tensor([0.5882, 0.1506, 0.2612], device='cuda:0'), new_distribution = tensor([0.5889, 0.1498, 0.2613], device='cuda:0')
2024-11-20 18:19:26,640 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 264: ref_distribution = tensor([0.5889, 0.1498, 0.2613], device='cuda:0'), new_distribution = tensor([0.5891, 0.1488, 0.2622], device='cuda:0')
2024-11-20 18:19:26,643 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 265: ref_distribution = tensor([0.5891, 0.1488, 0.2622], device='cuda:0'), new_distribution = tensor([0.5896, 0.1476, 0.2629], device='cuda:0')
2024-11-20 18:19:26,647 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 266: ref_distribution = tensor([0.5896, 0.1476, 0.2629], device='cuda:0'), new_distribution = tensor([0.5901, 0.1466, 0.2633], device='cuda:0')
2024-11-20 18:19:26,651 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 267: ref_distribution = tensor([0.5901, 0.1466, 0.2633], device='cuda:0'), new_distribution = tensor([0.5907, 0.1456, 0.2637], device='cuda:0')
2024-11-20 18:19:26,655 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 268: ref_distribution = tensor([0.5907, 0.1456, 0.2637], device='cuda:0'), new_distribution = tensor([0.5912, 0.1446, 0.2641], device='cuda:0')
2024-11-20 18:19:26,658 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 269: ref_distribution = tensor([0.5912, 0.1446, 0.2641], device='cuda:0'), new_distribution = tensor([0.5914, 0.1436, 0.2650], device='cuda:0')
2024-11-20 18:19:26,662 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 270: ref_distribution = tensor([0.5914, 0.1436, 0.2650], device='cuda:0'), new_distribution = tensor([0.5916, 0.1433, 0.2651], device='cuda:0')
2024-11-20 18:19:26,666 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 271: ref_distribution = tensor([0.5916, 0.1433, 0.2651], device='cuda:0'), new_distribution = tensor([0.5921, 0.1430, 0.2649], device='cuda:0')
2024-11-20 18:19:26,669 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 272: ref_distribution = tensor([0.5921, 0.1430, 0.2649], device='cuda:0'), new_distribution = tensor([0.5927, 0.1420, 0.2653], device='cuda:0')
2024-11-20 18:19:26,673 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 273: ref_distribution = tensor([0.5927, 0.1420, 0.2653], device='cuda:0'), new_distribution = tensor([0.5936, 0.1405, 0.2660], device='cuda:0')
2024-11-20 18:19:26,677 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 274: ref_distribution = tensor([0.5936, 0.1405, 0.2660], device='cuda:0'), new_distribution = tensor([0.5942, 0.1390, 0.2668], device='cuda:0')
2024-11-20 18:19:26,680 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 275: ref_distribution = tensor([0.5942, 0.1390, 0.2668], device='cuda:0'), new_distribution = tensor([0.5945, 0.1377, 0.2678], device='cuda:0')
2024-11-20 18:19:26,684 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 276: ref_distribution = tensor([0.5945, 0.1377, 0.2678], device='cuda:0'), new_distribution = tensor([0.5951, 0.1369, 0.2680], device='cuda:0')
2024-11-20 18:19:26,688 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 277: ref_distribution = tensor([0.5951, 0.1369, 0.2680], device='cuda:0'), new_distribution = tensor([0.5954, 0.1356, 0.2690], device='cuda:0')
2024-11-20 18:19:26,692 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 278: ref_distribution = tensor([0.5954, 0.1356, 0.2690], device='cuda:0'), new_distribution = tensor([0.5959, 0.1347, 0.2694], device='cuda:0')
2024-11-20 18:19:26,695 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 279: ref_distribution = tensor([0.5959, 0.1347, 0.2694], device='cuda:0'), new_distribution = tensor([0.5964, 0.1331, 0.2705], device='cuda:0')
2024-11-20 18:19:26,699 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 280: ref_distribution = tensor([0.5964, 0.1331, 0.2705], device='cuda:0'), new_distribution = tensor([0.5969, 0.1317, 0.2713], device='cuda:0')
2024-11-20 18:19:26,703 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 281: ref_distribution = tensor([0.5969, 0.1317, 0.2713], device='cuda:0'), new_distribution = tensor([0.5971, 0.1310, 0.2719], device='cuda:0')
2024-11-20 18:19:26,706 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 282: ref_distribution = tensor([0.5971, 0.1310, 0.2719], device='cuda:0'), new_distribution = tensor([0.5976, 0.1301, 0.2724], device='cuda:0')
2024-11-20 18:19:26,710 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 283: ref_distribution = tensor([0.5976, 0.1301, 0.2724], device='cuda:0'), new_distribution = tensor([0.5977, 0.1293, 0.2729], device='cuda:0')
2024-11-20 18:19:26,714 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 284: ref_distribution = tensor([0.5977, 0.1293, 0.2729], device='cuda:0'), new_distribution = tensor([0.5983, 0.1286, 0.2731], device='cuda:0')
2024-11-20 18:19:26,718 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 285: ref_distribution = tensor([0.5983, 0.1286, 0.2731], device='cuda:0'), new_distribution = tensor([0.5986, 0.1282, 0.2732], device='cuda:0')
2024-11-20 18:19:26,721 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 286: ref_distribution = tensor([0.5986, 0.1282, 0.2732], device='cuda:0'), new_distribution = tensor([0.5995, 0.1269, 0.2736], device='cuda:0')
2024-11-20 18:19:26,725 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 287: ref_distribution = tensor([0.5995, 0.1269, 0.2736], device='cuda:0'), new_distribution = tensor([0.5993, 0.1272, 0.2736], device='cuda:0')
2024-11-20 18:19:26,729 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 288: ref_distribution = tensor([0.5993, 0.1272, 0.2736], device='cuda:0'), new_distribution = tensor([0.5995, 0.1260, 0.2745], device='cuda:0')
2024-11-20 18:19:26,733 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 289: ref_distribution = tensor([0.5995, 0.1260, 0.2745], device='cuda:0'), new_distribution = tensor([0.5997, 0.1252, 0.2751], device='cuda:0')
2024-11-20 18:19:26,736 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 290: ref_distribution = tensor([0.5997, 0.1252, 0.2751], device='cuda:0'), new_distribution = tensor([0.5998, 0.1245, 0.2757], device='cuda:0')
2024-11-20 18:19:26,740 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 291: ref_distribution = tensor([0.5998, 0.1245, 0.2757], device='cuda:0'), new_distribution = tensor([0.5994, 0.1244, 0.2762], device='cuda:0')
2024-11-20 18:19:26,744 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 292: ref_distribution = tensor([0.5994, 0.1244, 0.2762], device='cuda:0'), new_distribution = tensor([0.5999, 0.1231, 0.2770], device='cuda:0')
2024-11-20 18:19:26,747 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 293: ref_distribution = tensor([0.5999, 0.1231, 0.2770], device='cuda:0'), new_distribution = tensor([0.5999, 0.1228, 0.2772], device='cuda:0')
2024-11-20 18:19:26,751 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 294: ref_distribution = tensor([0.5999, 0.1228, 0.2772], device='cuda:0'), new_distribution = tensor([0.6000, 0.1219, 0.2781], device='cuda:0')
2024-11-20 18:19:26,755 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 295: ref_distribution = tensor([0.6000, 0.1219, 0.2781], device='cuda:0'), new_distribution = tensor([0.6008, 0.1213, 0.2779], device='cuda:0')
2024-11-20 18:19:26,758 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 296: ref_distribution = tensor([0.6008, 0.1213, 0.2779], device='cuda:0'), new_distribution = tensor([0.6009, 0.1204, 0.2787], device='cuda:0')
2024-11-20 18:19:26,762 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 297: ref_distribution = tensor([0.6009, 0.1204, 0.2787], device='cuda:0'), new_distribution = tensor([0.6014, 0.1193, 0.2793], device='cuda:0')
2024-11-20 18:19:26,765 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 298: ref_distribution = tensor([0.6014, 0.1193, 0.2793], device='cuda:0'), new_distribution = tensor([0.6015, 0.1192, 0.2793], device='cuda:0')
2024-11-20 18:19:26,769 - /home/hanwen/policy_optimization/exp/algorithm.py[line:509] - INFO: Iteration 299: ref_distribution = tensor([0.6015, 0.1192, 0.2793], device='cuda:0'), new_distribution = tensor([0.6009, 0.1195, 0.2796], device='cuda:0')
