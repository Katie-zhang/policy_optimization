2024-12-07 17:37:09,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 0 loss: 0.6650 grad norm: 0.7181 policy: 0.3311 0.3813
2024-12-07 17:37:13,007 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 5 loss: 0.6157 grad norm: 0.6452 policy: 0.3675 0.3700
2024-12-07 17:37:16,399 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 10 loss: 0.5719 grad norm: 0.6340 policy: 0.4036 0.3595
2024-12-07 17:37:19,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 15 loss: 0.5312 grad norm: 0.6238 policy: 0.4356 0.3548
2024-12-07 17:37:23,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 20 loss: 0.4940 grad norm: 0.6215 policy: 0.4650 0.3524
2024-12-07 17:37:26,793 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 25 loss: 0.4583 grad norm: 0.6140 policy: 0.5006 0.3417
2024-12-07 17:37:30,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 30 loss: 0.4237 grad norm: 0.5929 policy: 0.5425 0.3234
2024-12-07 17:37:34,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 35 loss: 0.3909 grad norm: 0.5557 policy: 0.5881 0.3004
2024-12-07 17:37:37,723 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 40 loss: 0.3612 grad norm: 0.5051 policy: 0.6305 0.2795
2024-12-07 17:37:41,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 45 loss: 0.3356 grad norm: 0.4451 policy: 0.6681 0.2611
2024-12-07 17:37:45,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 50 loss: 0.3145 grad norm: 0.3806 policy: 0.7053 0.2393
2024-12-07 17:37:48,588 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 55 loss: 0.2980 grad norm: 0.3153 policy: 0.7408 0.2160
2024-12-07 17:37:52,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 60 loss: 0.2858 grad norm: 0.2537 policy: 0.7690 0.1972
2024-12-07 17:37:55,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 65 loss: 0.2773 grad norm: 0.1983 policy: 0.7916 0.1817
2024-12-07 17:37:59,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 70 loss: 0.2716 grad norm: 0.1500 policy: 0.8113 0.1670
2024-12-07 17:38:03,032 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 75 loss: 0.2680 grad norm: 0.1094 policy: 0.8267 0.1553
2024-12-07 17:38:06,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 80 loss: 0.2659 grad norm: 0.0768 policy: 0.8376 0.1470
2024-12-07 17:38:10,303 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 85 loss: 0.2648 grad norm: 0.0511 policy: 0.8464 0.1401
2024-12-07 17:38:13,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 90 loss: 0.2642 grad norm: 0.0314 policy: 0.8530 0.1347
2024-12-07 17:38:17,537 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 95 loss: 0.2639 grad norm: 0.0171 policy: 0.8572 0.1314
2024-12-07 17:38:21,100 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 100 loss: 0.2639 grad norm: 0.0071 policy: 0.8603 0.1289
2024-12-07 17:38:24,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 105 loss: 0.2638 grad norm: 0.0005 policy: 0.8624 0.1271
2024-12-07 17:38:28,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 110 loss: 0.2638 grad norm: 0.0037 policy: 0.8635 0.1262
2024-12-07 17:38:31,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 115 loss: 0.2639 grad norm: 0.0058 policy: 0.8641 0.1258
2024-12-07 17:38:35,413 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 120 loss: 0.2639 grad norm: 0.0066 policy: 0.8643 0.1256
2024-12-07 17:38:39,078 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 125 loss: 0.2639 grad norm: 0.0064 policy: 0.8642 0.1257
2024-12-07 17:38:42,532 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 130 loss: 0.2639 grad norm: 0.0057 policy: 0.8639 0.1259
2024-12-07 17:38:46,002 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 135 loss: 0.2638 grad norm: 0.0047 policy: 0.8636 0.1261
2024-12-07 17:38:49,189 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 140 loss: 0.2638 grad norm: 0.0037 policy: 0.8633 0.1264
2024-12-07 17:38:52,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 145 loss: 0.2638 grad norm: 0.0027 policy: 0.8629 0.1267
2024-12-07 17:38:56,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 0 loss: 1.5195 grad norm: 1.3933 policy: 0.2940 0.3360
2024-12-07 17:39:00,370 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 5 loss: 1.3935 grad norm: 1.2656 policy: 0.3443 0.3272
2024-12-07 17:39:03,899 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 10 loss: 1.2792 grad norm: 1.2051 policy: 0.3926 0.3191
2024-12-07 17:39:07,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 15 loss: 1.1744 grad norm: 1.2122 policy: 0.4401 0.3098
2024-12-07 17:39:11,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 20 loss: 1.0705 grad norm: 1.2448 policy: 0.4866 0.3015
2024-12-07 17:39:14,843 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 25 loss: 0.9709 grad norm: 1.2763 policy: 0.5340 0.2890
2024-12-07 17:39:18,634 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 30 loss: 0.8693 grad norm: 1.3101 policy: 0.5903 0.2652
2024-12-07 17:39:22,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 35 loss: 0.7662 grad norm: 1.3069 policy: 0.6456 0.2416
2024-12-07 17:39:26,127 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 40 loss: 0.6682 grad norm: 1.2580 policy: 0.6954 0.2199
2024-12-07 17:39:29,643 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 45 loss: 0.5766 grad norm: 1.1713 policy: 0.7483 0.1902
2024-12-07 17:39:33,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 50 loss: 0.4950 grad norm: 1.0419 policy: 0.7931 0.1641
2024-12-07 17:39:36,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 55 loss: 0.4270 grad norm: 0.8870 policy: 0.8327 0.1382
2024-12-07 17:39:40,395 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 60 loss: 0.3738 grad norm: 0.7262 policy: 0.8648 0.1158
2024-12-07 17:39:43,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 65 loss: 0.3347 grad norm: 0.5756 policy: 0.8901 0.0969
2024-12-07 17:39:47,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 70 loss: 0.3075 grad norm: 0.4436 policy: 0.9090 0.0821
2024-12-07 17:39:51,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 75 loss: 0.2895 grad norm: 0.3335 policy: 0.9235 0.0702
2024-12-07 17:39:54,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 80 loss: 0.2782 grad norm: 0.2446 policy: 0.9337 0.0617
2024-12-07 17:39:58,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 85 loss: 0.2714 grad norm: 0.1744 policy: 0.9415 0.0550
2024-12-07 17:40:02,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 90 loss: 0.2676 grad norm: 0.1205 policy: 0.9469 0.0503
2024-12-07 17:40:05,814 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 95 loss: 0.2655 grad norm: 0.0796 policy: 0.9509 0.0467
2024-12-07 17:40:08,886 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 100 loss: 0.2645 grad norm: 0.0494 policy: 0.9537 0.0442
2024-12-07 17:40:12,458 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 105 loss: 0.2640 grad norm: 0.0276 policy: 0.9556 0.0425
2024-12-07 17:40:16,031 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 110 loss: 0.2639 grad norm: 0.0125 policy: 0.9570 0.0413
2024-12-07 17:40:19,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 115 loss: 0.2638 grad norm: 0.0025 policy: 0.9578 0.0405
2024-12-07 17:40:23,578 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 120 loss: 0.2638 grad norm: 0.0038 policy: 0.9583 0.0400
2024-12-07 17:40:27,185 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 125 loss: 0.2639 grad norm: 0.0072 policy: 0.9586 0.0398
2024-12-07 17:40:30,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 130 loss: 0.2639 grad norm: 0.0087 policy: 0.9587 0.0397
2024-12-07 17:40:34,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 135 loss: 0.2639 grad norm: 0.0088 policy: 0.9587 0.0397
2024-12-07 17:40:37,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 140 loss: 0.2639 grad norm: 0.0081 policy: 0.9586 0.0398
2024-12-07 17:40:41,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 145 loss: 0.2639 grad norm: 0.0069 policy: 0.9585 0.0399
2024-12-07 17:40:45,744 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 0 loss: 12.9519 grad norm: 1.3997 policy: 0.3366 0.3431
2024-12-07 17:40:49,378 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 5 loss: 12.8228 grad norm: 1.3824 policy: 0.3887 0.3185
2024-12-07 17:40:52,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 10 loss: 12.7079 grad norm: 1.4109 policy: 0.4382 0.2945
2024-12-07 17:40:56,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 15 loss: 12.5908 grad norm: 1.5282 policy: 0.4904 0.2698
2024-12-07 17:40:59,998 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 20 loss: 12.4627 grad norm: 1.6894 policy: 0.5480 0.2429
2024-12-07 17:41:03,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 25 loss: 12.3182 grad norm: 1.8731 policy: 0.6115 0.2122
2024-12-07 17:41:07,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 30 loss: 12.1533 grad norm: 2.0829 policy: 0.6797 0.1781
2024-12-07 17:41:10,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 35 loss: 11.9631 grad norm: 2.3128 policy: 0.7498 0.1417
2024-12-07 17:41:11,029 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 40 loss: 11.7443 grad norm: 2.5626 policy: 0.8170 0.1056
2024-12-07 17:41:11,956 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 45 loss: 11.4905 grad norm: 2.8391 policy: 0.8768 0.0722
2024-12-07 17:41:12,969 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 50 loss: 11.1979 grad norm: 3.1327 policy: 0.9242 0.0451
2024-12-07 17:41:13,951 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 55 loss: 10.8639 grad norm: 3.4493 policy: 0.9575 0.0256
2024-12-07 17:41:14,780 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 60 loss: 10.4847 grad norm: 3.7890 policy: 0.9784 0.0132
2024-12-07 17:41:15,532 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 65 loss: 10.0565 grad norm: 4.1523 policy: 0.9901 0.0062
2024-12-07 17:41:16,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 70 loss: 9.5753 grad norm: 4.5393 policy: 0.9959 0.0026
2024-12-07 17:41:18,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 75 loss: 9.0373 grad norm: 4.9504 policy: 0.9985 0.0010
2024-12-07 17:41:19,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 80 loss: 8.4388 grad norm: 5.3855 policy: 0.9995 0.0003
2024-12-07 17:41:21,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 85 loss: 7.7761 grad norm: 5.8448 policy: 0.9998 0.0001
2024-12-07 17:41:22,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 90 loss: 7.0458 grad norm: 6.3282 policy: 1.0000 0.0000
2024-12-07 17:41:24,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 95 loss: 6.2443 grad norm: 6.8358 policy: 1.0000 0.0000
2024-12-07 17:41:25,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 100 loss: 5.3681 grad norm: 7.3670 policy: 1.0000 0.0000
2024-12-07 17:41:27,442 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 105 loss: 4.4141 grad norm: 7.9167 policy: 1.0000 0.0000
2024-12-07 17:41:28,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 110 loss: 3.3814 grad norm: 8.4469 policy: 1.0000 0.0000
2024-12-07 17:41:29,410 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 115 loss: 2.2882 grad norm: 8.6468 policy: 1.0000 0.0000
2024-12-07 17:41:31,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 120 loss: 1.2871 grad norm: 6.6633 policy: 1.0000 0.0000
2024-12-07 17:41:33,122 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 125 loss: 0.8006 grad norm: 2.1057 policy: 1.0000 0.0000
2024-12-07 17:41:34,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 130 loss: 0.7136 grad norm: 0.4843 policy: 1.0000 0.0000
2024-12-07 17:41:36,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 135 loss: 0.6999 grad norm: 0.1725 policy: 1.0000 0.0000
2024-12-07 17:41:37,538 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 140 loss: 0.6965 grad norm: 0.0893 policy: 1.0000 0.0000
2024-12-07 17:41:39,472 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 145 loss: 0.6953 grad norm: 0.0590 policy: 1.0000 0.0000
2024-12-07 17:41:41,448 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 0 loss: 0.3463 grad norm: 0.2537 policy: 0.3630 0.3789
2024-12-07 17:41:42,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 5 loss: 0.3252 grad norm: 0.2174 policy: 0.3961 0.3858
2024-12-07 17:41:43,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 10 loss: 0.3082 grad norm: 0.1922 policy: 0.4282 0.3900
2024-12-07 17:41:47,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 15 loss: 0.2939 grad norm: 0.1681 policy: 0.4619 0.3900
2024-12-07 17:41:47,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 20 loss: 0.2825 grad norm: 0.1406 policy: 0.4983 0.3831
2024-12-07 17:41:49,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 25 loss: 0.2739 grad norm: 0.1097 policy: 0.5413 0.3644
2024-12-07 17:41:50,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 30 loss: 0.2679 grad norm: 0.0721 policy: 0.5891 0.3362
2024-12-07 17:41:50,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 35 loss: 0.2649 grad norm: 0.0361 policy: 0.6326 0.3074
2024-12-07 17:41:51,568 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 40 loss: 0.2639 grad norm: 0.0115 policy: 0.6631 0.2874
2024-12-07 17:41:54,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 45 loss: 0.2640 grad norm: 0.0149 policy: 0.6774 0.2795
2024-12-07 17:41:57,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 50 loss: 0.2642 grad norm: 0.0229 policy: 0.6803 0.2793
2024-12-07 17:42:01,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 55 loss: 0.2643 grad norm: 0.0240 policy: 0.6789 0.2808
2024-12-07 17:42:04,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 60 loss: 0.2641 grad norm: 0.0192 policy: 0.6759 0.2819
2024-12-07 17:42:08,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 65 loss: 0.2640 grad norm: 0.0124 policy: 0.6709 0.2843
2024-12-07 17:42:12,214 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 70 loss: 0.2639 grad norm: 0.0057 policy: 0.6644 0.2886
2024-12-07 17:42:15,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 75 loss: 0.2638 grad norm: 0.0005 policy: 0.6584 0.2930
2024-12-07 17:42:19,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 80 loss: 0.2639 grad norm: 0.0038 policy: 0.6550 0.2954
2024-12-07 17:42:22,918 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 85 loss: 0.2639 grad norm: 0.0047 policy: 0.6547 0.2955
2024-12-07 17:42:26,701 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 90 loss: 0.2639 grad norm: 0.0041 policy: 0.6559 0.2944
2024-12-07 17:42:30,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 95 loss: 0.2638 grad norm: 0.0028 policy: 0.6574 0.2934
2024-12-07 17:42:33,918 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 100 loss: 0.2638 grad norm: 0.0013 policy: 0.6585 0.2929
2024-12-07 17:42:37,448 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 105 loss: 0.2638 grad norm: 0.0003 policy: 0.6595 0.2923
2024-12-07 17:42:40,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 110 loss: 0.2638 grad norm: 0.0008 policy: 0.6603 0.2918
2024-12-07 17:42:44,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 115 loss: 0.2638 grad norm: 0.0010 policy: 0.6606 0.2915
2024-12-07 17:42:48,266 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 120 loss: 0.2638 grad norm: 0.0009 policy: 0.6604 0.2916
2024-12-07 17:42:51,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 125 loss: 0.2638 grad norm: 0.0005 policy: 0.6599 0.2920
2024-12-07 17:42:55,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 130 loss: 0.2638 grad norm: 0.0002 policy: 0.6595 0.2922
2024-12-07 17:42:59,215 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 135 loss: 0.2638 grad norm: 0.0001 policy: 0.6594 0.2923
2024-12-07 17:43:02,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 140 loss: 0.2638 grad norm: 0.0002 policy: 0.6593 0.2923
2024-12-07 17:43:06,632 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:348] - INFO: [Policy] Epoch: 145 loss: 0.2638 grad norm: 0.0002 policy: 0.6593 0.2924
2024-12-07 17:50:41,589 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.3333, 0.3333, 0.3333], device='cuda:0'), new_distribution = tensor([0.3341, 0.3333, 0.3326], device='cuda:0')
2024-12-07 17:50:41,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.3341, 0.3333, 0.3326], device='cuda:0'), new_distribution = tensor([0.3350, 0.3332, 0.3319], device='cuda:0')
2024-12-07 17:50:42,350 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.3350, 0.3332, 0.3319], device='cuda:0'), new_distribution = tensor([0.3358, 0.3331, 0.3311], device='cuda:0')
2024-12-07 17:50:42,826 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.3358, 0.3331, 0.3311], device='cuda:0'), new_distribution = tensor([0.3366, 0.3330, 0.3304], device='cuda:0')
2024-12-07 17:50:43,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.3366, 0.3330, 0.3304], device='cuda:0'), new_distribution = tensor([0.3374, 0.3329, 0.3296], device='cuda:0')
2024-12-07 17:50:43,665 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.3374, 0.3329, 0.3296], device='cuda:0'), new_distribution = tensor([0.3382, 0.3329, 0.3289], device='cuda:0')
2024-12-07 17:50:43,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.3382, 0.3329, 0.3289], device='cuda:0'), new_distribution = tensor([0.3391, 0.3328, 0.3282], device='cuda:0')
2024-12-07 17:50:44,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.3391, 0.3328, 0.3282], device='cuda:0'), new_distribution = tensor([0.3399, 0.3327, 0.3274], device='cuda:0')
2024-12-07 17:50:44,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.3399, 0.3327, 0.3274], device='cuda:0'), new_distribution = tensor([0.3407, 0.3326, 0.3267], device='cuda:0')
2024-12-07 17:50:45,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.3407, 0.3326, 0.3267], device='cuda:0'), new_distribution = tensor([0.3415, 0.3325, 0.3260], device='cuda:0')
2024-12-07 17:50:45,624 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.3415, 0.3325, 0.3260], device='cuda:0'), new_distribution = tensor([0.3424, 0.3324, 0.3252], device='cuda:0')
2024-12-07 17:50:46,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.3424, 0.3324, 0.3252], device='cuda:0'), new_distribution = tensor([0.3432, 0.3323, 0.3245], device='cuda:0')
2024-12-07 17:50:46,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.3432, 0.3323, 0.3245], device='cuda:0'), new_distribution = tensor([0.3440, 0.3322, 0.3238], device='cuda:0')
2024-12-07 17:50:46,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.3440, 0.3322, 0.3238], device='cuda:0'), new_distribution = tensor([0.3448, 0.3321, 0.3230], device='cuda:0')
2024-12-07 17:50:47,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.3448, 0.3321, 0.3230], device='cuda:0'), new_distribution = tensor([0.3457, 0.3320, 0.3223], device='cuda:0')
2024-12-07 17:50:47,486 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.3457, 0.3320, 0.3223], device='cuda:0'), new_distribution = tensor([0.3465, 0.3319, 0.3216], device='cuda:0')
2024-12-07 17:50:47,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.3465, 0.3319, 0.3216], device='cuda:0'), new_distribution = tensor([0.3473, 0.3318, 0.3209], device='cuda:0')
2024-12-07 17:50:48,308 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.3473, 0.3318, 0.3209], device='cuda:0'), new_distribution = tensor([0.3482, 0.3317, 0.3201], device='cuda:0')
2024-12-07 17:50:48,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.3482, 0.3317, 0.3201], device='cuda:0'), new_distribution = tensor([0.3490, 0.3316, 0.3194], device='cuda:0')
2024-12-07 17:50:48,946 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.3490, 0.3316, 0.3194], device='cuda:0'), new_distribution = tensor([0.3498, 0.3315, 0.3187], device='cuda:0')
2024-12-07 17:50:49,416 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.3498, 0.3315, 0.3187], device='cuda:0'), new_distribution = tensor([0.3507, 0.3314, 0.3180], device='cuda:0')
2024-12-07 17:50:49,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.3507, 0.3314, 0.3180], device='cuda:0'), new_distribution = tensor([0.3515, 0.3313, 0.3172], device='cuda:0')
2024-12-07 17:50:50,075 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.3515, 0.3313, 0.3172], device='cuda:0'), new_distribution = tensor([0.3523, 0.3311, 0.3165], device='cuda:0')
2024-12-07 17:50:50,544 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.3523, 0.3311, 0.3165], device='cuda:0'), new_distribution = tensor([0.3532, 0.3310, 0.3158], device='cuda:0')
2024-12-07 17:50:50,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.3532, 0.3310, 0.3158], device='cuda:0'), new_distribution = tensor([0.3540, 0.3309, 0.3151], device='cuda:0')
2024-12-07 17:50:51,329 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.3540, 0.3309, 0.3151], device='cuda:0'), new_distribution = tensor([0.3549, 0.3308, 0.3144], device='cuda:0')
2024-12-07 17:50:51,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.3549, 0.3308, 0.3144], device='cuda:0'), new_distribution = tensor([0.3557, 0.3307, 0.3136], device='cuda:0')
2024-12-07 17:50:52,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.3557, 0.3307, 0.3136], device='cuda:0'), new_distribution = tensor([0.3565, 0.3305, 0.3129], device='cuda:0')
2024-12-07 17:50:52,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.3565, 0.3305, 0.3129], device='cuda:0'), new_distribution = tensor([0.3574, 0.3304, 0.3122], device='cuda:0')
2024-12-07 17:50:52,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.3574, 0.3304, 0.3122], device='cuda:0'), new_distribution = tensor([0.3582, 0.3303, 0.3115], device='cuda:0')
2024-12-07 17:50:53,291 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.3582, 0.3303, 0.3115], device='cuda:0'), new_distribution = tensor([0.3591, 0.3301, 0.3108], device='cuda:0')
2024-12-07 17:50:53,673 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.3591, 0.3301, 0.3108], device='cuda:0'), new_distribution = tensor([0.3599, 0.3300, 0.3101], device='cuda:0')
2024-12-07 17:50:53,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.3599, 0.3300, 0.3101], device='cuda:0'), new_distribution = tensor([0.3608, 0.3299, 0.3094], device='cuda:0')
2024-12-07 17:50:54,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.3608, 0.3299, 0.3094], device='cuda:0'), new_distribution = tensor([0.3616, 0.3297, 0.3086], device='cuda:0')
2024-12-07 17:50:54,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.3616, 0.3297, 0.3086], device='cuda:0'), new_distribution = tensor([0.3625, 0.3296, 0.3079], device='cuda:0')
2024-12-07 17:50:55,221 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.3625, 0.3296, 0.3079], device='cuda:0'), new_distribution = tensor([0.3633, 0.3295, 0.3072], device='cuda:0')
2024-12-07 17:50:55,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.3633, 0.3295, 0.3072], device='cuda:0'), new_distribution = tensor([0.3642, 0.3293, 0.3065], device='cuda:0')
2024-12-07 17:50:56,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.3642, 0.3293, 0.3065], device='cuda:0'), new_distribution = tensor([0.3650, 0.3292, 0.3058], device='cuda:0')
2024-12-07 17:50:56,469 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.3650, 0.3292, 0.3058], device='cuda:0'), new_distribution = tensor([0.3659, 0.3290, 0.3051], device='cuda:0')
2024-12-07 17:50:56,814 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.3659, 0.3290, 0.3051], device='cuda:0'), new_distribution = tensor([0.3667, 0.3289, 0.3044], device='cuda:0')
2024-12-07 17:50:57,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.3667, 0.3289, 0.3044], device='cuda:0'), new_distribution = tensor([0.3676, 0.3287, 0.3037], device='cuda:0')
2024-12-07 17:50:57,698 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.3676, 0.3287, 0.3037], device='cuda:0'), new_distribution = tensor([0.3684, 0.3286, 0.3030], device='cuda:0')
2024-12-07 17:50:58,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.3684, 0.3286, 0.3030], device='cuda:0'), new_distribution = tensor([0.3693, 0.3284, 0.3023], device='cuda:0')
2024-12-07 17:50:58,381 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.3693, 0.3284, 0.3023], device='cuda:0'), new_distribution = tensor([0.3702, 0.3283, 0.3016], device='cuda:0')
2024-12-07 17:50:58,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.3702, 0.3283, 0.3016], device='cuda:0'), new_distribution = tensor([0.3710, 0.3281, 0.3009], device='cuda:0')
2024-12-07 17:50:59,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.3710, 0.3281, 0.3009], device='cuda:0'), new_distribution = tensor([0.3719, 0.3279, 0.3002], device='cuda:0')
2024-12-07 17:50:59,586 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.3719, 0.3279, 0.3002], device='cuda:0'), new_distribution = tensor([0.3727, 0.3278, 0.2995], device='cuda:0')
2024-12-07 17:50:59,966 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.3727, 0.3278, 0.2995], device='cuda:0'), new_distribution = tensor([0.3736, 0.3276, 0.2988], device='cuda:0')
2024-12-07 17:51:00,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.3736, 0.3276, 0.2988], device='cuda:0'), new_distribution = tensor([0.3744, 0.3275, 0.2981], device='cuda:0')
2024-12-07 17:51:00,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.3744, 0.3275, 0.2981], device='cuda:0'), new_distribution = tensor([0.3753, 0.3273, 0.2974], device='cuda:0')
2024-12-07 17:51:01,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.3753, 0.3273, 0.2974], device='cuda:0'), new_distribution = tensor([0.3762, 0.3271, 0.2967], device='cuda:0')
2024-12-07 17:51:01,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.3762, 0.3271, 0.2967], device='cuda:0'), new_distribution = tensor([0.3770, 0.3270, 0.2960], device='cuda:0')
2024-12-07 17:51:02,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.3770, 0.3270, 0.2960], device='cuda:0'), new_distribution = tensor([0.3779, 0.3268, 0.2953], device='cuda:0')
2024-12-07 17:51:02,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.3779, 0.3268, 0.2953], device='cuda:0'), new_distribution = tensor([0.3788, 0.3266, 0.2946], device='cuda:0')
2024-12-07 17:51:02,728 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.3788, 0.3266, 0.2946], device='cuda:0'), new_distribution = tensor([0.3796, 0.3264, 0.2939], device='cuda:0')
2024-12-07 17:51:03,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.3796, 0.3264, 0.2939], device='cuda:0'), new_distribution = tensor([0.3805, 0.3263, 0.2932], device='cuda:0')
2024-12-07 17:51:03,671 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.3805, 0.3263, 0.2932], device='cuda:0'), new_distribution = tensor([0.3814, 0.3261, 0.2926], device='cuda:0')
2024-12-07 17:51:03,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.3814, 0.3261, 0.2926], device='cuda:0'), new_distribution = tensor([0.3822, 0.3259, 0.2919], device='cuda:0')
2024-12-07 17:51:04,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.3822, 0.3259, 0.2919], device='cuda:0'), new_distribution = tensor([0.3831, 0.3257, 0.2912], device='cuda:0')
2024-12-07 17:51:04,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.3831, 0.3257, 0.2912], device='cuda:0'), new_distribution = tensor([0.3840, 0.3255, 0.2905], device='cuda:0')
2024-12-07 17:51:05,162 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.3840, 0.3255, 0.2905], device='cuda:0'), new_distribution = tensor([0.3848, 0.3253, 0.2898], device='cuda:0')
2024-12-07 17:51:05,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.3848, 0.3253, 0.2898], device='cuda:0'), new_distribution = tensor([0.3857, 0.3252, 0.2891], device='cuda:0')
2024-12-07 17:51:05,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.3857, 0.3252, 0.2891], device='cuda:0'), new_distribution = tensor([0.3866, 0.3250, 0.2884], device='cuda:0')
2024-12-07 17:51:06,454 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.3866, 0.3250, 0.2884], device='cuda:0'), new_distribution = tensor([0.3875, 0.3248, 0.2878], device='cuda:0')
2024-12-07 17:51:06,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.3875, 0.3248, 0.2878], device='cuda:0'), new_distribution = tensor([0.3883, 0.3246, 0.2871], device='cuda:0')
2024-12-07 17:51:07,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.3883, 0.3246, 0.2871], device='cuda:0'), new_distribution = tensor([0.3892, 0.3244, 0.2864], device='cuda:0')
2024-12-07 17:51:07,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.3892, 0.3244, 0.2864], device='cuda:0'), new_distribution = tensor([0.3901, 0.3242, 0.2857], device='cuda:0')
2024-12-07 17:51:07,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.3901, 0.3242, 0.2857], device='cuda:0'), new_distribution = tensor([0.3910, 0.3240, 0.2850], device='cuda:0')
2024-12-07 17:51:08,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.3910, 0.3240, 0.2850], device='cuda:0'), new_distribution = tensor([0.3918, 0.3238, 0.2844], device='cuda:0')
2024-12-07 17:51:08,711 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.3918, 0.3238, 0.2844], device='cuda:0'), new_distribution = tensor([0.3927, 0.3236, 0.2837], device='cuda:0')
2024-12-07 17:51:09,119 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.3927, 0.3236, 0.2837], device='cuda:0'), new_distribution = tensor([0.3936, 0.3234, 0.2830], device='cuda:0')
2024-12-07 17:51:09,395 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.3936, 0.3234, 0.2830], device='cuda:0'), new_distribution = tensor([0.3945, 0.3232, 0.2823], device='cuda:0')
2024-12-07 17:51:09,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.3945, 0.3232, 0.2823], device='cuda:0'), new_distribution = tensor([0.3954, 0.3230, 0.2817], device='cuda:0')
2024-12-07 17:51:10,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.3954, 0.3230, 0.2817], device='cuda:0'), new_distribution = tensor([0.3962, 0.3228, 0.2810], device='cuda:0')
2024-12-07 17:51:10,591 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.3962, 0.3228, 0.2810], device='cuda:0'), new_distribution = tensor([0.3971, 0.3226, 0.2803], device='cuda:0')
2024-12-07 17:51:10,985 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.3971, 0.3226, 0.2803], device='cuda:0'), new_distribution = tensor([0.3980, 0.3223, 0.2796], device='cuda:0')
2024-12-07 17:51:11,445 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.3980, 0.3223, 0.2796], device='cuda:0'), new_distribution = tensor([0.3989, 0.3221, 0.2790], device='cuda:0')
2024-12-07 17:51:11,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.3989, 0.3221, 0.2790], device='cuda:0'), new_distribution = tensor([0.3998, 0.3219, 0.2783], device='cuda:0')
2024-12-07 17:51:12,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.3998, 0.3219, 0.2783], device='cuda:0'), new_distribution = tensor([0.4007, 0.3217, 0.2776], device='cuda:0')
2024-12-07 17:51:12,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.4007, 0.3217, 0.2776], device='cuda:0'), new_distribution = tensor([0.4015, 0.3215, 0.2770], device='cuda:0')
2024-12-07 17:51:12,884 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.4015, 0.3215, 0.2770], device='cuda:0'), new_distribution = tensor([0.4024, 0.3213, 0.2763], device='cuda:0')
2024-12-07 17:51:13,235 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.4024, 0.3213, 0.2763], device='cuda:0'), new_distribution = tensor([0.4033, 0.3210, 0.2756], device='cuda:0')
2024-12-07 17:51:13,701 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.4033, 0.3210, 0.2756], device='cuda:0'), new_distribution = tensor([0.4042, 0.3208, 0.2750], device='cuda:0')
2024-12-07 17:51:14,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.4042, 0.3208, 0.2750], device='cuda:0'), new_distribution = tensor([0.4051, 0.3206, 0.2743], device='cuda:0')
2024-12-07 17:51:14,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.4051, 0.3206, 0.2743], device='cuda:0'), new_distribution = tensor([0.4060, 0.3204, 0.2737], device='cuda:0')
2024-12-07 17:51:14,852 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.4060, 0.3204, 0.2737], device='cuda:0'), new_distribution = tensor([0.4069, 0.3201, 0.2730], device='cuda:0')
2024-12-07 17:51:15,331 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.4069, 0.3201, 0.2730], device='cuda:0'), new_distribution = tensor([0.4078, 0.3199, 0.2723], device='cuda:0')
2024-12-07 17:51:15,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.4078, 0.3199, 0.2723], device='cuda:0'), new_distribution = tensor([0.4087, 0.3197, 0.2717], device='cuda:0')
2024-12-07 17:51:15,981 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.4087, 0.3197, 0.2717], device='cuda:0'), new_distribution = tensor([0.4095, 0.3194, 0.2710], device='cuda:0')
2024-12-07 17:51:16,439 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.4095, 0.3194, 0.2710], device='cuda:0'), new_distribution = tensor([0.4104, 0.3192, 0.2704], device='cuda:0')
2024-12-07 17:51:16,910 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.4104, 0.3192, 0.2704], device='cuda:0'), new_distribution = tensor([0.4113, 0.3190, 0.2697], device='cuda:0')
2024-12-07 17:51:17,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.4113, 0.3190, 0.2697], device='cuda:0'), new_distribution = tensor([0.4122, 0.3187, 0.2691], device='cuda:0')
2024-12-07 17:51:17,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.4122, 0.3187, 0.2691], device='cuda:0'), new_distribution = tensor([0.4131, 0.3185, 0.2684], device='cuda:0')
2024-12-07 17:51:18,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.4131, 0.3185, 0.2684], device='cuda:0'), new_distribution = tensor([0.4140, 0.3182, 0.2678], device='cuda:0')
2024-12-07 17:51:18,337 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.4140, 0.3182, 0.2678], device='cuda:0'), new_distribution = tensor([0.4149, 0.3180, 0.2671], device='cuda:0')
2024-12-07 17:51:18,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.4149, 0.3180, 0.2671], device='cuda:0'), new_distribution = tensor([0.4158, 0.3177, 0.2665], device='cuda:0')
2024-12-07 17:51:19,173 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.4158, 0.3177, 0.2665], device='cuda:0'), new_distribution = tensor([0.4167, 0.3175, 0.2658], device='cuda:0')
2024-12-07 17:51:19,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.4167, 0.3175, 0.2658], device='cuda:0'), new_distribution = tensor([0.4176, 0.3172, 0.2652], device='cuda:0')
2024-12-07 17:51:19,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.4176, 0.3172, 0.2652], device='cuda:0'), new_distribution = tensor([0.4185, 0.3170, 0.2645], device='cuda:0')
2024-12-07 17:51:20,282 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.4185, 0.3170, 0.2645], device='cuda:0'), new_distribution = tensor([0.4194, 0.3167, 0.2639], device='cuda:0')
2024-12-07 17:51:20,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([0.4194, 0.3167, 0.2639], device='cuda:0'), new_distribution = tensor([0.4203, 0.3165, 0.2632], device='cuda:0')
2024-12-07 17:51:20,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([0.4203, 0.3165, 0.2632], device='cuda:0'), new_distribution = tensor([0.4212, 0.3162, 0.2626], device='cuda:0')
2024-12-07 17:51:21,402 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([0.4212, 0.3162, 0.2626], device='cuda:0'), new_distribution = tensor([0.4221, 0.3160, 0.2619], device='cuda:0')
2024-12-07 17:51:21,690 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([0.4221, 0.3160, 0.2619], device='cuda:0'), new_distribution = tensor([0.4230, 0.3157, 0.2613], device='cuda:0')
2024-12-07 17:51:22,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([0.4230, 0.3157, 0.2613], device='cuda:0'), new_distribution = tensor([0.4239, 0.3154, 0.2607], device='cuda:0')
2024-12-07 17:51:22,521 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([0.4239, 0.3154, 0.2607], device='cuda:0'), new_distribution = tensor([0.4248, 0.3152, 0.2600], device='cuda:0')
2024-12-07 17:51:22,907 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([0.4248, 0.3152, 0.2600], device='cuda:0'), new_distribution = tensor([0.4257, 0.3149, 0.2594], device='cuda:0')
2024-12-07 17:51:23,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([0.4257, 0.3149, 0.2594], device='cuda:0'), new_distribution = tensor([0.4266, 0.3147, 0.2588], device='cuda:0')
2024-12-07 17:51:23,624 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([0.4266, 0.3147, 0.2588], device='cuda:0'), new_distribution = tensor([0.4275, 0.3144, 0.2581], device='cuda:0')
2024-12-07 17:51:23,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([0.4275, 0.3144, 0.2581], device='cuda:0'), new_distribution = tensor([0.4284, 0.3141, 0.2575], device='cuda:0')
2024-12-07 17:51:24,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([0.4284, 0.3141, 0.2575], device='cuda:0'), new_distribution = tensor([0.4293, 0.3138, 0.2569], device='cuda:0')
2024-12-07 17:51:24,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([0.4293, 0.3138, 0.2569], device='cuda:0'), new_distribution = tensor([0.4302, 0.3136, 0.2562], device='cuda:0')
2024-12-07 17:51:25,034 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([0.4302, 0.3136, 0.2562], device='cuda:0'), new_distribution = tensor([0.4311, 0.3133, 0.2556], device='cuda:0')
2024-12-07 17:51:25,402 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([0.4311, 0.3133, 0.2556], device='cuda:0'), new_distribution = tensor([0.4320, 0.3130, 0.2550], device='cuda:0')
2024-12-07 17:51:25,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([0.4320, 0.3130, 0.2550], device='cuda:0'), new_distribution = tensor([0.4329, 0.3127, 0.2543], device='cuda:0')
2024-12-07 17:51:26,228 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([0.4329, 0.3127, 0.2543], device='cuda:0'), new_distribution = tensor([0.4338, 0.3125, 0.2537], device='cuda:0')
2024-12-07 17:51:26,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([0.4338, 0.3125, 0.2537], device='cuda:0'), new_distribution = tensor([0.4347, 0.3122, 0.2531], device='cuda:0')
2024-12-07 17:51:27,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([0.4347, 0.3122, 0.2531], device='cuda:0'), new_distribution = tensor([0.4356, 0.3119, 0.2524], device='cuda:0')
2024-12-07 17:51:27,469 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([0.4356, 0.3119, 0.2524], device='cuda:0'), new_distribution = tensor([0.4366, 0.3116, 0.2518], device='cuda:0')
2024-12-07 17:51:27,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([0.4366, 0.3116, 0.2518], device='cuda:0'), new_distribution = tensor([0.4375, 0.3113, 0.2512], device='cuda:0')
2024-12-07 17:51:28,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([0.4375, 0.3113, 0.2512], device='cuda:0'), new_distribution = tensor([0.4384, 0.3111, 0.2506], device='cuda:0')
2024-12-07 17:51:28,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([0.4384, 0.3111, 0.2506], device='cuda:0'), new_distribution = tensor([0.4393, 0.3108, 0.2500], device='cuda:0')
2024-12-07 17:51:29,048 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([0.4393, 0.3108, 0.2500], device='cuda:0'), new_distribution = tensor([0.4402, 0.3105, 0.2493], device='cuda:0')
2024-12-07 17:51:29,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([0.4402, 0.3105, 0.2493], device='cuda:0'), new_distribution = tensor([0.4411, 0.3102, 0.2487], device='cuda:0')
2024-12-07 17:51:29,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([0.4411, 0.3102, 0.2487], device='cuda:0'), new_distribution = tensor([0.4420, 0.3099, 0.2481], device='cuda:0')
2024-12-07 17:51:30,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([0.4420, 0.3099, 0.2481], device='cuda:0'), new_distribution = tensor([0.4429, 0.3096, 0.2475], device='cuda:0')
2024-12-07 17:51:30,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([0.4429, 0.3096, 0.2475], device='cuda:0'), new_distribution = tensor([0.4438, 0.3093, 0.2469], device='cuda:0')
2024-12-07 17:51:30,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([0.4438, 0.3093, 0.2469], device='cuda:0'), new_distribution = tensor([0.4447, 0.3090, 0.2463], device='cuda:0')
2024-12-07 17:51:31,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([0.4447, 0.3090, 0.2463], device='cuda:0'), new_distribution = tensor([0.4457, 0.3087, 0.2456], device='cuda:0')
2024-12-07 17:51:31,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([0.4457, 0.3087, 0.2456], device='cuda:0'), new_distribution = tensor([0.4466, 0.3084, 0.2450], device='cuda:0')
2024-12-07 17:51:32,057 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([0.4466, 0.3084, 0.2450], device='cuda:0'), new_distribution = tensor([0.4475, 0.3081, 0.2444], device='cuda:0')
2024-12-07 17:51:32,521 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([0.4475, 0.3081, 0.2444], device='cuda:0'), new_distribution = tensor([0.4484, 0.3078, 0.2438], device='cuda:0')
2024-12-07 17:51:32,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([0.4484, 0.3078, 0.2438], device='cuda:0'), new_distribution = tensor([0.4493, 0.3075, 0.2432], device='cuda:0')
2024-12-07 17:51:33,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([0.4493, 0.3075, 0.2432], device='cuda:0'), new_distribution = tensor([0.4502, 0.3072, 0.2426], device='cuda:0')
2024-12-07 17:51:33,640 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([0.4502, 0.3072, 0.2426], device='cuda:0'), new_distribution = tensor([0.4511, 0.3069, 0.2420], device='cuda:0')
2024-12-07 17:51:33,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([0.4511, 0.3069, 0.2420], device='cuda:0'), new_distribution = tensor([0.4521, 0.3066, 0.2414], device='cuda:0')
2024-12-07 17:51:34,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([0.4521, 0.3066, 0.2414], device='cuda:0'), new_distribution = tensor([0.4530, 0.3063, 0.2408], device='cuda:0')
2024-12-07 17:51:34,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([0.4530, 0.3063, 0.2408], device='cuda:0'), new_distribution = tensor([0.4539, 0.3060, 0.2402], device='cuda:0')
2024-12-07 17:51:35,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([0.4539, 0.3060, 0.2402], device='cuda:0'), new_distribution = tensor([0.4548, 0.3056, 0.2396], device='cuda:0')
2024-12-07 17:51:35,560 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([0.4548, 0.3056, 0.2396], device='cuda:0'), new_distribution = tensor([0.4557, 0.3053, 0.2390], device='cuda:0')
2024-12-07 17:51:35,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([0.4557, 0.3053, 0.2390], device='cuda:0'), new_distribution = tensor([0.4566, 0.3050, 0.2384], device='cuda:0')
2024-12-07 17:51:36,413 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([0.4566, 0.3050, 0.2384], device='cuda:0'), new_distribution = tensor([0.4576, 0.3047, 0.2378], device='cuda:0')
2024-12-07 17:51:36,723 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([0.4576, 0.3047, 0.2378], device='cuda:0'), new_distribution = tensor([0.4585, 0.3044, 0.2372], device='cuda:0')
2024-12-07 17:51:37,057 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([0.4585, 0.3044, 0.2372], device='cuda:0'), new_distribution = tensor([0.4594, 0.3041, 0.2366], device='cuda:0')
2024-12-07 17:51:37,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([0.4594, 0.3041, 0.2366], device='cuda:0'), new_distribution = tensor([0.4603, 0.3037, 0.2360], device='cuda:0')
2024-12-07 17:51:37,961 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([0.4603, 0.3037, 0.2360], device='cuda:0'), new_distribution = tensor([0.4612, 0.3034, 0.2354], device='cuda:0')
2024-12-07 17:51:38,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([0.4612, 0.3034, 0.2354], device='cuda:0'), new_distribution = tensor([0.4621, 0.3031, 0.2348], device='cuda:0')
2024-12-07 17:51:38,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([0.4621, 0.3031, 0.2348], device='cuda:0'), new_distribution = tensor([0.4631, 0.3028, 0.2342], device='cuda:0')
2024-12-07 17:51:39,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([0.4631, 0.3028, 0.2342], device='cuda:0'), new_distribution = tensor([0.4640, 0.3024, 0.2336], device='cuda:0')
2024-12-07 17:51:39,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([0.4640, 0.3024, 0.2336], device='cuda:0'), new_distribution = tensor([0.4649, 0.3021, 0.2330], device='cuda:0')
2024-12-07 17:51:39,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([0.4649, 0.3021, 0.2330], device='cuda:0'), new_distribution = tensor([0.4658, 0.3018, 0.2324], device='cuda:0')
2024-12-07 17:51:40,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([0.4658, 0.3018, 0.2324], device='cuda:0'), new_distribution = tensor([0.4667, 0.3014, 0.2318], device='cuda:0')
2024-12-07 17:51:40,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([0.4667, 0.3014, 0.2318], device='cuda:0'), new_distribution = tensor([0.4677, 0.3011, 0.2312], device='cuda:0')
2024-12-07 17:51:40,926 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([0.4677, 0.3011, 0.2312], device='cuda:0'), new_distribution = tensor([0.4686, 0.3008, 0.2306], device='cuda:0')
2024-12-07 17:51:41,399 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([0.4686, 0.3008, 0.2306], device='cuda:0'), new_distribution = tensor([0.4695, 0.3004, 0.2301], device='cuda:0')
2024-12-07 17:51:41,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([0.4695, 0.3004, 0.2301], device='cuda:0'), new_distribution = tensor([0.4704, 0.3001, 0.2295], device='cuda:0')
2024-12-07 17:51:42,067 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([0.4704, 0.3001, 0.2295], device='cuda:0'), new_distribution = tensor([0.4713, 0.2998, 0.2289], device='cuda:0')
2024-12-07 17:51:42,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([0.4713, 0.2998, 0.2289], device='cuda:0'), new_distribution = tensor([0.4723, 0.2994, 0.2283], device='cuda:0')
2024-12-07 17:51:43,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([0.4723, 0.2994, 0.2283], device='cuda:0'), new_distribution = tensor([0.4732, 0.2991, 0.2277], device='cuda:0')
2024-12-07 17:51:43,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([0.4732, 0.2991, 0.2277], device='cuda:0'), new_distribution = tensor([0.4741, 0.2987, 0.2271], device='cuda:0')
2024-12-07 17:51:43,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([0.4741, 0.2987, 0.2271], device='cuda:0'), new_distribution = tensor([0.4750, 0.2984, 0.2266], device='cuda:0')
2024-12-07 17:51:44,128 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([0.4750, 0.2984, 0.2266], device='cuda:0'), new_distribution = tensor([0.4759, 0.2981, 0.2260], device='cuda:0')
2024-12-07 17:51:44,453 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([0.4759, 0.2981, 0.2260], device='cuda:0'), new_distribution = tensor([0.4769, 0.2977, 0.2254], device='cuda:0')
2024-12-07 17:51:44,779 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([0.4769, 0.2977, 0.2254], device='cuda:0'), new_distribution = tensor([0.4778, 0.2974, 0.2248], device='cuda:0')
2024-12-07 17:51:45,247 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([0.4778, 0.2974, 0.2248], device='cuda:0'), new_distribution = tensor([0.4787, 0.2970, 0.2243], device='cuda:0')
2024-12-07 17:51:45,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([0.4787, 0.2970, 0.2243], device='cuda:0'), new_distribution = tensor([0.4796, 0.2967, 0.2237], device='cuda:0')
2024-12-07 17:51:45,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([0.4796, 0.2967, 0.2237], device='cuda:0'), new_distribution = tensor([0.4806, 0.2963, 0.2231], device='cuda:0')
2024-12-07 17:51:46,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([0.4806, 0.2963, 0.2231], device='cuda:0'), new_distribution = tensor([0.4815, 0.2960, 0.2226], device='cuda:0')
2024-12-07 17:51:46,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([0.4815, 0.2960, 0.2226], device='cuda:0'), new_distribution = tensor([0.4824, 0.2956, 0.2220], device='cuda:0')
2024-12-07 17:51:47,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([0.4824, 0.2956, 0.2220], device='cuda:0'), new_distribution = tensor([0.4833, 0.2953, 0.2214], device='cuda:0')
2024-12-07 17:51:47,506 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([0.4833, 0.2953, 0.2214], device='cuda:0'), new_distribution = tensor([0.4843, 0.2949, 0.2208], device='cuda:0')
2024-12-07 17:51:47,988 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([0.4843, 0.2949, 0.2208], device='cuda:0'), new_distribution = tensor([0.4852, 0.2945, 0.2203], device='cuda:0')
2024-12-07 17:51:48,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([0.4852, 0.2945, 0.2203], device='cuda:0'), new_distribution = tensor([0.4861, 0.2942, 0.2197], device='cuda:0')
2024-12-07 17:51:48,669 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([0.4861, 0.2942, 0.2197], device='cuda:0'), new_distribution = tensor([0.4870, 0.2938, 0.2191], device='cuda:0')
2024-12-07 17:51:49,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([0.4870, 0.2938, 0.2191], device='cuda:0'), new_distribution = tensor([0.4879, 0.2935, 0.2186], device='cuda:0')
2024-12-07 17:51:49,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([0.4879, 0.2935, 0.2186], device='cuda:0'), new_distribution = tensor([0.4889, 0.2931, 0.2180], device='cuda:0')
2024-12-07 17:51:49,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([0.4889, 0.2931, 0.2180], device='cuda:0'), new_distribution = tensor([0.4898, 0.2927, 0.2175], device='cuda:0')
2024-12-07 17:51:50,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([0.4898, 0.2927, 0.2175], device='cuda:0'), new_distribution = tensor([0.4907, 0.2924, 0.2169], device='cuda:0')
2024-12-07 17:51:50,724 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([0.4907, 0.2924, 0.2169], device='cuda:0'), new_distribution = tensor([0.4916, 0.2920, 0.2163], device='cuda:0')
2024-12-07 17:51:51,072 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([0.4916, 0.2920, 0.2163], device='cuda:0'), new_distribution = tensor([0.4926, 0.2916, 0.2158], device='cuda:0')
2024-12-07 17:51:51,386 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([0.4926, 0.2916, 0.2158], device='cuda:0'), new_distribution = tensor([0.4935, 0.2913, 0.2152], device='cuda:0')
2024-12-07 17:51:51,843 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([0.4935, 0.2913, 0.2152], device='cuda:0'), new_distribution = tensor([0.4944, 0.2909, 0.2147], device='cuda:0')
2024-12-07 17:51:52,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([0.4944, 0.2909, 0.2147], device='cuda:0'), new_distribution = tensor([0.4953, 0.2905, 0.2141], device='cuda:0')
2024-12-07 17:51:52,488 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([0.4953, 0.2905, 0.2141], device='cuda:0'), new_distribution = tensor([0.4963, 0.2902, 0.2136], device='cuda:0')
2024-12-07 17:51:52,955 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([0.4963, 0.2902, 0.2136], device='cuda:0'), new_distribution = tensor([0.4972, 0.2898, 0.2130], device='cuda:0')
2024-12-07 17:51:53,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([0.4972, 0.2898, 0.2130], device='cuda:0'), new_distribution = tensor([0.4981, 0.2894, 0.2125], device='cuda:0')
2024-12-07 17:51:53,699 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([0.4981, 0.2894, 0.2125], device='cuda:0'), new_distribution = tensor([0.4990, 0.2890, 0.2119], device='cuda:0')
2024-12-07 17:51:54,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([0.4990, 0.2890, 0.2119], device='cuda:0'), new_distribution = tensor([0.5000, 0.2887, 0.2114], device='cuda:0')
2024-12-07 17:51:54,575 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([0.5000, 0.2887, 0.2114], device='cuda:0'), new_distribution = tensor([0.5009, 0.2883, 0.2108], device='cuda:0')
2024-12-07 17:51:54,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([0.5009, 0.2883, 0.2108], device='cuda:0'), new_distribution = tensor([0.5018, 0.2879, 0.2103], device='cuda:0')
2024-12-07 17:51:55,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([0.5018, 0.2879, 0.2103], device='cuda:0'), new_distribution = tensor([0.5027, 0.2875, 0.2097], device='cuda:0')
2024-12-07 17:51:55,660 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([0.5027, 0.2875, 0.2097], device='cuda:0'), new_distribution = tensor([0.5037, 0.2872, 0.2092], device='cuda:0')
2024-12-07 17:51:55,915 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([0.5037, 0.2872, 0.2092], device='cuda:0'), new_distribution = tensor([0.5046, 0.2868, 0.2086], device='cuda:0')
2024-12-07 17:51:56,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([0.5046, 0.2868, 0.2086], device='cuda:0'), new_distribution = tensor([0.5055, 0.2864, 0.2081], device='cuda:0')
2024-12-07 17:51:56,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([0.5055, 0.2864, 0.2081], device='cuda:0'), new_distribution = tensor([0.5064, 0.2860, 0.2075], device='cuda:0')
2024-12-07 17:51:57,078 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([0.5064, 0.2860, 0.2075], device='cuda:0'), new_distribution = tensor([0.5074, 0.2856, 0.2070], device='cuda:0')
2024-12-07 17:51:57,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([0.5074, 0.2856, 0.2070], device='cuda:0'), new_distribution = tensor([0.5083, 0.2852, 0.2065], device='cuda:0')
2024-12-07 17:51:57,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([0.5083, 0.2852, 0.2065], device='cuda:0'), new_distribution = tensor([0.5092, 0.2849, 0.2059], device='cuda:0')
2024-12-07 17:51:58,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([0.5092, 0.2849, 0.2059], device='cuda:0'), new_distribution = tensor([0.5101, 0.2845, 0.2054], device='cuda:0')
2024-12-07 17:51:58,540 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([0.5101, 0.2845, 0.2054], device='cuda:0'), new_distribution = tensor([0.5111, 0.2841, 0.2049], device='cuda:0')
2024-12-07 17:51:58,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([0.5111, 0.2841, 0.2049], device='cuda:0'), new_distribution = tensor([0.5120, 0.2837, 0.2043], device='cuda:0')
2024-12-07 17:51:59,155 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([0.5120, 0.2837, 0.2043], device='cuda:0'), new_distribution = tensor([0.5129, 0.2833, 0.2038], device='cuda:0')
2024-12-07 17:51:59,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([0.5129, 0.2833, 0.2038], device='cuda:0'), new_distribution = tensor([0.5138, 0.2829, 0.2033], device='cuda:0')
2024-12-07 17:52:00,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([0.5138, 0.2829, 0.2033], device='cuda:0'), new_distribution = tensor([0.5148, 0.2825, 0.2027], device='cuda:0')
2024-12-07 17:52:00,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([0.5148, 0.2825, 0.2027], device='cuda:0'), new_distribution = tensor([0.5157, 0.2821, 0.2022], device='cuda:0')
2024-12-07 17:52:00,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([0.5157, 0.2821, 0.2022], device='cuda:0'), new_distribution = tensor([0.5166, 0.2817, 0.2017], device='cuda:0')
2024-12-07 17:52:01,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([0.5166, 0.2817, 0.2017], device='cuda:0'), new_distribution = tensor([0.5175, 0.2813, 0.2011], device='cuda:0')
2024-12-07 17:52:01,448 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([0.5175, 0.2813, 0.2011], device='cuda:0'), new_distribution = tensor([0.5185, 0.2809, 0.2006], device='cuda:0')
2024-12-07 17:52:01,860 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([0.5185, 0.2809, 0.2006], device='cuda:0'), new_distribution = tensor([0.5194, 0.2805, 0.2001], device='cuda:0')
2024-12-07 17:52:02,329 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([0.5194, 0.2805, 0.2001], device='cuda:0'), new_distribution = tensor([0.5203, 0.2801, 0.1996], device='cuda:0')
2024-12-07 17:52:02,620 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([0.5203, 0.2801, 0.1996], device='cuda:0'), new_distribution = tensor([0.5212, 0.2797, 0.1990], device='cuda:0')
2024-12-07 17:52:02,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([0.5212, 0.2797, 0.1990], device='cuda:0'), new_distribution = tensor([0.5221, 0.2793, 0.1985], device='cuda:0')
2024-12-07 17:52:03,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([0.5221, 0.2793, 0.1985], device='cuda:0'), new_distribution = tensor([0.5231, 0.2789, 0.1980], device='cuda:0')
2024-12-07 17:52:03,831 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([0.5231, 0.2789, 0.1980], device='cuda:0'), new_distribution = tensor([0.5240, 0.2785, 0.1975], device='cuda:0')
2024-12-07 17:52:04,170 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([0.5240, 0.2785, 0.1975], device='cuda:0'), new_distribution = tensor([0.5249, 0.2781, 0.1970], device='cuda:0')
2024-12-07 17:52:04,599 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([0.5249, 0.2781, 0.1970], device='cuda:0'), new_distribution = tensor([0.5258, 0.2777, 0.1964], device='cuda:0')
2024-12-07 17:52:05,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([0.5258, 0.2777, 0.1964], device='cuda:0'), new_distribution = tensor([0.5268, 0.2773, 0.1959], device='cuda:0')
2024-12-07 17:52:05,381 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([0.5268, 0.2773, 0.1959], device='cuda:0'), new_distribution = tensor([0.5277, 0.2769, 0.1954], device='cuda:0')
2024-12-07 17:52:05,709 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([0.5277, 0.2769, 0.1954], device='cuda:0'), new_distribution = tensor([0.5286, 0.2765, 0.1949], device='cuda:0')
2024-12-07 17:52:06,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([0.5286, 0.2765, 0.1949], device='cuda:0'), new_distribution = tensor([0.5295, 0.2761, 0.1944], device='cuda:0')
2024-12-07 17:52:06,469 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([0.5295, 0.2761, 0.1944], device='cuda:0'), new_distribution = tensor([0.5305, 0.2757, 0.1939], device='cuda:0')
2024-12-07 17:52:06,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([0.5305, 0.2757, 0.1939], device='cuda:0'), new_distribution = tensor([0.5314, 0.2753, 0.1934], device='cuda:0')
2024-12-07 17:52:07,295 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([0.5314, 0.2753, 0.1934], device='cuda:0'), new_distribution = tensor([0.5323, 0.2749, 0.1928], device='cuda:0')
2024-12-07 17:52:07,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([0.5323, 0.2749, 0.1928], device='cuda:0'), new_distribution = tensor([0.5332, 0.2745, 0.1923], device='cuda:0')
2024-12-07 17:52:07,996 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([0.5332, 0.2745, 0.1923], device='cuda:0'), new_distribution = tensor([0.5341, 0.2740, 0.1918], device='cuda:0')
2024-12-07 17:52:08,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([0.5341, 0.2740, 0.1918], device='cuda:0'), new_distribution = tensor([0.5351, 0.2736, 0.1913], device='cuda:0')
2024-12-07 17:52:08,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([0.5351, 0.2736, 0.1913], device='cuda:0'), new_distribution = tensor([0.5360, 0.2732, 0.1908], device='cuda:0')
2024-12-07 17:52:09,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([0.5360, 0.2732, 0.1908], device='cuda:0'), new_distribution = tensor([0.5369, 0.2728, 0.1903], device='cuda:0')
2024-12-07 17:52:09,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([0.5369, 0.2728, 0.1903], device='cuda:0'), new_distribution = tensor([0.5378, 0.2724, 0.1898], device='cuda:0')
2024-12-07 17:52:10,036 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([0.5378, 0.2724, 0.1898], device='cuda:0'), new_distribution = tensor([0.5387, 0.2720, 0.1893], device='cuda:0')
2024-12-07 17:52:10,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([0.5387, 0.2720, 0.1893], device='cuda:0'), new_distribution = tensor([0.5397, 0.2715, 0.1888], device='cuda:0')
2024-12-07 17:52:10,729 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([0.5397, 0.2715, 0.1888], device='cuda:0'), new_distribution = tensor([0.5406, 0.2711, 0.1883], device='cuda:0')
2024-12-07 17:52:11,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([0.5406, 0.2711, 0.1883], device='cuda:0'), new_distribution = tensor([0.5415, 0.2707, 0.1878], device='cuda:0')
2024-12-07 17:52:11,659 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([0.5415, 0.2707, 0.1878], device='cuda:0'), new_distribution = tensor([0.5424, 0.2703, 0.1873], device='cuda:0')
2024-12-07 17:52:12,009 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([0.5424, 0.2703, 0.1873], device='cuda:0'), new_distribution = tensor([0.5433, 0.2699, 0.1868], device='cuda:0')
2024-12-07 17:52:12,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([0.5433, 0.2699, 0.1868], device='cuda:0'), new_distribution = tensor([0.5443, 0.2694, 0.1863], device='cuda:0')
2024-12-07 17:52:12,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([0.5443, 0.2694, 0.1863], device='cuda:0'), new_distribution = tensor([0.5452, 0.2690, 0.1858], device='cuda:0')
2024-12-07 17:52:13,192 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([0.5452, 0.2690, 0.1858], device='cuda:0'), new_distribution = tensor([0.5461, 0.2686, 0.1853], device='cuda:0')
2024-12-07 17:52:13,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([0.5461, 0.2686, 0.1853], device='cuda:0'), new_distribution = tensor([0.5470, 0.2682, 0.1848], device='cuda:0')
2024-12-07 17:52:13,907 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([0.5470, 0.2682, 0.1848], device='cuda:0'), new_distribution = tensor([0.5479, 0.2677, 0.1843], device='cuda:0')
2024-12-07 17:52:14,380 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([0.5479, 0.2677, 0.1843], device='cuda:0'), new_distribution = tensor([0.5488, 0.2673, 0.1838], device='cuda:0')
2024-12-07 17:52:14,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([0.5488, 0.2673, 0.1838], device='cuda:0'), new_distribution = tensor([0.5498, 0.2669, 0.1833], device='cuda:0')
2024-12-07 17:52:15,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([0.5498, 0.2669, 0.1833], device='cuda:0'), new_distribution = tensor([0.5507, 0.2665, 0.1829], device='cuda:0')
2024-12-07 17:52:15,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([0.5507, 0.2665, 0.1829], device='cuda:0'), new_distribution = tensor([0.5516, 0.2660, 0.1824], device='cuda:0')
2024-12-07 17:52:15,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([0.5516, 0.2660, 0.1824], device='cuda:0'), new_distribution = tensor([0.5525, 0.2656, 0.1819], device='cuda:0')
2024-12-07 17:52:16,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([0.5525, 0.2656, 0.1819], device='cuda:0'), new_distribution = tensor([0.5534, 0.2652, 0.1814], device='cuda:0')
2024-12-07 17:52:16,630 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([0.5534, 0.2652, 0.1814], device='cuda:0'), new_distribution = tensor([0.5543, 0.2648, 0.1809], device='cuda:0')
2024-12-07 17:52:16,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([0.5543, 0.2648, 0.1809], device='cuda:0'), new_distribution = tensor([0.5552, 0.2643, 0.1804], device='cuda:0')
2024-12-07 17:52:17,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([0.5552, 0.2643, 0.1804], device='cuda:0'), new_distribution = tensor([0.5562, 0.2639, 0.1799], device='cuda:0')
2024-12-07 17:52:17,759 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([0.5562, 0.2639, 0.1799], device='cuda:0'), new_distribution = tensor([0.5571, 0.2635, 0.1795], device='cuda:0')
2024-12-07 17:52:18,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([0.5571, 0.2635, 0.1795], device='cuda:0'), new_distribution = tensor([0.5580, 0.2630, 0.1790], device='cuda:0')
2024-12-07 17:52:18,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([0.5580, 0.2630, 0.1790], device='cuda:0'), new_distribution = tensor([0.5589, 0.2626, 0.1785], device='cuda:0')
2024-12-07 17:52:18,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([0.5589, 0.2626, 0.1785], device='cuda:0'), new_distribution = tensor([0.5598, 0.2622, 0.1780], device='cuda:0')
2024-12-07 17:52:19,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([0.5598, 0.2622, 0.1780], device='cuda:0'), new_distribution = tensor([0.5607, 0.2617, 0.1776], device='cuda:0')
2024-12-07 17:52:19,779 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([0.5607, 0.2617, 0.1776], device='cuda:0'), new_distribution = tensor([0.5616, 0.2613, 0.1771], device='cuda:0')
2024-12-07 17:52:20,072 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([0.5616, 0.2613, 0.1771], device='cuda:0'), new_distribution = tensor([0.5625, 0.2609, 0.1766], device='cuda:0')
2024-12-07 17:52:20,521 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([0.5625, 0.2609, 0.1766], device='cuda:0'), new_distribution = tensor([0.5635, 0.2604, 0.1761], device='cuda:0')
2024-12-07 17:52:20,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([0.5635, 0.2604, 0.1761], device='cuda:0'), new_distribution = tensor([0.5644, 0.2600, 0.1757], device='cuda:0')
2024-12-07 17:52:21,259 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([0.5644, 0.2600, 0.1757], device='cuda:0'), new_distribution = tensor([0.5653, 0.2595, 0.1752], device='cuda:0')
2024-12-07 17:52:21,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([0.5653, 0.2595, 0.1752], device='cuda:0'), new_distribution = tensor([0.5662, 0.2591, 0.1747], device='cuda:0')
2024-12-07 17:52:22,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([0.5662, 0.2591, 0.1747], device='cuda:0'), new_distribution = tensor([0.5671, 0.2587, 0.1742], device='cuda:0')
2024-12-07 17:52:22,434 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([0.5671, 0.2587, 0.1742], device='cuda:0'), new_distribution = tensor([0.5680, 0.2582, 0.1738], device='cuda:0')
2024-12-07 17:52:22,802 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([0.5680, 0.2582, 0.1738], device='cuda:0'), new_distribution = tensor([0.5689, 0.2578, 0.1733], device='cuda:0')
2024-12-07 17:52:23,252 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([0.5689, 0.2578, 0.1733], device='cuda:0'), new_distribution = tensor([0.5698, 0.2573, 0.1728], device='cuda:0')
2024-12-07 17:52:23,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([0.5698, 0.2573, 0.1728], device='cuda:0'), new_distribution = tensor([0.5707, 0.2569, 0.1724], device='cuda:0')
2024-12-07 17:52:23,901 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([0.5707, 0.2569, 0.1724], device='cuda:0'), new_distribution = tensor([0.5716, 0.2565, 0.1719], device='cuda:0')
2024-12-07 17:52:24,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([0.5716, 0.2565, 0.1719], device='cuda:0'), new_distribution = tensor([0.5725, 0.2560, 0.1714], device='cuda:0')
2024-12-07 17:52:24,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([0.5725, 0.2560, 0.1714], device='cuda:0'), new_distribution = tensor([0.5734, 0.2556, 0.1710], device='cuda:0')
2024-12-07 17:52:24,961 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([0.5734, 0.2556, 0.1710], device='cuda:0'), new_distribution = tensor([0.5744, 0.2551, 0.1705], device='cuda:0')
2024-12-07 17:52:25,345 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([0.5744, 0.2551, 0.1705], device='cuda:0'), new_distribution = tensor([0.5753, 0.2547, 0.1701], device='cuda:0')
2024-12-07 17:52:25,598 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([0.5753, 0.2547, 0.1701], device='cuda:0'), new_distribution = tensor([0.5762, 0.2542, 0.1696], device='cuda:0')
2024-12-07 17:52:26,069 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([0.5762, 0.2542, 0.1696], device='cuda:0'), new_distribution = tensor([0.5771, 0.2538, 0.1691], device='cuda:0')
2024-12-07 17:52:26,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([0.5771, 0.2538, 0.1691], device='cuda:0'), new_distribution = tensor([0.5780, 0.2533, 0.1687], device='cuda:0')
2024-12-07 17:52:26,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([0.5780, 0.2533, 0.1687], device='cuda:0'), new_distribution = tensor([0.5789, 0.2529, 0.1682], device='cuda:0')
2024-12-07 17:52:27,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([0.5789, 0.2529, 0.1682], device='cuda:0'), new_distribution = tensor([0.5798, 0.2524, 0.1678], device='cuda:0')
2024-12-07 17:52:27,693 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([0.5798, 0.2524, 0.1678], device='cuda:0'), new_distribution = tensor([0.5807, 0.2520, 0.1673], device='cuda:0')
2024-12-07 17:52:27,945 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([0.5807, 0.2520, 0.1673], device='cuda:0'), new_distribution = tensor([0.5816, 0.2516, 0.1669], device='cuda:0')
2024-12-07 17:52:28,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([0.5816, 0.2516, 0.1669], device='cuda:0'), new_distribution = tensor([0.5825, 0.2511, 0.1664], device='cuda:0')
2024-12-07 17:52:28,806 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([0.5825, 0.2511, 0.1664], device='cuda:0'), new_distribution = tensor([0.5834, 0.2507, 0.1660], device='cuda:0')
2024-12-07 17:52:29,097 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([0.5834, 0.2507, 0.1660], device='cuda:0'), new_distribution = tensor([0.5843, 0.2502, 0.1655], device='cuda:0')
2024-12-07 17:52:29,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([0.5843, 0.2502, 0.1655], device='cuda:0'), new_distribution = tensor([0.5852, 0.2498, 0.1651], device='cuda:0')
2024-12-07 17:52:29,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([0.5852, 0.2498, 0.1651], device='cuda:0'), new_distribution = tensor([0.5861, 0.2493, 0.1646], device='cuda:0')
2024-12-07 17:52:30,096 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([0.5861, 0.2493, 0.1646], device='cuda:0'), new_distribution = tensor([0.5870, 0.2489, 0.1642], device='cuda:0')
2024-12-07 17:52:30,534 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([0.5870, 0.2489, 0.1642], device='cuda:0'), new_distribution = tensor([0.5879, 0.2484, 0.1637], device='cuda:0')
2024-12-07 17:52:30,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([0.5879, 0.2484, 0.1637], device='cuda:0'), new_distribution = tensor([0.5888, 0.2479, 0.1633], device='cuda:0')
2024-12-07 17:52:31,282 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([0.5888, 0.2479, 0.1633], device='cuda:0'), new_distribution = tensor([0.5897, 0.2475, 0.1628], device='cuda:0')
2024-12-07 17:52:31,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([0.5897, 0.2475, 0.1628], device='cuda:0'), new_distribution = tensor([0.5906, 0.2470, 0.1624], device='cuda:0')
2024-12-07 17:52:32,131 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([0.5906, 0.2470, 0.1624], device='cuda:0'), new_distribution = tensor([0.5914, 0.2466, 0.1620], device='cuda:0')
2024-12-07 17:52:32,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([0.5914, 0.2466, 0.1620], device='cuda:0'), new_distribution = tensor([0.5923, 0.2461, 0.1615], device='cuda:0')
2024-12-07 17:52:32,759 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([0.5923, 0.2461, 0.1615], device='cuda:0'), new_distribution = tensor([0.5932, 0.2457, 0.1611], device='cuda:0')
2024-12-07 17:52:33,205 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([0.5932, 0.2457, 0.1611], device='cuda:0'), new_distribution = tensor([0.5941, 0.2452, 0.1606], device='cuda:0')
2024-12-07 17:52:33,370 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([0.5941, 0.2452, 0.1606], device='cuda:0'), new_distribution = tensor([0.5950, 0.2448, 0.1602], device='cuda:0')
2024-12-07 17:52:33,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([0.5950, 0.2448, 0.1602], device='cuda:0'), new_distribution = tensor([0.5959, 0.2443, 0.1598], device='cuda:0')
2024-12-07 17:52:34,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([0.5959, 0.2443, 0.1598], device='cuda:0'), new_distribution = tensor([0.5968, 0.2439, 0.1593], device='cuda:0')
2024-12-07 17:52:34,521 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([0.5968, 0.2439, 0.1593], device='cuda:0'), new_distribution = tensor([0.5977, 0.2434, 0.1589], device='cuda:0')
2024-12-07 17:52:34,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([0.5977, 0.2434, 0.1589], device='cuda:0'), new_distribution = tensor([0.5986, 0.2429, 0.1585], device='cuda:0')
2024-12-07 17:52:35,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([0.5986, 0.2429, 0.1585], device='cuda:0'), new_distribution = tensor([0.5995, 0.2425, 0.1580], device='cuda:0')
2024-12-07 17:52:35,673 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([0.5995, 0.2425, 0.1580], device='cuda:0'), new_distribution = tensor([0.6004, 0.2420, 0.1576], device='cuda:0')
2024-12-07 17:52:36,111 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([0.6004, 0.2420, 0.1576], device='cuda:0'), new_distribution = tensor([0.6012, 0.2416, 0.1572], device='cuda:0')
2024-12-07 17:52:36,572 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([0.6012, 0.2416, 0.1572], device='cuda:0'), new_distribution = tensor([0.6021, 0.2411, 0.1567], device='cuda:0')
2024-12-07 17:52:36,843 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 300: ref_distribution = tensor([0.6021, 0.2411, 0.1567], device='cuda:0'), new_distribution = tensor([0.6030, 0.2407, 0.1563], device='cuda:0')
2024-12-07 17:52:37,230 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 301: ref_distribution = tensor([0.6030, 0.2407, 0.1563], device='cuda:0'), new_distribution = tensor([0.6039, 0.2402, 0.1559], device='cuda:0')
2024-12-07 17:52:37,699 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 302: ref_distribution = tensor([0.6039, 0.2402, 0.1559], device='cuda:0'), new_distribution = tensor([0.6048, 0.2397, 0.1555], device='cuda:0')
2024-12-07 17:52:38,057 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 303: ref_distribution = tensor([0.6048, 0.2397, 0.1555], device='cuda:0'), new_distribution = tensor([0.6057, 0.2393, 0.1550], device='cuda:0')
2024-12-07 17:52:38,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 304: ref_distribution = tensor([0.6057, 0.2393, 0.1550], device='cuda:0'), new_distribution = tensor([0.6066, 0.2388, 0.1546], device='cuda:0')
2024-12-07 17:52:38,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 305: ref_distribution = tensor([0.6066, 0.2388, 0.1546], device='cuda:0'), new_distribution = tensor([0.6074, 0.2384, 0.1542], device='cuda:0')
2024-12-07 17:52:39,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 306: ref_distribution = tensor([0.6074, 0.2384, 0.1542], device='cuda:0'), new_distribution = tensor([0.6083, 0.2379, 0.1538], device='cuda:0')
2024-12-07 17:52:39,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 307: ref_distribution = tensor([0.6083, 0.2379, 0.1538], device='cuda:0'), new_distribution = tensor([0.6092, 0.2374, 0.1533], device='cuda:0')
2024-12-07 17:52:39,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 308: ref_distribution = tensor([0.6092, 0.2374, 0.1533], device='cuda:0'), new_distribution = tensor([0.6101, 0.2370, 0.1529], device='cuda:0')
2024-12-07 17:52:40,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 309: ref_distribution = tensor([0.6101, 0.2370, 0.1529], device='cuda:0'), new_distribution = tensor([0.6110, 0.2365, 0.1525], device='cuda:0')
2024-12-07 17:52:40,673 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 310: ref_distribution = tensor([0.6110, 0.2365, 0.1525], device='cuda:0'), new_distribution = tensor([0.6118, 0.2361, 0.1521], device='cuda:0')
2024-12-07 17:52:41,076 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 311: ref_distribution = tensor([0.6118, 0.2361, 0.1521], device='cuda:0'), new_distribution = tensor([0.6127, 0.2356, 0.1517], device='cuda:0')
2024-12-07 17:52:41,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 312: ref_distribution = tensor([0.6127, 0.2356, 0.1517], device='cuda:0'), new_distribution = tensor([0.6136, 0.2351, 0.1513], device='cuda:0')
2024-12-07 17:52:41,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 313: ref_distribution = tensor([0.6136, 0.2351, 0.1513], device='cuda:0'), new_distribution = tensor([0.6145, 0.2347, 0.1508], device='cuda:0')
2024-12-07 17:52:42,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 314: ref_distribution = tensor([0.6145, 0.2347, 0.1508], device='cuda:0'), new_distribution = tensor([0.6154, 0.2342, 0.1504], device='cuda:0')
2024-12-07 17:52:42,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 315: ref_distribution = tensor([0.6154, 0.2342, 0.1504], device='cuda:0'), new_distribution = tensor([0.6162, 0.2338, 0.1500], device='cuda:0')
2024-12-07 17:52:43,078 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 316: ref_distribution = tensor([0.6162, 0.2338, 0.1500], device='cuda:0'), new_distribution = tensor([0.6171, 0.2333, 0.1496], device='cuda:0')
2024-12-07 17:52:43,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 317: ref_distribution = tensor([0.6171, 0.2333, 0.1496], device='cuda:0'), new_distribution = tensor([0.6180, 0.2328, 0.1492], device='cuda:0')
2024-12-07 17:52:43,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 318: ref_distribution = tensor([0.6180, 0.2328, 0.1492], device='cuda:0'), new_distribution = tensor([0.6189, 0.2324, 0.1488], device='cuda:0')
2024-12-07 17:52:44,294 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 319: ref_distribution = tensor([0.6189, 0.2324, 0.1488], device='cuda:0'), new_distribution = tensor([0.6197, 0.2319, 0.1484], device='cuda:0')
2024-12-07 17:52:44,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 320: ref_distribution = tensor([0.6197, 0.2319, 0.1484], device='cuda:0'), new_distribution = tensor([0.6206, 0.2314, 0.1480], device='cuda:0')
2024-12-07 17:52:44,951 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 321: ref_distribution = tensor([0.6206, 0.2314, 0.1480], device='cuda:0'), new_distribution = tensor([0.6215, 0.2310, 0.1476], device='cuda:0')
2024-12-07 17:52:45,413 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 322: ref_distribution = tensor([0.6215, 0.2310, 0.1476], device='cuda:0'), new_distribution = tensor([0.6223, 0.2305, 0.1472], device='cuda:0')
2024-12-07 17:52:45,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 323: ref_distribution = tensor([0.6223, 0.2305, 0.1472], device='cuda:0'), new_distribution = tensor([0.6232, 0.2300, 0.1467], device='cuda:0')
2024-12-07 17:52:46,185 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 324: ref_distribution = tensor([0.6232, 0.2300, 0.1467], device='cuda:0'), new_distribution = tensor([0.6241, 0.2296, 0.1463], device='cuda:0')
2024-12-07 17:52:46,568 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 325: ref_distribution = tensor([0.6241, 0.2296, 0.1463], device='cuda:0'), new_distribution = tensor([0.6249, 0.2291, 0.1459], device='cuda:0')
2024-12-07 17:52:47,029 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 326: ref_distribution = tensor([0.6249, 0.2291, 0.1459], device='cuda:0'), new_distribution = tensor([0.6258, 0.2287, 0.1455], device='cuda:0')
2024-12-07 17:52:47,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 327: ref_distribution = tensor([0.6258, 0.2287, 0.1455], device='cuda:0'), new_distribution = tensor([0.6267, 0.2282, 0.1451], device='cuda:0')
2024-12-07 17:52:47,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 328: ref_distribution = tensor([0.6267, 0.2282, 0.1451], device='cuda:0'), new_distribution = tensor([0.6275, 0.2277, 0.1447], device='cuda:0')
2024-12-07 17:52:48,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 329: ref_distribution = tensor([0.6275, 0.2277, 0.1447], device='cuda:0'), new_distribution = tensor([0.6284, 0.2273, 0.1443], device='cuda:0')
2024-12-07 17:52:48,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 330: ref_distribution = tensor([0.6284, 0.2273, 0.1443], device='cuda:0'), new_distribution = tensor([0.6293, 0.2268, 0.1439], device='cuda:0')
2024-12-07 17:52:48,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 331: ref_distribution = tensor([0.6293, 0.2268, 0.1439], device='cuda:0'), new_distribution = tensor([0.6301, 0.2263, 0.1435], device='cuda:0')
2024-12-07 17:52:49,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 332: ref_distribution = tensor([0.6301, 0.2263, 0.1435], device='cuda:0'), new_distribution = tensor([0.6310, 0.2259, 0.1431], device='cuda:0')
2024-12-07 17:52:49,568 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 333: ref_distribution = tensor([0.6310, 0.2259, 0.1431], device='cuda:0'), new_distribution = tensor([0.6319, 0.2254, 0.1428], device='cuda:0')
2024-12-07 17:52:49,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 334: ref_distribution = tensor([0.6319, 0.2254, 0.1428], device='cuda:0'), new_distribution = tensor([0.6327, 0.2249, 0.1424], device='cuda:0')
2024-12-07 17:52:50,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 335: ref_distribution = tensor([0.6327, 0.2249, 0.1424], device='cuda:0'), new_distribution = tensor([0.6336, 0.2245, 0.1420], device='cuda:0')
2024-12-07 17:52:50,585 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 336: ref_distribution = tensor([0.6336, 0.2245, 0.1420], device='cuda:0'), new_distribution = tensor([0.6344, 0.2240, 0.1416], device='cuda:0')
2024-12-07 17:52:50,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 337: ref_distribution = tensor([0.6344, 0.2240, 0.1416], device='cuda:0'), new_distribution = tensor([0.6353, 0.2235, 0.1412], device='cuda:0')
2024-12-07 17:52:51,486 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 338: ref_distribution = tensor([0.6353, 0.2235, 0.1412], device='cuda:0'), new_distribution = tensor([0.6361, 0.2231, 0.1408], device='cuda:0')
2024-12-07 17:52:51,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 339: ref_distribution = tensor([0.6361, 0.2231, 0.1408], device='cuda:0'), new_distribution = tensor([0.6370, 0.2226, 0.1404], device='cuda:0')
2024-12-07 17:52:52,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 340: ref_distribution = tensor([0.6370, 0.2226, 0.1404], device='cuda:0'), new_distribution = tensor([0.6379, 0.2221, 0.1400], device='cuda:0')
2024-12-07 17:52:52,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 341: ref_distribution = tensor([0.6379, 0.2221, 0.1400], device='cuda:0'), new_distribution = tensor([0.6387, 0.2217, 0.1396], device='cuda:0')
2024-12-07 17:52:53,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 342: ref_distribution = tensor([0.6387, 0.2217, 0.1396], device='cuda:0'), new_distribution = tensor([0.6396, 0.2212, 0.1392], device='cuda:0')
2024-12-07 17:52:53,295 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 343: ref_distribution = tensor([0.6396, 0.2212, 0.1392], device='cuda:0'), new_distribution = tensor([0.6404, 0.2207, 0.1389], device='cuda:0')
2024-12-07 17:52:53,760 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 344: ref_distribution = tensor([0.6404, 0.2207, 0.1389], device='cuda:0'), new_distribution = tensor([0.6413, 0.2203, 0.1385], device='cuda:0')
2024-12-07 17:52:54,223 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 345: ref_distribution = tensor([0.6413, 0.2203, 0.1385], device='cuda:0'), new_distribution = tensor([0.6421, 0.2198, 0.1381], device='cuda:0')
2024-12-07 17:52:54,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 346: ref_distribution = tensor([0.6421, 0.2198, 0.1381], device='cuda:0'), new_distribution = tensor([0.6430, 0.2193, 0.1377], device='cuda:0')
2024-12-07 17:52:54,876 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 347: ref_distribution = tensor([0.6430, 0.2193, 0.1377], device='cuda:0'), new_distribution = tensor([0.6438, 0.2189, 0.1373], device='cuda:0')
2024-12-07 17:52:55,346 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 348: ref_distribution = tensor([0.6438, 0.2189, 0.1373], device='cuda:0'), new_distribution = tensor([0.6447, 0.2184, 0.1369], device='cuda:0')
2024-12-07 17:52:55,625 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 349: ref_distribution = tensor([0.6447, 0.2184, 0.1369], device='cuda:0'), new_distribution = tensor([0.6455, 0.2179, 0.1366], device='cuda:0')
2024-12-07 17:52:55,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 350: ref_distribution = tensor([0.6455, 0.2179, 0.1366], device='cuda:0'), new_distribution = tensor([0.6464, 0.2175, 0.1362], device='cuda:0')
2024-12-07 17:52:56,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 351: ref_distribution = tensor([0.6464, 0.2175, 0.1362], device='cuda:0'), new_distribution = tensor([0.6472, 0.2170, 0.1358], device='cuda:0')
2024-12-07 17:52:56,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 352: ref_distribution = tensor([0.6472, 0.2170, 0.1358], device='cuda:0'), new_distribution = tensor([0.6480, 0.2165, 0.1354], device='cuda:0')
2024-12-07 17:52:57,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 353: ref_distribution = tensor([0.6480, 0.2165, 0.1354], device='cuda:0'), new_distribution = tensor([0.6489, 0.2161, 0.1350], device='cuda:0')
2024-12-07 17:52:57,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 354: ref_distribution = tensor([0.6489, 0.2161, 0.1350], device='cuda:0'), new_distribution = tensor([0.6497, 0.2156, 0.1347], device='cuda:0')
2024-12-07 17:52:57,845 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 355: ref_distribution = tensor([0.6497, 0.2156, 0.1347], device='cuda:0'), new_distribution = tensor([0.6506, 0.2151, 0.1343], device='cuda:0')
2024-12-07 17:52:58,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 356: ref_distribution = tensor([0.6506, 0.2151, 0.1343], device='cuda:0'), new_distribution = tensor([0.6514, 0.2147, 0.1339], device='cuda:0')
2024-12-07 17:52:58,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 357: ref_distribution = tensor([0.6514, 0.2147, 0.1339], device='cuda:0'), new_distribution = tensor([0.6523, 0.2142, 0.1335], device='cuda:0')
2024-12-07 17:52:58,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 358: ref_distribution = tensor([0.6523, 0.2142, 0.1335], device='cuda:0'), new_distribution = tensor([0.6531, 0.2137, 0.1332], device='cuda:0')
2024-12-07 17:52:59,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 359: ref_distribution = tensor([0.6531, 0.2137, 0.1332], device='cuda:0'), new_distribution = tensor([0.6539, 0.2133, 0.1328], device='cuda:0')
2024-12-07 17:52:59,759 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 360: ref_distribution = tensor([0.6539, 0.2133, 0.1328], device='cuda:0'), new_distribution = tensor([0.6548, 0.2128, 0.1324], device='cuda:0')
2024-12-07 17:53:00,097 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 361: ref_distribution = tensor([0.6548, 0.2128, 0.1324], device='cuda:0'), new_distribution = tensor([0.6556, 0.2123, 0.1321], device='cuda:0')
2024-12-07 17:53:00,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 362: ref_distribution = tensor([0.6556, 0.2123, 0.1321], device='cuda:0'), new_distribution = tensor([0.6564, 0.2119, 0.1317], device='cuda:0')
2024-12-07 17:53:00,906 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 363: ref_distribution = tensor([0.6564, 0.2119, 0.1317], device='cuda:0'), new_distribution = tensor([0.6573, 0.2114, 0.1313], device='cuda:0')
2024-12-07 17:53:01,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 364: ref_distribution = tensor([0.6573, 0.2114, 0.1313], device='cuda:0'), new_distribution = tensor([0.6581, 0.2109, 0.1310], device='cuda:0')
2024-12-07 17:53:01,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 365: ref_distribution = tensor([0.6581, 0.2109, 0.1310], device='cuda:0'), new_distribution = tensor([0.6589, 0.2105, 0.1306], device='cuda:0')
2024-12-07 17:53:02,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 366: ref_distribution = tensor([0.6589, 0.2105, 0.1306], device='cuda:0'), new_distribution = tensor([0.6598, 0.2100, 0.1302], device='cuda:0')
2024-12-07 17:53:02,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 367: ref_distribution = tensor([0.6598, 0.2100, 0.1302], device='cuda:0'), new_distribution = tensor([0.6606, 0.2095, 0.1299], device='cuda:0')
2024-12-07 17:53:02,912 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 368: ref_distribution = tensor([0.6606, 0.2095, 0.1299], device='cuda:0'), new_distribution = tensor([0.6614, 0.2091, 0.1295], device='cuda:0')
2024-12-07 17:53:03,208 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 369: ref_distribution = tensor([0.6614, 0.2091, 0.1295], device='cuda:0'), new_distribution = tensor([0.6622, 0.2086, 0.1292], device='cuda:0')
2024-12-07 17:53:03,660 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 370: ref_distribution = tensor([0.6622, 0.2086, 0.1292], device='cuda:0'), new_distribution = tensor([0.6631, 0.2081, 0.1288], device='cuda:0')
2024-12-07 17:53:04,137 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 371: ref_distribution = tensor([0.6631, 0.2081, 0.1288], device='cuda:0'), new_distribution = tensor([0.6639, 0.2077, 0.1284], device='cuda:0')
2024-12-07 17:53:04,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 372: ref_distribution = tensor([0.6639, 0.2077, 0.1284], device='cuda:0'), new_distribution = tensor([0.6647, 0.2072, 0.1281], device='cuda:0')
2024-12-07 17:53:04,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 373: ref_distribution = tensor([0.6647, 0.2072, 0.1281], device='cuda:0'), new_distribution = tensor([0.6655, 0.2067, 0.1277], device='cuda:0')
2024-12-07 17:53:05,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 374: ref_distribution = tensor([0.6655, 0.2067, 0.1277], device='cuda:0'), new_distribution = tensor([0.6664, 0.2063, 0.1274], device='cuda:0')
2024-12-07 17:53:05,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 375: ref_distribution = tensor([0.6664, 0.2063, 0.1274], device='cuda:0'), new_distribution = tensor([0.6672, 0.2058, 0.1270], device='cuda:0')
2024-12-07 17:53:05,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 376: ref_distribution = tensor([0.6672, 0.2058, 0.1270], device='cuda:0'), new_distribution = tensor([0.6680, 0.2053, 0.1266], device='cuda:0')
2024-12-07 17:53:06,349 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 377: ref_distribution = tensor([0.6680, 0.2053, 0.1266], device='cuda:0'), new_distribution = tensor([0.6688, 0.2049, 0.1263], device='cuda:0')
2024-12-07 17:53:06,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 378: ref_distribution = tensor([0.6688, 0.2049, 0.1263], device='cuda:0'), new_distribution = tensor([0.6697, 0.2044, 0.1259], device='cuda:0')
2024-12-07 17:53:06,994 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 379: ref_distribution = tensor([0.6697, 0.2044, 0.1259], device='cuda:0'), new_distribution = tensor([0.6705, 0.2039, 0.1256], device='cuda:0')
2024-12-07 17:53:07,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 380: ref_distribution = tensor([0.6705, 0.2039, 0.1256], device='cuda:0'), new_distribution = tensor([0.6713, 0.2035, 0.1252], device='cuda:0')
2024-12-07 17:53:07,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 381: ref_distribution = tensor([0.6713, 0.2035, 0.1252], device='cuda:0'), new_distribution = tensor([0.6721, 0.2030, 0.1249], device='cuda:0')
2024-12-07 17:53:08,090 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 382: ref_distribution = tensor([0.6721, 0.2030, 0.1249], device='cuda:0'), new_distribution = tensor([0.6729, 0.2026, 0.1245], device='cuda:0')
2024-12-07 17:53:08,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 383: ref_distribution = tensor([0.6729, 0.2026, 0.1245], device='cuda:0'), new_distribution = tensor([0.6737, 0.2021, 0.1242], device='cuda:0')
2024-12-07 17:53:08,888 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 384: ref_distribution = tensor([0.6737, 0.2021, 0.1242], device='cuda:0'), new_distribution = tensor([0.6745, 0.2016, 0.1238], device='cuda:0')
2024-12-07 17:53:09,216 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 385: ref_distribution = tensor([0.6745, 0.2016, 0.1238], device='cuda:0'), new_distribution = tensor([0.6753, 0.2012, 0.1235], device='cuda:0')
2024-12-07 17:53:09,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 386: ref_distribution = tensor([0.6753, 0.2012, 0.1235], device='cuda:0'), new_distribution = tensor([0.6762, 0.2007, 0.1231], device='cuda:0')
2024-12-07 17:53:10,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 387: ref_distribution = tensor([0.6762, 0.2007, 0.1231], device='cuda:0'), new_distribution = tensor([0.6770, 0.2002, 0.1228], device='cuda:0')
2024-12-07 17:53:10,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 388: ref_distribution = tensor([0.6770, 0.2002, 0.1228], device='cuda:0'), new_distribution = tensor([0.6778, 0.1998, 0.1225], device='cuda:0')
2024-12-07 17:53:10,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 389: ref_distribution = tensor([0.6778, 0.1998, 0.1225], device='cuda:0'), new_distribution = tensor([0.6786, 0.1993, 0.1221], device='cuda:0')
2024-12-07 17:53:11,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 390: ref_distribution = tensor([0.6786, 0.1993, 0.1221], device='cuda:0'), new_distribution = tensor([0.6794, 0.1988, 0.1218], device='cuda:0')
2024-12-07 17:53:11,605 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 391: ref_distribution = tensor([0.6794, 0.1988, 0.1218], device='cuda:0'), new_distribution = tensor([0.6802, 0.1984, 0.1214], device='cuda:0')
2024-12-07 17:53:11,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 392: ref_distribution = tensor([0.6802, 0.1984, 0.1214], device='cuda:0'), new_distribution = tensor([0.6810, 0.1979, 0.1211], device='cuda:0')
2024-12-07 17:53:12,431 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 393: ref_distribution = tensor([0.6810, 0.1979, 0.1211], device='cuda:0'), new_distribution = tensor([0.6818, 0.1975, 0.1207], device='cuda:0')
2024-12-07 17:53:12,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 394: ref_distribution = tensor([0.6818, 0.1975, 0.1207], device='cuda:0'), new_distribution = tensor([0.6826, 0.1970, 0.1204], device='cuda:0')
2024-12-07 17:53:13,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 395: ref_distribution = tensor([0.6826, 0.1970, 0.1204], device='cuda:0'), new_distribution = tensor([0.6834, 0.1965, 0.1201], device='cuda:0')
2024-12-07 17:53:13,557 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 396: ref_distribution = tensor([0.6834, 0.1965, 0.1201], device='cuda:0'), new_distribution = tensor([0.6842, 0.1961, 0.1197], device='cuda:0')
2024-12-07 17:53:13,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 397: ref_distribution = tensor([0.6842, 0.1961, 0.1197], device='cuda:0'), new_distribution = tensor([0.6850, 0.1956, 0.1194], device='cuda:0')
2024-12-07 17:53:14,241 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 398: ref_distribution = tensor([0.6850, 0.1956, 0.1194], device='cuda:0'), new_distribution = tensor([0.6858, 0.1951, 0.1191], device='cuda:0')
2024-12-07 17:53:14,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 399: ref_distribution = tensor([0.6858, 0.1951, 0.1191], device='cuda:0'), new_distribution = tensor([0.6866, 0.1947, 0.1187], device='cuda:0')
2024-12-07 17:53:15,147 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 400: ref_distribution = tensor([0.6866, 0.1947, 0.1187], device='cuda:0'), new_distribution = tensor([0.6874, 0.1942, 0.1184], device='cuda:0')
2024-12-07 17:53:15,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 401: ref_distribution = tensor([0.6874, 0.1942, 0.1184], device='cuda:0'), new_distribution = tensor([0.6882, 0.1938, 0.1181], device='cuda:0')
2024-12-07 17:53:15,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 402: ref_distribution = tensor([0.6882, 0.1938, 0.1181], device='cuda:0'), new_distribution = tensor([0.6890, 0.1933, 0.1177], device='cuda:0')
2024-12-07 17:53:16,324 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 403: ref_distribution = tensor([0.6890, 0.1933, 0.1177], device='cuda:0'), new_distribution = tensor([0.6898, 0.1928, 0.1174], device='cuda:0')
2024-12-07 17:53:16,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 404: ref_distribution = tensor([0.6898, 0.1928, 0.1174], device='cuda:0'), new_distribution = tensor([0.6905, 0.1924, 0.1171], device='cuda:0')
2024-12-07 17:53:16,961 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 405: ref_distribution = tensor([0.6905, 0.1924, 0.1171], device='cuda:0'), new_distribution = tensor([0.6913, 0.1919, 0.1167], device='cuda:0')
2024-12-07 17:53:17,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 406: ref_distribution = tensor([0.6913, 0.1919, 0.1167], device='cuda:0'), new_distribution = tensor([0.6921, 0.1915, 0.1164], device='cuda:0')
2024-12-07 17:53:17,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 407: ref_distribution = tensor([0.6921, 0.1915, 0.1164], device='cuda:0'), new_distribution = tensor([0.6929, 0.1910, 0.1161], device='cuda:0')
2024-12-07 17:53:18,115 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 408: ref_distribution = tensor([0.6929, 0.1910, 0.1161], device='cuda:0'), new_distribution = tensor([0.6937, 0.1906, 0.1157], device='cuda:0')
2024-12-07 17:53:18,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 409: ref_distribution = tensor([0.6937, 0.1906, 0.1157], device='cuda:0'), new_distribution = tensor([0.6945, 0.1901, 0.1154], device='cuda:0')
2024-12-07 17:53:19,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 410: ref_distribution = tensor([0.6945, 0.1901, 0.1154], device='cuda:0'), new_distribution = tensor([0.6953, 0.1896, 0.1151], device='cuda:0')
2024-12-07 17:53:19,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 411: ref_distribution = tensor([0.6953, 0.1896, 0.1151], device='cuda:0'), new_distribution = tensor([0.6960, 0.1892, 0.1148], device='cuda:0')
2024-12-07 17:53:19,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 412: ref_distribution = tensor([0.6960, 0.1892, 0.1148], device='cuda:0'), new_distribution = tensor([0.6968, 0.1887, 0.1144], device='cuda:0')
2024-12-07 17:53:20,215 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 413: ref_distribution = tensor([0.6968, 0.1887, 0.1144], device='cuda:0'), new_distribution = tensor([0.6976, 0.1883, 0.1141], device='cuda:0')
2024-12-07 17:53:20,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 414: ref_distribution = tensor([0.6976, 0.1883, 0.1141], device='cuda:0'), new_distribution = tensor([0.6984, 0.1878, 0.1138], device='cuda:0')
2024-12-07 17:53:20,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 415: ref_distribution = tensor([0.6984, 0.1878, 0.1138], device='cuda:0'), new_distribution = tensor([0.6992, 0.1874, 0.1135], device='cuda:0')
2024-12-07 17:53:21,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 416: ref_distribution = tensor([0.6992, 0.1874, 0.1135], device='cuda:0'), new_distribution = tensor([0.6999, 0.1869, 0.1132], device='cuda:0')
2024-12-07 17:53:21,851 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 417: ref_distribution = tensor([0.6999, 0.1869, 0.1132], device='cuda:0'), new_distribution = tensor([0.7007, 0.1864, 0.1128], device='cuda:0')
2024-12-07 17:53:22,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 418: ref_distribution = tensor([0.7007, 0.1864, 0.1128], device='cuda:0'), new_distribution = tensor([0.7015, 0.1860, 0.1125], device='cuda:0')
2024-12-07 17:53:22,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 419: ref_distribution = tensor([0.7015, 0.1860, 0.1125], device='cuda:0'), new_distribution = tensor([0.7023, 0.1855, 0.1122], device='cuda:0')
2024-12-07 17:53:22,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 420: ref_distribution = tensor([0.7023, 0.1855, 0.1122], device='cuda:0'), new_distribution = tensor([0.7030, 0.1851, 0.1119], device='cuda:0')
2024-12-07 17:53:23,458 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 421: ref_distribution = tensor([0.7030, 0.1851, 0.1119], device='cuda:0'), new_distribution = tensor([0.7038, 0.1846, 0.1116], device='cuda:0')
2024-12-07 17:53:23,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 422: ref_distribution = tensor([0.7038, 0.1846, 0.1116], device='cuda:0'), new_distribution = tensor([0.7046, 0.1842, 0.1113], device='cuda:0')
2024-12-07 17:53:24,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 423: ref_distribution = tensor([0.7046, 0.1842, 0.1113], device='cuda:0'), new_distribution = tensor([0.7053, 0.1837, 0.1109], device='cuda:0')
2024-12-07 17:53:24,606 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 424: ref_distribution = tensor([0.7053, 0.1837, 0.1109], device='cuda:0'), new_distribution = tensor([0.7061, 0.1833, 0.1106], device='cuda:0')
2024-12-07 17:53:25,013 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 425: ref_distribution = tensor([0.7061, 0.1833, 0.1106], device='cuda:0'), new_distribution = tensor([0.7069, 0.1828, 0.1103], device='cuda:0')
2024-12-07 17:53:25,322 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 426: ref_distribution = tensor([0.7069, 0.1828, 0.1103], device='cuda:0'), new_distribution = tensor([0.7076, 0.1824, 0.1100], device='cuda:0')
2024-12-07 17:53:25,758 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 427: ref_distribution = tensor([0.7076, 0.1824, 0.1100], device='cuda:0'), new_distribution = tensor([0.7084, 0.1819, 0.1097], device='cuda:0')
2024-12-07 17:53:26,228 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 428: ref_distribution = tensor([0.7084, 0.1819, 0.1097], device='cuda:0'), new_distribution = tensor([0.7092, 0.1815, 0.1094], device='cuda:0')
2024-12-07 17:53:26,469 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 429: ref_distribution = tensor([0.7092, 0.1815, 0.1094], device='cuda:0'), new_distribution = tensor([0.7099, 0.1810, 0.1091], device='cuda:0')
2024-12-07 17:53:26,875 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 430: ref_distribution = tensor([0.7099, 0.1810, 0.1091], device='cuda:0'), new_distribution = tensor([0.7107, 0.1806, 0.1088], device='cuda:0')
2024-12-07 17:53:27,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 431: ref_distribution = tensor([0.7107, 0.1806, 0.1088], device='cuda:0'), new_distribution = tensor([0.7114, 0.1801, 0.1085], device='cuda:0')
2024-12-07 17:53:27,589 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 432: ref_distribution = tensor([0.7114, 0.1801, 0.1085], device='cuda:0'), new_distribution = tensor([0.7122, 0.1797, 0.1081], device='cuda:0')
2024-12-07 17:53:27,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 433: ref_distribution = tensor([0.7122, 0.1797, 0.1081], device='cuda:0'), new_distribution = tensor([0.7130, 0.1792, 0.1078], device='cuda:0')
2024-12-07 17:53:28,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 434: ref_distribution = tensor([0.7130, 0.1792, 0.1078], device='cuda:0'), new_distribution = tensor([0.7137, 0.1788, 0.1075], device='cuda:0')
2024-12-07 17:53:28,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 435: ref_distribution = tensor([0.7137, 0.1788, 0.1075], device='cuda:0'), new_distribution = tensor([0.7145, 0.1783, 0.1072], device='cuda:0')
2024-12-07 17:53:29,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 436: ref_distribution = tensor([0.7145, 0.1783, 0.1072], device='cuda:0'), new_distribution = tensor([0.7152, 0.1779, 0.1069], device='cuda:0')
2024-12-07 17:53:29,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 437: ref_distribution = tensor([0.7152, 0.1779, 0.1069], device='cuda:0'), new_distribution = tensor([0.7160, 0.1774, 0.1066], device='cuda:0')
2024-12-07 17:53:30,013 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 438: ref_distribution = tensor([0.7160, 0.1774, 0.1066], device='cuda:0'), new_distribution = tensor([0.7167, 0.1770, 0.1063], device='cuda:0')
2024-12-07 17:53:30,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 439: ref_distribution = tensor([0.7167, 0.1770, 0.1063], device='cuda:0'), new_distribution = tensor([0.7175, 0.1765, 0.1060], device='cuda:0')
2024-12-07 17:53:30,738 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 440: ref_distribution = tensor([0.7175, 0.1765, 0.1060], device='cuda:0'), new_distribution = tensor([0.7182, 0.1761, 0.1057], device='cuda:0')
2024-12-07 17:53:31,216 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 441: ref_distribution = tensor([0.7182, 0.1761, 0.1057], device='cuda:0'), new_distribution = tensor([0.7190, 0.1756, 0.1054], device='cuda:0')
2024-12-07 17:53:31,598 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 442: ref_distribution = tensor([0.7190, 0.1756, 0.1054], device='cuda:0'), new_distribution = tensor([0.7197, 0.1752, 0.1051], device='cuda:0')
2024-12-07 17:53:31,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 443: ref_distribution = tensor([0.7197, 0.1752, 0.1051], device='cuda:0'), new_distribution = tensor([0.7205, 0.1747, 0.1048], device='cuda:0')
2024-12-07 17:53:32,309 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 444: ref_distribution = tensor([0.7205, 0.1747, 0.1048], device='cuda:0'), new_distribution = tensor([0.7212, 0.1743, 0.1045], device='cuda:0')
2024-12-07 17:53:32,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 445: ref_distribution = tensor([0.7212, 0.1743, 0.1045], device='cuda:0'), new_distribution = tensor([0.7219, 0.1738, 0.1042], device='cuda:0')
2024-12-07 17:53:32,981 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 446: ref_distribution = tensor([0.7219, 0.1738, 0.1042], device='cuda:0'), new_distribution = tensor([0.7227, 0.1734, 0.1039], device='cuda:0')
2024-12-07 17:53:33,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 447: ref_distribution = tensor([0.7227, 0.1734, 0.1039], device='cuda:0'), new_distribution = tensor([0.7234, 0.1729, 0.1036], device='cuda:0')
2024-12-07 17:53:33,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 448: ref_distribution = tensor([0.7234, 0.1729, 0.1036], device='cuda:0'), new_distribution = tensor([0.7242, 0.1725, 0.1033], device='cuda:0')
2024-12-07 17:53:34,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 449: ref_distribution = tensor([0.7242, 0.1725, 0.1033], device='cuda:0'), new_distribution = tensor([0.7249, 0.1721, 0.1030], device='cuda:0')
2024-12-07 17:53:34,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 450: ref_distribution = tensor([0.7249, 0.1721, 0.1030], device='cuda:0'), new_distribution = tensor([0.7256, 0.1716, 0.1028], device='cuda:0')
2024-12-07 17:53:35,053 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 451: ref_distribution = tensor([0.7256, 0.1716, 0.1028], device='cuda:0'), new_distribution = tensor([0.7264, 0.1712, 0.1025], device='cuda:0')
2024-12-07 17:53:35,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 452: ref_distribution = tensor([0.7264, 0.1712, 0.1025], device='cuda:0'), new_distribution = tensor([0.7271, 0.1707, 0.1022], device='cuda:0')
2024-12-07 17:53:35,697 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 453: ref_distribution = tensor([0.7271, 0.1707, 0.1022], device='cuda:0'), new_distribution = tensor([0.7278, 0.1703, 0.1019], device='cuda:0')
2024-12-07 17:53:36,166 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 454: ref_distribution = tensor([0.7278, 0.1703, 0.1019], device='cuda:0'), new_distribution = tensor([0.7286, 0.1699, 0.1016], device='cuda:0')
2024-12-07 17:53:36,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 455: ref_distribution = tensor([0.7286, 0.1699, 0.1016], device='cuda:0'), new_distribution = tensor([0.7293, 0.1694, 0.1013], device='cuda:0')
2024-12-07 17:53:36,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 456: ref_distribution = tensor([0.7293, 0.1694, 0.1013], device='cuda:0'), new_distribution = tensor([0.7300, 0.1690, 0.1010], device='cuda:0')
2024-12-07 17:53:37,306 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 457: ref_distribution = tensor([0.7300, 0.1690, 0.1010], device='cuda:0'), new_distribution = tensor([0.7307, 0.1685, 0.1007], device='cuda:0')
2024-12-07 17:53:37,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 458: ref_distribution = tensor([0.7307, 0.1685, 0.1007], device='cuda:0'), new_distribution = tensor([0.7315, 0.1681, 0.1004], device='cuda:0')
2024-12-07 17:53:38,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 459: ref_distribution = tensor([0.7315, 0.1681, 0.1004], device='cuda:0'), new_distribution = tensor([0.7322, 0.1677, 0.1002], device='cuda:0')
2024-12-07 17:53:38,464 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 460: ref_distribution = tensor([0.7322, 0.1677, 0.1002], device='cuda:0'), new_distribution = tensor([0.7329, 0.1672, 0.0999], device='cuda:0')
2024-12-07 17:53:38,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 461: ref_distribution = tensor([0.7329, 0.1672, 0.0999], device='cuda:0'), new_distribution = tensor([0.7336, 0.1668, 0.0996], device='cuda:0')
2024-12-07 17:53:39,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 462: ref_distribution = tensor([0.7336, 0.1668, 0.0996], device='cuda:0'), new_distribution = tensor([0.7343, 0.1664, 0.0993], device='cuda:0')
2024-12-07 17:53:39,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 463: ref_distribution = tensor([0.7343, 0.1664, 0.0993], device='cuda:0'), new_distribution = tensor([0.7351, 0.1659, 0.0990], device='cuda:0')
2024-12-07 17:53:40,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 464: ref_distribution = tensor([0.7351, 0.1659, 0.0990], device='cuda:0'), new_distribution = tensor([0.7358, 0.1655, 0.0987], device='cuda:0')
2024-12-07 17:53:40,454 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 465: ref_distribution = tensor([0.7358, 0.1655, 0.0987], device='cuda:0'), new_distribution = tensor([0.7365, 0.1650, 0.0985], device='cuda:0')
2024-12-07 17:53:40,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 466: ref_distribution = tensor([0.7365, 0.1650, 0.0985], device='cuda:0'), new_distribution = tensor([0.7372, 0.1646, 0.0982], device='cuda:0')
2024-12-07 17:53:41,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 467: ref_distribution = tensor([0.7372, 0.1646, 0.0982], device='cuda:0'), new_distribution = tensor([0.7379, 0.1642, 0.0979], device='cuda:0')
2024-12-07 17:53:41,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 468: ref_distribution = tensor([0.7379, 0.1642, 0.0979], device='cuda:0'), new_distribution = tensor([0.7386, 0.1637, 0.0976], device='cuda:0')
2024-12-07 17:53:41,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 469: ref_distribution = tensor([0.7386, 0.1637, 0.0976], device='cuda:0'), new_distribution = tensor([0.7394, 0.1633, 0.0973], device='cuda:0')
2024-12-07 17:53:42,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 470: ref_distribution = tensor([0.7394, 0.1633, 0.0973], device='cuda:0'), new_distribution = tensor([0.7401, 0.1629, 0.0971], device='cuda:0')
2024-12-07 17:53:42,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 471: ref_distribution = tensor([0.7401, 0.1629, 0.0971], device='cuda:0'), new_distribution = tensor([0.7408, 0.1624, 0.0968], device='cuda:0')
2024-12-07 17:53:42,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 472: ref_distribution = tensor([0.7408, 0.1624, 0.0968], device='cuda:0'), new_distribution = tensor([0.7415, 0.1620, 0.0965], device='cuda:0')
2024-12-07 17:53:43,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 473: ref_distribution = tensor([0.7415, 0.1620, 0.0965], device='cuda:0'), new_distribution = tensor([0.7422, 0.1616, 0.0962], device='cuda:0')
2024-12-07 17:53:43,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 474: ref_distribution = tensor([0.7422, 0.1616, 0.0962], device='cuda:0'), new_distribution = tensor([0.7429, 0.1612, 0.0960], device='cuda:0')
2024-12-07 17:53:44,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 475: ref_distribution = tensor([0.7429, 0.1612, 0.0960], device='cuda:0'), new_distribution = tensor([0.7436, 0.1607, 0.0957], device='cuda:0')
2024-12-07 17:53:44,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 476: ref_distribution = tensor([0.7436, 0.1607, 0.0957], device='cuda:0'), new_distribution = tensor([0.7443, 0.1603, 0.0954], device='cuda:0')
2024-12-07 17:53:45,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 477: ref_distribution = tensor([0.7443, 0.1603, 0.0954], device='cuda:0'), new_distribution = tensor([0.7450, 0.1599, 0.0951], device='cuda:0')
2024-12-07 17:53:45,350 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 478: ref_distribution = tensor([0.7450, 0.1599, 0.0951], device='cuda:0'), new_distribution = tensor([0.7457, 0.1594, 0.0949], device='cuda:0')
2024-12-07 17:53:45,646 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 479: ref_distribution = tensor([0.7457, 0.1594, 0.0949], device='cuda:0'), new_distribution = tensor([0.7464, 0.1590, 0.0946], device='cuda:0')
2024-12-07 17:53:46,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 480: ref_distribution = tensor([0.7464, 0.1590, 0.0946], device='cuda:0'), new_distribution = tensor([0.7471, 0.1586, 0.0943], device='cuda:0')
2024-12-07 17:53:46,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 481: ref_distribution = tensor([0.7471, 0.1586, 0.0943], device='cuda:0'), new_distribution = tensor([0.7478, 0.1582, 0.0941], device='cuda:0')
2024-12-07 17:53:46,753 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 482: ref_distribution = tensor([0.7478, 0.1582, 0.0941], device='cuda:0'), new_distribution = tensor([0.7485, 0.1577, 0.0938], device='cuda:0')
2024-12-07 17:53:47,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 483: ref_distribution = tensor([0.7485, 0.1577, 0.0938], device='cuda:0'), new_distribution = tensor([0.7492, 0.1573, 0.0935], device='cuda:0')
2024-12-07 17:53:47,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 484: ref_distribution = tensor([0.7492, 0.1573, 0.0935], device='cuda:0'), new_distribution = tensor([0.7499, 0.1569, 0.0932], device='cuda:0')
2024-12-07 17:53:47,928 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 485: ref_distribution = tensor([0.7499, 0.1569, 0.0932], device='cuda:0'), new_distribution = tensor([0.7506, 0.1565, 0.0930], device='cuda:0')
2024-12-07 17:53:48,380 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 486: ref_distribution = tensor([0.7506, 0.1565, 0.0930], device='cuda:0'), new_distribution = tensor([0.7513, 0.1560, 0.0927], device='cuda:0')
2024-12-07 17:53:48,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 487: ref_distribution = tensor([0.7513, 0.1560, 0.0927], device='cuda:0'), new_distribution = tensor([0.7519, 0.1556, 0.0925], device='cuda:0')
2024-12-07 17:53:49,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 488: ref_distribution = tensor([0.7519, 0.1556, 0.0925], device='cuda:0'), new_distribution = tensor([0.7526, 0.1552, 0.0922], device='cuda:0')
2024-12-07 17:53:49,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 489: ref_distribution = tensor([0.7526, 0.1552, 0.0922], device='cuda:0'), new_distribution = tensor([0.7533, 0.1548, 0.0919], device='cuda:0')
2024-12-07 17:53:49,969 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 490: ref_distribution = tensor([0.7533, 0.1548, 0.0919], device='cuda:0'), new_distribution = tensor([0.7540, 0.1543, 0.0917], device='cuda:0')
2024-12-07 17:53:50,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 491: ref_distribution = tensor([0.7540, 0.1543, 0.0917], device='cuda:0'), new_distribution = tensor([0.7547, 0.1539, 0.0914], device='cuda:0')
2024-12-07 17:53:50,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 492: ref_distribution = tensor([0.7547, 0.1539, 0.0914], device='cuda:0'), new_distribution = tensor([0.7554, 0.1535, 0.0911], device='cuda:0')
2024-12-07 17:53:51,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 493: ref_distribution = tensor([0.7554, 0.1535, 0.0911], device='cuda:0'), new_distribution = tensor([0.7560, 0.1531, 0.0909], device='cuda:0')
2024-12-07 17:53:51,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 494: ref_distribution = tensor([0.7560, 0.1531, 0.0909], device='cuda:0'), new_distribution = tensor([0.7567, 0.1527, 0.0906], device='cuda:0')
2024-12-07 17:53:51,734 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 495: ref_distribution = tensor([0.7567, 0.1527, 0.0906], device='cuda:0'), new_distribution = tensor([0.7574, 0.1522, 0.0904], device='cuda:0')
2024-12-07 17:53:52,214 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 496: ref_distribution = tensor([0.7574, 0.1522, 0.0904], device='cuda:0'), new_distribution = tensor([0.7581, 0.1518, 0.0901], device='cuda:0')
2024-12-07 17:53:52,665 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 497: ref_distribution = tensor([0.7581, 0.1518, 0.0901], device='cuda:0'), new_distribution = tensor([0.7587, 0.1514, 0.0898], device='cuda:0')
2024-12-07 17:53:52,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 498: ref_distribution = tensor([0.7587, 0.1514, 0.0898], device='cuda:0'), new_distribution = tensor([0.7594, 0.1510, 0.0896], device='cuda:0')
2024-12-07 17:53:53,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 499: ref_distribution = tensor([0.7594, 0.1510, 0.0896], device='cuda:0'), new_distribution = tensor([0.7601, 0.1506, 0.0893], device='cuda:0')
2024-12-07 17:53:53,831 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 500: ref_distribution = tensor([0.7601, 0.1506, 0.0893], device='cuda:0'), new_distribution = tensor([0.7608, 0.1502, 0.0891], device='cuda:0')
2024-12-07 17:53:54,129 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 501: ref_distribution = tensor([0.7608, 0.1502, 0.0891], device='cuda:0'), new_distribution = tensor([0.7614, 0.1498, 0.0888], device='cuda:0')
2024-12-07 17:53:54,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 502: ref_distribution = tensor([0.7614, 0.1498, 0.0888], device='cuda:0'), new_distribution = tensor([0.7621, 0.1493, 0.0886], device='cuda:0')
2024-12-07 17:53:54,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 503: ref_distribution = tensor([0.7621, 0.1493, 0.0886], device='cuda:0'), new_distribution = tensor([0.7628, 0.1489, 0.0883], device='cuda:0')
2024-12-07 17:53:55,210 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 504: ref_distribution = tensor([0.7628, 0.1489, 0.0883], device='cuda:0'), new_distribution = tensor([0.7634, 0.1485, 0.0880], device='cuda:0')
2024-12-07 17:53:55,595 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 505: ref_distribution = tensor([0.7634, 0.1485, 0.0880], device='cuda:0'), new_distribution = tensor([0.7641, 0.1481, 0.0878], device='cuda:0')
2024-12-07 17:53:56,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 506: ref_distribution = tensor([0.7641, 0.1481, 0.0878], device='cuda:0'), new_distribution = tensor([0.7648, 0.1477, 0.0875], device='cuda:0')
2024-12-07 17:53:56,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 507: ref_distribution = tensor([0.7648, 0.1477, 0.0875], device='cuda:0'), new_distribution = tensor([0.7654, 0.1473, 0.0873], device='cuda:0')
2024-12-07 17:53:56,725 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 508: ref_distribution = tensor([0.7654, 0.1473, 0.0873], device='cuda:0'), new_distribution = tensor([0.7661, 0.1469, 0.0870], device='cuda:0')
2024-12-07 17:53:57,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 509: ref_distribution = tensor([0.7661, 0.1469, 0.0870], device='cuda:0'), new_distribution = tensor([0.7667, 0.1465, 0.0868], device='cuda:0')
2024-12-07 17:53:57,640 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 510: ref_distribution = tensor([0.7667, 0.1465, 0.0868], device='cuda:0'), new_distribution = tensor([0.7674, 0.1461, 0.0865], device='cuda:0')
2024-12-07 17:53:57,988 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 511: ref_distribution = tensor([0.7674, 0.1461, 0.0865], device='cuda:0'), new_distribution = tensor([0.7681, 0.1456, 0.0863], device='cuda:0')
2024-12-07 17:53:58,342 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 512: ref_distribution = tensor([0.7681, 0.1456, 0.0863], device='cuda:0'), new_distribution = tensor([0.7687, 0.1452, 0.0860], device='cuda:0')
2024-12-07 17:53:58,811 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 513: ref_distribution = tensor([0.7687, 0.1452, 0.0860], device='cuda:0'), new_distribution = tensor([0.7694, 0.1448, 0.0858], device='cuda:0')
2024-12-07 17:53:59,194 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 514: ref_distribution = tensor([0.7694, 0.1448, 0.0858], device='cuda:0'), new_distribution = tensor([0.7700, 0.1444, 0.0856], device='cuda:0')
2024-12-07 17:53:59,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 515: ref_distribution = tensor([0.7700, 0.1444, 0.0856], device='cuda:0'), new_distribution = tensor([0.7707, 0.1440, 0.0853], device='cuda:0')
2024-12-07 17:53:59,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 516: ref_distribution = tensor([0.7707, 0.1440, 0.0853], device='cuda:0'), new_distribution = tensor([0.7713, 0.1436, 0.0851], device='cuda:0')
2024-12-07 17:54:00,157 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 517: ref_distribution = tensor([0.7713, 0.1436, 0.0851], device='cuda:0'), new_distribution = tensor([0.7720, 0.1432, 0.0848], device='cuda:0')
2024-12-07 17:54:00,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 518: ref_distribution = tensor([0.7720, 0.1432, 0.0848], device='cuda:0'), new_distribution = tensor([0.7726, 0.1428, 0.0846], device='cuda:0')
2024-12-07 17:54:01,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 519: ref_distribution = tensor([0.7726, 0.1428, 0.0846], device='cuda:0'), new_distribution = tensor([0.7733, 0.1424, 0.0843], device='cuda:0')
2024-12-07 17:54:01,350 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 520: ref_distribution = tensor([0.7733, 0.1424, 0.0843], device='cuda:0'), new_distribution = tensor([0.7739, 0.1420, 0.0841], device='cuda:0')
2024-12-07 17:54:01,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 521: ref_distribution = tensor([0.7739, 0.1420, 0.0841], device='cuda:0'), new_distribution = tensor([0.7746, 0.1416, 0.0838], device='cuda:0')
2024-12-07 17:54:02,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 522: ref_distribution = tensor([0.7746, 0.1416, 0.0838], device='cuda:0'), new_distribution = tensor([0.7752, 0.1412, 0.0836], device='cuda:0')
2024-12-07 17:54:02,560 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 523: ref_distribution = tensor([0.7752, 0.1412, 0.0836], device='cuda:0'), new_distribution = tensor([0.7758, 0.1408, 0.0834], device='cuda:0')
2024-12-07 17:54:02,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 524: ref_distribution = tensor([0.7758, 0.1408, 0.0834], device='cuda:0'), new_distribution = tensor([0.7765, 0.1404, 0.0831], device='cuda:0')
2024-12-07 17:54:03,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 525: ref_distribution = tensor([0.7765, 0.1404, 0.0831], device='cuda:0'), new_distribution = tensor([0.7771, 0.1400, 0.0829], device='cuda:0')
2024-12-07 17:54:03,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 526: ref_distribution = tensor([0.7771, 0.1400, 0.0829], device='cuda:0'), new_distribution = tensor([0.7778, 0.1396, 0.0826], device='cuda:0')
2024-12-07 17:54:03,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 527: ref_distribution = tensor([0.7778, 0.1396, 0.0826], device='cuda:0'), new_distribution = tensor([0.7784, 0.1392, 0.0824], device='cuda:0')
2024-12-07 17:54:04,434 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 528: ref_distribution = tensor([0.7784, 0.1392, 0.0824], device='cuda:0'), new_distribution = tensor([0.7790, 0.1388, 0.0822], device='cuda:0')
2024-12-07 17:54:04,899 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 529: ref_distribution = tensor([0.7790, 0.1388, 0.0822], device='cuda:0'), new_distribution = tensor([0.7797, 0.1384, 0.0819], device='cuda:0')
2024-12-07 17:54:05,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 530: ref_distribution = tensor([0.7797, 0.1384, 0.0819], device='cuda:0'), new_distribution = tensor([0.7803, 0.1380, 0.0817], device='cuda:0')
2024-12-07 17:54:05,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 531: ref_distribution = tensor([0.7803, 0.1380, 0.0817], device='cuda:0'), new_distribution = tensor([0.7809, 0.1376, 0.0815], device='cuda:0')
2024-12-07 17:54:05,491 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 532: ref_distribution = tensor([0.7809, 0.1376, 0.0815], device='cuda:0'), new_distribution = tensor([0.7815, 0.1372, 0.0812], device='cuda:0')
2024-12-07 17:54:05,847 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 533: ref_distribution = tensor([0.7815, 0.1372, 0.0812], device='cuda:0'), new_distribution = tensor([0.7822, 0.1368, 0.0810], device='cuda:0')
2024-12-07 17:54:06,255 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 534: ref_distribution = tensor([0.7822, 0.1368, 0.0810], device='cuda:0'), new_distribution = tensor([0.7828, 0.1364, 0.0808], device='cuda:0')
2024-12-07 17:54:06,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 535: ref_distribution = tensor([0.7828, 0.1364, 0.0808], device='cuda:0'), new_distribution = tensor([0.7834, 0.1360, 0.0805], device='cuda:0')
2024-12-07 17:54:07,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 536: ref_distribution = tensor([0.7834, 0.1360, 0.0805], device='cuda:0'), new_distribution = tensor([0.7840, 0.1357, 0.0803], device='cuda:0')
2024-12-07 17:54:07,418 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 537: ref_distribution = tensor([0.7840, 0.1357, 0.0803], device='cuda:0'), new_distribution = tensor([0.7847, 0.1353, 0.0801], device='cuda:0')
2024-12-07 17:54:07,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 538: ref_distribution = tensor([0.7847, 0.1353, 0.0801], device='cuda:0'), new_distribution = tensor([0.7853, 0.1349, 0.0798], device='cuda:0')
2024-12-07 17:54:08,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 539: ref_distribution = tensor([0.7853, 0.1349, 0.0798], device='cuda:0'), new_distribution = tensor([0.7859, 0.1345, 0.0796], device='cuda:0')
2024-12-07 17:54:08,553 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 540: ref_distribution = tensor([0.7859, 0.1345, 0.0796], device='cuda:0'), new_distribution = tensor([0.7865, 0.1341, 0.0794], device='cuda:0')
2024-12-07 17:54:09,043 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 541: ref_distribution = tensor([0.7865, 0.1341, 0.0794], device='cuda:0'), new_distribution = tensor([0.7871, 0.1337, 0.0792], device='cuda:0')
2024-12-07 17:54:09,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 542: ref_distribution = tensor([0.7871, 0.1337, 0.0792], device='cuda:0'), new_distribution = tensor([0.7878, 0.1333, 0.0789], device='cuda:0')
2024-12-07 17:54:09,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 543: ref_distribution = tensor([0.7878, 0.1333, 0.0789], device='cuda:0'), new_distribution = tensor([0.7884, 0.1329, 0.0787], device='cuda:0')
2024-12-07 17:54:10,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 544: ref_distribution = tensor([0.7884, 0.1329, 0.0787], device='cuda:0'), new_distribution = tensor([0.7890, 0.1325, 0.0785], device='cuda:0')
2024-12-07 17:54:10,646 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 545: ref_distribution = tensor([0.7890, 0.1325, 0.0785], device='cuda:0'), new_distribution = tensor([0.7896, 0.1322, 0.0782], device='cuda:0')
2024-12-07 17:54:10,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 546: ref_distribution = tensor([0.7896, 0.1322, 0.0782], device='cuda:0'), new_distribution = tensor([0.7902, 0.1318, 0.0780], device='cuda:0')
2024-12-07 17:54:11,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 547: ref_distribution = tensor([0.7902, 0.1318, 0.0780], device='cuda:0'), new_distribution = tensor([0.7908, 0.1314, 0.0778], device='cuda:0')
2024-12-07 17:54:11,772 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 548: ref_distribution = tensor([0.7908, 0.1314, 0.0778], device='cuda:0'), new_distribution = tensor([0.7914, 0.1310, 0.0776], device='cuda:0')
2024-12-07 17:54:11,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 549: ref_distribution = tensor([0.7914, 0.1310, 0.0776], device='cuda:0'), new_distribution = tensor([0.7920, 0.1306, 0.0773], device='cuda:0')
2024-12-07 17:54:12,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 550: ref_distribution = tensor([0.7920, 0.1306, 0.0773], device='cuda:0'), new_distribution = tensor([0.7926, 0.1302, 0.0771], device='cuda:0')
2024-12-07 17:54:12,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 551: ref_distribution = tensor([0.7926, 0.1302, 0.0771], device='cuda:0'), new_distribution = tensor([0.7932, 0.1299, 0.0769], device='cuda:0')
2024-12-07 17:54:13,167 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 552: ref_distribution = tensor([0.7932, 0.1299, 0.0769], device='cuda:0'), new_distribution = tensor([0.7938, 0.1295, 0.0767], device='cuda:0')
2024-12-07 17:54:13,531 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 553: ref_distribution = tensor([0.7938, 0.1295, 0.0767], device='cuda:0'), new_distribution = tensor([0.7944, 0.1291, 0.0765], device='cuda:0')
2024-12-07 17:54:13,993 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 554: ref_distribution = tensor([0.7944, 0.1291, 0.0765], device='cuda:0'), new_distribution = tensor([0.7950, 0.1287, 0.0762], device='cuda:0')
2024-12-07 17:54:14,351 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 555: ref_distribution = tensor([0.7950, 0.1287, 0.0762], device='cuda:0'), new_distribution = tensor([0.7956, 0.1283, 0.0760], device='cuda:0')
2024-12-07 17:54:14,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 556: ref_distribution = tensor([0.7956, 0.1283, 0.0760], device='cuda:0'), new_distribution = tensor([0.7962, 0.1280, 0.0758], device='cuda:0')
2024-12-07 17:54:15,090 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 557: ref_distribution = tensor([0.7962, 0.1280, 0.0758], device='cuda:0'), new_distribution = tensor([0.7968, 0.1276, 0.0756], device='cuda:0')
2024-12-07 17:54:15,404 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 558: ref_distribution = tensor([0.7968, 0.1276, 0.0756], device='cuda:0'), new_distribution = tensor([0.7974, 0.1272, 0.0754], device='cuda:0')
2024-12-07 17:54:15,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 559: ref_distribution = tensor([0.7974, 0.1272, 0.0754], device='cuda:0'), new_distribution = tensor([0.7980, 0.1268, 0.0751], device='cuda:0')
2024-12-07 17:54:16,230 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 560: ref_distribution = tensor([0.7980, 0.1268, 0.0751], device='cuda:0'), new_distribution = tensor([0.7986, 0.1265, 0.0749], device='cuda:0')
2024-12-07 17:54:16,690 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 561: ref_distribution = tensor([0.7986, 0.1265, 0.0749], device='cuda:0'), new_distribution = tensor([0.7992, 0.1261, 0.0747], device='cuda:0')
2024-12-07 17:54:17,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 562: ref_distribution = tensor([0.7992, 0.1261, 0.0747], device='cuda:0'), new_distribution = tensor([0.7998, 0.1257, 0.0745], device='cuda:0')
2024-12-07 17:54:17,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 563: ref_distribution = tensor([0.7998, 0.1257, 0.0745], device='cuda:0'), new_distribution = tensor([0.8004, 0.1253, 0.0743], device='cuda:0')
2024-12-07 17:54:17,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 564: ref_distribution = tensor([0.8004, 0.1253, 0.0743], device='cuda:0'), new_distribution = tensor([0.8010, 0.1250, 0.0741], device='cuda:0')
2024-12-07 17:54:18,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 565: ref_distribution = tensor([0.8010, 0.1250, 0.0741], device='cuda:0'), new_distribution = tensor([0.8016, 0.1246, 0.0738], device='cuda:0')
2024-12-07 17:54:18,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 566: ref_distribution = tensor([0.8016, 0.1246, 0.0738], device='cuda:0'), new_distribution = tensor([0.8021, 0.1242, 0.0736], device='cuda:0')
2024-12-07 17:54:18,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 567: ref_distribution = tensor([0.8021, 0.1242, 0.0736], device='cuda:0'), new_distribution = tensor([0.8027, 0.1239, 0.0734], device='cuda:0')
2024-12-07 17:54:19,489 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 568: ref_distribution = tensor([0.8027, 0.1239, 0.0734], device='cuda:0'), new_distribution = tensor([0.8033, 0.1235, 0.0732], device='cuda:0')
2024-12-07 17:54:19,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 569: ref_distribution = tensor([0.8033, 0.1235, 0.0732], device='cuda:0'), new_distribution = tensor([0.8039, 0.1231, 0.0730], device='cuda:0')
2024-12-07 17:54:20,121 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 570: ref_distribution = tensor([0.8039, 0.1231, 0.0730], device='cuda:0'), new_distribution = tensor([0.8045, 0.1228, 0.0728], device='cuda:0')
2024-12-07 17:54:20,605 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 571: ref_distribution = tensor([0.8045, 0.1228, 0.0728], device='cuda:0'), new_distribution = tensor([0.8050, 0.1224, 0.0726], device='cuda:0')
2024-12-07 17:54:20,876 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 572: ref_distribution = tensor([0.8050, 0.1224, 0.0726], device='cuda:0'), new_distribution = tensor([0.8056, 0.1220, 0.0724], device='cuda:0')
2024-12-07 17:54:21,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 573: ref_distribution = tensor([0.8056, 0.1220, 0.0724], device='cuda:0'), new_distribution = tensor([0.8062, 0.1217, 0.0722], device='cuda:0')
2024-12-07 17:54:21,725 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 574: ref_distribution = tensor([0.8062, 0.1217, 0.0722], device='cuda:0'), new_distribution = tensor([0.8068, 0.1213, 0.0719], device='cuda:0')
2024-12-07 17:54:22,007 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 575: ref_distribution = tensor([0.8068, 0.1213, 0.0719], device='cuda:0'), new_distribution = tensor([0.8073, 0.1209, 0.0717], device='cuda:0')
2024-12-07 17:54:22,375 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 576: ref_distribution = tensor([0.8073, 0.1209, 0.0717], device='cuda:0'), new_distribution = tensor([0.8079, 0.1206, 0.0715], device='cuda:0')
2024-12-07 17:54:22,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 577: ref_distribution = tensor([0.8079, 0.1206, 0.0715], device='cuda:0'), new_distribution = tensor([0.8085, 0.1202, 0.0713], device='cuda:0')
2024-12-07 17:54:23,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 578: ref_distribution = tensor([0.8085, 0.1202, 0.0713], device='cuda:0'), new_distribution = tensor([0.8090, 0.1198, 0.0711], device='cuda:0')
2024-12-07 17:54:23,480 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 579: ref_distribution = tensor([0.8090, 0.1198, 0.0711], device='cuda:0'), new_distribution = tensor([0.8096, 0.1195, 0.0709], device='cuda:0')
2024-12-07 17:54:23,949 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 580: ref_distribution = tensor([0.8096, 0.1195, 0.0709], device='cuda:0'), new_distribution = tensor([0.8102, 0.1191, 0.0707], device='cuda:0')
2024-12-07 17:54:24,262 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 581: ref_distribution = tensor([0.8102, 0.1191, 0.0707], device='cuda:0'), new_distribution = tensor([0.8107, 0.1188, 0.0705], device='cuda:0')
2024-12-07 17:54:24,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 582: ref_distribution = tensor([0.8107, 0.1188, 0.0705], device='cuda:0'), new_distribution = tensor([0.8113, 0.1184, 0.0703], device='cuda:0')
2024-12-07 17:54:25,086 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 583: ref_distribution = tensor([0.8113, 0.1184, 0.0703], device='cuda:0'), new_distribution = tensor([0.8119, 0.1180, 0.0701], device='cuda:0')
2024-12-07 17:54:25,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 584: ref_distribution = tensor([0.8119, 0.1180, 0.0701], device='cuda:0'), new_distribution = tensor([0.8124, 0.1177, 0.0699], device='cuda:0')
2024-12-07 17:54:25,891 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 585: ref_distribution = tensor([0.8124, 0.1177, 0.0699], device='cuda:0'), new_distribution = tensor([0.8130, 0.1173, 0.0697], device='cuda:0')
2024-12-07 17:54:26,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 586: ref_distribution = tensor([0.8130, 0.1173, 0.0697], device='cuda:0'), new_distribution = tensor([0.8135, 0.1170, 0.0695], device='cuda:0')
2024-12-07 17:54:26,705 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 587: ref_distribution = tensor([0.8135, 0.1170, 0.0695], device='cuda:0'), new_distribution = tensor([0.8141, 0.1166, 0.0693], device='cuda:0')
2024-12-07 17:54:27,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 588: ref_distribution = tensor([0.8141, 0.1166, 0.0693], device='cuda:0'), new_distribution = tensor([0.8146, 0.1163, 0.0691], device='cuda:0')
2024-12-07 17:54:27,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 589: ref_distribution = tensor([0.8146, 0.1163, 0.0691], device='cuda:0'), new_distribution = tensor([0.8152, 0.1159, 0.0689], device='cuda:0')
2024-12-07 17:54:27,858 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 590: ref_distribution = tensor([0.8152, 0.1159, 0.0689], device='cuda:0'), new_distribution = tensor([0.8158, 0.1156, 0.0687], device='cuda:0')
2024-12-07 17:54:28,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 591: ref_distribution = tensor([0.8158, 0.1156, 0.0687], device='cuda:0'), new_distribution = tensor([0.8163, 0.1152, 0.0685], device='cuda:0')
2024-12-07 17:54:28,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 592: ref_distribution = tensor([0.8163, 0.1152, 0.0685], device='cuda:0'), new_distribution = tensor([0.8169, 0.1149, 0.0683], device='cuda:0')
2024-12-07 17:54:28,971 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 593: ref_distribution = tensor([0.8169, 0.1149, 0.0683], device='cuda:0'), new_distribution = tensor([0.8174, 0.1145, 0.0681], device='cuda:0')
2024-12-07 17:54:29,434 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 594: ref_distribution = tensor([0.8174, 0.1145, 0.0681], device='cuda:0'), new_distribution = tensor([0.8179, 0.1142, 0.0679], device='cuda:0')
2024-12-07 17:54:29,690 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 595: ref_distribution = tensor([0.8179, 0.1142, 0.0679], device='cuda:0'), new_distribution = tensor([0.8185, 0.1138, 0.0677], device='cuda:0')
2024-12-07 17:54:30,086 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 596: ref_distribution = tensor([0.8185, 0.1138, 0.0677], device='cuda:0'), new_distribution = tensor([0.8190, 0.1135, 0.0675], device='cuda:0')
2024-12-07 17:54:30,557 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 597: ref_distribution = tensor([0.8190, 0.1135, 0.0675], device='cuda:0'), new_distribution = tensor([0.8196, 0.1131, 0.0673], device='cuda:0')
2024-12-07 17:54:30,847 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 598: ref_distribution = tensor([0.8196, 0.1131, 0.0673], device='cuda:0'), new_distribution = tensor([0.8201, 0.1128, 0.0671], device='cuda:0')
2024-12-07 17:54:31,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 599: ref_distribution = tensor([0.8201, 0.1128, 0.0671], device='cuda:0'), new_distribution = tensor([0.8207, 0.1124, 0.0669], device='cuda:0')
2024-12-07 17:54:31,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 600: ref_distribution = tensor([0.8207, 0.1124, 0.0669], device='cuda:0'), new_distribution = tensor([0.8212, 0.1121, 0.0667], device='cuda:0')
2024-12-07 17:54:31,906 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 601: ref_distribution = tensor([0.8212, 0.1121, 0.0667], device='cuda:0'), new_distribution = tensor([0.8217, 0.1117, 0.0665], device='cuda:0')
2024-12-07 17:54:32,291 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 602: ref_distribution = tensor([0.8217, 0.1117, 0.0665], device='cuda:0'), new_distribution = tensor([0.8223, 0.1114, 0.0663], device='cuda:0')
2024-12-07 17:54:32,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 603: ref_distribution = tensor([0.8223, 0.1114, 0.0663], device='cuda:0'), new_distribution = tensor([0.8228, 0.1110, 0.0661], device='cuda:0')
2024-12-07 17:54:33,053 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 604: ref_distribution = tensor([0.8228, 0.1110, 0.0661], device='cuda:0'), new_distribution = tensor([0.8233, 0.1107, 0.0659], device='cuda:0')
2024-12-07 17:54:33,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 605: ref_distribution = tensor([0.8233, 0.1107, 0.0659], device='cuda:0'), new_distribution = tensor([0.8239, 0.1104, 0.0658], device='cuda:0')
2024-12-07 17:54:33,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 606: ref_distribution = tensor([0.8239, 0.1104, 0.0658], device='cuda:0'), new_distribution = tensor([0.8244, 0.1100, 0.0656], device='cuda:0')
2024-12-07 17:54:34,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 607: ref_distribution = tensor([0.8244, 0.1100, 0.0656], device='cuda:0'), new_distribution = tensor([0.8249, 0.1097, 0.0654], device='cuda:0')
2024-12-07 17:54:34,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 608: ref_distribution = tensor([0.8249, 0.1097, 0.0654], device='cuda:0'), new_distribution = tensor([0.8255, 0.1093, 0.0652], device='cuda:0')
2024-12-07 17:54:34,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 609: ref_distribution = tensor([0.8255, 0.1093, 0.0652], device='cuda:0'), new_distribution = tensor([0.8260, 0.1090, 0.0650], device='cuda:0')
2024-12-07 17:54:35,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 610: ref_distribution = tensor([0.8260, 0.1090, 0.0650], device='cuda:0'), new_distribution = tensor([0.8265, 0.1087, 0.0648], device='cuda:0')
2024-12-07 17:54:35,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 611: ref_distribution = tensor([0.8265, 0.1087, 0.0648], device='cuda:0'), new_distribution = tensor([0.8271, 0.1083, 0.0646], device='cuda:0')
2024-12-07 17:54:36,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 612: ref_distribution = tensor([0.8271, 0.1083, 0.0646], device='cuda:0'), new_distribution = tensor([0.8276, 0.1080, 0.0644], device='cuda:0')
2024-12-07 17:54:36,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 613: ref_distribution = tensor([0.8276, 0.1080, 0.0644], device='cuda:0'), new_distribution = tensor([0.8281, 0.1077, 0.0642], device='cuda:0')
2024-12-07 17:54:36,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 614: ref_distribution = tensor([0.8281, 0.1077, 0.0642], device='cuda:0'), new_distribution = tensor([0.8286, 0.1073, 0.0641], device='cuda:0')
2024-12-07 17:54:37,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 615: ref_distribution = tensor([0.8286, 0.1073, 0.0641], device='cuda:0'), new_distribution = tensor([0.8291, 0.1070, 0.0639], device='cuda:0')
2024-12-07 17:54:37,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 616: ref_distribution = tensor([0.8291, 0.1070, 0.0639], device='cuda:0'), new_distribution = tensor([0.8297, 0.1067, 0.0637], device='cuda:0')
2024-12-07 17:54:37,968 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 617: ref_distribution = tensor([0.8297, 0.1067, 0.0637], device='cuda:0'), new_distribution = tensor([0.8302, 0.1063, 0.0635], device='cuda:0')
2024-12-07 17:54:38,381 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 618: ref_distribution = tensor([0.8302, 0.1063, 0.0635], device='cuda:0'), new_distribution = tensor([0.8307, 0.1060, 0.0633], device='cuda:0')
2024-12-07 17:54:38,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 619: ref_distribution = tensor([0.8307, 0.1060, 0.0633], device='cuda:0'), new_distribution = tensor([0.8312, 0.1057, 0.0631], device='cuda:0')
2024-12-07 17:54:39,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 620: ref_distribution = tensor([0.8312, 0.1057, 0.0631], device='cuda:0'), new_distribution = tensor([0.8317, 0.1053, 0.0629], device='cuda:0')
2024-12-07 17:54:39,502 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 621: ref_distribution = tensor([0.8317, 0.1053, 0.0629], device='cuda:0'), new_distribution = tensor([0.8322, 0.1050, 0.0628], device='cuda:0')
2024-12-07 17:54:39,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 622: ref_distribution = tensor([0.8322, 0.1050, 0.0628], device='cuda:0'), new_distribution = tensor([0.8327, 0.1047, 0.0626], device='cuda:0')
2024-12-07 17:54:40,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 623: ref_distribution = tensor([0.8327, 0.1047, 0.0626], device='cuda:0'), new_distribution = tensor([0.8333, 0.1043, 0.0624], device='cuda:0')
2024-12-07 17:54:40,749 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 624: ref_distribution = tensor([0.8333, 0.1043, 0.0624], device='cuda:0'), new_distribution = tensor([0.8338, 0.1040, 0.0622], device='cuda:0')
2024-12-07 17:54:41,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 625: ref_distribution = tensor([0.8338, 0.1040, 0.0622], device='cuda:0'), new_distribution = tensor([0.8343, 0.1037, 0.0620], device='cuda:0')
2024-12-07 17:54:41,586 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 626: ref_distribution = tensor([0.8343, 0.1037, 0.0620], device='cuda:0'), new_distribution = tensor([0.8348, 0.1034, 0.0619], device='cuda:0')
2024-12-07 17:54:41,901 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 627: ref_distribution = tensor([0.8348, 0.1034, 0.0619], device='cuda:0'), new_distribution = tensor([0.8353, 0.1030, 0.0617], device='cuda:0')
2024-12-07 17:54:42,271 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 628: ref_distribution = tensor([0.8353, 0.1030, 0.0617], device='cuda:0'), new_distribution = tensor([0.8358, 0.1027, 0.0615], device='cuda:0')
2024-12-07 17:54:42,728 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 629: ref_distribution = tensor([0.8358, 0.1027, 0.0615], device='cuda:0'), new_distribution = tensor([0.8363, 0.1024, 0.0613], device='cuda:0')
2024-12-07 17:54:43,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 630: ref_distribution = tensor([0.8363, 0.1024, 0.0613], device='cuda:0'), new_distribution = tensor([0.8368, 0.1021, 0.0611], device='cuda:0')
2024-12-07 17:54:43,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 631: ref_distribution = tensor([0.8368, 0.1021, 0.0611], device='cuda:0'), new_distribution = tensor([0.8373, 0.1017, 0.0610], device='cuda:0')
2024-12-07 17:54:43,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 632: ref_distribution = tensor([0.8373, 0.1017, 0.0610], device='cuda:0'), new_distribution = tensor([0.8378, 0.1014, 0.0608], device='cuda:0')
2024-12-07 17:54:44,332 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 633: ref_distribution = tensor([0.8378, 0.1014, 0.0608], device='cuda:0'), new_distribution = tensor([0.8383, 0.1011, 0.0606], device='cuda:0')
2024-12-07 17:54:44,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 634: ref_distribution = tensor([0.8383, 0.1011, 0.0606], device='cuda:0'), new_distribution = tensor([0.8388, 0.1008, 0.0604], device='cuda:0')
2024-12-07 17:54:44,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 635: ref_distribution = tensor([0.8388, 0.1008, 0.0604], device='cuda:0'), new_distribution = tensor([0.8393, 0.1005, 0.0603], device='cuda:0')
2024-12-07 17:54:45,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 636: ref_distribution = tensor([0.8393, 0.1005, 0.0603], device='cuda:0'), new_distribution = tensor([0.8398, 0.1002, 0.0601], device='cuda:0')
2024-12-07 17:54:45,754 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 637: ref_distribution = tensor([0.8398, 0.1002, 0.0601], device='cuda:0'), new_distribution = tensor([0.8403, 0.0998, 0.0599], device='cuda:0')
2024-12-07 17:54:46,093 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 638: ref_distribution = tensor([0.8403, 0.0998, 0.0599], device='cuda:0'), new_distribution = tensor([0.8408, 0.0995, 0.0597], device='cuda:0')
2024-12-07 17:54:46,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 639: ref_distribution = tensor([0.8408, 0.0995, 0.0597], device='cuda:0'), new_distribution = tensor([0.8412, 0.0992, 0.0596], device='cuda:0')
2024-12-07 17:54:46,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 640: ref_distribution = tensor([0.8412, 0.0992, 0.0596], device='cuda:0'), new_distribution = tensor([0.8417, 0.0989, 0.0594], device='cuda:0')
2024-12-07 17:54:47,205 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 641: ref_distribution = tensor([0.8417, 0.0989, 0.0594], device='cuda:0'), new_distribution = tensor([0.8422, 0.0986, 0.0592], device='cuda:0')
2024-12-07 17:54:47,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 642: ref_distribution = tensor([0.8422, 0.0986, 0.0592], device='cuda:0'), new_distribution = tensor([0.8427, 0.0983, 0.0590], device='cuda:0')
2024-12-07 17:54:48,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 643: ref_distribution = tensor([0.8427, 0.0983, 0.0590], device='cuda:0'), new_distribution = tensor([0.8432, 0.0979, 0.0589], device='cuda:0')
2024-12-07 17:54:48,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 644: ref_distribution = tensor([0.8432, 0.0979, 0.0589], device='cuda:0'), new_distribution = tensor([0.8437, 0.0976, 0.0587], device='cuda:0')
2024-12-07 17:54:48,845 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 645: ref_distribution = tensor([0.8437, 0.0976, 0.0587], device='cuda:0'), new_distribution = tensor([0.8442, 0.0973, 0.0585], device='cuda:0')
2024-12-07 17:54:49,327 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 646: ref_distribution = tensor([0.8442, 0.0973, 0.0585], device='cuda:0'), new_distribution = tensor([0.8446, 0.0970, 0.0584], device='cuda:0')
2024-12-07 17:54:49,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 647: ref_distribution = tensor([0.8446, 0.0970, 0.0584], device='cuda:0'), new_distribution = tensor([0.8451, 0.0967, 0.0582], device='cuda:0')
2024-12-07 17:54:49,955 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 648: ref_distribution = tensor([0.8451, 0.0967, 0.0582], device='cuda:0'), new_distribution = tensor([0.8456, 0.0964, 0.0580], device='cuda:0')
2024-12-07 17:54:50,416 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 649: ref_distribution = tensor([0.8456, 0.0964, 0.0580], device='cuda:0'), new_distribution = tensor([0.8461, 0.0961, 0.0578], device='cuda:0')
2024-12-07 17:54:50,682 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 650: ref_distribution = tensor([0.8461, 0.0961, 0.0578], device='cuda:0'), new_distribution = tensor([0.8465, 0.0958, 0.0577], device='cuda:0')
2024-12-07 17:54:51,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 651: ref_distribution = tensor([0.8465, 0.0958, 0.0577], device='cuda:0'), new_distribution = tensor([0.8470, 0.0955, 0.0575], device='cuda:0')
2024-12-07 17:54:51,540 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 652: ref_distribution = tensor([0.8470, 0.0955, 0.0575], device='cuda:0'), new_distribution = tensor([0.8475, 0.0952, 0.0573], device='cuda:0')
2024-12-07 17:54:51,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 653: ref_distribution = tensor([0.8475, 0.0952, 0.0573], device='cuda:0'), new_distribution = tensor([0.8480, 0.0949, 0.0572], device='cuda:0')
2024-12-07 17:54:52,224 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 654: ref_distribution = tensor([0.8480, 0.0949, 0.0572], device='cuda:0'), new_distribution = tensor([0.8484, 0.0946, 0.0570], device='cuda:0')
2024-12-07 17:54:52,680 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 655: ref_distribution = tensor([0.8484, 0.0946, 0.0570], device='cuda:0'), new_distribution = tensor([0.8489, 0.0943, 0.0568], device='cuda:0')
2024-12-07 17:54:53,143 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 656: ref_distribution = tensor([0.8489, 0.0943, 0.0568], device='cuda:0'), new_distribution = tensor([0.8494, 0.0939, 0.0567], device='cuda:0')
2024-12-07 17:54:53,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 657: ref_distribution = tensor([0.8494, 0.0939, 0.0567], device='cuda:0'), new_distribution = tensor([0.8498, 0.0936, 0.0565], device='cuda:0')
2024-12-07 17:54:53,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 658: ref_distribution = tensor([0.8498, 0.0936, 0.0565], device='cuda:0'), new_distribution = tensor([0.8503, 0.0933, 0.0563], device='cuda:0')
2024-12-07 17:54:54,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 659: ref_distribution = tensor([0.8503, 0.0933, 0.0563], device='cuda:0'), new_distribution = tensor([0.8508, 0.0930, 0.0562], device='cuda:0')
2024-12-07 17:54:54,597 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 660: ref_distribution = tensor([0.8508, 0.0930, 0.0562], device='cuda:0'), new_distribution = tensor([0.8512, 0.0927, 0.0560], device='cuda:0')
2024-12-07 17:54:54,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 661: ref_distribution = tensor([0.8512, 0.0927, 0.0560], device='cuda:0'), new_distribution = tensor([0.8517, 0.0924, 0.0559], device='cuda:0')
2024-12-07 17:54:55,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 662: ref_distribution = tensor([0.8517, 0.0924, 0.0559], device='cuda:0'), new_distribution = tensor([0.8522, 0.0921, 0.0557], device='cuda:0')
2024-12-07 17:54:55,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 663: ref_distribution = tensor([0.8522, 0.0921, 0.0557], device='cuda:0'), new_distribution = tensor([0.8526, 0.0918, 0.0555], device='cuda:0')
2024-12-07 17:54:56,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 664: ref_distribution = tensor([0.8526, 0.0918, 0.0555], device='cuda:0'), new_distribution = tensor([0.8531, 0.0915, 0.0554], device='cuda:0')
2024-12-07 17:54:56,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 665: ref_distribution = tensor([0.8531, 0.0915, 0.0554], device='cuda:0'), new_distribution = tensor([0.8535, 0.0913, 0.0552], device='cuda:0')
2024-12-07 17:54:56,940 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 666: ref_distribution = tensor([0.8535, 0.0913, 0.0552], device='cuda:0'), new_distribution = tensor([0.8540, 0.0910, 0.0550], device='cuda:0')
2024-12-07 17:54:57,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 667: ref_distribution = tensor([0.8540, 0.0910, 0.0550], device='cuda:0'), new_distribution = tensor([0.8545, 0.0907, 0.0549], device='cuda:0')
2024-12-07 17:54:57,643 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 668: ref_distribution = tensor([0.8545, 0.0907, 0.0549], device='cuda:0'), new_distribution = tensor([0.8549, 0.0904, 0.0547], device='cuda:0')
2024-12-07 17:54:58,003 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 669: ref_distribution = tensor([0.8549, 0.0904, 0.0547], device='cuda:0'), new_distribution = tensor([0.8554, 0.0901, 0.0546], device='cuda:0')
2024-12-07 17:54:58,313 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 670: ref_distribution = tensor([0.8554, 0.0901, 0.0546], device='cuda:0'), new_distribution = tensor([0.8558, 0.0898, 0.0544], device='cuda:0')
2024-12-07 17:54:58,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 671: ref_distribution = tensor([0.8558, 0.0898, 0.0544], device='cuda:0'), new_distribution = tensor([0.8563, 0.0895, 0.0542], device='cuda:0')
2024-12-07 17:54:59,260 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 672: ref_distribution = tensor([0.8563, 0.0895, 0.0542], device='cuda:0'), new_distribution = tensor([0.8567, 0.0892, 0.0541], device='cuda:0')
2024-12-07 17:54:59,534 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 673: ref_distribution = tensor([0.8567, 0.0892, 0.0541], device='cuda:0'), new_distribution = tensor([0.8572, 0.0889, 0.0539], device='cuda:0')
2024-12-07 17:54:59,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 674: ref_distribution = tensor([0.8572, 0.0889, 0.0539], device='cuda:0'), new_distribution = tensor([0.8576, 0.0886, 0.0538], device='cuda:0')
2024-12-07 17:55:00,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 675: ref_distribution = tensor([0.8576, 0.0886, 0.0538], device='cuda:0'), new_distribution = tensor([0.8581, 0.0883, 0.0536], device='cuda:0')
2024-12-07 17:55:00,744 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 676: ref_distribution = tensor([0.8581, 0.0883, 0.0536], device='cuda:0'), new_distribution = tensor([0.8585, 0.0880, 0.0535], device='cuda:0')
2024-12-07 17:55:01,093 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 677: ref_distribution = tensor([0.8585, 0.0880, 0.0535], device='cuda:0'), new_distribution = tensor([0.8589, 0.0878, 0.0533], device='cuda:0')
2024-12-07 17:55:01,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 678: ref_distribution = tensor([0.8589, 0.0878, 0.0533], device='cuda:0'), new_distribution = tensor([0.8594, 0.0875, 0.0531], device='cuda:0')
2024-12-07 17:55:02,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 679: ref_distribution = tensor([0.8594, 0.0875, 0.0531], device='cuda:0'), new_distribution = tensor([0.8598, 0.0872, 0.0530], device='cuda:0')
2024-12-07 17:55:02,435 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 680: ref_distribution = tensor([0.8598, 0.0872, 0.0530], device='cuda:0'), new_distribution = tensor([0.8603, 0.0869, 0.0528], device='cuda:0')
2024-12-07 17:55:02,718 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 681: ref_distribution = tensor([0.8603, 0.0869, 0.0528], device='cuda:0'), new_distribution = tensor([0.8607, 0.0866, 0.0527], device='cuda:0')
2024-12-07 17:55:03,168 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 682: ref_distribution = tensor([0.8607, 0.0866, 0.0527], device='cuda:0'), new_distribution = tensor([0.8611, 0.0863, 0.0525], device='cuda:0')
2024-12-07 17:55:03,650 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 683: ref_distribution = tensor([0.8611, 0.0863, 0.0525], device='cuda:0'), new_distribution = tensor([0.8616, 0.0860, 0.0524], device='cuda:0')
2024-12-07 17:55:03,965 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 684: ref_distribution = tensor([0.8616, 0.0860, 0.0524], device='cuda:0'), new_distribution = tensor([0.8620, 0.0858, 0.0522], device='cuda:0')
2024-12-07 17:55:04,338 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 685: ref_distribution = tensor([0.8620, 0.0858, 0.0522], device='cuda:0'), new_distribution = tensor([0.8624, 0.0855, 0.0521], device='cuda:0')
2024-12-07 17:55:04,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 686: ref_distribution = tensor([0.8624, 0.0855, 0.0521], device='cuda:0'), new_distribution = tensor([0.8629, 0.0852, 0.0519], device='cuda:0')
2024-12-07 17:55:05,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 687: ref_distribution = tensor([0.8629, 0.0852, 0.0519], device='cuda:0'), new_distribution = tensor([0.8633, 0.0849, 0.0518], device='cuda:0')
2024-12-07 17:55:05,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 688: ref_distribution = tensor([0.8633, 0.0849, 0.0518], device='cuda:0'), new_distribution = tensor([0.8637, 0.0846, 0.0516], device='cuda:0')
2024-12-07 17:55:05,926 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 689: ref_distribution = tensor([0.8637, 0.0846, 0.0516], device='cuda:0'), new_distribution = tensor([0.8642, 0.0844, 0.0515], device='cuda:0')
2024-12-07 17:55:06,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 690: ref_distribution = tensor([0.8642, 0.0844, 0.0515], device='cuda:0'), new_distribution = tensor([0.8646, 0.0841, 0.0513], device='cuda:0')
2024-12-07 17:55:06,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 691: ref_distribution = tensor([0.8646, 0.0841, 0.0513], device='cuda:0'), new_distribution = tensor([0.8650, 0.0838, 0.0512], device='cuda:0')
2024-12-07 17:55:07,067 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 692: ref_distribution = tensor([0.8650, 0.0838, 0.0512], device='cuda:0'), new_distribution = tensor([0.8655, 0.0835, 0.0510], device='cuda:0')
2024-12-07 17:55:07,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 693: ref_distribution = tensor([0.8655, 0.0835, 0.0510], device='cuda:0'), new_distribution = tensor([0.8659, 0.0833, 0.0509], device='cuda:0')
2024-12-07 17:55:08,031 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 694: ref_distribution = tensor([0.8659, 0.0833, 0.0509], device='cuda:0'), new_distribution = tensor([0.8663, 0.0830, 0.0507], device='cuda:0')
2024-12-07 17:55:08,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 695: ref_distribution = tensor([0.8663, 0.0830, 0.0507], device='cuda:0'), new_distribution = tensor([0.8667, 0.0827, 0.0506], device='cuda:0')
2024-12-07 17:55:08,670 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 696: ref_distribution = tensor([0.8667, 0.0827, 0.0506], device='cuda:0'), new_distribution = tensor([0.8671, 0.0824, 0.0504], device='cuda:0')
2024-12-07 17:55:09,144 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 697: ref_distribution = tensor([0.8671, 0.0824, 0.0504], device='cuda:0'), new_distribution = tensor([0.8676, 0.0822, 0.0503], device='cuda:0')
2024-12-07 17:55:09,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 698: ref_distribution = tensor([0.8676, 0.0822, 0.0503], device='cuda:0'), new_distribution = tensor([0.8680, 0.0819, 0.0501], device='cuda:0')
2024-12-07 17:55:09,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 699: ref_distribution = tensor([0.8680, 0.0819, 0.0501], device='cuda:0'), new_distribution = tensor([0.8684, 0.0816, 0.0500], device='cuda:0')
2024-12-07 17:55:10,553 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.7000, 0.2000, 0.1000], device='cuda:0'), new_distribution = tensor([0.7008, 0.1995, 0.0997], device='cuda:0')
2024-12-07 17:55:10,809 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.7008, 0.1995, 0.0997], device='cuda:0'), new_distribution = tensor([0.7016, 0.1990, 0.0994], device='cuda:0')
2024-12-07 17:55:11,277 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.7016, 0.1990, 0.0994], device='cuda:0'), new_distribution = tensor([0.7023, 0.1985, 0.0991], device='cuda:0')
2024-12-07 17:55:11,611 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.7023, 0.1985, 0.0991], device='cuda:0'), new_distribution = tensor([0.7031, 0.1980, 0.0989], device='cuda:0')
2024-12-07 17:55:11,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.7031, 0.1980, 0.0989], device='cuda:0'), new_distribution = tensor([0.7039, 0.1975, 0.0986], device='cuda:0')
2024-12-07 17:55:12,374 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.7039, 0.1975, 0.0986], device='cuda:0'), new_distribution = tensor([0.7047, 0.1970, 0.0983], device='cuda:0')
2024-12-07 17:55:12,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.7047, 0.1970, 0.0983], device='cuda:0'), new_distribution = tensor([0.7055, 0.1965, 0.0980], device='cuda:0')
2024-12-07 17:55:13,031 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.7055, 0.1965, 0.0980], device='cuda:0'), new_distribution = tensor([0.7062, 0.1960, 0.0977], device='cuda:0')
2024-12-07 17:55:13,502 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.7062, 0.1960, 0.0977], device='cuda:0'), new_distribution = tensor([0.7070, 0.1956, 0.0974], device='cuda:0')
2024-12-07 17:55:13,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.7070, 0.1956, 0.0974], device='cuda:0'), new_distribution = tensor([0.7078, 0.1951, 0.0972], device='cuda:0')
2024-12-07 17:55:14,213 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.7078, 0.1951, 0.0972], device='cuda:0'), new_distribution = tensor([0.7086, 0.1946, 0.0969], device='cuda:0')
2024-12-07 17:55:14,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.7086, 0.1946, 0.0969], device='cuda:0'), new_distribution = tensor([0.7093, 0.1941, 0.0966], device='cuda:0')
2024-12-07 17:55:15,143 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.7093, 0.1941, 0.0966], device='cuda:0'), new_distribution = tensor([0.7101, 0.1936, 0.0963], device='cuda:0')
2024-12-07 17:55:15,526 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.7101, 0.1936, 0.0963], device='cuda:0'), new_distribution = tensor([0.7109, 0.1931, 0.0960], device='cuda:0')
2024-12-07 17:55:15,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.7109, 0.1931, 0.0960], device='cuda:0'), new_distribution = tensor([0.7116, 0.1926, 0.0958], device='cuda:0')
2024-12-07 17:55:16,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.7116, 0.1926, 0.0958], device='cuda:0'), new_distribution = tensor([0.7124, 0.1921, 0.0955], device='cuda:0')
2024-12-07 17:55:16,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.7124, 0.1921, 0.0955], device='cuda:0'), new_distribution = tensor([0.7132, 0.1916, 0.0952], device='cuda:0')
2024-12-07 17:55:17,073 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.7132, 0.1916, 0.0952], device='cuda:0'), new_distribution = tensor([0.7139, 0.1911, 0.0949], device='cuda:0')
2024-12-07 17:55:17,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.7139, 0.1911, 0.0949], device='cuda:0'), new_distribution = tensor([0.7147, 0.1907, 0.0947], device='cuda:0')
2024-12-07 17:55:17,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.7147, 0.1907, 0.0947], device='cuda:0'), new_distribution = tensor([0.7154, 0.1902, 0.0944], device='cuda:0')
2024-12-07 17:55:18,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.7154, 0.1902, 0.0944], device='cuda:0'), new_distribution = tensor([0.7162, 0.1897, 0.0941], device='cuda:0')
2024-12-07 17:55:18,713 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.7162, 0.1897, 0.0941], device='cuda:0'), new_distribution = tensor([0.7170, 0.1892, 0.0938], device='cuda:0')
2024-12-07 17:55:19,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.7170, 0.1892, 0.0938], device='cuda:0'), new_distribution = tensor([0.7177, 0.1887, 0.0936], device='cuda:0')
2024-12-07 17:55:19,531 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.7177, 0.1887, 0.0936], device='cuda:0'), new_distribution = tensor([0.7185, 0.1882, 0.0933], device='cuda:0')
2024-12-07 17:55:19,847 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.7185, 0.1882, 0.0933], device='cuda:0'), new_distribution = tensor([0.7192, 0.1877, 0.0930], device='cuda:0')
2024-12-07 17:55:20,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.7192, 0.1877, 0.0930], device='cuda:0'), new_distribution = tensor([0.7200, 0.1873, 0.0928], device='cuda:0')
2024-12-07 17:55:20,651 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.7200, 0.1873, 0.0928], device='cuda:0'), new_distribution = tensor([0.7207, 0.1868, 0.0925], device='cuda:0')
2024-12-07 17:55:21,081 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.7207, 0.1868, 0.0925], device='cuda:0'), new_distribution = tensor([0.7215, 0.1863, 0.0922], device='cuda:0')
2024-12-07 17:55:21,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.7215, 0.1863, 0.0922], device='cuda:0'), new_distribution = tensor([0.7222, 0.1858, 0.0920], device='cuda:0')
2024-12-07 17:55:21,807 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.7222, 0.1858, 0.0920], device='cuda:0'), new_distribution = tensor([0.7230, 0.1853, 0.0917], device='cuda:0')
2024-12-07 17:55:22,288 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.7230, 0.1853, 0.0917], device='cuda:0'), new_distribution = tensor([0.7237, 0.1848, 0.0914], device='cuda:0')
2024-12-07 17:55:22,608 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.7237, 0.1848, 0.0914], device='cuda:0'), new_distribution = tensor([0.7245, 0.1844, 0.0912], device='cuda:0')
2024-12-07 17:55:22,969 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.7245, 0.1844, 0.0912], device='cuda:0'), new_distribution = tensor([0.7252, 0.1839, 0.0909], device='cuda:0')
2024-12-07 17:55:23,428 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.7252, 0.1839, 0.0909], device='cuda:0'), new_distribution = tensor([0.7260, 0.1834, 0.0906], device='cuda:0')
2024-12-07 17:55:23,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.7260, 0.1834, 0.0906], device='cuda:0'), new_distribution = tensor([0.7267, 0.1829, 0.0904], device='cuda:0')
2024-12-07 17:55:24,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.7267, 0.1829, 0.0904], device='cuda:0'), new_distribution = tensor([0.7274, 0.1824, 0.0901], device='cuda:0')
2024-12-07 17:55:24,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.7274, 0.1824, 0.0901], device='cuda:0'), new_distribution = tensor([0.7282, 0.1820, 0.0899], device='cuda:0')
2024-12-07 17:55:25,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.7282, 0.1820, 0.0899], device='cuda:0'), new_distribution = tensor([0.7289, 0.1815, 0.0896], device='cuda:0')
2024-12-07 17:55:25,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.7289, 0.1815, 0.0896], device='cuda:0'), new_distribution = tensor([0.7296, 0.1810, 0.0893], device='cuda:0')
2024-12-07 17:55:25,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.7296, 0.1810, 0.0893], device='cuda:0'), new_distribution = tensor([0.7304, 0.1805, 0.0891], device='cuda:0')
2024-12-07 17:55:26,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.7304, 0.1805, 0.0891], device='cuda:0'), new_distribution = tensor([0.7311, 0.1801, 0.0888], device='cuda:0')
2024-12-07 17:55:26,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.7311, 0.1801, 0.0888], device='cuda:0'), new_distribution = tensor([0.7318, 0.1796, 0.0886], device='cuda:0')
2024-12-07 17:55:26,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.7318, 0.1796, 0.0886], device='cuda:0'), new_distribution = tensor([0.7326, 0.1791, 0.0883], device='cuda:0')
2024-12-07 17:55:27,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.7326, 0.1791, 0.0883], device='cuda:0'), new_distribution = tensor([0.7333, 0.1786, 0.0881], device='cuda:0')
2024-12-07 17:55:27,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.7333, 0.1786, 0.0881], device='cuda:0'), new_distribution = tensor([0.7340, 0.1782, 0.0878], device='cuda:0')
2024-12-07 17:55:28,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.7340, 0.1782, 0.0878], device='cuda:0'), new_distribution = tensor([0.7348, 0.1777, 0.0875], device='cuda:0')
2024-12-07 17:55:28,433 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.7348, 0.1777, 0.0875], device='cuda:0'), new_distribution = tensor([0.7355, 0.1772, 0.0873], device='cuda:0')
2024-12-07 17:55:28,915 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.7355, 0.1772, 0.0873], device='cuda:0'), new_distribution = tensor([0.7362, 0.1767, 0.0870], device='cuda:0')
2024-12-07 17:55:29,110 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.7362, 0.1767, 0.0870], device='cuda:0'), new_distribution = tensor([0.7369, 0.1763, 0.0868], device='cuda:0')
2024-12-07 17:55:29,549 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.7369, 0.1763, 0.0868], device='cuda:0'), new_distribution = tensor([0.7377, 0.1758, 0.0865], device='cuda:0')
2024-12-07 17:55:30,019 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.7377, 0.1758, 0.0865], device='cuda:0'), new_distribution = tensor([0.7384, 0.1753, 0.0863], device='cuda:0')
2024-12-07 17:55:30,282 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.7384, 0.1753, 0.0863], device='cuda:0'), new_distribution = tensor([0.7391, 0.1749, 0.0860], device='cuda:0')
2024-12-07 17:55:30,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.7391, 0.1749, 0.0860], device='cuda:0'), new_distribution = tensor([0.7398, 0.1744, 0.0858], device='cuda:0')
2024-12-07 17:55:31,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.7398, 0.1744, 0.0858], device='cuda:0'), new_distribution = tensor([0.7405, 0.1739, 0.0855], device='cuda:0')
2024-12-07 17:55:31,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.7405, 0.1739, 0.0855], device='cuda:0'), new_distribution = tensor([0.7413, 0.1735, 0.0853], device='cuda:0')
2024-12-07 17:55:31,832 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.7413, 0.1735, 0.0853], device='cuda:0'), new_distribution = tensor([0.7420, 0.1730, 0.0850], device='cuda:0')
2024-12-07 17:55:32,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.7420, 0.1730, 0.0850], device='cuda:0'), new_distribution = tensor([0.7427, 0.1725, 0.0848], device='cuda:0')
2024-12-07 17:55:32,738 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.7427, 0.1725, 0.0848], device='cuda:0'), new_distribution = tensor([0.7434, 0.1721, 0.0845], device='cuda:0')
2024-12-07 17:55:33,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.7434, 0.1721, 0.0845], device='cuda:0'), new_distribution = tensor([0.7441, 0.1716, 0.0843], device='cuda:0')
2024-12-07 17:55:33,416 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.7441, 0.1716, 0.0843], device='cuda:0'), new_distribution = tensor([0.7448, 0.1711, 0.0841], device='cuda:0')
2024-12-07 17:55:33,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.7448, 0.1711, 0.0841], device='cuda:0'), new_distribution = tensor([0.7455, 0.1707, 0.0838], device='cuda:0')
2024-12-07 17:55:34,298 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.7455, 0.1707, 0.0838], device='cuda:0'), new_distribution = tensor([0.7462, 0.1702, 0.0836], device='cuda:0')
2024-12-07 17:55:34,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.7462, 0.1702, 0.0836], device='cuda:0'), new_distribution = tensor([0.7469, 0.1697, 0.0833], device='cuda:0')
2024-12-07 17:55:35,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.7469, 0.1697, 0.0833], device='cuda:0'), new_distribution = tensor([0.7476, 0.1693, 0.0831], device='cuda:0')
2024-12-07 17:55:35,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.7476, 0.1693, 0.0831], device='cuda:0'), new_distribution = tensor([0.7483, 0.1688, 0.0828], device='cuda:0')
2024-12-07 17:55:35,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.7483, 0.1688, 0.0828], device='cuda:0'), new_distribution = tensor([0.7490, 0.1684, 0.0826], device='cuda:0')
2024-12-07 17:55:36,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.7490, 0.1684, 0.0826], device='cuda:0'), new_distribution = tensor([0.7497, 0.1679, 0.0824], device='cuda:0')
2024-12-07 17:55:36,648 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.7497, 0.1679, 0.0824], device='cuda:0'), new_distribution = tensor([0.7504, 0.1674, 0.0821], device='cuda:0')
2024-12-07 17:55:36,983 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.7504, 0.1674, 0.0821], device='cuda:0'), new_distribution = tensor([0.7511, 0.1670, 0.0819], device='cuda:0')
2024-12-07 17:55:37,278 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.7511, 0.1670, 0.0819], device='cuda:0'), new_distribution = tensor([0.7518, 0.1665, 0.0817], device='cuda:0')
2024-12-07 17:55:37,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.7518, 0.1665, 0.0817], device='cuda:0'), new_distribution = tensor([0.7525, 0.1661, 0.0814], device='cuda:0')
2024-12-07 17:55:37,965 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.7525, 0.1661, 0.0814], device='cuda:0'), new_distribution = tensor([0.7532, 0.1656, 0.0812], device='cuda:0')
2024-12-07 17:55:38,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.7532, 0.1656, 0.0812], device='cuda:0'), new_distribution = tensor([0.7539, 0.1652, 0.0809], device='cuda:0')
2024-12-07 17:55:38,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.7539, 0.1652, 0.0809], device='cuda:0'), new_distribution = tensor([0.7546, 0.1647, 0.0807], device='cuda:0')
2024-12-07 17:55:39,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.7546, 0.1647, 0.0807], device='cuda:0'), new_distribution = tensor([0.7553, 0.1642, 0.0805], device='cuda:0')
2024-12-07 17:55:39,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.7553, 0.1642, 0.0805], device='cuda:0'), new_distribution = tensor([0.7560, 0.1638, 0.0802], device='cuda:0')
2024-12-07 17:55:39,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.7560, 0.1638, 0.0802], device='cuda:0'), new_distribution = tensor([0.7567, 0.1633, 0.0800], device='cuda:0')
2024-12-07 17:55:40,355 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.7567, 0.1633, 0.0800], device='cuda:0'), new_distribution = tensor([0.7573, 0.1629, 0.0798], device='cuda:0')
2024-12-07 17:55:40,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.7573, 0.1629, 0.0798], device='cuda:0'), new_distribution = tensor([0.7580, 0.1624, 0.0795], device='cuda:0')
2024-12-07 17:55:41,123 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.7580, 0.1624, 0.0795], device='cuda:0'), new_distribution = tensor([0.7587, 0.1620, 0.0793], device='cuda:0')
2024-12-07 17:55:41,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.7587, 0.1620, 0.0793], device='cuda:0'), new_distribution = tensor([0.7594, 0.1615, 0.0791], device='cuda:0')
2024-12-07 17:55:41,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.7594, 0.1615, 0.0791], device='cuda:0'), new_distribution = tensor([0.7601, 0.1611, 0.0788], device='cuda:0')
2024-12-07 17:55:42,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.7601, 0.1611, 0.0788], device='cuda:0'), new_distribution = tensor([0.7608, 0.1606, 0.0786], device='cuda:0')
2024-12-07 17:55:42,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.7608, 0.1606, 0.0786], device='cuda:0'), new_distribution = tensor([0.7614, 0.1602, 0.0784], device='cuda:0')
2024-12-07 17:55:43,049 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.7614, 0.1602, 0.0784], device='cuda:0'), new_distribution = tensor([0.7621, 0.1597, 0.0782], device='cuda:0')
2024-12-07 17:55:43,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.7621, 0.1597, 0.0782], device='cuda:0'), new_distribution = tensor([0.7628, 0.1593, 0.0779], device='cuda:0')
2024-12-07 17:55:43,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.7628, 0.1593, 0.0779], device='cuda:0'), new_distribution = tensor([0.7635, 0.1588, 0.0777], device='cuda:0')
2024-12-07 17:55:44,145 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.7635, 0.1588, 0.0777], device='cuda:0'), new_distribution = tensor([0.7641, 0.1584, 0.0775], device='cuda:0')
2024-12-07 17:55:44,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.7641, 0.1584, 0.0775], device='cuda:0'), new_distribution = tensor([0.7648, 0.1579, 0.0773], device='cuda:0')
2024-12-07 17:55:44,953 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.7648, 0.1579, 0.0773], device='cuda:0'), new_distribution = tensor([0.7655, 0.1575, 0.0770], device='cuda:0')
2024-12-07 17:55:45,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.7655, 0.1575, 0.0770], device='cuda:0'), new_distribution = tensor([0.7661, 0.1571, 0.0768], device='cuda:0')
2024-12-07 17:55:45,589 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.7661, 0.1571, 0.0768], device='cuda:0'), new_distribution = tensor([0.7668, 0.1566, 0.0766], device='cuda:0')
2024-12-07 17:55:46,055 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.7668, 0.1566, 0.0766], device='cuda:0'), new_distribution = tensor([0.7675, 0.1562, 0.0764], device='cuda:0')
2024-12-07 17:55:46,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.7675, 0.1562, 0.0764], device='cuda:0'), new_distribution = tensor([0.7681, 0.1557, 0.0761], device='cuda:0')
2024-12-07 17:55:46,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.7681, 0.1557, 0.0761], device='cuda:0'), new_distribution = tensor([0.7688, 0.1553, 0.0759], device='cuda:0')
2024-12-07 17:55:47,157 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.7688, 0.1553, 0.0759], device='cuda:0'), new_distribution = tensor([0.7695, 0.1549, 0.0757], device='cuda:0')
2024-12-07 17:55:47,564 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.7695, 0.1549, 0.0757], device='cuda:0'), new_distribution = tensor([0.7701, 0.1544, 0.0755], device='cuda:0')
2024-12-07 17:55:47,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.7701, 0.1544, 0.0755], device='cuda:0'), new_distribution = tensor([0.7708, 0.1540, 0.0753], device='cuda:0')
2024-12-07 17:55:48,262 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.7708, 0.1540, 0.0753], device='cuda:0'), new_distribution = tensor([0.7714, 0.1535, 0.0750], device='cuda:0')
2024-12-07 17:55:48,670 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.7714, 0.1535, 0.0750], device='cuda:0'), new_distribution = tensor([0.7721, 0.1531, 0.0748], device='cuda:0')
2024-12-07 17:55:48,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([0.7721, 0.1531, 0.0748], device='cuda:0'), new_distribution = tensor([0.7727, 0.1527, 0.0746], device='cuda:0')
2024-12-07 17:55:49,381 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([0.7727, 0.1527, 0.0746], device='cuda:0'), new_distribution = tensor([0.7734, 0.1522, 0.0744], device='cuda:0')
2024-12-07 17:55:49,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([0.7734, 0.1522, 0.0744], device='cuda:0'), new_distribution = tensor([0.7740, 0.1518, 0.0742], device='cuda:0')
2024-12-07 17:55:50,100 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([0.7740, 0.1518, 0.0742], device='cuda:0'), new_distribution = tensor([0.7747, 0.1514, 0.0739], device='cuda:0')
2024-12-07 17:55:50,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([0.7747, 0.1514, 0.0739], device='cuda:0'), new_distribution = tensor([0.7753, 0.1509, 0.0737], device='cuda:0')
2024-12-07 17:55:51,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([0.7753, 0.1509, 0.0737], device='cuda:0'), new_distribution = tensor([0.7760, 0.1505, 0.0735], device='cuda:0')
2024-12-07 17:55:51,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([0.7760, 0.1505, 0.0735], device='cuda:0'), new_distribution = tensor([0.7766, 0.1501, 0.0733], device='cuda:0')
2024-12-07 17:55:51,653 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([0.7766, 0.1501, 0.0733], device='cuda:0'), new_distribution = tensor([0.7773, 0.1496, 0.0731], device='cuda:0')
2024-12-07 17:55:52,121 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([0.7773, 0.1496, 0.0731], device='cuda:0'), new_distribution = tensor([0.7779, 0.1492, 0.0729], device='cuda:0')
2024-12-07 17:55:52,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([0.7779, 0.1492, 0.0729], device='cuda:0'), new_distribution = tensor([0.7786, 0.1488, 0.0727], device='cuda:0')
2024-12-07 17:55:52,754 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([0.7786, 0.1488, 0.0727], device='cuda:0'), new_distribution = tensor([0.7792, 0.1483, 0.0725], device='cuda:0')
2024-12-07 17:55:53,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([0.7792, 0.1483, 0.0725], device='cuda:0'), new_distribution = tensor([0.7798, 0.1479, 0.0722], device='cuda:0')
2024-12-07 17:55:53,517 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([0.7798, 0.1479, 0.0722], device='cuda:0'), new_distribution = tensor([0.7805, 0.1475, 0.0720], device='cuda:0')
2024-12-07 17:55:53,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([0.7805, 0.1475, 0.0720], device='cuda:0'), new_distribution = tensor([0.7811, 0.1471, 0.0718], device='cuda:0')
2024-12-07 17:55:54,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([0.7811, 0.1471, 0.0718], device='cuda:0'), new_distribution = tensor([0.7818, 0.1466, 0.0716], device='cuda:0')
2024-12-07 17:55:54,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([0.7818, 0.1466, 0.0716], device='cuda:0'), new_distribution = tensor([0.7824, 0.1462, 0.0714], device='cuda:0')
2024-12-07 17:55:54,988 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([0.7824, 0.1462, 0.0714], device='cuda:0'), new_distribution = tensor([0.7830, 0.1458, 0.0712], device='cuda:0')
2024-12-07 17:55:55,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([0.7830, 0.1458, 0.0712], device='cuda:0'), new_distribution = tensor([0.7837, 0.1454, 0.0710], device='cuda:0')
2024-12-07 17:55:55,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([0.7837, 0.1454, 0.0710], device='cuda:0'), new_distribution = tensor([0.7843, 0.1449, 0.0708], device='cuda:0')
2024-12-07 17:55:56,137 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([0.7843, 0.1449, 0.0708], device='cuda:0'), new_distribution = tensor([0.7849, 0.1445, 0.0706], device='cuda:0')
2024-12-07 17:55:56,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([0.7849, 0.1445, 0.0706], device='cuda:0'), new_distribution = tensor([0.7855, 0.1441, 0.0704], device='cuda:0')
2024-12-07 17:55:56,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([0.7855, 0.1441, 0.0704], device='cuda:0'), new_distribution = tensor([0.7862, 0.1437, 0.0702], device='cuda:0')
2024-12-07 17:55:57,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([0.7862, 0.1437, 0.0702], device='cuda:0'), new_distribution = tensor([0.7868, 0.1433, 0.0700], device='cuda:0')
2024-12-07 17:55:57,632 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([0.7868, 0.1433, 0.0700], device='cuda:0'), new_distribution = tensor([0.7874, 0.1428, 0.0697], device='cuda:0')
2024-12-07 17:55:57,958 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([0.7874, 0.1428, 0.0697], device='cuda:0'), new_distribution = tensor([0.7880, 0.1424, 0.0695], device='cuda:0')
2024-12-07 17:55:58,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([0.7880, 0.1424, 0.0695], device='cuda:0'), new_distribution = tensor([0.7887, 0.1420, 0.0693], device='cuda:0')
2024-12-07 17:55:58,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([0.7887, 0.1420, 0.0693], device='cuda:0'), new_distribution = tensor([0.7893, 0.1416, 0.0691], device='cuda:0')
2024-12-07 17:55:59,168 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([0.7893, 0.1416, 0.0691], device='cuda:0'), new_distribution = tensor([0.7899, 0.1412, 0.0689], device='cuda:0')
2024-12-07 17:55:59,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([0.7899, 0.1412, 0.0689], device='cuda:0'), new_distribution = tensor([0.7905, 0.1408, 0.0687], device='cuda:0')
2024-12-07 17:56:00,042 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([0.7905, 0.1408, 0.0687], device='cuda:0'), new_distribution = tensor([0.7911, 0.1403, 0.0685], device='cuda:0')
2024-12-07 17:56:00,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([0.7911, 0.1403, 0.0685], device='cuda:0'), new_distribution = tensor([0.7917, 0.1399, 0.0683], device='cuda:0')
2024-12-07 17:56:00,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([0.7917, 0.1399, 0.0683], device='cuda:0'), new_distribution = tensor([0.7923, 0.1395, 0.0681], device='cuda:0')
2024-12-07 17:56:01,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([0.7923, 0.1395, 0.0681], device='cuda:0'), new_distribution = tensor([0.7930, 0.1391, 0.0679], device='cuda:0')
2024-12-07 17:56:01,463 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([0.7930, 0.1391, 0.0679], device='cuda:0'), new_distribution = tensor([0.7936, 0.1387, 0.0677], device='cuda:0')
2024-12-07 17:56:01,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([0.7936, 0.1387, 0.0677], device='cuda:0'), new_distribution = tensor([0.7942, 0.1383, 0.0675], device='cuda:0')
2024-12-07 17:56:02,259 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([0.7942, 0.1383, 0.0675], device='cuda:0'), new_distribution = tensor([0.7948, 0.1379, 0.0673], device='cuda:0')
2024-12-07 17:56:02,574 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([0.7948, 0.1379, 0.0673], device='cuda:0'), new_distribution = tensor([0.7954, 0.1375, 0.0671], device='cuda:0')
2024-12-07 17:56:02,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([0.7954, 0.1375, 0.0671], device='cuda:0'), new_distribution = tensor([0.7960, 0.1371, 0.0670], device='cuda:0')
2024-12-07 17:56:03,398 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([0.7960, 0.1371, 0.0670], device='cuda:0'), new_distribution = tensor([0.7966, 0.1366, 0.0668], device='cuda:0')
2024-12-07 17:56:03,858 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([0.7966, 0.1366, 0.0668], device='cuda:0'), new_distribution = tensor([0.7972, 0.1362, 0.0666], device='cuda:0')
2024-12-07 17:56:04,206 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([0.7972, 0.1362, 0.0666], device='cuda:0'), new_distribution = tensor([0.7978, 0.1358, 0.0664], device='cuda:0')
2024-12-07 17:56:04,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([0.7978, 0.1358, 0.0664], device='cuda:0'), new_distribution = tensor([0.7984, 0.1354, 0.0662], device='cuda:0')
2024-12-07 17:56:05,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([0.7984, 0.1354, 0.0662], device='cuda:0'), new_distribution = tensor([0.7990, 0.1350, 0.0660], device='cuda:0')
2024-12-07 17:56:05,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([0.7990, 0.1350, 0.0660], device='cuda:0'), new_distribution = tensor([0.7996, 0.1346, 0.0658], device='cuda:0')
2024-12-07 17:56:05,647 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([0.7996, 0.1346, 0.0658], device='cuda:0'), new_distribution = tensor([0.8002, 0.1342, 0.0656], device='cuda:0')
2024-12-07 17:56:06,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([0.8002, 0.1342, 0.0656], device='cuda:0'), new_distribution = tensor([0.8008, 0.1338, 0.0654], device='cuda:0')
2024-12-07 17:56:06,578 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([0.8008, 0.1338, 0.0654], device='cuda:0'), new_distribution = tensor([0.8014, 0.1334, 0.0652], device='cuda:0')
2024-12-07 17:56:06,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([0.8014, 0.1334, 0.0652], device='cuda:0'), new_distribution = tensor([0.8020, 0.1330, 0.0650], device='cuda:0')
2024-12-07 17:56:07,282 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([0.8020, 0.1330, 0.0650], device='cuda:0'), new_distribution = tensor([0.8026, 0.1326, 0.0648], device='cuda:0')
2024-12-07 17:56:07,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([0.8026, 0.1326, 0.0648], device='cuda:0'), new_distribution = tensor([0.8031, 0.1322, 0.0646], device='cuda:0')
2024-12-07 17:56:08,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([0.8031, 0.1322, 0.0646], device='cuda:0'), new_distribution = tensor([0.8037, 0.1318, 0.0644], device='cuda:0')
2024-12-07 17:56:08,454 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([0.8037, 0.1318, 0.0644], device='cuda:0'), new_distribution = tensor([0.8043, 0.1314, 0.0643], device='cuda:0')
2024-12-07 17:56:08,906 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([0.8043, 0.1314, 0.0643], device='cuda:0'), new_distribution = tensor([0.8049, 0.1310, 0.0641], device='cuda:0')
2024-12-07 17:56:09,354 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([0.8049, 0.1310, 0.0641], device='cuda:0'), new_distribution = tensor([0.8055, 0.1306, 0.0639], device='cuda:0')
2024-12-07 17:56:09,701 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([0.8055, 0.1306, 0.0639], device='cuda:0'), new_distribution = tensor([0.8061, 0.1302, 0.0637], device='cuda:0')
2024-12-07 17:56:10,057 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([0.8061, 0.1302, 0.0637], device='cuda:0'), new_distribution = tensor([0.8066, 0.1298, 0.0635], device='cuda:0')
2024-12-07 17:56:10,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([0.8066, 0.1298, 0.0635], device='cuda:0'), new_distribution = tensor([0.8072, 0.1295, 0.0633], device='cuda:0')
2024-12-07 17:56:10,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([0.8072, 0.1295, 0.0633], device='cuda:0'), new_distribution = tensor([0.8078, 0.1291, 0.0631], device='cuda:0')
2024-12-07 17:56:11,169 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([0.8078, 0.1291, 0.0631], device='cuda:0'), new_distribution = tensor([0.8084, 0.1287, 0.0630], device='cuda:0')
2024-12-07 17:56:11,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([0.8084, 0.1287, 0.0630], device='cuda:0'), new_distribution = tensor([0.8089, 0.1283, 0.0628], device='cuda:0')
2024-12-07 17:56:11,994 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([0.8089, 0.1283, 0.0628], device='cuda:0'), new_distribution = tensor([0.8095, 0.1279, 0.0626], device='cuda:0')
2024-12-07 17:56:12,306 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([0.8095, 0.1279, 0.0626], device='cuda:0'), new_distribution = tensor([0.8101, 0.1275, 0.0624], device='cuda:0')
2024-12-07 17:56:12,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([0.8101, 0.1275, 0.0624], device='cuda:0'), new_distribution = tensor([0.8107, 0.1271, 0.0622], device='cuda:0')
2024-12-07 17:56:13,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([0.8107, 0.1271, 0.0622], device='cuda:0'), new_distribution = tensor([0.8112, 0.1267, 0.0620], device='cuda:0')
2024-12-07 17:56:13,506 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([0.8112, 0.1267, 0.0620], device='cuda:0'), new_distribution = tensor([0.8118, 0.1263, 0.0619], device='cuda:0')
2024-12-07 17:56:13,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([0.8118, 0.1263, 0.0619], device='cuda:0'), new_distribution = tensor([0.8124, 0.1260, 0.0617], device='cuda:0')
2024-12-07 17:56:14,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([0.8124, 0.1260, 0.0617], device='cuda:0'), new_distribution = tensor([0.8129, 0.1256, 0.0615], device='cuda:0')
2024-12-07 17:56:14,659 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([0.8129, 0.1256, 0.0615], device='cuda:0'), new_distribution = tensor([0.8135, 0.1252, 0.0613], device='cuda:0')
2024-12-07 17:56:15,046 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([0.8135, 0.1252, 0.0613], device='cuda:0'), new_distribution = tensor([0.8141, 0.1248, 0.0611], device='cuda:0')
2024-12-07 17:56:15,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([0.8141, 0.1248, 0.0611], device='cuda:0'), new_distribution = tensor([0.8146, 0.1244, 0.0610], device='cuda:0')
2024-12-07 17:56:15,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([0.8146, 0.1244, 0.0610], device='cuda:0'), new_distribution = tensor([0.8152, 0.1240, 0.0608], device='cuda:0')
2024-12-07 17:56:16,137 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([0.8152, 0.1240, 0.0608], device='cuda:0'), new_distribution = tensor([0.8157, 0.1237, 0.0606], device='cuda:0')
2024-12-07 17:56:16,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([0.8157, 0.1237, 0.0606], device='cuda:0'), new_distribution = tensor([0.8163, 0.1233, 0.0604], device='cuda:0')
2024-12-07 17:56:16,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([0.8163, 0.1233, 0.0604], device='cuda:0'), new_distribution = tensor([0.8169, 0.1229, 0.0602], device='cuda:0')
2024-12-07 17:56:17,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([0.8169, 0.1229, 0.0602], device='cuda:0'), new_distribution = tensor([0.8174, 0.1225, 0.0601], device='cuda:0')
2024-12-07 17:56:17,758 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([0.8174, 0.1225, 0.0601], device='cuda:0'), new_distribution = tensor([0.8180, 0.1222, 0.0599], device='cuda:0')
2024-12-07 17:56:18,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([0.8180, 0.1222, 0.0599], device='cuda:0'), new_distribution = tensor([0.8185, 0.1218, 0.0597], device='cuda:0')
2024-12-07 17:56:18,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([0.8185, 0.1218, 0.0597], device='cuda:0'), new_distribution = tensor([0.8191, 0.1214, 0.0595], device='cuda:0')
2024-12-07 17:56:18,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([0.8191, 0.1214, 0.0595], device='cuda:0'), new_distribution = tensor([0.8196, 0.1210, 0.0594], device='cuda:0')
2024-12-07 17:56:19,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([0.8196, 0.1210, 0.0594], device='cuda:0'), new_distribution = tensor([0.8202, 0.1206, 0.0592], device='cuda:0')
2024-12-07 17:56:19,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([0.8202, 0.1206, 0.0592], device='cuda:0'), new_distribution = tensor([0.8207, 0.1203, 0.0590], device='cuda:0')
2024-12-07 17:56:20,096 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([0.8207, 0.1203, 0.0590], device='cuda:0'), new_distribution = tensor([0.8213, 0.1199, 0.0588], device='cuda:0')
2024-12-07 17:56:20,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([0.8213, 0.1199, 0.0588], device='cuda:0'), new_distribution = tensor([0.8218, 0.1195, 0.0587], device='cuda:0')
2024-12-07 17:56:20,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([0.8218, 0.1195, 0.0587], device='cuda:0'), new_distribution = tensor([0.8223, 0.1192, 0.0585], device='cuda:0')
2024-12-07 17:56:21,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([0.8223, 0.1192, 0.0585], device='cuda:0'), new_distribution = tensor([0.8229, 0.1188, 0.0583], device='cuda:0')
2024-12-07 17:56:21,852 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([0.8229, 0.1188, 0.0583], device='cuda:0'), new_distribution = tensor([0.8234, 0.1184, 0.0582], device='cuda:0')
2024-12-07 17:56:22,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([0.8234, 0.1184, 0.0582], device='cuda:0'), new_distribution = tensor([0.8240, 0.1181, 0.0580], device='cuda:0')
2024-12-07 17:56:22,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([0.8240, 0.1181, 0.0580], device='cuda:0'), new_distribution = tensor([0.8245, 0.1177, 0.0578], device='cuda:0')
2024-12-07 17:56:23,398 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([0.8245, 0.1177, 0.0578], device='cuda:0'), new_distribution = tensor([0.8250, 0.1173, 0.0576], device='cuda:0')
2024-12-07 17:56:23,860 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([0.8250, 0.1173, 0.0576], device='cuda:0'), new_distribution = tensor([0.8256, 0.1170, 0.0575], device='cuda:0')
2024-12-07 17:56:24,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([0.8256, 0.1170, 0.0575], device='cuda:0'), new_distribution = tensor([0.8261, 0.1166, 0.0573], device='cuda:0')
2024-12-07 17:56:24,591 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([0.8261, 0.1166, 0.0573], device='cuda:0'), new_distribution = tensor([0.8266, 0.1162, 0.0571], device='cuda:0')
2024-12-07 17:56:25,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([0.8266, 0.1162, 0.0571], device='cuda:0'), new_distribution = tensor([0.8272, 0.1159, 0.0570], device='cuda:0')
2024-12-07 17:56:25,400 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([0.8272, 0.1159, 0.0570], device='cuda:0'), new_distribution = tensor([0.8277, 0.1155, 0.0568], device='cuda:0')
2024-12-07 17:56:25,707 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([0.8277, 0.1155, 0.0568], device='cuda:0'), new_distribution = tensor([0.8282, 0.1151, 0.0566], device='cuda:0')
2024-12-07 17:56:26,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([0.8282, 0.1151, 0.0566], device='cuda:0'), new_distribution = tensor([0.8287, 0.1148, 0.0565], device='cuda:0')
2024-12-07 17:56:26,578 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([0.8287, 0.1148, 0.0565], device='cuda:0'), new_distribution = tensor([0.8293, 0.1144, 0.0563], device='cuda:0')
2024-12-07 17:56:26,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([0.8293, 0.1144, 0.0563], device='cuda:0'), new_distribution = tensor([0.8298, 0.1141, 0.0561], device='cuda:0')
2024-12-07 17:56:26,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([0.8298, 0.1141, 0.0561], device='cuda:0'), new_distribution = tensor([0.8303, 0.1137, 0.0560], device='cuda:0')
2024-12-07 17:56:27,023 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([0.8303, 0.1137, 0.0560], device='cuda:0'), new_distribution = tensor([0.8308, 0.1133, 0.0558], device='cuda:0')
2024-12-07 17:56:27,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([0.8308, 0.1133, 0.0558], device='cuda:0'), new_distribution = tensor([0.8314, 0.1130, 0.0556], device='cuda:0')
2024-12-07 17:56:27,213 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([0.8314, 0.1130, 0.0556], device='cuda:0'), new_distribution = tensor([0.8319, 0.1126, 0.0555], device='cuda:0')
2024-12-07 17:56:27,301 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([0.8319, 0.1126, 0.0555], device='cuda:0'), new_distribution = tensor([0.8324, 0.1123, 0.0553], device='cuda:0')
2024-12-07 17:56:27,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([0.8324, 0.1123, 0.0553], device='cuda:0'), new_distribution = tensor([0.8329, 0.1119, 0.0552], device='cuda:0')
2024-12-07 17:56:27,480 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([0.8329, 0.1119, 0.0552], device='cuda:0'), new_distribution = tensor([0.8334, 0.1116, 0.0550], device='cuda:0')
2024-12-07 17:56:27,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([0.8334, 0.1116, 0.0550], device='cuda:0'), new_distribution = tensor([0.8339, 0.1112, 0.0548], device='cuda:0')
2024-12-07 17:56:27,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([0.8339, 0.1112, 0.0548], device='cuda:0'), new_distribution = tensor([0.8345, 0.1109, 0.0547], device='cuda:0')
2024-12-07 17:56:27,806 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([0.8345, 0.1109, 0.0547], device='cuda:0'), new_distribution = tensor([0.8350, 0.1105, 0.0545], device='cuda:0')
2024-12-07 17:56:27,897 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([0.8350, 0.1105, 0.0545], device='cuda:0'), new_distribution = tensor([0.8355, 0.1102, 0.0544], device='cuda:0')
2024-12-07 17:56:27,993 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([0.8355, 0.1102, 0.0544], device='cuda:0'), new_distribution = tensor([0.8360, 0.1098, 0.0542], device='cuda:0')
2024-12-07 17:56:28,085 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([0.8360, 0.1098, 0.0542], device='cuda:0'), new_distribution = tensor([0.8365, 0.1095, 0.0540], device='cuda:0')
2024-12-07 17:56:28,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([0.8365, 0.1095, 0.0540], device='cuda:0'), new_distribution = tensor([0.8370, 0.1091, 0.0539], device='cuda:0')
2024-12-07 17:56:28,266 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([0.8370, 0.1091, 0.0539], device='cuda:0'), new_distribution = tensor([0.8375, 0.1088, 0.0537], device='cuda:0')
2024-12-07 17:56:28,357 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([0.8375, 0.1088, 0.0537], device='cuda:0'), new_distribution = tensor([0.8380, 0.1084, 0.0536], device='cuda:0')
2024-12-07 17:56:28,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([0.8380, 0.1084, 0.0536], device='cuda:0'), new_distribution = tensor([0.8385, 0.1081, 0.0534], device='cuda:0')
2024-12-07 17:56:28,540 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([0.8385, 0.1081, 0.0534], device='cuda:0'), new_distribution = tensor([0.8390, 0.1077, 0.0532], device='cuda:0')
2024-12-07 17:56:28,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([0.8390, 0.1077, 0.0532], device='cuda:0'), new_distribution = tensor([0.8395, 0.1074, 0.0531], device='cuda:0')
2024-12-07 17:56:28,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([0.8395, 0.1074, 0.0531], device='cuda:0'), new_distribution = tensor([0.8400, 0.1071, 0.0529], device='cuda:0')
2024-12-07 17:56:28,822 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([0.8400, 0.1071, 0.0529], device='cuda:0'), new_distribution = tensor([0.8405, 0.1067, 0.0528], device='cuda:0')
2024-12-07 17:56:28,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([0.8405, 0.1067, 0.0528], device='cuda:0'), new_distribution = tensor([0.8410, 0.1064, 0.0526], device='cuda:0')
2024-12-07 17:56:29,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([0.8410, 0.1064, 0.0526], device='cuda:0'), new_distribution = tensor([0.8415, 0.1060, 0.0525], device='cuda:0')
2024-12-07 17:56:29,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([0.8415, 0.1060, 0.0525], device='cuda:0'), new_distribution = tensor([0.8420, 0.1057, 0.0523], device='cuda:0')
2024-12-07 17:56:29,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([0.8420, 0.1057, 0.0523], device='cuda:0'), new_distribution = tensor([0.8425, 0.1054, 0.0522], device='cuda:0')
2024-12-07 17:56:29,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([0.8425, 0.1054, 0.0522], device='cuda:0'), new_distribution = tensor([0.8430, 0.1050, 0.0520], device='cuda:0')
2024-12-07 17:56:29,463 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([0.8430, 0.1050, 0.0520], device='cuda:0'), new_distribution = tensor([0.8435, 0.1047, 0.0519], device='cuda:0')
2024-12-07 17:56:29,586 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([0.8435, 0.1047, 0.0519], device='cuda:0'), new_distribution = tensor([0.8440, 0.1043, 0.0517], device='cuda:0')
2024-12-07 17:56:29,714 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([0.8440, 0.1043, 0.0517], device='cuda:0'), new_distribution = tensor([0.8444, 0.1040, 0.0515], device='cuda:0')
2024-12-07 17:56:29,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([0.8444, 0.1040, 0.0515], device='cuda:0'), new_distribution = tensor([0.8449, 0.1037, 0.0514], device='cuda:0')
2024-12-07 17:56:29,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([0.8449, 0.1037, 0.0514], device='cuda:0'), new_distribution = tensor([0.8454, 0.1033, 0.0512], device='cuda:0')
2024-12-07 17:56:30,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([0.8454, 0.1033, 0.0512], device='cuda:0'), new_distribution = tensor([0.8459, 0.1030, 0.0511], device='cuda:0')
2024-12-07 17:56:30,201 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([0.8459, 0.1030, 0.0511], device='cuda:0'), new_distribution = tensor([0.8464, 0.1027, 0.0509], device='cuda:0')
2024-12-07 17:56:30,322 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([0.8464, 0.1027, 0.0509], device='cuda:0'), new_distribution = tensor([0.8469, 0.1023, 0.0508], device='cuda:0')
2024-12-07 17:56:30,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([0.8469, 0.1023, 0.0508], device='cuda:0'), new_distribution = tensor([0.8473, 0.1020, 0.0506], device='cuda:0')
2024-12-07 17:56:30,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([0.8473, 0.1020, 0.0506], device='cuda:0'), new_distribution = tensor([0.8478, 0.1017, 0.0505], device='cuda:0')
2024-12-07 17:56:30,690 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([0.8478, 0.1017, 0.0505], device='cuda:0'), new_distribution = tensor([0.8483, 0.1014, 0.0503], device='cuda:0')
2024-12-07 17:56:30,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([0.8483, 0.1014, 0.0503], device='cuda:0'), new_distribution = tensor([0.8488, 0.1010, 0.0502], device='cuda:0')
2024-12-07 17:56:30,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([0.8488, 0.1010, 0.0502], device='cuda:0'), new_distribution = tensor([0.8492, 0.1007, 0.0501], device='cuda:0')
2024-12-07 17:56:31,057 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([0.8492, 0.1007, 0.0501], device='cuda:0'), new_distribution = tensor([0.8497, 0.1004, 0.0499], device='cuda:0')
2024-12-07 17:56:31,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([0.8497, 0.1004, 0.0499], device='cuda:0'), new_distribution = tensor([0.8502, 0.1001, 0.0498], device='cuda:0')
2024-12-07 17:56:31,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([0.8502, 0.1001, 0.0498], device='cuda:0'), new_distribution = tensor([0.8507, 0.0997, 0.0496], device='cuda:0')
2024-12-07 17:56:31,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([0.8507, 0.0997, 0.0496], device='cuda:0'), new_distribution = tensor([0.8511, 0.0994, 0.0495], device='cuda:0')
2024-12-07 17:56:31,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([0.8511, 0.0994, 0.0495], device='cuda:0'), new_distribution = tensor([0.8516, 0.0991, 0.0493], device='cuda:0')
2024-12-07 17:56:31,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([0.8516, 0.0991, 0.0493], device='cuda:0'), new_distribution = tensor([0.8521, 0.0988, 0.0492], device='cuda:0')
2024-12-07 17:56:31,683 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([0.8521, 0.0988, 0.0492], device='cuda:0'), new_distribution = tensor([0.8525, 0.0984, 0.0490], device='cuda:0')
2024-12-07 17:56:31,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([0.8525, 0.0984, 0.0490], device='cuda:0'), new_distribution = tensor([0.8530, 0.0981, 0.0489], device='cuda:0')
2024-12-07 17:56:31,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([0.8530, 0.0981, 0.0489], device='cuda:0'), new_distribution = tensor([0.8535, 0.0978, 0.0487], device='cuda:0')
2024-12-07 17:56:31,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([0.8535, 0.0978, 0.0487], device='cuda:0'), new_distribution = tensor([0.8539, 0.0975, 0.0486], device='cuda:0')
2024-12-07 17:56:32,049 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([0.8539, 0.0975, 0.0486], device='cuda:0'), new_distribution = tensor([0.8544, 0.0972, 0.0485], device='cuda:0')
2024-12-07 17:56:32,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([0.8544, 0.0972, 0.0485], device='cuda:0'), new_distribution = tensor([0.8548, 0.0968, 0.0483], device='cuda:0')
2024-12-07 17:56:32,232 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([0.8548, 0.0968, 0.0483], device='cuda:0'), new_distribution = tensor([0.8553, 0.0965, 0.0482], device='cuda:0')
2024-12-07 17:56:32,324 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([0.8553, 0.0965, 0.0482], device='cuda:0'), new_distribution = tensor([0.8558, 0.0962, 0.0480], device='cuda:0')
2024-12-07 17:56:32,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([0.8558, 0.0962, 0.0480], device='cuda:0'), new_distribution = tensor([0.8562, 0.0959, 0.0479], device='cuda:0')
2024-12-07 17:56:32,506 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([0.8562, 0.0959, 0.0479], device='cuda:0'), new_distribution = tensor([0.8567, 0.0956, 0.0477], device='cuda:0')
2024-12-07 17:56:32,598 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([0.8567, 0.0956, 0.0477], device='cuda:0'), new_distribution = tensor([0.8571, 0.0953, 0.0476], device='cuda:0')
2024-12-07 17:56:32,689 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([0.8571, 0.0953, 0.0476], device='cuda:0'), new_distribution = tensor([0.8576, 0.0950, 0.0475], device='cuda:0')
2024-12-07 17:56:32,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([0.8576, 0.0950, 0.0475], device='cuda:0'), new_distribution = tensor([0.8580, 0.0946, 0.0473], device='cuda:0')
2024-12-07 17:56:32,873 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([0.8580, 0.0946, 0.0473], device='cuda:0'), new_distribution = tensor([0.8585, 0.0943, 0.0472], device='cuda:0')
2024-12-07 17:56:32,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([0.8585, 0.0943, 0.0472], device='cuda:0'), new_distribution = tensor([0.8589, 0.0940, 0.0470], device='cuda:0')
2024-12-07 17:56:33,058 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([0.8589, 0.0940, 0.0470], device='cuda:0'), new_distribution = tensor([0.8594, 0.0937, 0.0469], device='cuda:0')
2024-12-07 17:56:33,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([0.8594, 0.0937, 0.0469], device='cuda:0'), new_distribution = tensor([0.8598, 0.0934, 0.0468], device='cuda:0')
2024-12-07 17:56:33,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([0.8598, 0.0934, 0.0468], device='cuda:0'), new_distribution = tensor([0.8603, 0.0931, 0.0466], device='cuda:0')
2024-12-07 17:56:33,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([0.8603, 0.0931, 0.0466], device='cuda:0'), new_distribution = tensor([0.8607, 0.0928, 0.0465], device='cuda:0')
2024-12-07 17:56:33,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([0.8607, 0.0928, 0.0465], device='cuda:0'), new_distribution = tensor([0.8611, 0.0925, 0.0464], device='cuda:0')
2024-12-07 17:56:33,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([0.8611, 0.0925, 0.0464], device='cuda:0'), new_distribution = tensor([0.8616, 0.0922, 0.0462], device='cuda:0')
2024-12-07 17:56:33,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([0.8616, 0.0922, 0.0462], device='cuda:0'), new_distribution = tensor([0.8620, 0.0919, 0.0461], device='cuda:0')
2024-12-07 17:56:33,956 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([0.8620, 0.0919, 0.0461], device='cuda:0'), new_distribution = tensor([0.8625, 0.0916, 0.0460], device='cuda:0')
2024-12-07 17:56:34,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([0.8625, 0.0916, 0.0460], device='cuda:0'), new_distribution = tensor([0.8629, 0.0913, 0.0458], device='cuda:0')
2024-12-07 17:56:34,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([0.8629, 0.0913, 0.0458], device='cuda:0'), new_distribution = tensor([0.8633, 0.0910, 0.0457], device='cuda:0')
2024-12-07 17:56:34,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([0.8633, 0.0910, 0.0457], device='cuda:0'), new_distribution = tensor([0.8638, 0.0907, 0.0455], device='cuda:0')
2024-12-07 17:56:34,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([0.8638, 0.0907, 0.0455], device='cuda:0'), new_distribution = tensor([0.8642, 0.0904, 0.0454], device='cuda:0')
2024-12-07 17:56:34,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([0.8642, 0.0904, 0.0454], device='cuda:0'), new_distribution = tensor([0.8646, 0.0901, 0.0453], device='cuda:0')
2024-12-07 17:56:34,562 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([0.8646, 0.0901, 0.0453], device='cuda:0'), new_distribution = tensor([0.8651, 0.0898, 0.0451], device='cuda:0')
2024-12-07 17:56:34,872 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([0.8651, 0.0898, 0.0451], device='cuda:0'), new_distribution = tensor([0.8655, 0.0895, 0.0450], device='cuda:0')
2024-12-07 17:56:35,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([0.8655, 0.0895, 0.0450], device='cuda:0'), new_distribution = tensor([0.8659, 0.0892, 0.0449], device='cuda:0')
2024-12-07 17:56:35,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([0.8659, 0.0892, 0.0449], device='cuda:0'), new_distribution = tensor([0.8664, 0.0889, 0.0447], device='cuda:0')
2024-12-07 17:56:35,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([0.8664, 0.0889, 0.0447], device='cuda:0'), new_distribution = tensor([0.8668, 0.0886, 0.0446], device='cuda:0')
2024-12-07 17:56:35,889 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([0.8668, 0.0886, 0.0446], device='cuda:0'), new_distribution = tensor([0.8672, 0.0883, 0.0445], device='cuda:0')
2024-12-07 17:56:36,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([0.8672, 0.0883, 0.0445], device='cuda:0'), new_distribution = tensor([0.8676, 0.0880, 0.0444], device='cuda:0')
2024-12-07 17:56:36,477 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([0.8676, 0.0880, 0.0444], device='cuda:0'), new_distribution = tensor([0.8681, 0.0877, 0.0442], device='cuda:0')
2024-12-07 17:56:36,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([0.8681, 0.0877, 0.0442], device='cuda:0'), new_distribution = tensor([0.8685, 0.0874, 0.0441], device='cuda:0')
2024-12-07 17:56:37,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([0.8685, 0.0874, 0.0441], device='cuda:0'), new_distribution = tensor([0.8689, 0.0871, 0.0440], device='cuda:0')
2024-12-07 17:56:37,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([0.8689, 0.0871, 0.0440], device='cuda:0'), new_distribution = tensor([0.8693, 0.0868, 0.0438], device='cuda:0')
2024-12-07 17:56:37,199 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([0.8693, 0.0868, 0.0438], device='cuda:0'), new_distribution = tensor([0.8698, 0.0865, 0.0437], device='cuda:0')
2024-12-07 17:56:37,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([0.8698, 0.0865, 0.0437], device='cuda:0'), new_distribution = tensor([0.8702, 0.0863, 0.0436], device='cuda:0')
2024-12-07 17:56:37,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([0.8702, 0.0863, 0.0436], device='cuda:0'), new_distribution = tensor([0.8706, 0.0860, 0.0434], device='cuda:0')
2024-12-07 17:56:37,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([0.8706, 0.0860, 0.0434], device='cuda:0'), new_distribution = tensor([0.8710, 0.0857, 0.0433], device='cuda:0')
2024-12-07 17:56:37,743 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([0.8710, 0.0857, 0.0433], device='cuda:0'), new_distribution = tensor([0.8714, 0.0854, 0.0432], device='cuda:0')
2024-12-07 17:56:37,834 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([0.8714, 0.0854, 0.0432], device='cuda:0'), new_distribution = tensor([0.8718, 0.0851, 0.0431], device='cuda:0')
2024-12-07 17:56:37,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([0.8718, 0.0851, 0.0431], device='cuda:0'), new_distribution = tensor([0.8722, 0.0848, 0.0429], device='cuda:0')
2024-12-07 17:56:38,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([0.8722, 0.0848, 0.0429], device='cuda:0'), new_distribution = tensor([0.8727, 0.0845, 0.0428], device='cuda:0')
2024-12-07 17:56:38,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([0.8727, 0.0845, 0.0428], device='cuda:0'), new_distribution = tensor([0.8731, 0.0843, 0.0427], device='cuda:0')
2024-12-07 17:56:38,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([0.8731, 0.0843, 0.0427], device='cuda:0'), new_distribution = tensor([0.8735, 0.0840, 0.0426], device='cuda:0')
2024-12-07 17:56:38,289 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([0.8735, 0.0840, 0.0426], device='cuda:0'), new_distribution = tensor([0.8739, 0.0837, 0.0424], device='cuda:0')
2024-12-07 17:56:38,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([0.8739, 0.0837, 0.0424], device='cuda:0'), new_distribution = tensor([0.8743, 0.0834, 0.0423], device='cuda:0')
2024-12-07 17:56:38,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([0.8743, 0.0834, 0.0423], device='cuda:0'), new_distribution = tensor([0.8747, 0.0831, 0.0422], device='cuda:0')
2024-12-07 17:56:38,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([0.8747, 0.0831, 0.0422], device='cuda:0'), new_distribution = tensor([0.8751, 0.0828, 0.0421], device='cuda:0')
2024-12-07 17:56:38,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([0.8751, 0.0828, 0.0421], device='cuda:0'), new_distribution = tensor([0.8755, 0.0826, 0.0419], device='cuda:0')
2024-12-07 17:56:39,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([0.8755, 0.0826, 0.0419], device='cuda:0'), new_distribution = tensor([0.8759, 0.0823, 0.0418], device='cuda:0')
2024-12-07 17:56:39,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([0.8759, 0.0823, 0.0418], device='cuda:0'), new_distribution = tensor([0.8763, 0.0820, 0.0417], device='cuda:0')
2024-12-07 17:56:39,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([0.8763, 0.0820, 0.0417], device='cuda:0'), new_distribution = tensor([0.8767, 0.0817, 0.0416], device='cuda:0')
2024-12-07 17:56:40,007 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 300: ref_distribution = tensor([0.8767, 0.0817, 0.0416], device='cuda:0'), new_distribution = tensor([0.8771, 0.0815, 0.0414], device='cuda:0')
2024-12-07 17:56:40,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 301: ref_distribution = tensor([0.8771, 0.0815, 0.0414], device='cuda:0'), new_distribution = tensor([0.8775, 0.0812, 0.0413], device='cuda:0')
2024-12-07 17:56:40,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 302: ref_distribution = tensor([0.8775, 0.0812, 0.0413], device='cuda:0'), new_distribution = tensor([0.8779, 0.0809, 0.0412], device='cuda:0')
2024-12-07 17:56:40,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 303: ref_distribution = tensor([0.8779, 0.0809, 0.0412], device='cuda:0'), new_distribution = tensor([0.8783, 0.0806, 0.0411], device='cuda:0')
2024-12-07 17:56:41,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 304: ref_distribution = tensor([0.8783, 0.0806, 0.0411], device='cuda:0'), new_distribution = tensor([0.8787, 0.0804, 0.0410], device='cuda:0')
2024-12-07 17:56:41,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 305: ref_distribution = tensor([0.8787, 0.0804, 0.0410], device='cuda:0'), new_distribution = tensor([0.8791, 0.0801, 0.0408], device='cuda:0')
2024-12-07 17:56:41,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 306: ref_distribution = tensor([0.8791, 0.0801, 0.0408], device='cuda:0'), new_distribution = tensor([0.8795, 0.0798, 0.0407], device='cuda:0')
2024-12-07 17:56:41,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 307: ref_distribution = tensor([0.8795, 0.0798, 0.0407], device='cuda:0'), new_distribution = tensor([0.8799, 0.0796, 0.0406], device='cuda:0')
2024-12-07 17:56:41,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 308: ref_distribution = tensor([0.8799, 0.0796, 0.0406], device='cuda:0'), new_distribution = tensor([0.8802, 0.0793, 0.0405], device='cuda:0')
2024-12-07 17:56:41,650 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 309: ref_distribution = tensor([0.8802, 0.0793, 0.0405], device='cuda:0'), new_distribution = tensor([0.8806, 0.0790, 0.0404], device='cuda:0')
2024-12-07 17:56:41,915 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 310: ref_distribution = tensor([0.8806, 0.0790, 0.0404], device='cuda:0'), new_distribution = tensor([0.8810, 0.0787, 0.0402], device='cuda:0')
2024-12-07 17:56:42,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 311: ref_distribution = tensor([0.8810, 0.0787, 0.0402], device='cuda:0'), new_distribution = tensor([0.8814, 0.0785, 0.0401], device='cuda:0')
2024-12-07 17:56:42,096 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 312: ref_distribution = tensor([0.8814, 0.0785, 0.0401], device='cuda:0'), new_distribution = tensor([0.8818, 0.0782, 0.0400], device='cuda:0')
2024-12-07 17:56:42,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 313: ref_distribution = tensor([0.8818, 0.0782, 0.0400], device='cuda:0'), new_distribution = tensor([0.8822, 0.0779, 0.0399], device='cuda:0')
2024-12-07 17:56:42,278 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 314: ref_distribution = tensor([0.8822, 0.0779, 0.0399], device='cuda:0'), new_distribution = tensor([0.8826, 0.0777, 0.0398], device='cuda:0')
2024-12-07 17:56:42,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 315: ref_distribution = tensor([0.8826, 0.0777, 0.0398], device='cuda:0'), new_distribution = tensor([0.8829, 0.0774, 0.0396], device='cuda:0')
2024-12-07 17:56:42,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 316: ref_distribution = tensor([0.8829, 0.0774, 0.0396], device='cuda:0'), new_distribution = tensor([0.8833, 0.0772, 0.0395], device='cuda:0')
2024-12-07 17:56:42,551 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 317: ref_distribution = tensor([0.8833, 0.0772, 0.0395], device='cuda:0'), new_distribution = tensor([0.8837, 0.0769, 0.0394], device='cuda:0')
2024-12-07 17:56:42,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 318: ref_distribution = tensor([0.8837, 0.0769, 0.0394], device='cuda:0'), new_distribution = tensor([0.8841, 0.0766, 0.0393], device='cuda:0')
2024-12-07 17:56:42,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 319: ref_distribution = tensor([0.8841, 0.0766, 0.0393], device='cuda:0'), new_distribution = tensor([0.8845, 0.0764, 0.0392], device='cuda:0')
2024-12-07 17:56:42,824 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 320: ref_distribution = tensor([0.8845, 0.0764, 0.0392], device='cuda:0'), new_distribution = tensor([0.8848, 0.0761, 0.0391], device='cuda:0')
2024-12-07 17:56:43,147 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 321: ref_distribution = tensor([0.8848, 0.0761, 0.0391], device='cuda:0'), new_distribution = tensor([0.8852, 0.0758, 0.0389], device='cuda:0')
2024-12-07 17:56:43,424 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 322: ref_distribution = tensor([0.8852, 0.0758, 0.0389], device='cuda:0'), new_distribution = tensor([0.8856, 0.0756, 0.0388], device='cuda:0')
2024-12-07 17:56:43,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 323: ref_distribution = tensor([0.8856, 0.0756, 0.0388], device='cuda:0'), new_distribution = tensor([0.8860, 0.0753, 0.0387], device='cuda:0')
2024-12-07 17:56:44,036 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 324: ref_distribution = tensor([0.8860, 0.0753, 0.0387], device='cuda:0'), new_distribution = tensor([0.8863, 0.0751, 0.0386], device='cuda:0')
2024-12-07 17:56:44,240 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 325: ref_distribution = tensor([0.8863, 0.0751, 0.0386], device='cuda:0'), new_distribution = tensor([0.8867, 0.0748, 0.0385], device='cuda:0')
2024-12-07 17:56:44,518 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 326: ref_distribution = tensor([0.8867, 0.0748, 0.0385], device='cuda:0'), new_distribution = tensor([0.8871, 0.0746, 0.0384], device='cuda:0')
2024-12-07 17:56:44,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 327: ref_distribution = tensor([0.8871, 0.0746, 0.0384], device='cuda:0'), new_distribution = tensor([0.8874, 0.0743, 0.0383], device='cuda:0')
2024-12-07 17:56:45,114 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 328: ref_distribution = tensor([0.8874, 0.0743, 0.0383], device='cuda:0'), new_distribution = tensor([0.8878, 0.0740, 0.0381], device='cuda:0')
2024-12-07 17:56:45,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 329: ref_distribution = tensor([0.8878, 0.0740, 0.0381], device='cuda:0'), new_distribution = tensor([0.8882, 0.0738, 0.0380], device='cuda:0')
2024-12-07 17:56:45,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 330: ref_distribution = tensor([0.8882, 0.0738, 0.0380], device='cuda:0'), new_distribution = tensor([0.8885, 0.0735, 0.0379], device='cuda:0')
2024-12-07 17:56:45,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 331: ref_distribution = tensor([0.8885, 0.0735, 0.0379], device='cuda:0'), new_distribution = tensor([0.8889, 0.0733, 0.0378], device='cuda:0')
2024-12-07 17:56:45,637 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 332: ref_distribution = tensor([0.8889, 0.0733, 0.0378], device='cuda:0'), new_distribution = tensor([0.8893, 0.0730, 0.0377], device='cuda:0')
2024-12-07 17:56:45,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 333: ref_distribution = tensor([0.8893, 0.0730, 0.0377], device='cuda:0'), new_distribution = tensor([0.8896, 0.0728, 0.0376], device='cuda:0')
2024-12-07 17:56:45,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 334: ref_distribution = tensor([0.8896, 0.0728, 0.0376], device='cuda:0'), new_distribution = tensor([0.8900, 0.0725, 0.0375], device='cuda:0')
2024-12-07 17:56:45,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 335: ref_distribution = tensor([0.8900, 0.0725, 0.0375], device='cuda:0'), new_distribution = tensor([0.8903, 0.0723, 0.0374], device='cuda:0')
2024-12-07 17:56:46,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 336: ref_distribution = tensor([0.8903, 0.0723, 0.0374], device='cuda:0'), new_distribution = tensor([0.8907, 0.0720, 0.0373], device='cuda:0')
2024-12-07 17:56:46,313 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 337: ref_distribution = tensor([0.8907, 0.0720, 0.0373], device='cuda:0'), new_distribution = tensor([0.8911, 0.0718, 0.0371], device='cuda:0')
2024-12-07 17:56:46,404 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 338: ref_distribution = tensor([0.8911, 0.0718, 0.0371], device='cuda:0'), new_distribution = tensor([0.8914, 0.0715, 0.0370], device='cuda:0')
2024-12-07 17:56:46,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 339: ref_distribution = tensor([0.8914, 0.0715, 0.0370], device='cuda:0'), new_distribution = tensor([0.8918, 0.0713, 0.0369], device='cuda:0')
2024-12-07 17:56:46,590 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 340: ref_distribution = tensor([0.8918, 0.0713, 0.0369], device='cuda:0'), new_distribution = tensor([0.8921, 0.0711, 0.0368], device='cuda:0')
2024-12-07 17:56:46,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 341: ref_distribution = tensor([0.8921, 0.0711, 0.0368], device='cuda:0'), new_distribution = tensor([0.8925, 0.0708, 0.0367], device='cuda:0')
2024-12-07 17:56:46,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 342: ref_distribution = tensor([0.8925, 0.0708, 0.0367], device='cuda:0'), new_distribution = tensor([0.8928, 0.0706, 0.0366], device='cuda:0')
2024-12-07 17:56:46,864 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 343: ref_distribution = tensor([0.8928, 0.0706, 0.0366], device='cuda:0'), new_distribution = tensor([0.8932, 0.0703, 0.0365], device='cuda:0')
2024-12-07 17:56:46,955 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 344: ref_distribution = tensor([0.8932, 0.0703, 0.0365], device='cuda:0'), new_distribution = tensor([0.8935, 0.0701, 0.0364], device='cuda:0')
2024-12-07 17:56:47,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 345: ref_distribution = tensor([0.8935, 0.0701, 0.0364], device='cuda:0'), new_distribution = tensor([0.8939, 0.0698, 0.0363], device='cuda:0')
2024-12-07 17:56:47,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 346: ref_distribution = tensor([0.8939, 0.0698, 0.0363], device='cuda:0'), new_distribution = tensor([0.8942, 0.0696, 0.0362], device='cuda:0')
2024-12-07 17:56:47,442 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 347: ref_distribution = tensor([0.8942, 0.0696, 0.0362], device='cuda:0'), new_distribution = tensor([0.8946, 0.0694, 0.0361], device='cuda:0')
2024-12-07 17:56:47,713 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 348: ref_distribution = tensor([0.8946, 0.0694, 0.0361], device='cuda:0'), new_distribution = tensor([0.8949, 0.0691, 0.0360], device='cuda:0')
2024-12-07 17:56:47,993 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 349: ref_distribution = tensor([0.8949, 0.0691, 0.0360], device='cuda:0'), new_distribution = tensor([0.8953, 0.0689, 0.0359], device='cuda:0')
2024-12-07 17:56:48,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 350: ref_distribution = tensor([0.8953, 0.0689, 0.0359], device='cuda:0'), new_distribution = tensor([0.8956, 0.0686, 0.0357], device='cuda:0')
2024-12-07 17:56:48,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 351: ref_distribution = tensor([0.8956, 0.0686, 0.0357], device='cuda:0'), new_distribution = tensor([0.8960, 0.0684, 0.0356], device='cuda:0')
2024-12-07 17:56:48,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 352: ref_distribution = tensor([0.8960, 0.0684, 0.0356], device='cuda:0'), new_distribution = tensor([0.8963, 0.0682, 0.0355], device='cuda:0')
2024-12-07 17:56:49,124 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 353: ref_distribution = tensor([0.8963, 0.0682, 0.0355], device='cuda:0'), new_distribution = tensor([0.8967, 0.0679, 0.0354], device='cuda:0')
2024-12-07 17:56:49,420 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 354: ref_distribution = tensor([0.8967, 0.0679, 0.0354], device='cuda:0'), new_distribution = tensor([0.8970, 0.0677, 0.0353], device='cuda:0')
2024-12-07 17:56:49,680 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 355: ref_distribution = tensor([0.8970, 0.0677, 0.0353], device='cuda:0'), new_distribution = tensor([0.8973, 0.0674, 0.0352], device='cuda:0')
2024-12-07 17:56:49,772 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 356: ref_distribution = tensor([0.8973, 0.0674, 0.0352], device='cuda:0'), new_distribution = tensor([0.8977, 0.0672, 0.0351], device='cuda:0')
2024-12-07 17:56:49,863 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 357: ref_distribution = tensor([0.8977, 0.0672, 0.0351], device='cuda:0'), new_distribution = tensor([0.8980, 0.0670, 0.0350], device='cuda:0')
2024-12-07 17:56:49,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 358: ref_distribution = tensor([0.8980, 0.0670, 0.0350], device='cuda:0'), new_distribution = tensor([0.8983, 0.0667, 0.0349], device='cuda:0')
2024-12-07 17:56:50,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 359: ref_distribution = tensor([0.8983, 0.0667, 0.0349], device='cuda:0'), new_distribution = tensor([0.8987, 0.0665, 0.0348], device='cuda:0')
2024-12-07 17:56:50,137 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 360: ref_distribution = tensor([0.8987, 0.0665, 0.0348], device='cuda:0'), new_distribution = tensor([0.8990, 0.0663, 0.0347], device='cuda:0')
2024-12-07 17:56:50,240 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 361: ref_distribution = tensor([0.8990, 0.0663, 0.0347], device='cuda:0'), new_distribution = tensor([0.8993, 0.0661, 0.0346], device='cuda:0')
2024-12-07 17:56:50,518 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 362: ref_distribution = tensor([0.8993, 0.0661, 0.0346], device='cuda:0'), new_distribution = tensor([0.8997, 0.0658, 0.0345], device='cuda:0')
2024-12-07 17:56:50,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 363: ref_distribution = tensor([0.8997, 0.0658, 0.0345], device='cuda:0'), new_distribution = tensor([0.9000, 0.0656, 0.0344], device='cuda:0')
2024-12-07 17:56:50,701 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 364: ref_distribution = tensor([0.9000, 0.0656, 0.0344], device='cuda:0'), new_distribution = tensor([0.9003, 0.0654, 0.0343], device='cuda:0')
2024-12-07 17:56:50,792 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 365: ref_distribution = tensor([0.9003, 0.0654, 0.0343], device='cuda:0'), new_distribution = tensor([0.9007, 0.0651, 0.0342], device='cuda:0')
2024-12-07 17:56:50,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 366: ref_distribution = tensor([0.9007, 0.0651, 0.0342], device='cuda:0'), new_distribution = tensor([0.9010, 0.0649, 0.0341], device='cuda:0')
2024-12-07 17:56:50,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 367: ref_distribution = tensor([0.9010, 0.0649, 0.0341], device='cuda:0'), new_distribution = tensor([0.9013, 0.0647, 0.0340], device='cuda:0')
2024-12-07 17:56:51,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 368: ref_distribution = tensor([0.9013, 0.0647, 0.0340], device='cuda:0'), new_distribution = tensor([0.9017, 0.0645, 0.0339], device='cuda:0')
2024-12-07 17:56:51,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 369: ref_distribution = tensor([0.9017, 0.0645, 0.0339], device='cuda:0'), new_distribution = tensor([0.9020, 0.0642, 0.0338], device='cuda:0')
2024-12-07 17:56:51,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 370: ref_distribution = tensor([0.9020, 0.0642, 0.0338], device='cuda:0'), new_distribution = tensor([0.9023, 0.0640, 0.0337], device='cuda:0')
2024-12-07 17:56:51,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 371: ref_distribution = tensor([0.9023, 0.0640, 0.0337], device='cuda:0'), new_distribution = tensor([0.9026, 0.0638, 0.0336], device='cuda:0')
2024-12-07 17:56:51,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 372: ref_distribution = tensor([0.9026, 0.0638, 0.0336], device='cuda:0'), new_distribution = tensor([0.9030, 0.0636, 0.0335], device='cuda:0')
2024-12-07 17:56:51,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 373: ref_distribution = tensor([0.9030, 0.0636, 0.0335], device='cuda:0'), new_distribution = tensor([0.9033, 0.0633, 0.0334], device='cuda:0')
2024-12-07 17:56:51,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 374: ref_distribution = tensor([0.9033, 0.0633, 0.0334], device='cuda:0'), new_distribution = tensor([0.9036, 0.0631, 0.0333], device='cuda:0')
2024-12-07 17:56:52,140 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 375: ref_distribution = tensor([0.9036, 0.0631, 0.0333], device='cuda:0'), new_distribution = tensor([0.9039, 0.0629, 0.0332], device='cuda:0')
2024-12-07 17:56:52,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 376: ref_distribution = tensor([0.9039, 0.0629, 0.0332], device='cuda:0'), new_distribution = tensor([0.9042, 0.0627, 0.0331], device='cuda:0')
2024-12-07 17:56:52,698 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 377: ref_distribution = tensor([0.9042, 0.0627, 0.0331], device='cuda:0'), new_distribution = tensor([0.9045, 0.0625, 0.0330], device='cuda:0')
2024-12-07 17:56:52,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 378: ref_distribution = tensor([0.9045, 0.0625, 0.0330], device='cuda:0'), new_distribution = tensor([0.9049, 0.0622, 0.0329], device='cuda:0')
2024-12-07 17:56:53,295 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 379: ref_distribution = tensor([0.9049, 0.0622, 0.0329], device='cuda:0'), new_distribution = tensor([0.9052, 0.0620, 0.0328], device='cuda:0')
2024-12-07 17:56:53,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 380: ref_distribution = tensor([0.9052, 0.0620, 0.0328], device='cuda:0'), new_distribution = tensor([0.9055, 0.0618, 0.0327], device='cuda:0')
2024-12-07 17:56:53,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 381: ref_distribution = tensor([0.9055, 0.0618, 0.0327], device='cuda:0'), new_distribution = tensor([0.9058, 0.0616, 0.0326], device='cuda:0')
2024-12-07 17:56:54,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 382: ref_distribution = tensor([0.9058, 0.0616, 0.0326], device='cuda:0'), new_distribution = tensor([0.9061, 0.0614, 0.0325], device='cuda:0')
2024-12-07 17:56:54,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 383: ref_distribution = tensor([0.9061, 0.0614, 0.0325], device='cuda:0'), new_distribution = tensor([0.9064, 0.0611, 0.0324], device='cuda:0')
2024-12-07 17:56:54,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 384: ref_distribution = tensor([0.9064, 0.0611, 0.0324], device='cuda:0'), new_distribution = tensor([0.9067, 0.0609, 0.0323], device='cuda:0')
2024-12-07 17:56:54,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 385: ref_distribution = tensor([0.9067, 0.0609, 0.0323], device='cuda:0'), new_distribution = tensor([0.9071, 0.0607, 0.0322], device='cuda:0')
2024-12-07 17:56:54,409 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 386: ref_distribution = tensor([0.9071, 0.0607, 0.0322], device='cuda:0'), new_distribution = tensor([0.9074, 0.0605, 0.0321], device='cuda:0')
2024-12-07 17:56:54,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 387: ref_distribution = tensor([0.9074, 0.0605, 0.0321], device='cuda:0'), new_distribution = tensor([0.9077, 0.0603, 0.0320], device='cuda:0')
2024-12-07 17:56:54,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 388: ref_distribution = tensor([0.9077, 0.0603, 0.0320], device='cuda:0'), new_distribution = tensor([0.9080, 0.0601, 0.0319], device='cuda:0')
2024-12-07 17:56:54,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 389: ref_distribution = tensor([0.9080, 0.0601, 0.0319], device='cuda:0'), new_distribution = tensor([0.9083, 0.0599, 0.0318], device='cuda:0')
2024-12-07 17:56:54,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 390: ref_distribution = tensor([0.9083, 0.0599, 0.0318], device='cuda:0'), new_distribution = tensor([0.9086, 0.0597, 0.0318], device='cuda:0')
2024-12-07 17:56:54,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 391: ref_distribution = tensor([0.9086, 0.0597, 0.0318], device='cuda:0'), new_distribution = tensor([0.9089, 0.0594, 0.0317], device='cuda:0')
2024-12-07 17:56:55,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 392: ref_distribution = tensor([0.9089, 0.0594, 0.0317], device='cuda:0'), new_distribution = tensor([0.9092, 0.0592, 0.0316], device='cuda:0')
2024-12-07 17:56:55,278 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 393: ref_distribution = tensor([0.9092, 0.0592, 0.0316], device='cuda:0'), new_distribution = tensor([0.9095, 0.0590, 0.0315], device='cuda:0')
2024-12-07 17:56:55,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 394: ref_distribution = tensor([0.9095, 0.0590, 0.0315], device='cuda:0'), new_distribution = tensor([0.9098, 0.0588, 0.0314], device='cuda:0')
2024-12-07 17:56:55,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 395: ref_distribution = tensor([0.9098, 0.0588, 0.0314], device='cuda:0'), new_distribution = tensor([0.9101, 0.0586, 0.0313], device='cuda:0')
2024-12-07 17:56:55,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 396: ref_distribution = tensor([0.9101, 0.0586, 0.0313], device='cuda:0'), new_distribution = tensor([0.9104, 0.0584, 0.0312], device='cuda:0')
2024-12-07 17:56:56,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 397: ref_distribution = tensor([0.9104, 0.0584, 0.0312], device='cuda:0'), new_distribution = tensor([0.9107, 0.0582, 0.0311], device='cuda:0')
2024-12-07 17:56:56,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 398: ref_distribution = tensor([0.9107, 0.0582, 0.0311], device='cuda:0'), new_distribution = tensor([0.9110, 0.0580, 0.0310], device='cuda:0')
2024-12-07 17:56:56,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 399: ref_distribution = tensor([0.9110, 0.0580, 0.0310], device='cuda:0'), new_distribution = tensor([0.9113, 0.0578, 0.0309], device='cuda:0')
2024-12-07 17:56:56,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 400: ref_distribution = tensor([0.9113, 0.0578, 0.0309], device='cuda:0'), new_distribution = tensor([0.9116, 0.0576, 0.0308], device='cuda:0')
2024-12-07 17:56:57,239 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 401: ref_distribution = tensor([0.9116, 0.0576, 0.0308], device='cuda:0'), new_distribution = tensor([0.9119, 0.0574, 0.0307], device='cuda:0')
2024-12-07 17:56:57,470 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 402: ref_distribution = tensor([0.9119, 0.0574, 0.0307], device='cuda:0'), new_distribution = tensor([0.9122, 0.0572, 0.0306], device='cuda:0')
2024-12-07 17:56:57,651 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 403: ref_distribution = tensor([0.9122, 0.0572, 0.0306], device='cuda:0'), new_distribution = tensor([0.9125, 0.0570, 0.0306], device='cuda:0')
2024-12-07 17:56:57,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 404: ref_distribution = tensor([0.9125, 0.0570, 0.0306], device='cuda:0'), new_distribution = tensor([0.9128, 0.0568, 0.0305], device='cuda:0')
2024-12-07 17:56:58,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 405: ref_distribution = tensor([0.9128, 0.0568, 0.0305], device='cuda:0'), new_distribution = tensor([0.9131, 0.0566, 0.0304], device='cuda:0')
2024-12-07 17:56:58,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 406: ref_distribution = tensor([0.9131, 0.0566, 0.0304], device='cuda:0'), new_distribution = tensor([0.9134, 0.0564, 0.0303], device='cuda:0')
2024-12-07 17:56:58,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 407: ref_distribution = tensor([0.9134, 0.0564, 0.0303], device='cuda:0'), new_distribution = tensor([0.9136, 0.0562, 0.0302], device='cuda:0')
2024-12-07 17:56:58,291 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 408: ref_distribution = tensor([0.9136, 0.0562, 0.0302], device='cuda:0'), new_distribution = tensor([0.9139, 0.0560, 0.0301], device='cuda:0')
2024-12-07 17:56:58,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 409: ref_distribution = tensor([0.9139, 0.0560, 0.0301], device='cuda:0'), new_distribution = tensor([0.9142, 0.0558, 0.0300], device='cuda:0')
2024-12-07 17:56:58,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 410: ref_distribution = tensor([0.9142, 0.0558, 0.0300], device='cuda:0'), new_distribution = tensor([0.9145, 0.0556, 0.0299], device='cuda:0')
2024-12-07 17:56:58,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 411: ref_distribution = tensor([0.9145, 0.0556, 0.0299], device='cuda:0'), new_distribution = tensor([0.9148, 0.0554, 0.0298], device='cuda:0')
2024-12-07 17:56:58,651 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 412: ref_distribution = tensor([0.9148, 0.0554, 0.0298], device='cuda:0'), new_distribution = tensor([0.9151, 0.0552, 0.0297], device='cuda:0')
2024-12-07 17:56:58,738 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 413: ref_distribution = tensor([0.9151, 0.0552, 0.0297], device='cuda:0'), new_distribution = tensor([0.9154, 0.0550, 0.0297], device='cuda:0')
2024-12-07 17:56:58,828 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 414: ref_distribution = tensor([0.9154, 0.0550, 0.0297], device='cuda:0'), new_distribution = tensor([0.9157, 0.0548, 0.0296], device='cuda:0')
2024-12-07 17:56:58,916 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 415: ref_distribution = tensor([0.9157, 0.0548, 0.0296], device='cuda:0'), new_distribution = tensor([0.9159, 0.0546, 0.0295], device='cuda:0')
2024-12-07 17:56:59,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 416: ref_distribution = tensor([0.9159, 0.0546, 0.0295], device='cuda:0'), new_distribution = tensor([0.9162, 0.0544, 0.0294], device='cuda:0')
2024-12-07 17:56:59,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 417: ref_distribution = tensor([0.9162, 0.0544, 0.0294], device='cuda:0'), new_distribution = tensor([0.9165, 0.0542, 0.0293], device='cuda:0')
2024-12-07 17:56:59,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 418: ref_distribution = tensor([0.9165, 0.0542, 0.0293], device='cuda:0'), new_distribution = tensor([0.9168, 0.0540, 0.0292], device='cuda:0')
2024-12-07 17:56:59,518 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 419: ref_distribution = tensor([0.9168, 0.0540, 0.0292], device='cuda:0'), new_distribution = tensor([0.9171, 0.0538, 0.0291], device='cuda:0')
2024-12-07 17:56:59,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 420: ref_distribution = tensor([0.9171, 0.0538, 0.0291], device='cuda:0'), new_distribution = tensor([0.9173, 0.0536, 0.0291], device='cuda:0')
2024-12-07 17:56:59,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 421: ref_distribution = tensor([0.9173, 0.0536, 0.0291], device='cuda:0'), new_distribution = tensor([0.9176, 0.0534, 0.0290], device='cuda:0')
2024-12-07 17:56:59,793 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 422: ref_distribution = tensor([0.9176, 0.0534, 0.0290], device='cuda:0'), new_distribution = tensor([0.9179, 0.0532, 0.0289], device='cuda:0')
2024-12-07 17:56:59,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 423: ref_distribution = tensor([0.9179, 0.0532, 0.0289], device='cuda:0'), new_distribution = tensor([0.9182, 0.0530, 0.0288], device='cuda:0')
2024-12-07 17:56:59,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 424: ref_distribution = tensor([0.9182, 0.0530, 0.0288], device='cuda:0'), new_distribution = tensor([0.9184, 0.0528, 0.0287], device='cuda:0')
2024-12-07 17:57:00,069 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 425: ref_distribution = tensor([0.9184, 0.0528, 0.0287], device='cuda:0'), new_distribution = tensor([0.9187, 0.0527, 0.0286], device='cuda:0')
2024-12-07 17:57:00,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 426: ref_distribution = tensor([0.9187, 0.0527, 0.0286], device='cuda:0'), new_distribution = tensor([0.9190, 0.0525, 0.0285], device='cuda:0')
2024-12-07 17:57:00,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 427: ref_distribution = tensor([0.9190, 0.0525, 0.0285], device='cuda:0'), new_distribution = tensor([0.9193, 0.0523, 0.0285], device='cuda:0')
2024-12-07 17:57:00,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 428: ref_distribution = tensor([0.9193, 0.0523, 0.0285], device='cuda:0'), new_distribution = tensor([0.9195, 0.0521, 0.0284], device='cuda:0')
2024-12-07 17:57:00,433 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 429: ref_distribution = tensor([0.9195, 0.0521, 0.0284], device='cuda:0'), new_distribution = tensor([0.9198, 0.0519, 0.0283], device='cuda:0')
2024-12-07 17:57:00,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 430: ref_distribution = tensor([0.9198, 0.0519, 0.0283], device='cuda:0'), new_distribution = tensor([0.9201, 0.0517, 0.0282], device='cuda:0')
2024-12-07 17:57:00,615 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 431: ref_distribution = tensor([0.9201, 0.0517, 0.0282], device='cuda:0'), new_distribution = tensor([0.9203, 0.0515, 0.0281], device='cuda:0')
2024-12-07 17:57:00,708 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 432: ref_distribution = tensor([0.9203, 0.0515, 0.0281], device='cuda:0'), new_distribution = tensor([0.9206, 0.0514, 0.0280], device='cuda:0')
2024-12-07 17:57:00,810 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 433: ref_distribution = tensor([0.9206, 0.0514, 0.0280], device='cuda:0'), new_distribution = tensor([0.9209, 0.0512, 0.0280], device='cuda:0')
2024-12-07 17:57:01,121 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 434: ref_distribution = tensor([0.9209, 0.0512, 0.0280], device='cuda:0'), new_distribution = tensor([0.9211, 0.0510, 0.0279], device='cuda:0')
2024-12-07 17:57:01,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 435: ref_distribution = tensor([0.9211, 0.0510, 0.0279], device='cuda:0'), new_distribution = tensor([0.9214, 0.0508, 0.0278], device='cuda:0')
2024-12-07 17:57:01,697 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 436: ref_distribution = tensor([0.9214, 0.0508, 0.0278], device='cuda:0'), new_distribution = tensor([0.9217, 0.0506, 0.0277], device='cuda:0')
2024-12-07 17:57:01,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 437: ref_distribution = tensor([0.9217, 0.0506, 0.0277], device='cuda:0'), new_distribution = tensor([0.9219, 0.0504, 0.0276], device='cuda:0')
2024-12-07 17:57:02,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 438: ref_distribution = tensor([0.9219, 0.0504, 0.0276], device='cuda:0'), new_distribution = tensor([0.9222, 0.0503, 0.0275], device='cuda:0')
2024-12-07 17:57:02,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 439: ref_distribution = tensor([0.9222, 0.0503, 0.0275], device='cuda:0'), new_distribution = tensor([0.9225, 0.0501, 0.0275], device='cuda:0')
2024-12-07 17:57:02,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 440: ref_distribution = tensor([0.9225, 0.0501, 0.0275], device='cuda:0'), new_distribution = tensor([0.9227, 0.0499, 0.0274], device='cuda:0')
2024-12-07 17:57:02,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 441: ref_distribution = tensor([0.9227, 0.0499, 0.0274], device='cuda:0'), new_distribution = tensor([0.9230, 0.0497, 0.0273], device='cuda:0')
2024-12-07 17:57:02,651 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 442: ref_distribution = tensor([0.9230, 0.0497, 0.0273], device='cuda:0'), new_distribution = tensor([0.9233, 0.0495, 0.0272], device='cuda:0')
2024-12-07 17:57:02,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 443: ref_distribution = tensor([0.9233, 0.0495, 0.0272], device='cuda:0'), new_distribution = tensor([0.9235, 0.0494, 0.0271], device='cuda:0')
2024-12-07 17:57:02,831 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 444: ref_distribution = tensor([0.9235, 0.0494, 0.0271], device='cuda:0'), new_distribution = tensor([0.9238, 0.0492, 0.0271], device='cuda:0')
2024-12-07 17:57:02,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 445: ref_distribution = tensor([0.9238, 0.0492, 0.0271], device='cuda:0'), new_distribution = tensor([0.9240, 0.0490, 0.0270], device='cuda:0')
2024-12-07 17:57:03,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 446: ref_distribution = tensor([0.9240, 0.0490, 0.0270], device='cuda:0'), new_distribution = tensor([0.9243, 0.0488, 0.0269], device='cuda:0')
2024-12-07 17:57:03,103 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 447: ref_distribution = tensor([0.9243, 0.0488, 0.0269], device='cuda:0'), new_distribution = tensor([0.9245, 0.0486, 0.0268], device='cuda:0')
2024-12-07 17:57:03,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 448: ref_distribution = tensor([0.9245, 0.0486, 0.0268], device='cuda:0'), new_distribution = tensor([0.9248, 0.0485, 0.0267], device='cuda:0')
2024-12-07 17:57:03,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 449: ref_distribution = tensor([0.9248, 0.0485, 0.0267], device='cuda:0'), new_distribution = tensor([0.9250, 0.0483, 0.0267], device='cuda:0')
2024-12-07 17:57:03,378 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 450: ref_distribution = tensor([0.9250, 0.0483, 0.0267], device='cuda:0'), new_distribution = tensor([0.9253, 0.0481, 0.0266], device='cuda:0')
2024-12-07 17:57:03,469 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 451: ref_distribution = tensor([0.9253, 0.0481, 0.0266], device='cuda:0'), new_distribution = tensor([0.9256, 0.0479, 0.0265], device='cuda:0')
2024-12-07 17:57:03,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 452: ref_distribution = tensor([0.9256, 0.0479, 0.0265], device='cuda:0'), new_distribution = tensor([0.9258, 0.0478, 0.0264], device='cuda:0')
2024-12-07 17:57:03,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 453: ref_distribution = tensor([0.9258, 0.0478, 0.0264], device='cuda:0'), new_distribution = tensor([0.9261, 0.0476, 0.0263], device='cuda:0')
2024-12-07 17:57:03,743 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 454: ref_distribution = tensor([0.9261, 0.0476, 0.0263], device='cuda:0'), new_distribution = tensor([0.9263, 0.0474, 0.0263], device='cuda:0')
2024-12-07 17:57:03,835 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 455: ref_distribution = tensor([0.9263, 0.0474, 0.0263], device='cuda:0'), new_distribution = tensor([0.9266, 0.0473, 0.0262], device='cuda:0')
2024-12-07 17:57:03,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 456: ref_distribution = tensor([0.9266, 0.0473, 0.0262], device='cuda:0'), new_distribution = tensor([0.9268, 0.0471, 0.0261], device='cuda:0')
2024-12-07 17:57:04,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 457: ref_distribution = tensor([0.9268, 0.0471, 0.0261], device='cuda:0'), new_distribution = tensor([0.9271, 0.0469, 0.0260], device='cuda:0')
2024-12-07 17:57:04,103 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 458: ref_distribution = tensor([0.9271, 0.0469, 0.0260], device='cuda:0'), new_distribution = tensor([0.9273, 0.0467, 0.0260], device='cuda:0')
2024-12-07 17:57:04,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 459: ref_distribution = tensor([0.9273, 0.0467, 0.0260], device='cuda:0'), new_distribution = tensor([0.9275, 0.0466, 0.0259], device='cuda:0')
2024-12-07 17:57:04,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 460: ref_distribution = tensor([0.9275, 0.0466, 0.0259], device='cuda:0'), new_distribution = tensor([0.9278, 0.0464, 0.0258], device='cuda:0')
2024-12-07 17:57:04,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 461: ref_distribution = tensor([0.9278, 0.0464, 0.0258], device='cuda:0'), new_distribution = tensor([0.9280, 0.0462, 0.0257], device='cuda:0')
2024-12-07 17:57:04,463 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 462: ref_distribution = tensor([0.9280, 0.0462, 0.0257], device='cuda:0'), new_distribution = tensor([0.9283, 0.0461, 0.0256], device='cuda:0')
2024-12-07 17:57:04,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 463: ref_distribution = tensor([0.9283, 0.0461, 0.0256], device='cuda:0'), new_distribution = tensor([0.9285, 0.0459, 0.0256], device='cuda:0')
2024-12-07 17:57:04,649 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 464: ref_distribution = tensor([0.9285, 0.0459, 0.0256], device='cuda:0'), new_distribution = tensor([0.9288, 0.0457, 0.0255], device='cuda:0')
2024-12-07 17:57:04,738 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 465: ref_distribution = tensor([0.9288, 0.0457, 0.0255], device='cuda:0'), new_distribution = tensor([0.9290, 0.0456, 0.0254], device='cuda:0')
2024-12-07 17:57:04,831 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 466: ref_distribution = tensor([0.9290, 0.0456, 0.0254], device='cuda:0'), new_distribution = tensor([0.9292, 0.0454, 0.0253], device='cuda:0')
2024-12-07 17:57:04,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 467: ref_distribution = tensor([0.9292, 0.0454, 0.0253], device='cuda:0'), new_distribution = tensor([0.9295, 0.0452, 0.0253], device='cuda:0')
2024-12-07 17:57:05,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 468: ref_distribution = tensor([0.9295, 0.0452, 0.0253], device='cuda:0'), new_distribution = tensor([0.9297, 0.0451, 0.0252], device='cuda:0')
2024-12-07 17:57:05,111 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 469: ref_distribution = tensor([0.9297, 0.0451, 0.0252], device='cuda:0'), new_distribution = tensor([0.9300, 0.0449, 0.0251], device='cuda:0')
2024-12-07 17:57:05,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 470: ref_distribution = tensor([0.9300, 0.0449, 0.0251], device='cuda:0'), new_distribution = tensor([0.9302, 0.0448, 0.0250], device='cuda:0')
2024-12-07 17:57:05,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 471: ref_distribution = tensor([0.9302, 0.0448, 0.0250], device='cuda:0'), new_distribution = tensor([0.9304, 0.0446, 0.0250], device='cuda:0')
2024-12-07 17:57:05,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 472: ref_distribution = tensor([0.9304, 0.0446, 0.0250], device='cuda:0'), new_distribution = tensor([0.9307, 0.0444, 0.0249], device='cuda:0')
2024-12-07 17:57:05,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 473: ref_distribution = tensor([0.9307, 0.0444, 0.0249], device='cuda:0'), new_distribution = tensor([0.9309, 0.0443, 0.0248], device='cuda:0')
2024-12-07 17:57:05,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 474: ref_distribution = tensor([0.9309, 0.0443, 0.0248], device='cuda:0'), new_distribution = tensor([0.9311, 0.0441, 0.0247], device='cuda:0')
2024-12-07 17:57:05,659 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 475: ref_distribution = tensor([0.9311, 0.0441, 0.0247], device='cuda:0'), new_distribution = tensor([0.9314, 0.0439, 0.0247], device='cuda:0')
2024-12-07 17:57:05,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 476: ref_distribution = tensor([0.9314, 0.0439, 0.0247], device='cuda:0'), new_distribution = tensor([0.9316, 0.0438, 0.0246], device='cuda:0')
2024-12-07 17:57:05,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 477: ref_distribution = tensor([0.9316, 0.0438, 0.0246], device='cuda:0'), new_distribution = tensor([0.9318, 0.0436, 0.0245], device='cuda:0')
2024-12-07 17:57:05,936 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 478: ref_distribution = tensor([0.9318, 0.0436, 0.0245], device='cuda:0'), new_distribution = tensor([0.9321, 0.0435, 0.0245], device='cuda:0')
2024-12-07 17:57:06,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 479: ref_distribution = tensor([0.9321, 0.0435, 0.0245], device='cuda:0'), new_distribution = tensor([0.9323, 0.0433, 0.0244], device='cuda:0')
2024-12-07 17:57:06,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 480: ref_distribution = tensor([0.9323, 0.0433, 0.0244], device='cuda:0'), new_distribution = tensor([0.9325, 0.0431, 0.0243], device='cuda:0')
2024-12-07 17:57:06,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 481: ref_distribution = tensor([0.9325, 0.0431, 0.0243], device='cuda:0'), new_distribution = tensor([0.9328, 0.0430, 0.0242], device='cuda:0')
2024-12-07 17:57:06,304 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 482: ref_distribution = tensor([0.9328, 0.0430, 0.0242], device='cuda:0'), new_distribution = tensor([0.9330, 0.0428, 0.0242], device='cuda:0')
2024-12-07 17:57:06,395 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 483: ref_distribution = tensor([0.9330, 0.0428, 0.0242], device='cuda:0'), new_distribution = tensor([0.9332, 0.0427, 0.0241], device='cuda:0')
2024-12-07 17:57:06,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 484: ref_distribution = tensor([0.9332, 0.0427, 0.0241], device='cuda:0'), new_distribution = tensor([0.9335, 0.0425, 0.0240], device='cuda:0')
2024-12-07 17:57:06,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 485: ref_distribution = tensor([0.9335, 0.0425, 0.0240], device='cuda:0'), new_distribution = tensor([0.9337, 0.0424, 0.0240], device='cuda:0')
2024-12-07 17:57:06,911 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 486: ref_distribution = tensor([0.9337, 0.0424, 0.0240], device='cuda:0'), new_distribution = tensor([0.9339, 0.0422, 0.0239], device='cuda:0')
2024-12-07 17:57:07,269 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 487: ref_distribution = tensor([0.9339, 0.0422, 0.0239], device='cuda:0'), new_distribution = tensor([0.9341, 0.0421, 0.0238], device='cuda:0')
2024-12-07 17:57:07,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 488: ref_distribution = tensor([0.9341, 0.0421, 0.0238], device='cuda:0'), new_distribution = tensor([0.9344, 0.0419, 0.0237], device='cuda:0')
2024-12-07 17:57:08,063 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 489: ref_distribution = tensor([0.9344, 0.0419, 0.0237], device='cuda:0'), new_distribution = tensor([0.9346, 0.0417, 0.0237], device='cuda:0')
2024-12-07 17:57:08,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 490: ref_distribution = tensor([0.9346, 0.0417, 0.0237], device='cuda:0'), new_distribution = tensor([0.9348, 0.0416, 0.0236], device='cuda:0')
2024-12-07 17:57:08,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 491: ref_distribution = tensor([0.9348, 0.0416, 0.0236], device='cuda:0'), new_distribution = tensor([0.9350, 0.0414, 0.0235], device='cuda:0')
2024-12-07 17:57:09,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 492: ref_distribution = tensor([0.9350, 0.0414, 0.0235], device='cuda:0'), new_distribution = tensor([0.9352, 0.0413, 0.0235], device='cuda:0')
2024-12-07 17:57:09,529 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 493: ref_distribution = tensor([0.9352, 0.0413, 0.0235], device='cuda:0'), new_distribution = tensor([0.9355, 0.0411, 0.0234], device='cuda:0')
2024-12-07 17:57:09,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 494: ref_distribution = tensor([0.9355, 0.0411, 0.0234], device='cuda:0'), new_distribution = tensor([0.9357, 0.0410, 0.0233], device='cuda:0')
2024-12-07 17:57:10,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 495: ref_distribution = tensor([0.9357, 0.0410, 0.0233], device='cuda:0'), new_distribution = tensor([0.9359, 0.0408, 0.0233], device='cuda:0')
2024-12-07 17:57:10,700 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 496: ref_distribution = tensor([0.9359, 0.0408, 0.0233], device='cuda:0'), new_distribution = tensor([0.9361, 0.0407, 0.0232], device='cuda:0')
2024-12-07 17:57:11,143 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 497: ref_distribution = tensor([0.9361, 0.0407, 0.0232], device='cuda:0'), new_distribution = tensor([0.9363, 0.0405, 0.0231], device='cuda:0')
2024-12-07 17:57:11,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 498: ref_distribution = tensor([0.9363, 0.0405, 0.0231], device='cuda:0'), new_distribution = tensor([0.9366, 0.0404, 0.0230], device='cuda:0')
2024-12-07 17:57:11,910 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 499: ref_distribution = tensor([0.9366, 0.0404, 0.0230], device='cuda:0'), new_distribution = tensor([0.9368, 0.0402, 0.0230], device='cuda:0')
2024-12-07 17:57:12,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 500: ref_distribution = tensor([0.9368, 0.0402, 0.0230], device='cuda:0'), new_distribution = tensor([0.9370, 0.0401, 0.0229], device='cuda:0')
2024-12-07 17:57:12,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 501: ref_distribution = tensor([0.9370, 0.0401, 0.0229], device='cuda:0'), new_distribution = tensor([0.9372, 0.0399, 0.0228], device='cuda:0')
2024-12-07 17:57:13,028 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 502: ref_distribution = tensor([0.9372, 0.0399, 0.0228], device='cuda:0'), new_distribution = tensor([0.9374, 0.0398, 0.0228], device='cuda:0')
2024-12-07 17:57:13,398 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 503: ref_distribution = tensor([0.9374, 0.0398, 0.0228], device='cuda:0'), new_distribution = tensor([0.9376, 0.0397, 0.0227], device='cuda:0')
2024-12-07 17:57:13,875 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 504: ref_distribution = tensor([0.9376, 0.0397, 0.0227], device='cuda:0'), new_distribution = tensor([0.9379, 0.0395, 0.0226], device='cuda:0')
2024-12-07 17:57:14,280 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 505: ref_distribution = tensor([0.9379, 0.0395, 0.0226], device='cuda:0'), new_distribution = tensor([0.9381, 0.0394, 0.0226], device='cuda:0')
2024-12-07 17:57:14,574 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 506: ref_distribution = tensor([0.9381, 0.0394, 0.0226], device='cuda:0'), new_distribution = tensor([0.9383, 0.0392, 0.0225], device='cuda:0')
2024-12-07 17:57:15,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 507: ref_distribution = tensor([0.9383, 0.0392, 0.0225], device='cuda:0'), new_distribution = tensor([0.9385, 0.0391, 0.0224], device='cuda:0')
2024-12-07 17:57:15,485 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 508: ref_distribution = tensor([0.9385, 0.0391, 0.0224], device='cuda:0'), new_distribution = tensor([0.9387, 0.0389, 0.0224], device='cuda:0')
2024-12-07 17:57:15,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 509: ref_distribution = tensor([0.9387, 0.0389, 0.0224], device='cuda:0'), new_distribution = tensor([0.9389, 0.0388, 0.0223], device='cuda:0')
2024-12-07 17:57:16,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 510: ref_distribution = tensor([0.9389, 0.0388, 0.0223], device='cuda:0'), new_distribution = tensor([0.9391, 0.0386, 0.0222], device='cuda:0')
2024-12-07 17:57:16,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 511: ref_distribution = tensor([0.9391, 0.0386, 0.0222], device='cuda:0'), new_distribution = tensor([0.9393, 0.0385, 0.0222], device='cuda:0')
2024-12-07 17:57:16,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 512: ref_distribution = tensor([0.9393, 0.0385, 0.0222], device='cuda:0'), new_distribution = tensor([0.9395, 0.0384, 0.0221], device='cuda:0')
2024-12-07 17:57:17,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 513: ref_distribution = tensor([0.9395, 0.0384, 0.0221], device='cuda:0'), new_distribution = tensor([0.9397, 0.0382, 0.0220], device='cuda:0')
2024-12-07 17:57:17,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 514: ref_distribution = tensor([0.9397, 0.0382, 0.0220], device='cuda:0'), new_distribution = tensor([0.9399, 0.0381, 0.0220], device='cuda:0')
2024-12-07 17:57:18,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 515: ref_distribution = tensor([0.9399, 0.0381, 0.0220], device='cuda:0'), new_distribution = tensor([0.9402, 0.0379, 0.0219], device='cuda:0')
2024-12-07 17:57:18,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 516: ref_distribution = tensor([0.9402, 0.0379, 0.0219], device='cuda:0'), new_distribution = tensor([0.9404, 0.0378, 0.0218], device='cuda:0')
2024-12-07 17:57:18,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 517: ref_distribution = tensor([0.9404, 0.0378, 0.0218], device='cuda:0'), new_distribution = tensor([0.9406, 0.0377, 0.0218], device='cuda:0')
2024-12-07 17:57:19,209 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 518: ref_distribution = tensor([0.9406, 0.0377, 0.0218], device='cuda:0'), new_distribution = tensor([0.9408, 0.0375, 0.0217], device='cuda:0')
2024-12-07 17:57:19,549 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 519: ref_distribution = tensor([0.9408, 0.0375, 0.0217], device='cuda:0'), new_distribution = tensor([0.9410, 0.0374, 0.0217], device='cuda:0')
2024-12-07 17:57:19,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 520: ref_distribution = tensor([0.9410, 0.0374, 0.0217], device='cuda:0'), new_distribution = tensor([0.9412, 0.0372, 0.0216], device='cuda:0')
2024-12-07 17:57:20,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 521: ref_distribution = tensor([0.9412, 0.0372, 0.0216], device='cuda:0'), new_distribution = tensor([0.9414, 0.0371, 0.0215], device='cuda:0')
2024-12-07 17:57:20,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 522: ref_distribution = tensor([0.9414, 0.0371, 0.0215], device='cuda:0'), new_distribution = tensor([0.9416, 0.0370, 0.0215], device='cuda:0')
2024-12-07 17:57:21,093 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 523: ref_distribution = tensor([0.9416, 0.0370, 0.0215], device='cuda:0'), new_distribution = tensor([0.9418, 0.0368, 0.0214], device='cuda:0')
2024-12-07 17:57:21,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 524: ref_distribution = tensor([0.9418, 0.0368, 0.0214], device='cuda:0'), new_distribution = tensor([0.9420, 0.0367, 0.0213], device='cuda:0')
2024-12-07 17:57:21,772 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 525: ref_distribution = tensor([0.9420, 0.0367, 0.0213], device='cuda:0'), new_distribution = tensor([0.9422, 0.0366, 0.0213], device='cuda:0')
2024-12-07 17:57:22,211 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 526: ref_distribution = tensor([0.9422, 0.0366, 0.0213], device='cuda:0'), new_distribution = tensor([0.9424, 0.0364, 0.0212], device='cuda:0')
2024-12-07 17:57:22,699 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 527: ref_distribution = tensor([0.9424, 0.0364, 0.0212], device='cuda:0'), new_distribution = tensor([0.9426, 0.0363, 0.0211], device='cuda:0')
2024-12-07 17:57:23,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 528: ref_distribution = tensor([0.9426, 0.0363, 0.0211], device='cuda:0'), new_distribution = tensor([0.9428, 0.0362, 0.0211], device='cuda:0')
2024-12-07 17:57:23,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 529: ref_distribution = tensor([0.9428, 0.0362, 0.0211], device='cuda:0'), new_distribution = tensor([0.9430, 0.0360, 0.0210], device='cuda:0')
2024-12-07 17:57:23,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 530: ref_distribution = tensor([0.9430, 0.0360, 0.0210], device='cuda:0'), new_distribution = tensor([0.9432, 0.0359, 0.0210], device='cuda:0')
2024-12-07 17:57:24,330 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 531: ref_distribution = tensor([0.9432, 0.0359, 0.0210], device='cuda:0'), new_distribution = tensor([0.9433, 0.0358, 0.0209], device='cuda:0')
2024-12-07 17:57:24,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 532: ref_distribution = tensor([0.9433, 0.0358, 0.0209], device='cuda:0'), new_distribution = tensor([0.9435, 0.0356, 0.0208], device='cuda:0')
2024-12-07 17:57:24,984 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 533: ref_distribution = tensor([0.9435, 0.0356, 0.0208], device='cuda:0'), new_distribution = tensor([0.9437, 0.0355, 0.0208], device='cuda:0')
2024-12-07 17:57:25,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 534: ref_distribution = tensor([0.9437, 0.0355, 0.0208], device='cuda:0'), new_distribution = tensor([0.9439, 0.0354, 0.0207], device='cuda:0')
2024-12-07 17:57:25,902 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 535: ref_distribution = tensor([0.9439, 0.0354, 0.0207], device='cuda:0'), new_distribution = tensor([0.9441, 0.0352, 0.0206], device='cuda:0')
2024-12-07 17:57:26,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 536: ref_distribution = tensor([0.9441, 0.0352, 0.0206], device='cuda:0'), new_distribution = tensor([0.9443, 0.0351, 0.0206], device='cuda:0')
2024-12-07 17:57:26,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 537: ref_distribution = tensor([0.9443, 0.0351, 0.0206], device='cuda:0'), new_distribution = tensor([0.9445, 0.0350, 0.0205], device='cuda:0')
2024-12-07 17:57:27,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 538: ref_distribution = tensor([0.9445, 0.0350, 0.0205], device='cuda:0'), new_distribution = tensor([0.9447, 0.0348, 0.0205], device='cuda:0')
2024-12-07 17:57:27,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 539: ref_distribution = tensor([0.9447, 0.0348, 0.0205], device='cuda:0'), new_distribution = tensor([0.9449, 0.0347, 0.0204], device='cuda:0')
2024-12-07 17:57:27,753 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 540: ref_distribution = tensor([0.9449, 0.0347, 0.0204], device='cuda:0'), new_distribution = tensor([0.9451, 0.0346, 0.0203], device='cuda:0')
2024-12-07 17:57:28,232 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 541: ref_distribution = tensor([0.9451, 0.0346, 0.0203], device='cuda:0'), new_distribution = tensor([0.9453, 0.0345, 0.0203], device='cuda:0')
2024-12-07 17:57:28,615 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 542: ref_distribution = tensor([0.9453, 0.0345, 0.0203], device='cuda:0'), new_distribution = tensor([0.9455, 0.0343, 0.0202], device='cuda:0')
2024-12-07 17:57:28,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 543: ref_distribution = tensor([0.9455, 0.0343, 0.0202], device='cuda:0'), new_distribution = tensor([0.9456, 0.0342, 0.0202], device='cuda:0')
2024-12-07 17:57:29,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 544: ref_distribution = tensor([0.9456, 0.0342, 0.0202], device='cuda:0'), new_distribution = tensor([0.9458, 0.0341, 0.0201], device='cuda:0')
2024-12-07 17:57:29,886 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 545: ref_distribution = tensor([0.9458, 0.0341, 0.0201], device='cuda:0'), new_distribution = tensor([0.9460, 0.0339, 0.0200], device='cuda:0')
2024-12-07 17:57:30,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 546: ref_distribution = tensor([0.9460, 0.0339, 0.0200], device='cuda:0'), new_distribution = tensor([0.9462, 0.0338, 0.0200], device='cuda:0')
2024-12-07 17:57:30,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 547: ref_distribution = tensor([0.9462, 0.0338, 0.0200], device='cuda:0'), new_distribution = tensor([0.9464, 0.0337, 0.0199], device='cuda:0')
2024-12-07 17:57:30,969 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 548: ref_distribution = tensor([0.9464, 0.0337, 0.0199], device='cuda:0'), new_distribution = tensor([0.9466, 0.0336, 0.0199], device='cuda:0')
2024-12-07 17:57:31,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 549: ref_distribution = tensor([0.9466, 0.0336, 0.0199], device='cuda:0'), new_distribution = tensor([0.9468, 0.0334, 0.0198], device='cuda:0')
2024-12-07 17:57:31,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 550: ref_distribution = tensor([0.9468, 0.0334, 0.0198], device='cuda:0'), new_distribution = tensor([0.9469, 0.0333, 0.0197], device='cuda:0')
2024-12-07 17:57:32,097 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 551: ref_distribution = tensor([0.9469, 0.0333, 0.0197], device='cuda:0'), new_distribution = tensor([0.9471, 0.0332, 0.0197], device='cuda:0')
2024-12-07 17:57:32,412 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 552: ref_distribution = tensor([0.9471, 0.0332, 0.0197], device='cuda:0'), new_distribution = tensor([0.9473, 0.0331, 0.0196], device='cuda:0')
2024-12-07 17:57:32,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 553: ref_distribution = tensor([0.9473, 0.0331, 0.0196], device='cuda:0'), new_distribution = tensor([0.9475, 0.0329, 0.0196], device='cuda:0')
2024-12-07 17:57:33,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 554: ref_distribution = tensor([0.9475, 0.0329, 0.0196], device='cuda:0'), new_distribution = tensor([0.9477, 0.0328, 0.0195], device='cuda:0')
2024-12-07 17:57:33,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 555: ref_distribution = tensor([0.9477, 0.0328, 0.0195], device='cuda:0'), new_distribution = tensor([0.9478, 0.0327, 0.0195], device='cuda:0')
2024-12-07 17:57:33,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 556: ref_distribution = tensor([0.9478, 0.0327, 0.0195], device='cuda:0'), new_distribution = tensor([0.9480, 0.0326, 0.0194], device='cuda:0')
2024-12-07 17:57:34,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 557: ref_distribution = tensor([0.9480, 0.0326, 0.0194], device='cuda:0'), new_distribution = tensor([0.9482, 0.0325, 0.0193], device='cuda:0')
2024-12-07 17:57:34,818 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 558: ref_distribution = tensor([0.9482, 0.0325, 0.0193], device='cuda:0'), new_distribution = tensor([0.9484, 0.0323, 0.0193], device='cuda:0')
2024-12-07 17:57:35,165 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 559: ref_distribution = tensor([0.9484, 0.0323, 0.0193], device='cuda:0'), new_distribution = tensor([0.9486, 0.0322, 0.0192], device='cuda:0')
2024-12-07 17:57:35,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 560: ref_distribution = tensor([0.9486, 0.0322, 0.0192], device='cuda:0'), new_distribution = tensor([0.9487, 0.0321, 0.0192], device='cuda:0')
2024-12-07 17:57:35,984 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 561: ref_distribution = tensor([0.9487, 0.0321, 0.0192], device='cuda:0'), new_distribution = tensor([0.9489, 0.0320, 0.0191], device='cuda:0')
2024-12-07 17:57:36,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 562: ref_distribution = tensor([0.9489, 0.0320, 0.0191], device='cuda:0'), new_distribution = tensor([0.9491, 0.0319, 0.0191], device='cuda:0')
2024-12-07 17:57:36,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 563: ref_distribution = tensor([0.9491, 0.0319, 0.0191], device='cuda:0'), new_distribution = tensor([0.9493, 0.0317, 0.0190], device='cuda:0')
2024-12-07 17:57:37,133 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 564: ref_distribution = tensor([0.9493, 0.0317, 0.0190], device='cuda:0'), new_distribution = tensor([0.9494, 0.0316, 0.0189], device='cuda:0')
2024-12-07 17:57:37,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 565: ref_distribution = tensor([0.9494, 0.0316, 0.0189], device='cuda:0'), new_distribution = tensor([0.9496, 0.0315, 0.0189], device='cuda:0')
2024-12-07 17:57:37,862 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 566: ref_distribution = tensor([0.9496, 0.0315, 0.0189], device='cuda:0'), new_distribution = tensor([0.9498, 0.0314, 0.0188], device='cuda:0')
2024-12-07 17:57:38,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 567: ref_distribution = tensor([0.9498, 0.0314, 0.0188], device='cuda:0'), new_distribution = tensor([0.9500, 0.0313, 0.0188], device='cuda:0')
2024-12-07 17:57:38,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 568: ref_distribution = tensor([0.9500, 0.0313, 0.0188], device='cuda:0'), new_distribution = tensor([0.9501, 0.0312, 0.0187], device='cuda:0')
2024-12-07 17:57:39,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 569: ref_distribution = tensor([0.9501, 0.0312, 0.0187], device='cuda:0'), new_distribution = tensor([0.9503, 0.0310, 0.0187], device='cuda:0')
2024-12-07 17:57:39,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 570: ref_distribution = tensor([0.9503, 0.0310, 0.0187], device='cuda:0'), new_distribution = tensor([0.9505, 0.0309, 0.0186], device='cuda:0')
2024-12-07 17:57:39,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 571: ref_distribution = tensor([0.9505, 0.0309, 0.0186], device='cuda:0'), new_distribution = tensor([0.9506, 0.0308, 0.0186], device='cuda:0')
2024-12-07 17:57:40,224 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 572: ref_distribution = tensor([0.9506, 0.0308, 0.0186], device='cuda:0'), new_distribution = tensor([0.9508, 0.0307, 0.0185], device='cuda:0')
2024-12-07 17:57:40,586 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 573: ref_distribution = tensor([0.9508, 0.0307, 0.0185], device='cuda:0'), new_distribution = tensor([0.9510, 0.0306, 0.0184], device='cuda:0')
2024-12-07 17:57:40,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 574: ref_distribution = tensor([0.9510, 0.0306, 0.0184], device='cuda:0'), new_distribution = tensor([0.9512, 0.0305, 0.0184], device='cuda:0')
2024-12-07 17:57:41,446 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 575: ref_distribution = tensor([0.9512, 0.0305, 0.0184], device='cuda:0'), new_distribution = tensor([0.9513, 0.0303, 0.0183], device='cuda:0')
2024-12-07 17:57:41,855 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 576: ref_distribution = tensor([0.9513, 0.0303, 0.0183], device='cuda:0'), new_distribution = tensor([0.9515, 0.0302, 0.0183], device='cuda:0')
2024-12-07 17:57:42,083 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 577: ref_distribution = tensor([0.9515, 0.0302, 0.0183], device='cuda:0'), new_distribution = tensor([0.9517, 0.0301, 0.0182], device='cuda:0')
2024-12-07 17:57:42,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 578: ref_distribution = tensor([0.9517, 0.0301, 0.0182], device='cuda:0'), new_distribution = tensor([0.9518, 0.0300, 0.0182], device='cuda:0')
2024-12-07 17:57:42,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 579: ref_distribution = tensor([0.9518, 0.0300, 0.0182], device='cuda:0'), new_distribution = tensor([0.9520, 0.0299, 0.0181], device='cuda:0')
2024-12-07 17:57:43,201 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 580: ref_distribution = tensor([0.9520, 0.0299, 0.0181], device='cuda:0'), new_distribution = tensor([0.9522, 0.0298, 0.0181], device='cuda:0')
2024-12-07 17:57:43,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 581: ref_distribution = tensor([0.9522, 0.0298, 0.0181], device='cuda:0'), new_distribution = tensor([0.9523, 0.0297, 0.0180], device='cuda:0')
2024-12-07 17:57:43,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 582: ref_distribution = tensor([0.9523, 0.0297, 0.0180], device='cuda:0'), new_distribution = tensor([0.9525, 0.0296, 0.0180], device='cuda:0')
2024-12-07 17:57:44,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 583: ref_distribution = tensor([0.9525, 0.0296, 0.0180], device='cuda:0'), new_distribution = tensor([0.9527, 0.0294, 0.0179], device='cuda:0')
2024-12-07 17:57:44,789 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 584: ref_distribution = tensor([0.9527, 0.0294, 0.0179], device='cuda:0'), new_distribution = tensor([0.9528, 0.0293, 0.0178], device='cuda:0')
2024-12-07 17:57:45,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 585: ref_distribution = tensor([0.9528, 0.0293, 0.0178], device='cuda:0'), new_distribution = tensor([0.9530, 0.0292, 0.0178], device='cuda:0')
2024-12-07 17:57:45,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 586: ref_distribution = tensor([0.9530, 0.0292, 0.0178], device='cuda:0'), new_distribution = tensor([0.9531, 0.0291, 0.0177], device='cuda:0')
2024-12-07 17:57:45,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 587: ref_distribution = tensor([0.9531, 0.0291, 0.0177], device='cuda:0'), new_distribution = tensor([0.9533, 0.0290, 0.0177], device='cuda:0')
2024-12-07 17:57:46,286 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 588: ref_distribution = tensor([0.9533, 0.0290, 0.0177], device='cuda:0'), new_distribution = tensor([0.9535, 0.0289, 0.0176], device='cuda:0')
2024-12-07 17:57:46,542 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 589: ref_distribution = tensor([0.9535, 0.0289, 0.0176], device='cuda:0'), new_distribution = tensor([0.9536, 0.0288, 0.0176], device='cuda:0')
2024-12-07 17:57:47,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 590: ref_distribution = tensor([0.9536, 0.0288, 0.0176], device='cuda:0'), new_distribution = tensor([0.9538, 0.0287, 0.0175], device='cuda:0')
2024-12-07 17:57:47,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 591: ref_distribution = tensor([0.9538, 0.0287, 0.0175], device='cuda:0'), new_distribution = tensor([0.9539, 0.0286, 0.0175], device='cuda:0')
2024-12-07 17:57:47,657 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 592: ref_distribution = tensor([0.9539, 0.0286, 0.0175], device='cuda:0'), new_distribution = tensor([0.9541, 0.0285, 0.0174], device='cuda:0')
2024-12-07 17:57:48,125 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 593: ref_distribution = tensor([0.9541, 0.0285, 0.0174], device='cuda:0'), new_distribution = tensor([0.9543, 0.0284, 0.0174], device='cuda:0')
2024-12-07 17:57:48,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 594: ref_distribution = tensor([0.9543, 0.0284, 0.0174], device='cuda:0'), new_distribution = tensor([0.9544, 0.0283, 0.0173], device='cuda:0')
2024-12-07 17:57:48,826 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 595: ref_distribution = tensor([0.9544, 0.0283, 0.0173], device='cuda:0'), new_distribution = tensor([0.9546, 0.0281, 0.0173], device='cuda:0')
2024-12-07 17:57:49,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 596: ref_distribution = tensor([0.9546, 0.0281, 0.0173], device='cuda:0'), new_distribution = tensor([0.9547, 0.0280, 0.0172], device='cuda:0')
2024-12-07 17:57:49,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 597: ref_distribution = tensor([0.9547, 0.0280, 0.0172], device='cuda:0'), new_distribution = tensor([0.9549, 0.0279, 0.0172], device='cuda:0')
2024-12-07 17:57:50,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 598: ref_distribution = tensor([0.9549, 0.0279, 0.0172], device='cuda:0'), new_distribution = tensor([0.9551, 0.0278, 0.0171], device='cuda:0')
2024-12-07 17:57:50,390 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 599: ref_distribution = tensor([0.9551, 0.0278, 0.0171], device='cuda:0'), new_distribution = tensor([0.9552, 0.0277, 0.0171], device='cuda:0')
2024-12-07 17:57:50,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 600: ref_distribution = tensor([0.9552, 0.0277, 0.0171], device='cuda:0'), new_distribution = tensor([0.9554, 0.0276, 0.0170], device='cuda:0')
2024-12-07 17:57:51,074 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 601: ref_distribution = tensor([0.9554, 0.0276, 0.0170], device='cuda:0'), new_distribution = tensor([0.9555, 0.0275, 0.0170], device='cuda:0')
2024-12-07 17:57:51,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 602: ref_distribution = tensor([0.9555, 0.0275, 0.0170], device='cuda:0'), new_distribution = tensor([0.9557, 0.0274, 0.0169], device='cuda:0')
2024-12-07 17:57:51,968 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 603: ref_distribution = tensor([0.9557, 0.0274, 0.0169], device='cuda:0'), new_distribution = tensor([0.9558, 0.0273, 0.0169], device='cuda:0')
2024-12-07 17:57:52,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 604: ref_distribution = tensor([0.9558, 0.0273, 0.0169], device='cuda:0'), new_distribution = tensor([0.9560, 0.0272, 0.0168], device='cuda:0')
2024-12-07 17:57:52,595 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 605: ref_distribution = tensor([0.9560, 0.0272, 0.0168], device='cuda:0'), new_distribution = tensor([0.9561, 0.0271, 0.0168], device='cuda:0')
2024-12-07 17:57:53,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 606: ref_distribution = tensor([0.9561, 0.0271, 0.0168], device='cuda:0'), new_distribution = tensor([0.9563, 0.0270, 0.0167], device='cuda:0')
2024-12-07 17:57:53,386 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 607: ref_distribution = tensor([0.9563, 0.0270, 0.0167], device='cuda:0'), new_distribution = tensor([0.9564, 0.0269, 0.0167], device='cuda:0')
2024-12-07 17:57:53,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 608: ref_distribution = tensor([0.9564, 0.0269, 0.0167], device='cuda:0'), new_distribution = tensor([0.9566, 0.0268, 0.0166], device='cuda:0')
2024-12-07 17:57:54,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 609: ref_distribution = tensor([0.9566, 0.0268, 0.0166], device='cuda:0'), new_distribution = tensor([0.9567, 0.0267, 0.0166], device='cuda:0')
2024-12-07 17:57:54,677 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 610: ref_distribution = tensor([0.9567, 0.0267, 0.0166], device='cuda:0'), new_distribution = tensor([0.9569, 0.0266, 0.0165], device='cuda:0')
2024-12-07 17:57:55,026 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 611: ref_distribution = tensor([0.9569, 0.0266, 0.0165], device='cuda:0'), new_distribution = tensor([0.9570, 0.0265, 0.0165], device='cuda:0')
2024-12-07 17:57:55,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 612: ref_distribution = tensor([0.9570, 0.0265, 0.0165], device='cuda:0'), new_distribution = tensor([0.9572, 0.0264, 0.0164], device='cuda:0')
2024-12-07 17:57:55,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 613: ref_distribution = tensor([0.9572, 0.0264, 0.0164], device='cuda:0'), new_distribution = tensor([0.9573, 0.0263, 0.0164], device='cuda:0')
2024-12-07 17:57:56,224 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 614: ref_distribution = tensor([0.9573, 0.0263, 0.0164], device='cuda:0'), new_distribution = tensor([0.9575, 0.0262, 0.0163], device='cuda:0')
2024-12-07 17:57:56,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 615: ref_distribution = tensor([0.9575, 0.0262, 0.0163], device='cuda:0'), new_distribution = tensor([0.9576, 0.0261, 0.0163], device='cuda:0')
2024-12-07 17:57:56,992 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 616: ref_distribution = tensor([0.9576, 0.0261, 0.0163], device='cuda:0'), new_distribution = tensor([0.9578, 0.0260, 0.0162], device='cuda:0')
2024-12-07 17:57:57,476 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 617: ref_distribution = tensor([0.9578, 0.0260, 0.0162], device='cuda:0'), new_distribution = tensor([0.9579, 0.0259, 0.0162], device='cuda:0')
2024-12-07 17:57:57,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 618: ref_distribution = tensor([0.9579, 0.0259, 0.0162], device='cuda:0'), new_distribution = tensor([0.9581, 0.0258, 0.0161], device='cuda:0')
2024-12-07 17:57:58,157 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 619: ref_distribution = tensor([0.9581, 0.0258, 0.0161], device='cuda:0'), new_distribution = tensor([0.9582, 0.0257, 0.0161], device='cuda:0')
2024-12-07 17:57:58,639 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 620: ref_distribution = tensor([0.9582, 0.0257, 0.0161], device='cuda:0'), new_distribution = tensor([0.9584, 0.0256, 0.0160], device='cuda:0')
2024-12-07 17:57:59,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 621: ref_distribution = tensor([0.9584, 0.0256, 0.0160], device='cuda:0'), new_distribution = tensor([0.9585, 0.0255, 0.0160], device='cuda:0')
2024-12-07 17:57:59,435 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 622: ref_distribution = tensor([0.9585, 0.0255, 0.0160], device='cuda:0'), new_distribution = tensor([0.9586, 0.0254, 0.0159], device='cuda:0')
2024-12-07 17:57:59,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 623: ref_distribution = tensor([0.9586, 0.0254, 0.0159], device='cuda:0'), new_distribution = tensor([0.9588, 0.0253, 0.0159], device='cuda:0')
2024-12-07 17:58:00,241 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 624: ref_distribution = tensor([0.9588, 0.0253, 0.0159], device='cuda:0'), new_distribution = tensor([0.9589, 0.0252, 0.0158], device='cuda:0')
2024-12-07 17:58:00,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 625: ref_distribution = tensor([0.9589, 0.0252, 0.0158], device='cuda:0'), new_distribution = tensor([0.9591, 0.0251, 0.0158], device='cuda:0')
2024-12-07 17:58:00,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 626: ref_distribution = tensor([0.9591, 0.0251, 0.0158], device='cuda:0'), new_distribution = tensor([0.9592, 0.0250, 0.0157], device='cuda:0')
2024-12-07 17:58:01,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 627: ref_distribution = tensor([0.9592, 0.0250, 0.0157], device='cuda:0'), new_distribution = tensor([0.9594, 0.0249, 0.0157], device='cuda:0')
2024-12-07 17:58:01,871 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 628: ref_distribution = tensor([0.9594, 0.0249, 0.0157], device='cuda:0'), new_distribution = tensor([0.9595, 0.0248, 0.0157], device='cuda:0')
2024-12-07 17:58:02,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 629: ref_distribution = tensor([0.9595, 0.0248, 0.0157], device='cuda:0'), new_distribution = tensor([0.9596, 0.0248, 0.0156], device='cuda:0')
2024-12-07 17:58:02,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 630: ref_distribution = tensor([0.9596, 0.0248, 0.0156], device='cuda:0'), new_distribution = tensor([0.9598, 0.0247, 0.0156], device='cuda:0')
2024-12-07 17:58:02,998 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 631: ref_distribution = tensor([0.9598, 0.0247, 0.0156], device='cuda:0'), new_distribution = tensor([0.9599, 0.0246, 0.0155], device='cuda:0')
2024-12-07 17:58:03,297 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 632: ref_distribution = tensor([0.9599, 0.0246, 0.0155], device='cuda:0'), new_distribution = tensor([0.9601, 0.0245, 0.0155], device='cuda:0')
2024-12-07 17:58:03,657 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 633: ref_distribution = tensor([0.9601, 0.0245, 0.0155], device='cuda:0'), new_distribution = tensor([0.9602, 0.0244, 0.0154], device='cuda:0')
2024-12-07 17:58:04,118 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 634: ref_distribution = tensor([0.9602, 0.0244, 0.0154], device='cuda:0'), new_distribution = tensor([0.9603, 0.0243, 0.0154], device='cuda:0')
2024-12-07 17:58:04,410 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 635: ref_distribution = tensor([0.9603, 0.0243, 0.0154], device='cuda:0'), new_distribution = tensor([0.9605, 0.0242, 0.0153], device='cuda:0')
2024-12-07 17:58:04,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 636: ref_distribution = tensor([0.9605, 0.0242, 0.0153], device='cuda:0'), new_distribution = tensor([0.9606, 0.0241, 0.0153], device='cuda:0')
2024-12-07 17:58:05,239 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 637: ref_distribution = tensor([0.9606, 0.0241, 0.0153], device='cuda:0'), new_distribution = tensor([0.9607, 0.0240, 0.0152], device='cuda:0')
2024-12-07 17:58:05,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 638: ref_distribution = tensor([0.9607, 0.0240, 0.0152], device='cuda:0'), new_distribution = tensor([0.9609, 0.0239, 0.0152], device='cuda:0')
2024-12-07 17:58:05,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 639: ref_distribution = tensor([0.9609, 0.0239, 0.0152], device='cuda:0'), new_distribution = tensor([0.9610, 0.0238, 0.0152], device='cuda:0')
2024-12-07 17:58:06,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 640: ref_distribution = tensor([0.9610, 0.0238, 0.0152], device='cuda:0'), new_distribution = tensor([0.9612, 0.0237, 0.0151], device='cuda:0')
2024-12-07 17:58:06,857 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 641: ref_distribution = tensor([0.9612, 0.0237, 0.0151], device='cuda:0'), new_distribution = tensor([0.9613, 0.0237, 0.0151], device='cuda:0')
2024-12-07 17:58:07,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 642: ref_distribution = tensor([0.9613, 0.0237, 0.0151], device='cuda:0'), new_distribution = tensor([0.9614, 0.0236, 0.0150], device='cuda:0')
2024-12-07 17:58:07,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 643: ref_distribution = tensor([0.9614, 0.0236, 0.0150], device='cuda:0'), new_distribution = tensor([0.9616, 0.0235, 0.0150], device='cuda:0')
2024-12-07 17:58:07,983 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 644: ref_distribution = tensor([0.9616, 0.0235, 0.0150], device='cuda:0'), new_distribution = tensor([0.9617, 0.0234, 0.0149], device='cuda:0')
2024-12-07 17:58:08,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 645: ref_distribution = tensor([0.9617, 0.0234, 0.0149], device='cuda:0'), new_distribution = tensor([0.9618, 0.0233, 0.0149], device='cuda:0')
2024-12-07 17:58:08,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 646: ref_distribution = tensor([0.9618, 0.0233, 0.0149], device='cuda:0'), new_distribution = tensor([0.9620, 0.0232, 0.0148], device='cuda:0')
2024-12-07 17:58:09,138 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 647: ref_distribution = tensor([0.9620, 0.0232, 0.0148], device='cuda:0'), new_distribution = tensor([0.9621, 0.0231, 0.0148], device='cuda:0')
2024-12-07 17:58:09,589 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 648: ref_distribution = tensor([0.9621, 0.0231, 0.0148], device='cuda:0'), new_distribution = tensor([0.9622, 0.0230, 0.0148], device='cuda:0')
2024-12-07 17:58:09,858 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 649: ref_distribution = tensor([0.9622, 0.0230, 0.0148], device='cuda:0'), new_distribution = tensor([0.9624, 0.0229, 0.0147], device='cuda:0')
2024-12-07 17:58:10,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 650: ref_distribution = tensor([0.9624, 0.0229, 0.0147], device='cuda:0'), new_distribution = tensor([0.9625, 0.0229, 0.0147], device='cuda:0')
2024-12-07 17:58:10,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 651: ref_distribution = tensor([0.9625, 0.0229, 0.0147], device='cuda:0'), new_distribution = tensor([0.9626, 0.0228, 0.0146], device='cuda:0')
2024-12-07 17:58:11,023 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 652: ref_distribution = tensor([0.9626, 0.0228, 0.0146], device='cuda:0'), new_distribution = tensor([0.9627, 0.0227, 0.0146], device='cuda:0')
2024-12-07 17:58:11,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 653: ref_distribution = tensor([0.9627, 0.0227, 0.0146], device='cuda:0'), new_distribution = tensor([0.9629, 0.0226, 0.0145], device='cuda:0')
2024-12-07 17:58:11,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 654: ref_distribution = tensor([0.9629, 0.0226, 0.0145], device='cuda:0'), new_distribution = tensor([0.9630, 0.0225, 0.0145], device='cuda:0')
2024-12-07 17:58:12,230 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 655: ref_distribution = tensor([0.9630, 0.0225, 0.0145], device='cuda:0'), new_distribution = tensor([0.9631, 0.0224, 0.0144], device='cuda:0')
2024-12-07 17:58:12,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 656: ref_distribution = tensor([0.9631, 0.0224, 0.0144], device='cuda:0'), new_distribution = tensor([0.9633, 0.0223, 0.0144], device='cuda:0')
2024-12-07 17:58:12,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 657: ref_distribution = tensor([0.9633, 0.0223, 0.0144], device='cuda:0'), new_distribution = tensor([0.9634, 0.0223, 0.0144], device='cuda:0')
2024-12-07 17:58:13,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 658: ref_distribution = tensor([0.9634, 0.0223, 0.0144], device='cuda:0'), new_distribution = tensor([0.9635, 0.0222, 0.0143], device='cuda:0')
2024-12-07 17:58:13,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 659: ref_distribution = tensor([0.9635, 0.0222, 0.0143], device='cuda:0'), new_distribution = tensor([0.9636, 0.0221, 0.0143], device='cuda:0')
2024-12-07 17:58:14,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 660: ref_distribution = tensor([0.9636, 0.0221, 0.0143], device='cuda:0'), new_distribution = tensor([0.9638, 0.0220, 0.0142], device='cuda:0')
2024-12-07 17:58:14,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 661: ref_distribution = tensor([0.9638, 0.0220, 0.0142], device='cuda:0'), new_distribution = tensor([0.9639, 0.0219, 0.0142], device='cuda:0')
2024-12-07 17:58:14,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 662: ref_distribution = tensor([0.9639, 0.0219, 0.0142], device='cuda:0'), new_distribution = tensor([0.9640, 0.0218, 0.0141], device='cuda:0')
2024-12-07 17:58:15,259 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 663: ref_distribution = tensor([0.9640, 0.0218, 0.0141], device='cuda:0'), new_distribution = tensor([0.9641, 0.0218, 0.0141], device='cuda:0')
2024-12-07 17:58:15,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 664: ref_distribution = tensor([0.9641, 0.0218, 0.0141], device='cuda:0'), new_distribution = tensor([0.9643, 0.0217, 0.0141], device='cuda:0')
2024-12-07 17:58:16,003 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 665: ref_distribution = tensor([0.9643, 0.0217, 0.0141], device='cuda:0'), new_distribution = tensor([0.9644, 0.0216, 0.0140], device='cuda:0')
2024-12-07 17:58:16,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 666: ref_distribution = tensor([0.9644, 0.0216, 0.0140], device='cuda:0'), new_distribution = tensor([0.9645, 0.0215, 0.0140], device='cuda:0')
2024-12-07 17:58:16,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 667: ref_distribution = tensor([0.9645, 0.0215, 0.0140], device='cuda:0'), new_distribution = tensor([0.9646, 0.0214, 0.0139], device='cuda:0')
2024-12-07 17:58:17,179 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 668: ref_distribution = tensor([0.9646, 0.0214, 0.0139], device='cuda:0'), new_distribution = tensor([0.9648, 0.0213, 0.0139], device='cuda:0')
2024-12-07 17:58:17,492 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 669: ref_distribution = tensor([0.9648, 0.0213, 0.0139], device='cuda:0'), new_distribution = tensor([0.9649, 0.0213, 0.0139], device='cuda:0')
2024-12-07 17:58:17,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 670: ref_distribution = tensor([0.9649, 0.0213, 0.0139], device='cuda:0'), new_distribution = tensor([0.9650, 0.0212, 0.0138], device='cuda:0')
2024-12-07 17:58:18,434 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 671: ref_distribution = tensor([0.9650, 0.0212, 0.0138], device='cuda:0'), new_distribution = tensor([0.9651, 0.0211, 0.0138], device='cuda:0')
2024-12-07 17:58:18,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 672: ref_distribution = tensor([0.9651, 0.0211, 0.0138], device='cuda:0'), new_distribution = tensor([0.9653, 0.0210, 0.0137], device='cuda:0')
2024-12-07 17:58:19,114 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 673: ref_distribution = tensor([0.9653, 0.0210, 0.0137], device='cuda:0'), new_distribution = tensor([0.9654, 0.0209, 0.0137], device='cuda:0')
2024-12-07 17:58:19,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 674: ref_distribution = tensor([0.9654, 0.0209, 0.0137], device='cuda:0'), new_distribution = tensor([0.9655, 0.0209, 0.0137], device='cuda:0')
2024-12-07 17:58:19,985 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 675: ref_distribution = tensor([0.9655, 0.0209, 0.0137], device='cuda:0'), new_distribution = tensor([0.9656, 0.0208, 0.0136], device='cuda:0')
2024-12-07 17:58:20,348 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 676: ref_distribution = tensor([0.9656, 0.0208, 0.0136], device='cuda:0'), new_distribution = tensor([0.9657, 0.0207, 0.0136], device='cuda:0')
2024-12-07 17:58:20,728 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 677: ref_distribution = tensor([0.9657, 0.0207, 0.0136], device='cuda:0'), new_distribution = tensor([0.9659, 0.0206, 0.0135], device='cuda:0')
2024-12-07 17:58:21,189 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 678: ref_distribution = tensor([0.9659, 0.0206, 0.0135], device='cuda:0'), new_distribution = tensor([0.9660, 0.0205, 0.0135], device='cuda:0')
2024-12-07 17:58:21,516 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 679: ref_distribution = tensor([0.9660, 0.0205, 0.0135], device='cuda:0'), new_distribution = tensor([0.9661, 0.0205, 0.0134], device='cuda:0')
2024-12-07 17:58:21,855 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 680: ref_distribution = tensor([0.9661, 0.0205, 0.0134], device='cuda:0'), new_distribution = tensor([0.9662, 0.0204, 0.0134], device='cuda:0')
2024-12-07 17:58:22,337 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 681: ref_distribution = tensor([0.9662, 0.0204, 0.0134], device='cuda:0'), new_distribution = tensor([0.9663, 0.0203, 0.0134], device='cuda:0')
2024-12-07 17:58:22,697 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 682: ref_distribution = tensor([0.9663, 0.0203, 0.0134], device='cuda:0'), new_distribution = tensor([0.9664, 0.0202, 0.0133], device='cuda:0')
2024-12-07 17:58:23,009 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 683: ref_distribution = tensor([0.9664, 0.0202, 0.0133], device='cuda:0'), new_distribution = tensor([0.9666, 0.0202, 0.0133], device='cuda:0')
2024-12-07 17:58:23,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 684: ref_distribution = tensor([0.9666, 0.0202, 0.0133], device='cuda:0'), new_distribution = tensor([0.9667, 0.0201, 0.0133], device='cuda:0')
2024-12-07 17:58:23,968 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 685: ref_distribution = tensor([0.9667, 0.0201, 0.0133], device='cuda:0'), new_distribution = tensor([0.9668, 0.0200, 0.0132], device='cuda:0')
2024-12-07 17:58:24,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 686: ref_distribution = tensor([0.9668, 0.0200, 0.0132], device='cuda:0'), new_distribution = tensor([0.9669, 0.0199, 0.0132], device='cuda:0')
2024-12-07 17:58:24,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 687: ref_distribution = tensor([0.9669, 0.0199, 0.0132], device='cuda:0'), new_distribution = tensor([0.9670, 0.0198, 0.0131], device='cuda:0')
2024-12-07 17:58:25,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 688: ref_distribution = tensor([0.9670, 0.0198, 0.0131], device='cuda:0'), new_distribution = tensor([0.9671, 0.0198, 0.0131], device='cuda:0')
2024-12-07 17:58:25,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 689: ref_distribution = tensor([0.9671, 0.0198, 0.0131], device='cuda:0'), new_distribution = tensor([0.9673, 0.0197, 0.0131], device='cuda:0')
2024-12-07 17:58:25,902 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 690: ref_distribution = tensor([0.9673, 0.0197, 0.0131], device='cuda:0'), new_distribution = tensor([0.9674, 0.0196, 0.0130], device='cuda:0')
2024-12-07 17:58:26,257 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 691: ref_distribution = tensor([0.9674, 0.0196, 0.0130], device='cuda:0'), new_distribution = tensor([0.9675, 0.0195, 0.0130], device='cuda:0')
2024-12-07 17:58:26,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 692: ref_distribution = tensor([0.9675, 0.0195, 0.0130], device='cuda:0'), new_distribution = tensor([0.9676, 0.0195, 0.0129], device='cuda:0')
2024-12-07 17:58:27,134 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 693: ref_distribution = tensor([0.9676, 0.0195, 0.0129], device='cuda:0'), new_distribution = tensor([0.9677, 0.0194, 0.0129], device='cuda:0')
2024-12-07 17:58:27,418 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 694: ref_distribution = tensor([0.9677, 0.0194, 0.0129], device='cuda:0'), new_distribution = tensor([0.9678, 0.0193, 0.0129], device='cuda:0')
2024-12-07 17:58:27,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 695: ref_distribution = tensor([0.9678, 0.0193, 0.0129], device='cuda:0'), new_distribution = tensor([0.9679, 0.0192, 0.0128], device='cuda:0')
2024-12-07 17:58:28,350 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 696: ref_distribution = tensor([0.9679, 0.0192, 0.0128], device='cuda:0'), new_distribution = tensor([0.9680, 0.0192, 0.0128], device='cuda:0')
2024-12-07 17:58:28,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 697: ref_distribution = tensor([0.9680, 0.0192, 0.0128], device='cuda:0'), new_distribution = tensor([0.9682, 0.0191, 0.0127], device='cuda:0')
2024-12-07 17:58:29,009 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 698: ref_distribution = tensor([0.9682, 0.0191, 0.0127], device='cuda:0'), new_distribution = tensor([0.9683, 0.0190, 0.0127], device='cuda:0')
2024-12-07 17:58:29,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 699: ref_distribution = tensor([0.9683, 0.0190, 0.0127], device='cuda:0'), new_distribution = tensor([0.9684, 0.0190, 0.0127], device='cuda:0')
2024-12-07 17:58:30,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:30,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:30,768 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:31,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:31,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:31,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:32,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:32,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:33,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:33,574 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:33,902 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:34,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:34,860 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:35,165 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:35,541 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:36,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:36,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:36,636 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:37,110 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:37,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:37,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:38,210 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:38,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:38,892 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:39,363 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:39,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:40,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:40,517 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:40,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:41,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:41,673 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:42,128 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:42,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:42,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:43,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:43,728 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:44,086 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:44,435 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:44,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:45,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:45,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:46,007 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:46,478 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:46,936 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:47,201 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:47,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:48,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:48,452 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:48,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:49,229 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:49,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:50,048 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:50,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:50,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:51,232 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:51,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:51,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:52,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:52,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:53,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:53,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:53,844 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:54,239 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:54,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:55,000 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:55,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:55,814 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:56,128 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:56,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:56,955 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:57,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:57,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:58,091 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:58,560 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:58,966 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:59,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:58:59,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:00,181 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:00,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:00,826 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:01,297 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:01,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:01,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:02,393 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:02,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:03,037 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:03,508 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:03,798 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:04,140 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:04,611 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:04,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:05,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:05,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:06,024 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:06,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:06,829 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:07,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:07,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:07,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:08,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:08,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:09,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:09,346 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:09,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:10,182 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:10,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:10,872 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:11,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:11,778 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:12,105 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:12,446 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:12,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:13,309 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:13,596 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:14,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:14,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:14,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:15,197 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:15,630 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:15,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:16,304 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:16,777 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:17,032 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:17,424 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:17,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:18,209 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:18,566 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:19,024 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:19,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:19,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:20,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:20,640 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:21,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:21,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:21,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:22,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:22,424 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:22,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:23,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:23,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:24,026 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:24,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:24,810 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:25,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:25,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:26,043 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:26,360 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:26,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:27,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:27,560 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:27,892 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:28,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:28,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:29,000 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:29,469 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:29,857 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:30,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:30,607 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:31,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:31,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:31,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:32,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:32,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:32,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:33,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:33,630 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:33,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:34,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:34,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:35,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:35,626 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:36,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:36,442 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:36,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:37,228 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:37,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:37,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:38,377 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:38,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:39,137 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:39,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:39,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:40,240 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:40,606 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:41,069 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:41,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:41,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:42,190 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:42,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:42,994 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:43,344 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:43,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:44,223 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:44,448 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:44,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:45,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:45,556 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:46,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:46,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:46,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:47,137 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:47,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:47,768 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:48,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:48,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:48,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:49,344 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:49,705 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:50,015 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:50,481 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:50,714 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:51,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:51,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:51,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:52,220 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:52,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:53,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:53,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:53,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:54,312 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:54,594 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:54,956 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:55,428 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:55,716 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:56,069 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:56,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:56,833 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:57,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:57,644 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:57,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:58,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:58,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:59,227 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:59,464 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 17:59:59,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:00,385 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:00,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:01,032 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:01,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:01,826 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:02,158 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:02,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:02,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:03,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:03,709 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:04,035 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:04,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:04,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:05,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:05,556 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:06,037 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:06,517 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:06,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:07,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:07,649 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:08,106 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:08,454 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:08,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:09,262 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:09,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:09,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:10,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:10,768 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:11,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:11,494 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:11,779 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:12,129 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:12,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:12,984 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:13,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:13,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:14,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:14,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:14,860 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:15,327 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:15,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:15,956 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:16,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:16,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:17,121 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:17,575 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:18,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:18,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:18,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:19,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:19,669 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:19,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:20,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:20,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:21,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:21,439 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:21,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:22,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:22,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:23,069 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:23,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:23,892 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:24,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:24,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:24,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:25,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 300: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:25,798 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 301: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:26,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 302: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:26,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 303: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:26,950 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 304: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:27,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 305: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:27,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 306: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:28,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 307: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:28,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 308: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:28,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 309: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:29,173 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 310: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:29,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 311: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:29,953 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 312: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:30,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 313: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:30,783 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 314: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:31,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 315: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:31,468 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 316: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:31,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 317: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:32,374 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 318: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:32,723 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 319: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:33,020 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 320: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:33,502 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 321: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:33,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 322: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:34,189 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 323: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:34,657 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 324: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:35,106 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 325: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:35,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 326: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:35,781 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 327: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:36,248 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 328: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:36,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 329: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:36,882 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 330: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:37,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 331: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:37,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 332: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:38,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 333: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:38,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 334: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:38,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 335: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:39,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 336: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:39,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 337: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:40,116 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 338: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:40,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 339: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:40,763 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 340: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:41,245 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 341: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:41,706 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 342: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:41,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 343: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:42,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 344: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:42,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 345: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:43,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 346: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:43,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 347: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:43,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 348: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:44,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 349: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:44,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 350: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:45,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 351: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:45,437 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 352: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:45,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 353: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:46,232 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 354: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:46,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 355: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:46,857 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 356: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:47,337 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 357: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:47,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 358: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:47,991 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 359: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:48,463 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 360: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:48,940 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 361: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:49,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 362: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:49,613 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 363: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:50,078 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 364: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:50,374 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 365: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:50,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 366: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:51,191 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 367: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:51,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 368: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:51,845 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 369: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:52,313 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 370: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:52,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 371: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:53,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 372: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:53,465 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 373: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:53,928 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 374: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:54,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 375: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:54,575 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 376: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:55,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 377: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:55,326 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 378: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:55,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 379: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:56,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 380: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:56,512 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 381: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:56,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 382: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:57,279 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 383: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:57,544 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 384: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:57,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 385: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:58,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 386: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:58,649 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 387: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:59,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 388: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:59,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 389: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:00:59,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 390: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:00,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 391: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:00,600 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 392: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:00,886 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 393: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:01,284 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 394: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:01,753 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 395: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:02,048 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 396: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:02,403 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 397: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:02,875 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 398: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:03,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 399: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:03,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 400: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:04,020 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 401: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:04,494 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 402: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:04,821 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 403: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:05,144 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 404: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:05,626 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 405: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:06,077 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 406: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:06,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 407: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:06,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 408: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:07,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 409: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:07,477 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 410: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:07,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 411: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:08,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 412: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:08,526 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 413: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:08,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 414: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:09,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 415: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:09,728 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 416: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:10,100 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 417: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:10,560 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 418: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:10,852 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 419: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:11,194 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 420: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:11,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 421: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:11,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 422: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:12,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 423: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:12,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 424: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:13,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 425: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:13,581 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 426: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:13,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 427: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:14,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 428: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:14,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 429: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:15,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 430: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:15,517 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 431: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:15,926 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 432: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:16,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 433: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:16,639 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 434: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:17,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 435: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:17,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 436: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:17,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 437: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:18,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 438: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:18,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 439: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:18,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 440: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:19,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 441: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:19,734 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 442: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:20,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 443: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:20,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 444: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:20,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 445: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:21,321 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 446: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:21,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 447: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:22,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 448: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:22,615 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 449: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:22,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 450: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:23,319 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 451: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:23,793 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 452: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:24,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 453: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:24,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 454: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:24,886 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 455: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:25,100 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 456: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:25,535 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 457: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:26,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 458: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:26,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 459: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:26,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 460: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:27,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 461: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:27,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 462: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:27,754 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 463: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:28,215 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 464: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:28,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 465: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:28,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 466: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:29,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 467: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:29,601 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 468: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:29,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 469: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:30,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 470: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:30,762 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 471: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:31,116 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 472: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:31,578 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 473: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:32,041 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 474: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:32,390 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 475: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:32,740 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 476: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:33,209 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 477: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:33,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 478: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:33,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 479: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:34,342 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 480: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:34,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 481: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:35,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 482: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:35,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 483: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:35,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 484: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:36,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 485: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:36,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 486: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:37,072 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 487: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:37,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 488: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:37,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 489: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:38,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 490: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:38,691 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 491: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:39,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 492: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:39,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 493: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:39,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 494: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:40,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 495: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:40,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 496: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:40,970 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 497: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:41,428 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 498: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:41,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 499: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:42,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 500: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:42,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 501: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:42,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 502: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:43,182 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 503: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:43,651 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 504: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:43,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 505: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:44,282 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 506: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:44,741 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 507: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:45,046 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 508: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:45,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 509: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:45,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 510: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:46,174 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 511: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:46,531 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 512: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:46,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 513: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:47,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 514: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:47,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 515: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:48,146 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 516: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:48,629 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 517: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:49,037 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 518: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:49,266 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 519: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:49,744 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 520: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:50,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 521: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:50,413 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 522: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:50,891 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 523: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:51,349 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 524: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:51,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 525: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:51,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 526: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:52,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 527: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:52,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 528: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:53,110 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 529: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:53,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 530: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:53,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 531: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:54,234 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 532: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:54,697 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 533: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:55,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 534: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:55,391 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 535: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:55,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 536: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:56,319 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 537: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:56,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 538: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:56,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 539: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:57,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 540: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:57,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 541: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:58,131 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 542: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:58,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 543: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:59,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 544: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:59,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 545: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:01:59,699 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 546: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:00,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 547: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:00,464 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 548: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:00,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 549: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:01,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 550: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:01,668 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 551: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:01,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 552: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:02,439 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 553: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:02,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 554: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:03,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 555: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:03,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 556: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:03,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 557: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:03,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 558: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:04,198 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 559: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:04,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 560: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:05,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 561: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:05,433 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 562: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:05,777 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 563: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:06,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 564: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:06,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 565: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:07,039 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 566: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:07,342 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 567: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:07,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 568: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:08,287 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 569: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:08,580 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 570: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:08,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 571: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:09,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 572: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:09,660 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 573: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:10,042 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 574: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:10,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 575: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:10,807 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 576: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:11,145 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 577: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:11,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 578: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:11,848 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 579: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:12,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 580: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:12,709 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 581: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:12,972 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 582: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:13,360 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 583: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:13,830 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 584: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:14,144 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 585: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:14,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 586: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:14,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 587: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:15,453 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 588: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:15,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 589: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:16,097 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 590: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:16,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 591: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:16,947 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 592: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:17,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 593: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:17,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 594: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:18,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 595: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:18,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 596: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:18,828 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 597: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:19,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 598: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:19,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 599: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:19,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 600: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:20,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 601: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:20,682 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 602: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:21,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 603: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:21,508 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 604: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:21,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 605: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:22,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 606: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:22,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 607: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:22,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 608: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:22,983 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 609: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:23,446 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 610: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:23,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 611: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:24,094 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 612: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:24,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 613: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:24,861 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 614: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:25,211 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 615: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:25,673 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 616: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:26,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 617: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:26,326 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 618: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:26,798 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 619: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:27,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 620: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:27,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 621: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:27,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 622: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:28,408 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 623: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:28,537 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 624: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:28,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 625: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:29,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 626: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:29,660 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 627: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:29,864 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 628: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:30,289 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 629: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:30,758 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 630: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:31,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 631: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:31,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 632: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:31,869 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 633: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:32,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 634: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:32,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 635: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:33,022 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 636: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:33,487 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 637: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:33,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 638: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:34,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 639: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:34,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 640: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:35,000 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 641: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:35,304 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 642: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:35,772 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 643: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:36,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 644: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:36,484 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 645: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:36,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 646: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:37,348 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 647: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:37,567 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 648: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:38,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 649: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:38,625 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 650: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:38,908 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 651: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:39,282 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 652: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:39,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 653: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:40,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 654: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:40,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 655: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:40,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 656: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:41,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 657: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:41,685 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 658: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:42,012 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 659: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:42,483 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 660: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:42,867 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 661: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:43,155 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 662: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:43,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 663: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:44,088 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 664: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:44,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 665: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:44,739 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 666: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:45,221 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 667: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:45,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 668: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:45,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 669: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:46,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 670: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:46,822 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 671: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:47,147 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 672: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:47,498 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 673: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:47,982 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 674: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:48,458 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 675: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:48,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 676: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:49,140 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 677: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:49,270 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 678: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:49,751 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 679: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:50,057 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 680: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:50,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 681: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:50,910 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 682: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:51,192 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 683: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:51,546 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 684: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:52,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 685: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:52,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 686: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:52,708 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 687: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:53,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 688: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:53,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 689: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:53,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 690: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:54,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 691: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:54,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 692: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:55,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 693: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:55,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 694: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:55,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 695: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:56,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 696: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:56,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 697: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:56,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 698: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:57,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 699: ref_distribution = tensor([1., 0., 0.], device='cuda:0'), new_distribution = tensor([1., 0., 0.], device='cuda:0')
2024-12-07 18:02:58,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 0: ref_distribution = tensor([0.1000, 0.3000, 0.6000], device='cuda:0'), new_distribution = tensor([0.1003, 0.3005, 0.5992], device='cuda:0')
2024-12-07 18:02:58,402 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 1: ref_distribution = tensor([0.1003, 0.3005, 0.5992], device='cuda:0'), new_distribution = tensor([0.1006, 0.3009, 0.5984], device='cuda:0')
2024-12-07 18:02:58,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 2: ref_distribution = tensor([0.1006, 0.3009, 0.5984], device='cuda:0'), new_distribution = tensor([0.1010, 0.3014, 0.5976], device='cuda:0')
2024-12-07 18:02:59,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 3: ref_distribution = tensor([0.1010, 0.3014, 0.5976], device='cuda:0'), new_distribution = tensor([0.1013, 0.3019, 0.5968], device='cuda:0')
2024-12-07 18:02:59,635 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 4: ref_distribution = tensor([0.1013, 0.3019, 0.5968], device='cuda:0'), new_distribution = tensor([0.1016, 0.3024, 0.5960], device='cuda:0')
2024-12-07 18:02:59,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 5: ref_distribution = tensor([0.1016, 0.3024, 0.5960], device='cuda:0'), new_distribution = tensor([0.1019, 0.3028, 0.5952], device='cuda:0')
2024-12-07 18:03:00,309 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 6: ref_distribution = tensor([0.1019, 0.3028, 0.5952], device='cuda:0'), new_distribution = tensor([0.1022, 0.3033, 0.5944], device='cuda:0')
2024-12-07 18:03:00,792 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 7: ref_distribution = tensor([0.1022, 0.3033, 0.5944], device='cuda:0'), new_distribution = tensor([0.1026, 0.3038, 0.5936], device='cuda:0')
2024-12-07 18:03:01,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 8: ref_distribution = tensor([0.1026, 0.3038, 0.5936], device='cuda:0'), new_distribution = tensor([0.1029, 0.3043, 0.5928], device='cuda:0')
2024-12-07 18:03:01,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 9: ref_distribution = tensor([0.1029, 0.3043, 0.5928], device='cuda:0'), new_distribution = tensor([0.1032, 0.3047, 0.5920], device='cuda:0')
2024-12-07 18:03:01,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 10: ref_distribution = tensor([0.1032, 0.3047, 0.5920], device='cuda:0'), new_distribution = tensor([0.1036, 0.3052, 0.5913], device='cuda:0')
2024-12-07 18:03:02,413 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 11: ref_distribution = tensor([0.1036, 0.3052, 0.5913], device='cuda:0'), new_distribution = tensor([0.1039, 0.3057, 0.5905], device='cuda:0')
2024-12-07 18:03:02,779 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 12: ref_distribution = tensor([0.1039, 0.3057, 0.5905], device='cuda:0'), new_distribution = tensor([0.1042, 0.3061, 0.5897], device='cuda:0')
2024-12-07 18:03:03,047 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 13: ref_distribution = tensor([0.1042, 0.3061, 0.5897], device='cuda:0'), new_distribution = tensor([0.1045, 0.3066, 0.5889], device='cuda:0')
2024-12-07 18:03:03,517 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 14: ref_distribution = tensor([0.1045, 0.3066, 0.5889], device='cuda:0'), new_distribution = tensor([0.1049, 0.3071, 0.5881], device='cuda:0')
2024-12-07 18:03:03,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 15: ref_distribution = tensor([0.1049, 0.3071, 0.5881], device='cuda:0'), new_distribution = tensor([0.1052, 0.3075, 0.5872], device='cuda:0')
2024-12-07 18:03:04,199 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 16: ref_distribution = tensor([0.1052, 0.3075, 0.5872], device='cuda:0'), new_distribution = tensor([0.1055, 0.3080, 0.5864], device='cuda:0')
2024-12-07 18:03:04,669 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 17: ref_distribution = tensor([0.1055, 0.3080, 0.5864], device='cuda:0'), new_distribution = tensor([0.1059, 0.3085, 0.5856], device='cuda:0')
2024-12-07 18:03:05,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 18: ref_distribution = tensor([0.1059, 0.3085, 0.5856], device='cuda:0'), new_distribution = tensor([0.1062, 0.3089, 0.5848], device='cuda:0')
2024-12-07 18:03:05,409 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 19: ref_distribution = tensor([0.1062, 0.3089, 0.5848], device='cuda:0'), new_distribution = tensor([0.1066, 0.3094, 0.5840], device='cuda:0')
2024-12-07 18:03:05,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 20: ref_distribution = tensor([0.1066, 0.3094, 0.5840], device='cuda:0'), new_distribution = tensor([0.1069, 0.3099, 0.5832], device='cuda:0')
2024-12-07 18:03:06,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 21: ref_distribution = tensor([0.1069, 0.3099, 0.5832], device='cuda:0'), new_distribution = tensor([0.1072, 0.3103, 0.5824], device='cuda:0')
2024-12-07 18:03:06,562 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 22: ref_distribution = tensor([0.1072, 0.3103, 0.5824], device='cuda:0'), new_distribution = tensor([0.1076, 0.3108, 0.5816], device='cuda:0')
2024-12-07 18:03:06,916 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 23: ref_distribution = tensor([0.1076, 0.3108, 0.5816], device='cuda:0'), new_distribution = tensor([0.1079, 0.3113, 0.5808], device='cuda:0')
2024-12-07 18:03:07,386 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 24: ref_distribution = tensor([0.1079, 0.3113, 0.5808], device='cuda:0'), new_distribution = tensor([0.1083, 0.3117, 0.5800], device='cuda:0')
2024-12-07 18:03:07,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 25: ref_distribution = tensor([0.1083, 0.3117, 0.5800], device='cuda:0'), new_distribution = tensor([0.1086, 0.3122, 0.5792], device='cuda:0')
2024-12-07 18:03:08,181 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 26: ref_distribution = tensor([0.1086, 0.3122, 0.5792], device='cuda:0'), new_distribution = tensor([0.1089, 0.3127, 0.5784], device='cuda:0')
2024-12-07 18:03:08,523 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 27: ref_distribution = tensor([0.1089, 0.3127, 0.5784], device='cuda:0'), new_distribution = tensor([0.1093, 0.3131, 0.5776], device='cuda:0')
2024-12-07 18:03:08,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 28: ref_distribution = tensor([0.1093, 0.3131, 0.5776], device='cuda:0'), new_distribution = tensor([0.1096, 0.3136, 0.5768], device='cuda:0')
2024-12-07 18:03:09,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 29: ref_distribution = tensor([0.1096, 0.3136, 0.5768], device='cuda:0'), new_distribution = tensor([0.1100, 0.3140, 0.5760], device='cuda:0')
2024-12-07 18:03:09,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 30: ref_distribution = tensor([0.1100, 0.3140, 0.5760], device='cuda:0'), new_distribution = tensor([0.1103, 0.3145, 0.5752], device='cuda:0')
2024-12-07 18:03:10,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 31: ref_distribution = tensor([0.1103, 0.3145, 0.5752], device='cuda:0'), new_distribution = tensor([0.1107, 0.3150, 0.5744], device='cuda:0')
2024-12-07 18:03:10,632 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 32: ref_distribution = tensor([0.1107, 0.3150, 0.5744], device='cuda:0'), new_distribution = tensor([0.1110, 0.3154, 0.5735], device='cuda:0')
2024-12-07 18:03:10,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 33: ref_distribution = tensor([0.1110, 0.3154, 0.5735], device='cuda:0'), new_distribution = tensor([0.1114, 0.3159, 0.5727], device='cuda:0')
2024-12-07 18:03:11,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 34: ref_distribution = tensor([0.1114, 0.3159, 0.5727], device='cuda:0'), new_distribution = tensor([0.1117, 0.3163, 0.5719], device='cuda:0')
2024-12-07 18:03:11,744 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 35: ref_distribution = tensor([0.1117, 0.3163, 0.5719], device='cuda:0'), new_distribution = tensor([0.1121, 0.3168, 0.5711], device='cuda:0')
2024-12-07 18:03:12,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 36: ref_distribution = tensor([0.1121, 0.3168, 0.5711], device='cuda:0'), new_distribution = tensor([0.1124, 0.3173, 0.5703], device='cuda:0')
2024-12-07 18:03:12,440 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 37: ref_distribution = tensor([0.1124, 0.3173, 0.5703], device='cuda:0'), new_distribution = tensor([0.1128, 0.3177, 0.5695], device='cuda:0')
2024-12-07 18:03:12,891 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 38: ref_distribution = tensor([0.1128, 0.3177, 0.5695], device='cuda:0'), new_distribution = tensor([0.1132, 0.3182, 0.5687], device='cuda:0')
2024-12-07 18:03:13,371 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 39: ref_distribution = tensor([0.1132, 0.3182, 0.5687], device='cuda:0'), new_distribution = tensor([0.1135, 0.3186, 0.5679], device='cuda:0')
2024-12-07 18:03:13,604 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 40: ref_distribution = tensor([0.1135, 0.3186, 0.5679], device='cuda:0'), new_distribution = tensor([0.1139, 0.3191, 0.5670], device='cuda:0')
2024-12-07 18:03:14,021 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 41: ref_distribution = tensor([0.1139, 0.3191, 0.5670], device='cuda:0'), new_distribution = tensor([0.1142, 0.3195, 0.5662], device='cuda:0')
2024-12-07 18:03:14,492 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 42: ref_distribution = tensor([0.1142, 0.3195, 0.5662], device='cuda:0'), new_distribution = tensor([0.1146, 0.3200, 0.5654], device='cuda:0')
2024-12-07 18:03:14,842 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 43: ref_distribution = tensor([0.1146, 0.3200, 0.5654], device='cuda:0'), new_distribution = tensor([0.1150, 0.3205, 0.5646], device='cuda:0')
2024-12-07 18:03:15,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 44: ref_distribution = tensor([0.1150, 0.3205, 0.5646], device='cuda:0'), new_distribution = tensor([0.1153, 0.3209, 0.5638], device='cuda:0')
2024-12-07 18:03:15,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 45: ref_distribution = tensor([0.1153, 0.3209, 0.5638], device='cuda:0'), new_distribution = tensor([0.1157, 0.3214, 0.5630], device='cuda:0')
2024-12-07 18:03:16,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 46: ref_distribution = tensor([0.1157, 0.3214, 0.5630], device='cuda:0'), new_distribution = tensor([0.1160, 0.3218, 0.5621], device='cuda:0')
2024-12-07 18:03:16,372 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 47: ref_distribution = tensor([0.1160, 0.3218, 0.5621], device='cuda:0'), new_distribution = tensor([0.1164, 0.3223, 0.5613], device='cuda:0')
2024-12-07 18:03:16,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 48: ref_distribution = tensor([0.1164, 0.3223, 0.5613], device='cuda:0'), new_distribution = tensor([0.1168, 0.3227, 0.5605], device='cuda:0')
2024-12-07 18:03:17,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 49: ref_distribution = tensor([0.1168, 0.3227, 0.5605], device='cuda:0'), new_distribution = tensor([0.1172, 0.3232, 0.5597], device='cuda:0')
2024-12-07 18:03:17,552 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 50: ref_distribution = tensor([0.1172, 0.3232, 0.5597], device='cuda:0'), new_distribution = tensor([0.1175, 0.3236, 0.5589], device='cuda:0')
2024-12-07 18:03:17,897 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 51: ref_distribution = tensor([0.1175, 0.3236, 0.5589], device='cuda:0'), new_distribution = tensor([0.1179, 0.3241, 0.5580], device='cuda:0')
2024-12-07 18:03:18,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 52: ref_distribution = tensor([0.1179, 0.3241, 0.5580], device='cuda:0'), new_distribution = tensor([0.1183, 0.3245, 0.5572], device='cuda:0')
2024-12-07 18:03:18,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 53: ref_distribution = tensor([0.1183, 0.3245, 0.5572], device='cuda:0'), new_distribution = tensor([0.1186, 0.3250, 0.5564], device='cuda:0')
2024-12-07 18:03:19,080 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 54: ref_distribution = tensor([0.1186, 0.3250, 0.5564], device='cuda:0'), new_distribution = tensor([0.1190, 0.3254, 0.5556], device='cuda:0')
2024-12-07 18:03:19,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 55: ref_distribution = tensor([0.1190, 0.3254, 0.5556], device='cuda:0'), new_distribution = tensor([0.1194, 0.3259, 0.5548], device='cuda:0')
2024-12-07 18:03:19,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 56: ref_distribution = tensor([0.1194, 0.3259, 0.5548], device='cuda:0'), new_distribution = tensor([0.1198, 0.3263, 0.5539], device='cuda:0')
2024-12-07 18:03:20,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 57: ref_distribution = tensor([0.1198, 0.3263, 0.5539], device='cuda:0'), new_distribution = tensor([0.1201, 0.3267, 0.5531], device='cuda:0')
2024-12-07 18:03:20,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 58: ref_distribution = tensor([0.1201, 0.3267, 0.5531], device='cuda:0'), new_distribution = tensor([0.1205, 0.3272, 0.5523], device='cuda:0')
2024-12-07 18:03:21,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 59: ref_distribution = tensor([0.1205, 0.3272, 0.5523], device='cuda:0'), new_distribution = tensor([0.1209, 0.3276, 0.5515], device='cuda:0')
2024-12-07 18:03:21,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 60: ref_distribution = tensor([0.1209, 0.3276, 0.5515], device='cuda:0'), new_distribution = tensor([0.1213, 0.3281, 0.5506], device='cuda:0')
2024-12-07 18:03:21,817 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 61: ref_distribution = tensor([0.1213, 0.3281, 0.5506], device='cuda:0'), new_distribution = tensor([0.1217, 0.3285, 0.5498], device='cuda:0')
2024-12-07 18:03:22,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 62: ref_distribution = tensor([0.1217, 0.3285, 0.5498], device='cuda:0'), new_distribution = tensor([0.1220, 0.3290, 0.5490], device='cuda:0')
2024-12-07 18:03:22,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 63: ref_distribution = tensor([0.1220, 0.3290, 0.5490], device='cuda:0'), new_distribution = tensor([0.1224, 0.3294, 0.5482], device='cuda:0')
2024-12-07 18:03:23,005 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 64: ref_distribution = tensor([0.1224, 0.3294, 0.5482], device='cuda:0'), new_distribution = tensor([0.1228, 0.3298, 0.5474], device='cuda:0')
2024-12-07 18:03:23,384 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 65: ref_distribution = tensor([0.1228, 0.3298, 0.5474], device='cuda:0'), new_distribution = tensor([0.1232, 0.3303, 0.5465], device='cuda:0')
2024-12-07 18:03:23,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 66: ref_distribution = tensor([0.1232, 0.3303, 0.5465], device='cuda:0'), new_distribution = tensor([0.1236, 0.3307, 0.5457], device='cuda:0')
2024-12-07 18:03:24,247 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 67: ref_distribution = tensor([0.1236, 0.3307, 0.5457], device='cuda:0'), new_distribution = tensor([0.1240, 0.3311, 0.5449], device='cuda:0')
2024-12-07 18:03:24,597 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 68: ref_distribution = tensor([0.1240, 0.3311, 0.5449], device='cuda:0'), new_distribution = tensor([0.1244, 0.3316, 0.5440], device='cuda:0')
2024-12-07 18:03:25,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 69: ref_distribution = tensor([0.1244, 0.3316, 0.5440], device='cuda:0'), new_distribution = tensor([0.1248, 0.3320, 0.5432], device='cuda:0')
2024-12-07 18:03:25,463 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 70: ref_distribution = tensor([0.1248, 0.3320, 0.5432], device='cuda:0'), new_distribution = tensor([0.1251, 0.3325, 0.5424], device='cuda:0')
2024-12-07 18:03:25,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 71: ref_distribution = tensor([0.1251, 0.3325, 0.5424], device='cuda:0'), new_distribution = tensor([0.1255, 0.3329, 0.5416], device='cuda:0')
2024-12-07 18:03:26,159 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 72: ref_distribution = tensor([0.1255, 0.3329, 0.5416], device='cuda:0'), new_distribution = tensor([0.1259, 0.3333, 0.5407], device='cuda:0')
2024-12-07 18:03:26,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 73: ref_distribution = tensor([0.1259, 0.3333, 0.5407], device='cuda:0'), new_distribution = tensor([0.1263, 0.3338, 0.5399], device='cuda:0')
2024-12-07 18:03:27,065 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 74: ref_distribution = tensor([0.1263, 0.3338, 0.5399], device='cuda:0'), new_distribution = tensor([0.1267, 0.3342, 0.5391], device='cuda:0')
2024-12-07 18:03:27,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 75: ref_distribution = tensor([0.1267, 0.3342, 0.5391], device='cuda:0'), new_distribution = tensor([0.1271, 0.3346, 0.5383], device='cuda:0')
2024-12-07 18:03:27,809 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 76: ref_distribution = tensor([0.1271, 0.3346, 0.5383], device='cuda:0'), new_distribution = tensor([0.1275, 0.3350, 0.5374], device='cuda:0')
2024-12-07 18:03:28,291 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 77: ref_distribution = tensor([0.1275, 0.3350, 0.5374], device='cuda:0'), new_distribution = tensor([0.1279, 0.3355, 0.5366], device='cuda:0')
2024-12-07 18:03:28,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 78: ref_distribution = tensor([0.1279, 0.3355, 0.5366], device='cuda:0'), new_distribution = tensor([0.1283, 0.3359, 0.5358], device='cuda:0')
2024-12-07 18:03:28,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 79: ref_distribution = tensor([0.1283, 0.3359, 0.5358], device='cuda:0'), new_distribution = tensor([0.1287, 0.3363, 0.5349], device='cuda:0')
2024-12-07 18:03:29,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 80: ref_distribution = tensor([0.1287, 0.3363, 0.5349], device='cuda:0'), new_distribution = tensor([0.1291, 0.3368, 0.5341], device='cuda:0')
2024-12-07 18:03:29,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 81: ref_distribution = tensor([0.1291, 0.3368, 0.5341], device='cuda:0'), new_distribution = tensor([0.1295, 0.3372, 0.5333], device='cuda:0')
2024-12-07 18:03:30,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 82: ref_distribution = tensor([0.1295, 0.3372, 0.5333], device='cuda:0'), new_distribution = tensor([0.1299, 0.3376, 0.5324], device='cuda:0')
2024-12-07 18:03:30,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 83: ref_distribution = tensor([0.1299, 0.3376, 0.5324], device='cuda:0'), new_distribution = tensor([0.1303, 0.3380, 0.5316], device='cuda:0')
2024-12-07 18:03:30,845 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 84: ref_distribution = tensor([0.1303, 0.3380, 0.5316], device='cuda:0'), new_distribution = tensor([0.1308, 0.3385, 0.5308], device='cuda:0')
2024-12-07 18:03:31,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 85: ref_distribution = tensor([0.1308, 0.3385, 0.5308], device='cuda:0'), new_distribution = tensor([0.1312, 0.3389, 0.5300], device='cuda:0')
2024-12-07 18:03:31,660 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 86: ref_distribution = tensor([0.1312, 0.3389, 0.5300], device='cuda:0'), new_distribution = tensor([0.1316, 0.3393, 0.5291], device='cuda:0')
2024-12-07 18:03:32,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 87: ref_distribution = tensor([0.1316, 0.3393, 0.5291], device='cuda:0'), new_distribution = tensor([0.1320, 0.3397, 0.5283], device='cuda:0')
2024-12-07 18:03:32,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 88: ref_distribution = tensor([0.1320, 0.3397, 0.5283], device='cuda:0'), new_distribution = tensor([0.1324, 0.3401, 0.5275], device='cuda:0')
2024-12-07 18:03:32,807 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 89: ref_distribution = tensor([0.1324, 0.3401, 0.5275], device='cuda:0'), new_distribution = tensor([0.1328, 0.3406, 0.5266], device='cuda:0')
2024-12-07 18:03:33,031 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 90: ref_distribution = tensor([0.1328, 0.3406, 0.5266], device='cuda:0'), new_distribution = tensor([0.1332, 0.3410, 0.5258], device='cuda:0')
2024-12-07 18:03:33,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 91: ref_distribution = tensor([0.1332, 0.3410, 0.5258], device='cuda:0'), new_distribution = tensor([0.1336, 0.3414, 0.5250], device='cuda:0')
2024-12-07 18:03:33,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 92: ref_distribution = tensor([0.1336, 0.3414, 0.5250], device='cuda:0'), new_distribution = tensor([0.1341, 0.3418, 0.5241], device='cuda:0')
2024-12-07 18:03:34,235 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 93: ref_distribution = tensor([0.1341, 0.3418, 0.5241], device='cuda:0'), new_distribution = tensor([0.1345, 0.3422, 0.5233], device='cuda:0')
2024-12-07 18:03:34,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 94: ref_distribution = tensor([0.1345, 0.3422, 0.5233], device='cuda:0'), new_distribution = tensor([0.1349, 0.3426, 0.5225], device='cuda:0')
2024-12-07 18:03:35,076 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 95: ref_distribution = tensor([0.1349, 0.3426, 0.5225], device='cuda:0'), new_distribution = tensor([0.1353, 0.3431, 0.5216], device='cuda:0')
2024-12-07 18:03:35,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 96: ref_distribution = tensor([0.1353, 0.3431, 0.5216], device='cuda:0'), new_distribution = tensor([0.1357, 0.3435, 0.5208], device='cuda:0')
2024-12-07 18:03:35,853 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 97: ref_distribution = tensor([0.1357, 0.3435, 0.5208], device='cuda:0'), new_distribution = tensor([0.1362, 0.3439, 0.5200], device='cuda:0')
2024-12-07 18:03:36,237 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 98: ref_distribution = tensor([0.1362, 0.3439, 0.5200], device='cuda:0'), new_distribution = tensor([0.1366, 0.3443, 0.5191], device='cuda:0')
2024-12-07 18:03:36,717 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 99: ref_distribution = tensor([0.1366, 0.3443, 0.5191], device='cuda:0'), new_distribution = tensor([0.1370, 0.3447, 0.5183], device='cuda:0')
2024-12-07 18:03:37,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 100: ref_distribution = tensor([0.1370, 0.3447, 0.5183], device='cuda:0'), new_distribution = tensor([0.1374, 0.3451, 0.5174], device='cuda:0')
2024-12-07 18:03:37,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 101: ref_distribution = tensor([0.1374, 0.3451, 0.5174], device='cuda:0'), new_distribution = tensor([0.1379, 0.3455, 0.5166], device='cuda:0')
2024-12-07 18:03:37,873 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 102: ref_distribution = tensor([0.1379, 0.3455, 0.5166], device='cuda:0'), new_distribution = tensor([0.1383, 0.3459, 0.5158], device='cuda:0')
2024-12-07 18:03:38,347 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 103: ref_distribution = tensor([0.1383, 0.3459, 0.5158], device='cuda:0'), new_distribution = tensor([0.1387, 0.3463, 0.5149], device='cuda:0')
2024-12-07 18:03:38,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 104: ref_distribution = tensor([0.1387, 0.3463, 0.5149], device='cuda:0'), new_distribution = tensor([0.1392, 0.3467, 0.5141], device='cuda:0')
2024-12-07 18:03:38,993 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 105: ref_distribution = tensor([0.1392, 0.3467, 0.5141], device='cuda:0'), new_distribution = tensor([0.1396, 0.3471, 0.5133], device='cuda:0')
2024-12-07 18:03:39,472 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 106: ref_distribution = tensor([0.1396, 0.3471, 0.5133], device='cuda:0'), new_distribution = tensor([0.1400, 0.3475, 0.5124], device='cuda:0')
2024-12-07 18:03:39,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 107: ref_distribution = tensor([0.1400, 0.3475, 0.5124], device='cuda:0'), new_distribution = tensor([0.1405, 0.3479, 0.5116], device='cuda:0')
2024-12-07 18:03:40,145 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 108: ref_distribution = tensor([0.1405, 0.3479, 0.5116], device='cuda:0'), new_distribution = tensor([0.1409, 0.3483, 0.5108], device='cuda:0')
2024-12-07 18:03:40,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 109: ref_distribution = tensor([0.1409, 0.3483, 0.5108], device='cuda:0'), new_distribution = tensor([0.1413, 0.3487, 0.5099], device='cuda:0')
2024-12-07 18:03:41,090 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 110: ref_distribution = tensor([0.1413, 0.3487, 0.5099], device='cuda:0'), new_distribution = tensor([0.1418, 0.3491, 0.5091], device='cuda:0')
2024-12-07 18:03:41,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 111: ref_distribution = tensor([0.1418, 0.3491, 0.5091], device='cuda:0'), new_distribution = tensor([0.1422, 0.3495, 0.5082], device='cuda:0')
2024-12-07 18:03:41,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 112: ref_distribution = tensor([0.1422, 0.3495, 0.5082], device='cuda:0'), new_distribution = tensor([0.1427, 0.3499, 0.5074], device='cuda:0')
2024-12-07 18:03:42,247 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 113: ref_distribution = tensor([0.1427, 0.3499, 0.5074], device='cuda:0'), new_distribution = tensor([0.1431, 0.3503, 0.5066], device='cuda:0')
2024-12-07 18:03:42,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 114: ref_distribution = tensor([0.1431, 0.3503, 0.5066], device='cuda:0'), new_distribution = tensor([0.1435, 0.3507, 0.5057], device='cuda:0')
2024-12-07 18:03:42,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 115: ref_distribution = tensor([0.1435, 0.3507, 0.5057], device='cuda:0'), new_distribution = tensor([0.1440, 0.3511, 0.5049], device='cuda:0')
2024-12-07 18:03:43,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 116: ref_distribution = tensor([0.1440, 0.3511, 0.5049], device='cuda:0'), new_distribution = tensor([0.1444, 0.3515, 0.5041], device='cuda:0')
2024-12-07 18:03:43,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 117: ref_distribution = tensor([0.1444, 0.3515, 0.5041], device='cuda:0'), new_distribution = tensor([0.1449, 0.3519, 0.5032], device='cuda:0')
2024-12-07 18:03:44,195 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 118: ref_distribution = tensor([0.1449, 0.3519, 0.5032], device='cuda:0'), new_distribution = tensor([0.1453, 0.3523, 0.5024], device='cuda:0')
2024-12-07 18:03:44,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 119: ref_distribution = tensor([0.1453, 0.3523, 0.5024], device='cuda:0'), new_distribution = tensor([0.1458, 0.3527, 0.5015], device='cuda:0')
2024-12-07 18:03:45,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 120: ref_distribution = tensor([0.1458, 0.3527, 0.5015], device='cuda:0'), new_distribution = tensor([0.1462, 0.3531, 0.5007], device='cuda:0')
2024-12-07 18:03:45,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 121: ref_distribution = tensor([0.1462, 0.3531, 0.5007], device='cuda:0'), new_distribution = tensor([0.1467, 0.3534, 0.4999], device='cuda:0')
2024-12-07 18:03:45,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 122: ref_distribution = tensor([0.1467, 0.3534, 0.4999], device='cuda:0'), new_distribution = tensor([0.1471, 0.3538, 0.4990], device='cuda:0')
2024-12-07 18:03:46,166 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 123: ref_distribution = tensor([0.1471, 0.3538, 0.4990], device='cuda:0'), new_distribution = tensor([0.1476, 0.3542, 0.4982], device='cuda:0')
2024-12-07 18:03:46,643 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 124: ref_distribution = tensor([0.1476, 0.3542, 0.4982], device='cuda:0'), new_distribution = tensor([0.1481, 0.3546, 0.4974], device='cuda:0')
2024-12-07 18:03:47,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 125: ref_distribution = tensor([0.1481, 0.3546, 0.4974], device='cuda:0'), new_distribution = tensor([0.1485, 0.3550, 0.4965], device='cuda:0')
2024-12-07 18:03:47,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 126: ref_distribution = tensor([0.1485, 0.3550, 0.4965], device='cuda:0'), new_distribution = tensor([0.1490, 0.3554, 0.4957], device='cuda:0')
2024-12-07 18:03:47,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 127: ref_distribution = tensor([0.1490, 0.3554, 0.4957], device='cuda:0'), new_distribution = tensor([0.1494, 0.3557, 0.4948], device='cuda:0')
2024-12-07 18:03:48,202 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 128: ref_distribution = tensor([0.1494, 0.3557, 0.4948], device='cuda:0'), new_distribution = tensor([0.1499, 0.3561, 0.4940], device='cuda:0')
2024-12-07 18:03:48,432 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 129: ref_distribution = tensor([0.1499, 0.3561, 0.4940], device='cuda:0'), new_distribution = tensor([0.1504, 0.3565, 0.4932], device='cuda:0')
2024-12-07 18:03:48,671 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 130: ref_distribution = tensor([0.1504, 0.3565, 0.4932], device='cuda:0'), new_distribution = tensor([0.1508, 0.3569, 0.4923], device='cuda:0')
2024-12-07 18:03:49,081 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 131: ref_distribution = tensor([0.1508, 0.3569, 0.4923], device='cuda:0'), new_distribution = tensor([0.1513, 0.3572, 0.4915], device='cuda:0')
2024-12-07 18:03:49,556 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 132: ref_distribution = tensor([0.1513, 0.3572, 0.4915], device='cuda:0'), new_distribution = tensor([0.1517, 0.3576, 0.4906], device='cuda:0')
2024-12-07 18:03:49,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 133: ref_distribution = tensor([0.1517, 0.3576, 0.4906], device='cuda:0'), new_distribution = tensor([0.1522, 0.3580, 0.4898], device='cuda:0')
2024-12-07 18:03:50,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 134: ref_distribution = tensor([0.1522, 0.3580, 0.4898], device='cuda:0'), new_distribution = tensor([0.1527, 0.3584, 0.4890], device='cuda:0')
2024-12-07 18:03:50,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 135: ref_distribution = tensor([0.1527, 0.3584, 0.4890], device='cuda:0'), new_distribution = tensor([0.1532, 0.3587, 0.4881], device='cuda:0')
2024-12-07 18:03:50,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 136: ref_distribution = tensor([0.1532, 0.3587, 0.4881], device='cuda:0'), new_distribution = tensor([0.1536, 0.3591, 0.4873], device='cuda:0')
2024-12-07 18:03:51,314 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 137: ref_distribution = tensor([0.1536, 0.3591, 0.4873], device='cuda:0'), new_distribution = tensor([0.1541, 0.3595, 0.4864], device='cuda:0')
2024-12-07 18:03:51,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 138: ref_distribution = tensor([0.1541, 0.3595, 0.4864], device='cuda:0'), new_distribution = tensor([0.1546, 0.3598, 0.4856], device='cuda:0')
2024-12-07 18:03:52,236 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 139: ref_distribution = tensor([0.1546, 0.3598, 0.4856], device='cuda:0'), new_distribution = tensor([0.1550, 0.3602, 0.4848], device='cuda:0')
2024-12-07 18:03:52,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 140: ref_distribution = tensor([0.1550, 0.3602, 0.4848], device='cuda:0'), new_distribution = tensor([0.1555, 0.3605, 0.4839], device='cuda:0')
2024-12-07 18:03:52,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 141: ref_distribution = tensor([0.1555, 0.3605, 0.4839], device='cuda:0'), new_distribution = tensor([0.1560, 0.3609, 0.4831], device='cuda:0')
2024-12-07 18:03:53,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 142: ref_distribution = tensor([0.1560, 0.3609, 0.4831], device='cuda:0'), new_distribution = tensor([0.1565, 0.3613, 0.4823], device='cuda:0')
2024-12-07 18:03:53,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 143: ref_distribution = tensor([0.1565, 0.3613, 0.4823], device='cuda:0'), new_distribution = tensor([0.1570, 0.3616, 0.4814], device='cuda:0')
2024-12-07 18:03:54,102 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 144: ref_distribution = tensor([0.1570, 0.3616, 0.4814], device='cuda:0'), new_distribution = tensor([0.1574, 0.3620, 0.4806], device='cuda:0')
2024-12-07 18:03:54,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 145: ref_distribution = tensor([0.1574, 0.3620, 0.4806], device='cuda:0'), new_distribution = tensor([0.1579, 0.3623, 0.4797], device='cuda:0')
2024-12-07 18:03:55,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 146: ref_distribution = tensor([0.1579, 0.3623, 0.4797], device='cuda:0'), new_distribution = tensor([0.1584, 0.3627, 0.4789], device='cuda:0')
2024-12-07 18:03:55,346 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 147: ref_distribution = tensor([0.1584, 0.3627, 0.4789], device='cuda:0'), new_distribution = tensor([0.1589, 0.3631, 0.4781], device='cuda:0')
2024-12-07 18:03:55,721 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 148: ref_distribution = tensor([0.1589, 0.3631, 0.4781], device='cuda:0'), new_distribution = tensor([0.1594, 0.3634, 0.4772], device='cuda:0')
2024-12-07 18:03:56,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 149: ref_distribution = tensor([0.1594, 0.3634, 0.4772], device='cuda:0'), new_distribution = tensor([0.1599, 0.3638, 0.4764], device='cuda:0')
2024-12-07 18:03:56,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 150: ref_distribution = tensor([0.1599, 0.3638, 0.4764], device='cuda:0'), new_distribution = tensor([0.1604, 0.3641, 0.4755], device='cuda:0')
2024-12-07 18:03:56,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 151: ref_distribution = tensor([0.1604, 0.3641, 0.4755], device='cuda:0'), new_distribution = tensor([0.1608, 0.3645, 0.4747], device='cuda:0')
2024-12-07 18:03:57,329 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 152: ref_distribution = tensor([0.1608, 0.3645, 0.4747], device='cuda:0'), new_distribution = tensor([0.1613, 0.3648, 0.4739], device='cuda:0')
2024-12-07 18:03:57,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 153: ref_distribution = tensor([0.1613, 0.3648, 0.4739], device='cuda:0'), new_distribution = tensor([0.1618, 0.3651, 0.4730], device='cuda:0')
2024-12-07 18:03:58,092 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 154: ref_distribution = tensor([0.1618, 0.3651, 0.4730], device='cuda:0'), new_distribution = tensor([0.1623, 0.3655, 0.4722], device='cuda:0')
2024-12-07 18:03:58,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 155: ref_distribution = tensor([0.1623, 0.3655, 0.4722], device='cuda:0'), new_distribution = tensor([0.1628, 0.3658, 0.4713], device='cuda:0')
2024-12-07 18:03:58,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 156: ref_distribution = tensor([0.1628, 0.3658, 0.4713], device='cuda:0'), new_distribution = tensor([0.1633, 0.3662, 0.4705], device='cuda:0')
2024-12-07 18:03:59,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 157: ref_distribution = tensor([0.1633, 0.3662, 0.4705], device='cuda:0'), new_distribution = tensor([0.1638, 0.3665, 0.4697], device='cuda:0')
2024-12-07 18:03:59,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 158: ref_distribution = tensor([0.1638, 0.3665, 0.4697], device='cuda:0'), new_distribution = tensor([0.1643, 0.3669, 0.4688], device='cuda:0')
2024-12-07 18:04:00,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 159: ref_distribution = tensor([0.1643, 0.3669, 0.4688], device='cuda:0'), new_distribution = tensor([0.1648, 0.3672, 0.4680], device='cuda:0')
2024-12-07 18:04:00,469 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 160: ref_distribution = tensor([0.1648, 0.3672, 0.4680], device='cuda:0'), new_distribution = tensor([0.1653, 0.3675, 0.4671], device='cuda:0')
2024-12-07 18:04:00,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 161: ref_distribution = tensor([0.1653, 0.3675, 0.4671], device='cuda:0'), new_distribution = tensor([0.1658, 0.3679, 0.4663], device='cuda:0')
2024-12-07 18:04:01,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 162: ref_distribution = tensor([0.1658, 0.3679, 0.4663], device='cuda:0'), new_distribution = tensor([0.1663, 0.3682, 0.4655], device='cuda:0')
2024-12-07 18:04:01,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 163: ref_distribution = tensor([0.1663, 0.3682, 0.4655], device='cuda:0'), new_distribution = tensor([0.1668, 0.3685, 0.4646], device='cuda:0')
2024-12-07 18:04:01,940 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 164: ref_distribution = tensor([0.1668, 0.3685, 0.4646], device='cuda:0'), new_distribution = tensor([0.1673, 0.3689, 0.4638], device='cuda:0')
2024-12-07 18:04:02,327 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 165: ref_distribution = tensor([0.1673, 0.3689, 0.4638], device='cuda:0'), new_distribution = tensor([0.1679, 0.3692, 0.4630], device='cuda:0')
2024-12-07 18:04:02,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 166: ref_distribution = tensor([0.1679, 0.3692, 0.4630], device='cuda:0'), new_distribution = tensor([0.1684, 0.3695, 0.4621], device='cuda:0')
2024-12-07 18:04:03,140 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 167: ref_distribution = tensor([0.1684, 0.3695, 0.4621], device='cuda:0'), new_distribution = tensor([0.1689, 0.3698, 0.4613], device='cuda:0')
2024-12-07 18:04:03,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 168: ref_distribution = tensor([0.1689, 0.3698, 0.4613], device='cuda:0'), new_distribution = tensor([0.1694, 0.3702, 0.4604], device='cuda:0')
2024-12-07 18:04:03,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 169: ref_distribution = tensor([0.1694, 0.3702, 0.4604], device='cuda:0'), new_distribution = tensor([0.1699, 0.3705, 0.4596], device='cuda:0')
2024-12-07 18:04:04,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 170: ref_distribution = tensor([0.1699, 0.3705, 0.4596], device='cuda:0'), new_distribution = tensor([0.1704, 0.3708, 0.4588], device='cuda:0')
2024-12-07 18:04:04,658 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 171: ref_distribution = tensor([0.1704, 0.3708, 0.4588], device='cuda:0'), new_distribution = tensor([0.1709, 0.3711, 0.4579], device='cuda:0')
2024-12-07 18:04:05,087 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 172: ref_distribution = tensor([0.1709, 0.3711, 0.4579], device='cuda:0'), new_distribution = tensor([0.1715, 0.3714, 0.4571], device='cuda:0')
2024-12-07 18:04:05,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 173: ref_distribution = tensor([0.1715, 0.3714, 0.4571], device='cuda:0'), new_distribution = tensor([0.1720, 0.3718, 0.4563], device='cuda:0')
2024-12-07 18:04:05,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 174: ref_distribution = tensor([0.1720, 0.3718, 0.4563], device='cuda:0'), new_distribution = tensor([0.1725, 0.3721, 0.4554], device='cuda:0')
2024-12-07 18:04:06,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 175: ref_distribution = tensor([0.1725, 0.3721, 0.4554], device='cuda:0'), new_distribution = tensor([0.1730, 0.3724, 0.4546], device='cuda:0')
2024-12-07 18:04:06,687 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 176: ref_distribution = tensor([0.1730, 0.3724, 0.4546], device='cuda:0'), new_distribution = tensor([0.1735, 0.3727, 0.4538], device='cuda:0')
2024-12-07 18:04:06,996 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 177: ref_distribution = tensor([0.1735, 0.3727, 0.4538], device='cuda:0'), new_distribution = tensor([0.1741, 0.3730, 0.4529], device='cuda:0')
2024-12-07 18:04:07,323 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 178: ref_distribution = tensor([0.1741, 0.3730, 0.4529], device='cuda:0'), new_distribution = tensor([0.1746, 0.3733, 0.4521], device='cuda:0')
2024-12-07 18:04:07,798 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 179: ref_distribution = tensor([0.1746, 0.3733, 0.4521], device='cuda:0'), new_distribution = tensor([0.1751, 0.3736, 0.4512], device='cuda:0')
2024-12-07 18:04:08,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 180: ref_distribution = tensor([0.1751, 0.3736, 0.4512], device='cuda:0'), new_distribution = tensor([0.1756, 0.3739, 0.4504], device='cuda:0')
2024-12-07 18:04:08,442 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 181: ref_distribution = tensor([0.1756, 0.3739, 0.4504], device='cuda:0'), new_distribution = tensor([0.1762, 0.3743, 0.4496], device='cuda:0')
2024-12-07 18:04:08,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 182: ref_distribution = tensor([0.1762, 0.3743, 0.4496], device='cuda:0'), new_distribution = tensor([0.1767, 0.3746, 0.4487], device='cuda:0')
2024-12-07 18:04:09,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 183: ref_distribution = tensor([0.1767, 0.3746, 0.4487], device='cuda:0'), new_distribution = tensor([0.1772, 0.3749, 0.4479], device='cuda:0')
2024-12-07 18:04:09,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 184: ref_distribution = tensor([0.1772, 0.3749, 0.4479], device='cuda:0'), new_distribution = tensor([0.1778, 0.3752, 0.4471], device='cuda:0')
2024-12-07 18:04:10,029 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 185: ref_distribution = tensor([0.1778, 0.3752, 0.4471], device='cuda:0'), new_distribution = tensor([0.1783, 0.3755, 0.4462], device='cuda:0')
2024-12-07 18:04:10,453 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 186: ref_distribution = tensor([0.1783, 0.3755, 0.4462], device='cuda:0'), new_distribution = tensor([0.1788, 0.3758, 0.4454], device='cuda:0')
2024-12-07 18:04:10,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 187: ref_distribution = tensor([0.1788, 0.3758, 0.4454], device='cuda:0'), new_distribution = tensor([0.1794, 0.3760, 0.4446], device='cuda:0')
2024-12-07 18:04:11,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 188: ref_distribution = tensor([0.1794, 0.3760, 0.4446], device='cuda:0'), new_distribution = tensor([0.1799, 0.3763, 0.4437], device='cuda:0')
2024-12-07 18:04:11,569 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 189: ref_distribution = tensor([0.1799, 0.3763, 0.4437], device='cuda:0'), new_distribution = tensor([0.1805, 0.3766, 0.4429], device='cuda:0')
2024-12-07 18:04:11,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 190: ref_distribution = tensor([0.1805, 0.3766, 0.4429], device='cuda:0'), new_distribution = tensor([0.1810, 0.3769, 0.4421], device='cuda:0')
2024-12-07 18:04:12,313 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 191: ref_distribution = tensor([0.1810, 0.3769, 0.4421], device='cuda:0'), new_distribution = tensor([0.1816, 0.3772, 0.4412], device='cuda:0')
2024-12-07 18:04:12,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 192: ref_distribution = tensor([0.1816, 0.3772, 0.4412], device='cuda:0'), new_distribution = tensor([0.1821, 0.3775, 0.4404], device='cuda:0')
2024-12-07 18:04:13,110 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 193: ref_distribution = tensor([0.1821, 0.3775, 0.4404], device='cuda:0'), new_distribution = tensor([0.1826, 0.3778, 0.4396], device='cuda:0')
2024-12-07 18:04:13,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 194: ref_distribution = tensor([0.1826, 0.3778, 0.4396], device='cuda:0'), new_distribution = tensor([0.1832, 0.3781, 0.4387], device='cuda:0')
2024-12-07 18:04:13,935 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 195: ref_distribution = tensor([0.1832, 0.3781, 0.4387], device='cuda:0'), new_distribution = tensor([0.1837, 0.3784, 0.4379], device='cuda:0')
2024-12-07 18:04:14,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 196: ref_distribution = tensor([0.1837, 0.3784, 0.4379], device='cuda:0'), new_distribution = tensor([0.1843, 0.3786, 0.4371], device='cuda:0')
2024-12-07 18:04:14,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 197: ref_distribution = tensor([0.1843, 0.3786, 0.4371], device='cuda:0'), new_distribution = tensor([0.1848, 0.3789, 0.4362], device='cuda:0')
2024-12-07 18:04:15,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 198: ref_distribution = tensor([0.1848, 0.3789, 0.4362], device='cuda:0'), new_distribution = tensor([0.1854, 0.3792, 0.4354], device='cuda:0')
2024-12-07 18:04:15,541 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 199: ref_distribution = tensor([0.1854, 0.3792, 0.4354], device='cuda:0'), new_distribution = tensor([0.1859, 0.3795, 0.4346], device='cuda:0')
2024-12-07 18:04:15,949 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 200: ref_distribution = tensor([0.1859, 0.3795, 0.4346], device='cuda:0'), new_distribution = tensor([0.1865, 0.3797, 0.4338], device='cuda:0')
2024-12-07 18:04:16,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 201: ref_distribution = tensor([0.1865, 0.3797, 0.4338], device='cuda:0'), new_distribution = tensor([0.1871, 0.3800, 0.4329], device='cuda:0')
2024-12-07 18:04:16,694 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 202: ref_distribution = tensor([0.1871, 0.3800, 0.4329], device='cuda:0'), new_distribution = tensor([0.1876, 0.3803, 0.4321], device='cuda:0')
2024-12-07 18:04:17,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 203: ref_distribution = tensor([0.1876, 0.3803, 0.4321], device='cuda:0'), new_distribution = tensor([0.1882, 0.3806, 0.4313], device='cuda:0')
2024-12-07 18:04:17,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 204: ref_distribution = tensor([0.1882, 0.3806, 0.4313], device='cuda:0'), new_distribution = tensor([0.1887, 0.3808, 0.4304], device='cuda:0')
2024-12-07 18:04:17,805 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 205: ref_distribution = tensor([0.1887, 0.3808, 0.4304], device='cuda:0'), new_distribution = tensor([0.1893, 0.3811, 0.4296], device='cuda:0')
2024-12-07 18:04:18,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 206: ref_distribution = tensor([0.1893, 0.3811, 0.4296], device='cuda:0'), new_distribution = tensor([0.1899, 0.3814, 0.4288], device='cuda:0')
2024-12-07 18:04:18,551 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 207: ref_distribution = tensor([0.1899, 0.3814, 0.4288], device='cuda:0'), new_distribution = tensor([0.1904, 0.3816, 0.4279], device='cuda:0')
2024-12-07 18:04:18,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 208: ref_distribution = tensor([0.1904, 0.3816, 0.4279], device='cuda:0'), new_distribution = tensor([0.1910, 0.3819, 0.4271], device='cuda:0')
2024-12-07 18:04:19,378 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 209: ref_distribution = tensor([0.1910, 0.3819, 0.4271], device='cuda:0'), new_distribution = tensor([0.1916, 0.3821, 0.4263], device='cuda:0')
2024-12-07 18:04:19,667 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 210: ref_distribution = tensor([0.1916, 0.3821, 0.4263], device='cuda:0'), new_distribution = tensor([0.1921, 0.3824, 0.4255], device='cuda:0')
2024-12-07 18:04:20,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 211: ref_distribution = tensor([0.1921, 0.3824, 0.4255], device='cuda:0'), new_distribution = tensor([0.1927, 0.3827, 0.4246], device='cuda:0')
2024-12-07 18:04:20,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 212: ref_distribution = tensor([0.1927, 0.3827, 0.4246], device='cuda:0'), new_distribution = tensor([0.1933, 0.3829, 0.4238], device='cuda:0')
2024-12-07 18:04:20,968 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 213: ref_distribution = tensor([0.1933, 0.3829, 0.4238], device='cuda:0'), new_distribution = tensor([0.1939, 0.3832, 0.4230], device='cuda:0')
2024-12-07 18:04:21,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 214: ref_distribution = tensor([0.1939, 0.3832, 0.4230], device='cuda:0'), new_distribution = tensor([0.1944, 0.3834, 0.4222], device='cuda:0')
2024-12-07 18:04:21,669 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 215: ref_distribution = tensor([0.1944, 0.3834, 0.4222], device='cuda:0'), new_distribution = tensor([0.1950, 0.3837, 0.4213], device='cuda:0')
2024-12-07 18:04:22,145 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 216: ref_distribution = tensor([0.1950, 0.3837, 0.4213], device='cuda:0'), new_distribution = tensor([0.1956, 0.3839, 0.4205], device='cuda:0')
2024-12-07 18:04:22,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 217: ref_distribution = tensor([0.1956, 0.3839, 0.4205], device='cuda:0'), new_distribution = tensor([0.1962, 0.3842, 0.4197], device='cuda:0')
2024-12-07 18:04:22,797 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 218: ref_distribution = tensor([0.1962, 0.3842, 0.4197], device='cuda:0'), new_distribution = tensor([0.1967, 0.3844, 0.4189], device='cuda:0')
2024-12-07 18:04:23,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 219: ref_distribution = tensor([0.1967, 0.3844, 0.4189], device='cuda:0'), new_distribution = tensor([0.1973, 0.3846, 0.4180], device='cuda:0')
2024-12-07 18:04:23,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 220: ref_distribution = tensor([0.1973, 0.3846, 0.4180], device='cuda:0'), new_distribution = tensor([0.1979, 0.3849, 0.4172], device='cuda:0')
2024-12-07 18:04:23,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 221: ref_distribution = tensor([0.1979, 0.3849, 0.4172], device='cuda:0'), new_distribution = tensor([0.1985, 0.3851, 0.4164], device='cuda:0')
2024-12-07 18:04:24,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 222: ref_distribution = tensor([0.1985, 0.3851, 0.4164], device='cuda:0'), new_distribution = tensor([0.1991, 0.3854, 0.4156], device='cuda:0')
2024-12-07 18:04:24,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 223: ref_distribution = tensor([0.1991, 0.3854, 0.4156], device='cuda:0'), new_distribution = tensor([0.1997, 0.3856, 0.4147], device='cuda:0')
2024-12-07 18:04:25,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 224: ref_distribution = tensor([0.1997, 0.3856, 0.4147], device='cuda:0'), new_distribution = tensor([0.2003, 0.3858, 0.4139], device='cuda:0')
2024-12-07 18:04:25,534 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 225: ref_distribution = tensor([0.2003, 0.3858, 0.4139], device='cuda:0'), new_distribution = tensor([0.2008, 0.3860, 0.4131], device='cuda:0')
2024-12-07 18:04:26,009 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 226: ref_distribution = tensor([0.2008, 0.3860, 0.4131], device='cuda:0'), new_distribution = tensor([0.2014, 0.3863, 0.4123], device='cuda:0')
2024-12-07 18:04:26,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 227: ref_distribution = tensor([0.2014, 0.3863, 0.4123], device='cuda:0'), new_distribution = tensor([0.2020, 0.3865, 0.4115], device='cuda:0')
2024-12-07 18:04:26,659 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 228: ref_distribution = tensor([0.2020, 0.3865, 0.4115], device='cuda:0'), new_distribution = tensor([0.2026, 0.3867, 0.4106], device='cuda:0')
2024-12-07 18:04:27,131 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 229: ref_distribution = tensor([0.2026, 0.3867, 0.4106], device='cuda:0'), new_distribution = tensor([0.2032, 0.3870, 0.4098], device='cuda:0')
2024-12-07 18:04:27,423 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 230: ref_distribution = tensor([0.2032, 0.3870, 0.4098], device='cuda:0'), new_distribution = tensor([0.2038, 0.3872, 0.4090], device='cuda:0')
2024-12-07 18:04:27,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 231: ref_distribution = tensor([0.2038, 0.3872, 0.4090], device='cuda:0'), new_distribution = tensor([0.2044, 0.3874, 0.4082], device='cuda:0')
2024-12-07 18:04:28,256 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 232: ref_distribution = tensor([0.2044, 0.3874, 0.4082], device='cuda:0'), new_distribution = tensor([0.2050, 0.3876, 0.4074], device='cuda:0')
2024-12-07 18:04:28,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 233: ref_distribution = tensor([0.2050, 0.3876, 0.4074], device='cuda:0'), new_distribution = tensor([0.2056, 0.3878, 0.4065], device='cuda:0')
2024-12-07 18:04:29,039 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 234: ref_distribution = tensor([0.2056, 0.3878, 0.4065], device='cuda:0'), new_distribution = tensor([0.2062, 0.3880, 0.4057], device='cuda:0')
2024-12-07 18:04:29,416 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 235: ref_distribution = tensor([0.2062, 0.3880, 0.4057], device='cuda:0'), new_distribution = tensor([0.2068, 0.3883, 0.4049], device='cuda:0')
2024-12-07 18:04:29,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 236: ref_distribution = tensor([0.2068, 0.3883, 0.4049], device='cuda:0'), new_distribution = tensor([0.2074, 0.3885, 0.4041], device='cuda:0')
2024-12-07 18:04:30,196 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 237: ref_distribution = tensor([0.2074, 0.3885, 0.4041], device='cuda:0'), new_distribution = tensor([0.2080, 0.3887, 0.4033], device='cuda:0')
2024-12-07 18:04:30,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 238: ref_distribution = tensor([0.2080, 0.3887, 0.4033], device='cuda:0'), new_distribution = tensor([0.2086, 0.3889, 0.4025], device='cuda:0')
2024-12-07 18:04:30,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 239: ref_distribution = tensor([0.2086, 0.3889, 0.4025], device='cuda:0'), new_distribution = tensor([0.2093, 0.3891, 0.4017], device='cuda:0')
2024-12-07 18:04:31,277 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 240: ref_distribution = tensor([0.2093, 0.3891, 0.4017], device='cuda:0'), new_distribution = tensor([0.2099, 0.3893, 0.4008], device='cuda:0')
2024-12-07 18:04:31,620 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 241: ref_distribution = tensor([0.2099, 0.3893, 0.4008], device='cuda:0'), new_distribution = tensor([0.2105, 0.3895, 0.4000], device='cuda:0')
2024-12-07 18:04:32,093 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 242: ref_distribution = tensor([0.2105, 0.3895, 0.4000], device='cuda:0'), new_distribution = tensor([0.2111, 0.3897, 0.3992], device='cuda:0')
2024-12-07 18:04:32,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 243: ref_distribution = tensor([0.2111, 0.3897, 0.3992], device='cuda:0'), new_distribution = tensor([0.2117, 0.3899, 0.3984], device='cuda:0')
2024-12-07 18:04:32,771 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 244: ref_distribution = tensor([0.2117, 0.3899, 0.3984], device='cuda:0'), new_distribution = tensor([0.2123, 0.3901, 0.3976], device='cuda:0')
2024-12-07 18:04:33,240 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 245: ref_distribution = tensor([0.2123, 0.3901, 0.3976], device='cuda:0'), new_distribution = tensor([0.2129, 0.3903, 0.3968], device='cuda:0')
2024-12-07 18:04:33,649 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 246: ref_distribution = tensor([0.2129, 0.3903, 0.3968], device='cuda:0'), new_distribution = tensor([0.2136, 0.3905, 0.3960], device='cuda:0')
2024-12-07 18:04:33,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 247: ref_distribution = tensor([0.2136, 0.3905, 0.3960], device='cuda:0'), new_distribution = tensor([0.2142, 0.3907, 0.3952], device='cuda:0')
2024-12-07 18:04:34,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 248: ref_distribution = tensor([0.2142, 0.3907, 0.3952], device='cuda:0'), new_distribution = tensor([0.2148, 0.3909, 0.3943], device='cuda:0')
2024-12-07 18:04:34,858 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 249: ref_distribution = tensor([0.2148, 0.3909, 0.3943], device='cuda:0'), new_distribution = tensor([0.2154, 0.3910, 0.3935], device='cuda:0')
2024-12-07 18:04:35,164 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 250: ref_distribution = tensor([0.2154, 0.3910, 0.3935], device='cuda:0'), new_distribution = tensor([0.2161, 0.3912, 0.3927], device='cuda:0')
2024-12-07 18:04:35,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 251: ref_distribution = tensor([0.2161, 0.3912, 0.3927], device='cuda:0'), new_distribution = tensor([0.2167, 0.3914, 0.3919], device='cuda:0')
2024-12-07 18:04:35,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 252: ref_distribution = tensor([0.2167, 0.3914, 0.3919], device='cuda:0'), new_distribution = tensor([0.2173, 0.3916, 0.3911], device='cuda:0')
2024-12-07 18:04:36,344 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 253: ref_distribution = tensor([0.2173, 0.3916, 0.3911], device='cuda:0'), new_distribution = tensor([0.2179, 0.3918, 0.3903], device='cuda:0')
2024-12-07 18:04:36,692 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 254: ref_distribution = tensor([0.2179, 0.3918, 0.3903], device='cuda:0'), new_distribution = tensor([0.2186, 0.3919, 0.3895], device='cuda:0')
2024-12-07 18:04:37,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 255: ref_distribution = tensor([0.2186, 0.3919, 0.3895], device='cuda:0'), new_distribution = tensor([0.2192, 0.3921, 0.3887], device='cuda:0')
2024-12-07 18:04:37,609 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 256: ref_distribution = tensor([0.2192, 0.3921, 0.3887], device='cuda:0'), new_distribution = tensor([0.2198, 0.3923, 0.3879], device='cuda:0')
2024-12-07 18:04:37,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 257: ref_distribution = tensor([0.2198, 0.3923, 0.3879], device='cuda:0'), new_distribution = tensor([0.2205, 0.3925, 0.3871], device='cuda:0')
2024-12-07 18:04:38,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 258: ref_distribution = tensor([0.2205, 0.3925, 0.3871], device='cuda:0'), new_distribution = tensor([0.2211, 0.3926, 0.3863], device='cuda:0')
2024-12-07 18:04:38,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 259: ref_distribution = tensor([0.2211, 0.3926, 0.3863], device='cuda:0'), new_distribution = tensor([0.2217, 0.3928, 0.3855], device='cuda:0')
2024-12-07 18:04:39,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 260: ref_distribution = tensor([0.2217, 0.3928, 0.3855], device='cuda:0'), new_distribution = tensor([0.2224, 0.3930, 0.3847], device='cuda:0')
2024-12-07 18:04:39,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 261: ref_distribution = tensor([0.2224, 0.3930, 0.3847], device='cuda:0'), new_distribution = tensor([0.2230, 0.3931, 0.3839], device='cuda:0')
2024-12-07 18:04:39,932 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 262: ref_distribution = tensor([0.2230, 0.3931, 0.3839], device='cuda:0'), new_distribution = tensor([0.2237, 0.3933, 0.3831], device='cuda:0')
2024-12-07 18:04:40,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 263: ref_distribution = tensor([0.2237, 0.3933, 0.3831], device='cuda:0'), new_distribution = tensor([0.2243, 0.3934, 0.3823], device='cuda:0')
2024-12-07 18:04:40,640 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 264: ref_distribution = tensor([0.2243, 0.3934, 0.3823], device='cuda:0'), new_distribution = tensor([0.2250, 0.3936, 0.3815], device='cuda:0')
2024-12-07 18:04:41,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 265: ref_distribution = tensor([0.2250, 0.3936, 0.3815], device='cuda:0'), new_distribution = tensor([0.2256, 0.3938, 0.3807], device='cuda:0')
2024-12-07 18:04:41,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 266: ref_distribution = tensor([0.2256, 0.3938, 0.3807], device='cuda:0'), new_distribution = tensor([0.2262, 0.3939, 0.3799], device='cuda:0')
2024-12-07 18:04:42,170 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 267: ref_distribution = tensor([0.2262, 0.3939, 0.3799], device='cuda:0'), new_distribution = tensor([0.2269, 0.3941, 0.3791], device='cuda:0')
2024-12-07 18:04:42,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 268: ref_distribution = tensor([0.2269, 0.3941, 0.3791], device='cuda:0'), new_distribution = tensor([0.2275, 0.3942, 0.3783], device='cuda:0')
2024-12-07 18:04:43,139 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 269: ref_distribution = tensor([0.2275, 0.3942, 0.3783], device='cuda:0'), new_distribution = tensor([0.2282, 0.3944, 0.3775], device='cuda:0')
2024-12-07 18:04:43,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 270: ref_distribution = tensor([0.2282, 0.3944, 0.3775], device='cuda:0'), new_distribution = tensor([0.2288, 0.3945, 0.3767], device='cuda:0')
2024-12-07 18:04:43,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 271: ref_distribution = tensor([0.2288, 0.3945, 0.3767], device='cuda:0'), new_distribution = tensor([0.2295, 0.3946, 0.3759], device='cuda:0')
2024-12-07 18:04:44,400 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 272: ref_distribution = tensor([0.2295, 0.3946, 0.3759], device='cuda:0'), new_distribution = tensor([0.2302, 0.3948, 0.3751], device='cuda:0')
2024-12-07 18:04:44,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 273: ref_distribution = tensor([0.2302, 0.3948, 0.3751], device='cuda:0'), new_distribution = tensor([0.2308, 0.3949, 0.3743], device='cuda:0')
2024-12-07 18:04:45,138 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 274: ref_distribution = tensor([0.2308, 0.3949, 0.3743], device='cuda:0'), new_distribution = tensor([0.2315, 0.3951, 0.3735], device='cuda:0')
2024-12-07 18:04:45,581 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 275: ref_distribution = tensor([0.2315, 0.3951, 0.3735], device='cuda:0'), new_distribution = tensor([0.2321, 0.3952, 0.3727], device='cuda:0')
2024-12-07 18:04:46,061 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 276: ref_distribution = tensor([0.2321, 0.3952, 0.3727], device='cuda:0'), new_distribution = tensor([0.2328, 0.3953, 0.3719], device='cuda:0')
2024-12-07 18:04:46,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 277: ref_distribution = tensor([0.2328, 0.3953, 0.3719], device='cuda:0'), new_distribution = tensor([0.2335, 0.3954, 0.3711], device='cuda:0')
2024-12-07 18:04:46,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 278: ref_distribution = tensor([0.2335, 0.3954, 0.3711], device='cuda:0'), new_distribution = tensor([0.2341, 0.3956, 0.3703], device='cuda:0')
2024-12-07 18:04:47,217 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 279: ref_distribution = tensor([0.2341, 0.3956, 0.3703], device='cuda:0'), new_distribution = tensor([0.2348, 0.3957, 0.3695], device='cuda:0')
2024-12-07 18:04:47,486 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 280: ref_distribution = tensor([0.2348, 0.3957, 0.3695], device='cuda:0'), new_distribution = tensor([0.2355, 0.3958, 0.3687], device='cuda:0')
2024-12-07 18:04:47,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 281: ref_distribution = tensor([0.2355, 0.3958, 0.3687], device='cuda:0'), new_distribution = tensor([0.2361, 0.3960, 0.3679], device='cuda:0')
2024-12-07 18:04:48,326 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 282: ref_distribution = tensor([0.2361, 0.3960, 0.3679], device='cuda:0'), new_distribution = tensor([0.2368, 0.3961, 0.3671], device='cuda:0')
2024-12-07 18:04:48,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 283: ref_distribution = tensor([0.2368, 0.3961, 0.3671], device='cuda:0'), new_distribution = tensor([0.2375, 0.3962, 0.3664], device='cuda:0')
2024-12-07 18:04:48,518 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 284: ref_distribution = tensor([0.2375, 0.3962, 0.3664], device='cuda:0'), new_distribution = tensor([0.2381, 0.3963, 0.3656], device='cuda:0')
2024-12-07 18:04:48,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 285: ref_distribution = tensor([0.2381, 0.3963, 0.3656], device='cuda:0'), new_distribution = tensor([0.2388, 0.3964, 0.3648], device='cuda:0')
2024-12-07 18:04:48,733 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 286: ref_distribution = tensor([0.2388, 0.3964, 0.3648], device='cuda:0'), new_distribution = tensor([0.2395, 0.3965, 0.3640], device='cuda:0')
2024-12-07 18:04:48,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 287: ref_distribution = tensor([0.2395, 0.3965, 0.3640], device='cuda:0'), new_distribution = tensor([0.2402, 0.3966, 0.3632], device='cuda:0')
2024-12-07 18:04:49,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 288: ref_distribution = tensor([0.2402, 0.3966, 0.3632], device='cuda:0'), new_distribution = tensor([0.2408, 0.3967, 0.3624], device='cuda:0')
2024-12-07 18:04:49,226 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 289: ref_distribution = tensor([0.2408, 0.3967, 0.3624], device='cuda:0'), new_distribution = tensor([0.2415, 0.3969, 0.3616], device='cuda:0')
2024-12-07 18:04:49,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 290: ref_distribution = tensor([0.2415, 0.3969, 0.3616], device='cuda:0'), new_distribution = tensor([0.2422, 0.3970, 0.3608], device='cuda:0')
2024-12-07 18:04:49,552 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 291: ref_distribution = tensor([0.2422, 0.3970, 0.3608], device='cuda:0'), new_distribution = tensor([0.2429, 0.3971, 0.3601], device='cuda:0')
2024-12-07 18:04:49,715 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 292: ref_distribution = tensor([0.2429, 0.3971, 0.3601], device='cuda:0'), new_distribution = tensor([0.2436, 0.3972, 0.3593], device='cuda:0')
2024-12-07 18:04:49,877 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 293: ref_distribution = tensor([0.2436, 0.3972, 0.3593], device='cuda:0'), new_distribution = tensor([0.2442, 0.3973, 0.3585], device='cuda:0')
2024-12-07 18:04:50,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 294: ref_distribution = tensor([0.2442, 0.3973, 0.3585], device='cuda:0'), new_distribution = tensor([0.2449, 0.3973, 0.3577], device='cuda:0')
2024-12-07 18:04:50,201 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 295: ref_distribution = tensor([0.2449, 0.3973, 0.3577], device='cuda:0'), new_distribution = tensor([0.2456, 0.3974, 0.3569], device='cuda:0')
2024-12-07 18:04:50,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 296: ref_distribution = tensor([0.2456, 0.3974, 0.3569], device='cuda:0'), new_distribution = tensor([0.2463, 0.3975, 0.3562], device='cuda:0')
2024-12-07 18:04:50,521 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 297: ref_distribution = tensor([0.2463, 0.3975, 0.3562], device='cuda:0'), new_distribution = tensor([0.2470, 0.3976, 0.3554], device='cuda:0')
2024-12-07 18:04:50,665 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 298: ref_distribution = tensor([0.2470, 0.3976, 0.3554], device='cuda:0'), new_distribution = tensor([0.2477, 0.3977, 0.3546], device='cuda:0')
2024-12-07 18:04:50,801 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 299: ref_distribution = tensor([0.2477, 0.3977, 0.3546], device='cuda:0'), new_distribution = tensor([0.2484, 0.3978, 0.3538], device='cuda:0')
2024-12-07 18:04:50,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 300: ref_distribution = tensor([0.2484, 0.3978, 0.3538], device='cuda:0'), new_distribution = tensor([0.2491, 0.3979, 0.3530], device='cuda:0')
2024-12-07 18:04:51,032 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 301: ref_distribution = tensor([0.2491, 0.3979, 0.3530], device='cuda:0'), new_distribution = tensor([0.2498, 0.3980, 0.3523], device='cuda:0')
2024-12-07 18:04:51,135 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 302: ref_distribution = tensor([0.2498, 0.3980, 0.3523], device='cuda:0'), new_distribution = tensor([0.2505, 0.3980, 0.3515], device='cuda:0')
2024-12-07 18:04:51,230 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 303: ref_distribution = tensor([0.2505, 0.3980, 0.3515], device='cuda:0'), new_distribution = tensor([0.2512, 0.3981, 0.3507], device='cuda:0')
2024-12-07 18:04:51,322 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 304: ref_distribution = tensor([0.2512, 0.3981, 0.3507], device='cuda:0'), new_distribution = tensor([0.2519, 0.3982, 0.3499], device='cuda:0')
2024-12-07 18:04:51,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 305: ref_distribution = tensor([0.2519, 0.3982, 0.3499], device='cuda:0'), new_distribution = tensor([0.2526, 0.3983, 0.3492], device='cuda:0')
2024-12-07 18:04:51,508 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 306: ref_distribution = tensor([0.2526, 0.3983, 0.3492], device='cuda:0'), new_distribution = tensor([0.2533, 0.3983, 0.3484], device='cuda:0')
2024-12-07 18:04:51,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 307: ref_distribution = tensor([0.2533, 0.3983, 0.3484], device='cuda:0'), new_distribution = tensor([0.2540, 0.3984, 0.3476], device='cuda:0')
2024-12-07 18:04:51,694 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 308: ref_distribution = tensor([0.2540, 0.3984, 0.3476], device='cuda:0'), new_distribution = tensor([0.2547, 0.3985, 0.3469], device='cuda:0')
2024-12-07 18:04:51,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 309: ref_distribution = tensor([0.2547, 0.3985, 0.3469], device='cuda:0'), new_distribution = tensor([0.2554, 0.3985, 0.3461], device='cuda:0')
2024-12-07 18:04:51,876 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 310: ref_distribution = tensor([0.2554, 0.3985, 0.3461], device='cuda:0'), new_distribution = tensor([0.2561, 0.3986, 0.3453], device='cuda:0')
2024-12-07 18:04:51,968 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 311: ref_distribution = tensor([0.2561, 0.3986, 0.3453], device='cuda:0'), new_distribution = tensor([0.2568, 0.3986, 0.3446], device='cuda:0')
2024-12-07 18:04:52,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 312: ref_distribution = tensor([0.2568, 0.3986, 0.3446], device='cuda:0'), new_distribution = tensor([0.2575, 0.3987, 0.3438], device='cuda:0')
2024-12-07 18:04:52,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 313: ref_distribution = tensor([0.2575, 0.3987, 0.3438], device='cuda:0'), new_distribution = tensor([0.2582, 0.3988, 0.3430], device='cuda:0')
2024-12-07 18:04:52,242 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 314: ref_distribution = tensor([0.2582, 0.3988, 0.3430], device='cuda:0'), new_distribution = tensor([0.2589, 0.3988, 0.3423], device='cuda:0')
2024-12-07 18:04:52,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 315: ref_distribution = tensor([0.2589, 0.3988, 0.3423], device='cuda:0'), new_distribution = tensor([0.2597, 0.3989, 0.3415], device='cuda:0')
2024-12-07 18:04:52,427 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 316: ref_distribution = tensor([0.2597, 0.3989, 0.3415], device='cuda:0'), new_distribution = tensor([0.2604, 0.3989, 0.3407], device='cuda:0')
2024-12-07 18:04:52,519 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 317: ref_distribution = tensor([0.2604, 0.3989, 0.3407], device='cuda:0'), new_distribution = tensor([0.2611, 0.3989, 0.3400], device='cuda:0')
2024-12-07 18:04:52,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 318: ref_distribution = tensor([0.2611, 0.3989, 0.3400], device='cuda:0'), new_distribution = tensor([0.2618, 0.3990, 0.3392], device='cuda:0')
2024-12-07 18:04:52,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 319: ref_distribution = tensor([0.2618, 0.3990, 0.3392], device='cuda:0'), new_distribution = tensor([0.2625, 0.3990, 0.3384], device='cuda:0')
2024-12-07 18:04:52,794 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 320: ref_distribution = tensor([0.2625, 0.3990, 0.3384], device='cuda:0'), new_distribution = tensor([0.2632, 0.3991, 0.3377], device='cuda:0')
2024-12-07 18:04:52,887 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 321: ref_distribution = tensor([0.2632, 0.3991, 0.3377], device='cuda:0'), new_distribution = tensor([0.2640, 0.3991, 0.3369], device='cuda:0')
2024-12-07 18:04:52,979 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 322: ref_distribution = tensor([0.2640, 0.3991, 0.3369], device='cuda:0'), new_distribution = tensor([0.2647, 0.3991, 0.3362], device='cuda:0')
2024-12-07 18:04:53,070 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 323: ref_distribution = tensor([0.2647, 0.3991, 0.3362], device='cuda:0'), new_distribution = tensor([0.2654, 0.3992, 0.3354], device='cuda:0')
2024-12-07 18:04:53,162 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 324: ref_distribution = tensor([0.2654, 0.3992, 0.3354], device='cuda:0'), new_distribution = tensor([0.2661, 0.3992, 0.3346], device='cuda:0')
2024-12-07 18:04:53,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 325: ref_distribution = tensor([0.2661, 0.3992, 0.3346], device='cuda:0'), new_distribution = tensor([0.2669, 0.3992, 0.3339], device='cuda:0')
2024-12-07 18:04:53,346 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 326: ref_distribution = tensor([0.2669, 0.3992, 0.3339], device='cuda:0'), new_distribution = tensor([0.2676, 0.3993, 0.3331], device='cuda:0')
2024-12-07 18:04:53,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 327: ref_distribution = tensor([0.2676, 0.3993, 0.3331], device='cuda:0'), new_distribution = tensor([0.2683, 0.3993, 0.3324], device='cuda:0')
2024-12-07 18:04:53,530 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 328: ref_distribution = tensor([0.2683, 0.3993, 0.3324], device='cuda:0'), new_distribution = tensor([0.2691, 0.3993, 0.3316], device='cuda:0')
2024-12-07 18:04:53,621 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 329: ref_distribution = tensor([0.2691, 0.3993, 0.3316], device='cuda:0'), new_distribution = tensor([0.2698, 0.3993, 0.3309], device='cuda:0')
2024-12-07 18:04:53,712 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 330: ref_distribution = tensor([0.2698, 0.3993, 0.3309], device='cuda:0'), new_distribution = tensor([0.2705, 0.3993, 0.3301], device='cuda:0')
2024-12-07 18:04:53,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 331: ref_distribution = tensor([0.2705, 0.3993, 0.3301], device='cuda:0'), new_distribution = tensor([0.2713, 0.3994, 0.3294], device='cuda:0')
2024-12-07 18:04:53,895 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 332: ref_distribution = tensor([0.2713, 0.3994, 0.3294], device='cuda:0'), new_distribution = tensor([0.2720, 0.3994, 0.3286], device='cuda:0')
2024-12-07 18:04:53,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 333: ref_distribution = tensor([0.2720, 0.3994, 0.3286], device='cuda:0'), new_distribution = tensor([0.2728, 0.3994, 0.3279], device='cuda:0')
2024-12-07 18:04:54,079 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 334: ref_distribution = tensor([0.2728, 0.3994, 0.3279], device='cuda:0'), new_distribution = tensor([0.2735, 0.3994, 0.3271], device='cuda:0')
2024-12-07 18:04:54,173 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 335: ref_distribution = tensor([0.2735, 0.3994, 0.3271], device='cuda:0'), new_distribution = tensor([0.2742, 0.3994, 0.3264], device='cuda:0')
2024-12-07 18:04:54,265 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 336: ref_distribution = tensor([0.2742, 0.3994, 0.3264], device='cuda:0'), new_distribution = tensor([0.2750, 0.3994, 0.3256], device='cuda:0')
2024-12-07 18:04:54,356 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 337: ref_distribution = tensor([0.2750, 0.3994, 0.3256], device='cuda:0'), new_distribution = tensor([0.2757, 0.3994, 0.3249], device='cuda:0')
2024-12-07 18:04:54,448 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 338: ref_distribution = tensor([0.2757, 0.3994, 0.3249], device='cuda:0'), new_distribution = tensor([0.2765, 0.3994, 0.3241], device='cuda:0')
2024-12-07 18:04:54,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 339: ref_distribution = tensor([0.2765, 0.3994, 0.3241], device='cuda:0'), new_distribution = tensor([0.2772, 0.3994, 0.3234], device='cuda:0')
2024-12-07 18:04:54,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 340: ref_distribution = tensor([0.2772, 0.3994, 0.3234], device='cuda:0'), new_distribution = tensor([0.2780, 0.3994, 0.3226], device='cuda:0')
2024-12-07 18:04:54,724 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 341: ref_distribution = tensor([0.2780, 0.3994, 0.3226], device='cuda:0'), new_distribution = tensor([0.2787, 0.3994, 0.3219], device='cuda:0')
2024-12-07 18:04:54,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 342: ref_distribution = tensor([0.2787, 0.3994, 0.3219], device='cuda:0'), new_distribution = tensor([0.2795, 0.3994, 0.3212], device='cuda:0')
2024-12-07 18:04:54,907 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 343: ref_distribution = tensor([0.2795, 0.3994, 0.3212], device='cuda:0'), new_distribution = tensor([0.2802, 0.3994, 0.3204], device='cuda:0')
2024-12-07 18:04:55,008 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 344: ref_distribution = tensor([0.2802, 0.3994, 0.3204], device='cuda:0'), new_distribution = tensor([0.2810, 0.3994, 0.3197], device='cuda:0')
2024-12-07 18:04:55,331 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 345: ref_distribution = tensor([0.2810, 0.3994, 0.3197], device='cuda:0'), new_distribution = tensor([0.2817, 0.3993, 0.3189], device='cuda:0')
2024-12-07 18:04:55,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 346: ref_distribution = tensor([0.2817, 0.3993, 0.3189], device='cuda:0'), new_distribution = tensor([0.2825, 0.3993, 0.3182], device='cuda:0')
2024-12-07 18:04:55,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 347: ref_distribution = tensor([0.2825, 0.3993, 0.3182], device='cuda:0'), new_distribution = tensor([0.2832, 0.3993, 0.3175], device='cuda:0')
2024-12-07 18:04:55,852 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 348: ref_distribution = tensor([0.2832, 0.3993, 0.3175], device='cuda:0'), new_distribution = tensor([0.2840, 0.3993, 0.3167], device='cuda:0')
2024-12-07 18:04:56,141 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 349: ref_distribution = tensor([0.2840, 0.3993, 0.3167], device='cuda:0'), new_distribution = tensor([0.2848, 0.3993, 0.3160], device='cuda:0')
2024-12-07 18:04:56,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 350: ref_distribution = tensor([0.2848, 0.3993, 0.3160], device='cuda:0'), new_distribution = tensor([0.2855, 0.3992, 0.3153], device='cuda:0')
2024-12-07 18:04:56,713 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 351: ref_distribution = tensor([0.2855, 0.3992, 0.3153], device='cuda:0'), new_distribution = tensor([0.2863, 0.3992, 0.3145], device='cuda:0')
2024-12-07 18:04:57,026 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 352: ref_distribution = tensor([0.2863, 0.3992, 0.3145], device='cuda:0'), new_distribution = tensor([0.2870, 0.3992, 0.3138], device='cuda:0')
2024-12-07 18:04:57,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 353: ref_distribution = tensor([0.2870, 0.3992, 0.3138], device='cuda:0'), new_distribution = tensor([0.2878, 0.3991, 0.3131], device='cuda:0')
2024-12-07 18:04:57,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 354: ref_distribution = tensor([0.2878, 0.3991, 0.3131], device='cuda:0'), new_distribution = tensor([0.2886, 0.3991, 0.3123], device='cuda:0')
2024-12-07 18:04:57,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 355: ref_distribution = tensor([0.2886, 0.3991, 0.3123], device='cuda:0'), new_distribution = tensor([0.2893, 0.3991, 0.3116], device='cuda:0')
2024-12-07 18:04:58,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 356: ref_distribution = tensor([0.2893, 0.3991, 0.3116], device='cuda:0'), new_distribution = tensor([0.2901, 0.3990, 0.3109], device='cuda:0')
2024-12-07 18:04:58,116 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 357: ref_distribution = tensor([0.2901, 0.3990, 0.3109], device='cuda:0'), new_distribution = tensor([0.2909, 0.3990, 0.3101], device='cuda:0')
2024-12-07 18:04:58,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 358: ref_distribution = tensor([0.2909, 0.3990, 0.3101], device='cuda:0'), new_distribution = tensor([0.2916, 0.3989, 0.3094], device='cuda:0')
2024-12-07 18:04:58,299 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 359: ref_distribution = tensor([0.2916, 0.3989, 0.3094], device='cuda:0'), new_distribution = tensor([0.2924, 0.3989, 0.3087], device='cuda:0')
2024-12-07 18:04:58,390 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 360: ref_distribution = tensor([0.2924, 0.3989, 0.3087], device='cuda:0'), new_distribution = tensor([0.2932, 0.3988, 0.3080], device='cuda:0')
2024-12-07 18:04:58,481 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 361: ref_distribution = tensor([0.2932, 0.3988, 0.3080], device='cuda:0'), new_distribution = tensor([0.2940, 0.3988, 0.3072], device='cuda:0')
2024-12-07 18:04:58,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 362: ref_distribution = tensor([0.2940, 0.3988, 0.3072], device='cuda:0'), new_distribution = tensor([0.2947, 0.3987, 0.3065], device='cuda:0')
2024-12-07 18:04:58,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 363: ref_distribution = tensor([0.2947, 0.3987, 0.3065], device='cuda:0'), new_distribution = tensor([0.2955, 0.3987, 0.3058], device='cuda:0')
2024-12-07 18:04:58,755 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 364: ref_distribution = tensor([0.2955, 0.3987, 0.3058], device='cuda:0'), new_distribution = tensor([0.2963, 0.3986, 0.3051], device='cuda:0')
2024-12-07 18:04:58,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 365: ref_distribution = tensor([0.2963, 0.3986, 0.3051], device='cuda:0'), new_distribution = tensor([0.2971, 0.3986, 0.3044], device='cuda:0')
2024-12-07 18:04:58,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 366: ref_distribution = tensor([0.2971, 0.3986, 0.3044], device='cuda:0'), new_distribution = tensor([0.2979, 0.3985, 0.3036], device='cuda:0')
2024-12-07 18:04:59,029 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 367: ref_distribution = tensor([0.2979, 0.3985, 0.3036], device='cuda:0'), new_distribution = tensor([0.2986, 0.3984, 0.3029], device='cuda:0')
2024-12-07 18:04:59,120 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 368: ref_distribution = tensor([0.2986, 0.3984, 0.3029], device='cuda:0'), new_distribution = tensor([0.2994, 0.3984, 0.3022], device='cuda:0')
2024-12-07 18:04:59,446 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 369: ref_distribution = tensor([0.2994, 0.3984, 0.3022], device='cuda:0'), new_distribution = tensor([0.3002, 0.3983, 0.3015], device='cuda:0')
2024-12-07 18:04:59,537 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 370: ref_distribution = tensor([0.3002, 0.3983, 0.3015], device='cuda:0'), new_distribution = tensor([0.3010, 0.3982, 0.3008], device='cuda:0')
2024-12-07 18:04:59,628 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 371: ref_distribution = tensor([0.3010, 0.3982, 0.3008], device='cuda:0'), new_distribution = tensor([0.3018, 0.3982, 0.3001], device='cuda:0')
2024-12-07 18:04:59,737 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 372: ref_distribution = tensor([0.3018, 0.3982, 0.3001], device='cuda:0'), new_distribution = tensor([0.3026, 0.3981, 0.2993], device='cuda:0')
2024-12-07 18:05:00,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 373: ref_distribution = tensor([0.3026, 0.3981, 0.2993], device='cuda:0'), new_distribution = tensor([0.3034, 0.3980, 0.2986], device='cuda:0')
2024-12-07 18:05:00,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 374: ref_distribution = tensor([0.3034, 0.3980, 0.2986], device='cuda:0'), new_distribution = tensor([0.3042, 0.3979, 0.2979], device='cuda:0')
2024-12-07 18:05:00,615 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 375: ref_distribution = tensor([0.3042, 0.3979, 0.2979], device='cuda:0'), new_distribution = tensor([0.3050, 0.3978, 0.2972], device='cuda:0')
2024-12-07 18:05:00,886 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 376: ref_distribution = tensor([0.3050, 0.3978, 0.2972], device='cuda:0'), new_distribution = tensor([0.3057, 0.3978, 0.2965], device='cuda:0')
2024-12-07 18:05:01,170 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 377: ref_distribution = tensor([0.3057, 0.3978, 0.2965], device='cuda:0'), new_distribution = tensor([0.3065, 0.3977, 0.2958], device='cuda:0')
2024-12-07 18:05:01,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 378: ref_distribution = tensor([0.3065, 0.3977, 0.2958], device='cuda:0'), new_distribution = tensor([0.3073, 0.3976, 0.2951], device='cuda:0')
2024-12-07 18:05:01,706 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 379: ref_distribution = tensor([0.3073, 0.3976, 0.2951], device='cuda:0'), new_distribution = tensor([0.3081, 0.3975, 0.2944], device='cuda:0')
2024-12-07 18:05:02,007 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 380: ref_distribution = tensor([0.3081, 0.3975, 0.2944], device='cuda:0'), new_distribution = tensor([0.3089, 0.3974, 0.2937], device='cuda:0')
2024-12-07 18:05:02,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 381: ref_distribution = tensor([0.3089, 0.3974, 0.2937], device='cuda:0'), new_distribution = tensor([0.3097, 0.3973, 0.2930], device='cuda:0')
2024-12-07 18:05:02,381 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 382: ref_distribution = tensor([0.3097, 0.3973, 0.2930], device='cuda:0'), new_distribution = tensor([0.3105, 0.3972, 0.2923], device='cuda:0')
2024-12-07 18:05:02,472 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 383: ref_distribution = tensor([0.3105, 0.3972, 0.2923], device='cuda:0'), new_distribution = tensor([0.3113, 0.3971, 0.2916], device='cuda:0')
2024-12-07 18:05:02,563 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 384: ref_distribution = tensor([0.3113, 0.3971, 0.2916], device='cuda:0'), new_distribution = tensor([0.3121, 0.3970, 0.2909], device='cuda:0')
2024-12-07 18:05:02,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 385: ref_distribution = tensor([0.3121, 0.3970, 0.2909], device='cuda:0'), new_distribution = tensor([0.3129, 0.3969, 0.2902], device='cuda:0')
2024-12-07 18:05:02,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 386: ref_distribution = tensor([0.3129, 0.3969, 0.2902], device='cuda:0'), new_distribution = tensor([0.3138, 0.3968, 0.2895], device='cuda:0')
2024-12-07 18:05:02,836 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 387: ref_distribution = tensor([0.3138, 0.3968, 0.2895], device='cuda:0'), new_distribution = tensor([0.3146, 0.3967, 0.2888], device='cuda:0')
2024-12-07 18:05:02,927 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 388: ref_distribution = tensor([0.3146, 0.3967, 0.2888], device='cuda:0'), new_distribution = tensor([0.3154, 0.3966, 0.2881], device='cuda:0')
2024-12-07 18:05:03,018 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 389: ref_distribution = tensor([0.3154, 0.3966, 0.2881], device='cuda:0'), new_distribution = tensor([0.3162, 0.3965, 0.2874], device='cuda:0')
2024-12-07 18:05:03,109 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 390: ref_distribution = tensor([0.3162, 0.3965, 0.2874], device='cuda:0'), new_distribution = tensor([0.3170, 0.3963, 0.2867], device='cuda:0')
2024-12-07 18:05:03,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 391: ref_distribution = tensor([0.3170, 0.3963, 0.2867], device='cuda:0'), new_distribution = tensor([0.3178, 0.3962, 0.2860], device='cuda:0')
2024-12-07 18:05:03,291 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 392: ref_distribution = tensor([0.3178, 0.3962, 0.2860], device='cuda:0'), new_distribution = tensor([0.3186, 0.3961, 0.2853], device='cuda:0')
2024-12-07 18:05:03,396 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 393: ref_distribution = tensor([0.3186, 0.3961, 0.2853], device='cuda:0'), new_distribution = tensor([0.3194, 0.3960, 0.2846], device='cuda:0')
2024-12-07 18:05:03,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 394: ref_distribution = tensor([0.3194, 0.3960, 0.2846], device='cuda:0'), new_distribution = tensor([0.3202, 0.3959, 0.2839], device='cuda:0')
2024-12-07 18:05:03,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 395: ref_distribution = tensor([0.3202, 0.3959, 0.2839], device='cuda:0'), new_distribution = tensor([0.3211, 0.3957, 0.2832], device='cuda:0')
2024-12-07 18:05:03,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 396: ref_distribution = tensor([0.3211, 0.3957, 0.2832], device='cuda:0'), new_distribution = tensor([0.3219, 0.3956, 0.2825], device='cuda:0')
2024-12-07 18:05:03,960 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 397: ref_distribution = tensor([0.3219, 0.3956, 0.2825], device='cuda:0'), new_distribution = tensor([0.3227, 0.3955, 0.2818], device='cuda:0')
2024-12-07 18:05:04,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 398: ref_distribution = tensor([0.3227, 0.3955, 0.2818], device='cuda:0'), new_distribution = tensor([0.3235, 0.3953, 0.2811], device='cuda:0')
2024-12-07 18:05:04,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 399: ref_distribution = tensor([0.3235, 0.3953, 0.2811], device='cuda:0'), new_distribution = tensor([0.3243, 0.3952, 0.2805], device='cuda:0')
2024-12-07 18:05:04,453 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 400: ref_distribution = tensor([0.3243, 0.3952, 0.2805], device='cuda:0'), new_distribution = tensor([0.3252, 0.3951, 0.2798], device='cuda:0')
2024-12-07 18:05:04,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 401: ref_distribution = tensor([0.3252, 0.3951, 0.2798], device='cuda:0'), new_distribution = tensor([0.3260, 0.3949, 0.2791], device='cuda:0')
2024-12-07 18:05:05,051 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 402: ref_distribution = tensor([0.3260, 0.3949, 0.2791], device='cuda:0'), new_distribution = tensor([0.3268, 0.3948, 0.2784], device='cuda:0')
2024-12-07 18:05:05,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 403: ref_distribution = tensor([0.3268, 0.3948, 0.2784], device='cuda:0'), new_distribution = tensor([0.3276, 0.3947, 0.2777], device='cuda:0')
2024-12-07 18:05:05,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 404: ref_distribution = tensor([0.3276, 0.3947, 0.2777], device='cuda:0'), new_distribution = tensor([0.3285, 0.3945, 0.2770], device='cuda:0')
2024-12-07 18:05:05,923 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 405: ref_distribution = tensor([0.3285, 0.3945, 0.2770], device='cuda:0'), new_distribution = tensor([0.3293, 0.3944, 0.2764], device='cuda:0')
2024-12-07 18:05:06,205 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 406: ref_distribution = tensor([0.3293, 0.3944, 0.2764], device='cuda:0'), new_distribution = tensor([0.3301, 0.3942, 0.2757], device='cuda:0')
2024-12-07 18:05:06,497 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 407: ref_distribution = tensor([0.3301, 0.3942, 0.2757], device='cuda:0'), new_distribution = tensor([0.3309, 0.3941, 0.2750], device='cuda:0')
2024-12-07 18:05:06,783 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 408: ref_distribution = tensor([0.3309, 0.3941, 0.2750], device='cuda:0'), new_distribution = tensor([0.3318, 0.3939, 0.2743], device='cuda:0')
2024-12-07 18:05:06,874 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 409: ref_distribution = tensor([0.3318, 0.3939, 0.2743], device='cuda:0'), new_distribution = tensor([0.3326, 0.3937, 0.2737], device='cuda:0')
2024-12-07 18:05:06,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 410: ref_distribution = tensor([0.3326, 0.3937, 0.2737], device='cuda:0'), new_distribution = tensor([0.3334, 0.3936, 0.2730], device='cuda:0')
2024-12-07 18:05:07,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 411: ref_distribution = tensor([0.3334, 0.3936, 0.2730], device='cuda:0'), new_distribution = tensor([0.3343, 0.3934, 0.2723], device='cuda:0')
2024-12-07 18:05:07,147 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 412: ref_distribution = tensor([0.3343, 0.3934, 0.2723], device='cuda:0'), new_distribution = tensor([0.3351, 0.3933, 0.2716], device='cuda:0')
2024-12-07 18:05:07,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 413: ref_distribution = tensor([0.3351, 0.3933, 0.2716], device='cuda:0'), new_distribution = tensor([0.3359, 0.3931, 0.2710], device='cuda:0')
2024-12-07 18:05:07,332 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 414: ref_distribution = tensor([0.3359, 0.3931, 0.2710], device='cuda:0'), new_distribution = tensor([0.3368, 0.3929, 0.2703], device='cuda:0')
2024-12-07 18:05:07,423 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 415: ref_distribution = tensor([0.3368, 0.3929, 0.2703], device='cuda:0'), new_distribution = tensor([0.3376, 0.3928, 0.2696], device='cuda:0')
2024-12-07 18:05:07,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 416: ref_distribution = tensor([0.3376, 0.3928, 0.2696], device='cuda:0'), new_distribution = tensor([0.3385, 0.3926, 0.2690], device='cuda:0')
2024-12-07 18:05:07,605 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 417: ref_distribution = tensor([0.3385, 0.3926, 0.2690], device='cuda:0'), new_distribution = tensor([0.3393, 0.3924, 0.2683], device='cuda:0')
2024-12-07 18:05:07,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 418: ref_distribution = tensor([0.3393, 0.3924, 0.2683], device='cuda:0'), new_distribution = tensor([0.3401, 0.3922, 0.2676], device='cuda:0')
2024-12-07 18:05:07,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 419: ref_distribution = tensor([0.3401, 0.3922, 0.2676], device='cuda:0'), new_distribution = tensor([0.3410, 0.3921, 0.2670], device='cuda:0')
2024-12-07 18:05:07,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 420: ref_distribution = tensor([0.3410, 0.3921, 0.2670], device='cuda:0'), new_distribution = tensor([0.3418, 0.3919, 0.2663], device='cuda:0')
2024-12-07 18:05:07,969 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 421: ref_distribution = tensor([0.3418, 0.3919, 0.2663], device='cuda:0'), new_distribution = tensor([0.3427, 0.3917, 0.2656], device='cuda:0')
2024-12-07 18:05:08,295 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 422: ref_distribution = tensor([0.3427, 0.3917, 0.2656], device='cuda:0'), new_distribution = tensor([0.3435, 0.3915, 0.2650], device='cuda:0')
2024-12-07 18:05:08,588 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 423: ref_distribution = tensor([0.3435, 0.3915, 0.2650], device='cuda:0'), new_distribution = tensor([0.3444, 0.3913, 0.2643], device='cuda:0')
2024-12-07 18:05:08,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 424: ref_distribution = tensor([0.3444, 0.3913, 0.2643], device='cuda:0'), new_distribution = tensor([0.3452, 0.3911, 0.2637], device='cuda:0')
2024-12-07 18:05:09,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 425: ref_distribution = tensor([0.3452, 0.3911, 0.2637], device='cuda:0'), new_distribution = tensor([0.3461, 0.3909, 0.2630], device='cuda:0')
2024-12-07 18:05:09,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 426: ref_distribution = tensor([0.3461, 0.3909, 0.2630], device='cuda:0'), new_distribution = tensor([0.3469, 0.3907, 0.2623], device='cuda:0')
2024-12-07 18:05:09,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 427: ref_distribution = tensor([0.3469, 0.3907, 0.2623], device='cuda:0'), new_distribution = tensor([0.3478, 0.3906, 0.2617], device='cuda:0')
2024-12-07 18:05:09,796 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 428: ref_distribution = tensor([0.3478, 0.3906, 0.2617], device='cuda:0'), new_distribution = tensor([0.3486, 0.3904, 0.2610], device='cuda:0')
2024-12-07 18:05:10,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 429: ref_distribution = tensor([0.3486, 0.3904, 0.2610], device='cuda:0'), new_distribution = tensor([0.3495, 0.3902, 0.2604], device='cuda:0')
2024-12-07 18:05:10,333 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 430: ref_distribution = tensor([0.3495, 0.3902, 0.2604], device='cuda:0'), new_distribution = tensor([0.3503, 0.3900, 0.2597], device='cuda:0')
2024-12-07 18:05:10,615 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 431: ref_distribution = tensor([0.3503, 0.3900, 0.2597], device='cuda:0'), new_distribution = tensor([0.3512, 0.3898, 0.2591], device='cuda:0')
2024-12-07 18:05:10,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 432: ref_distribution = tensor([0.3512, 0.3898, 0.2591], device='cuda:0'), new_distribution = tensor([0.3520, 0.3895, 0.2584], device='cuda:0')
2024-12-07 18:05:10,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 433: ref_distribution = tensor([0.3520, 0.3895, 0.2584], device='cuda:0'), new_distribution = tensor([0.3529, 0.3893, 0.2578], device='cuda:0')
2024-12-07 18:05:11,086 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 434: ref_distribution = tensor([0.3529, 0.3893, 0.2578], device='cuda:0'), new_distribution = tensor([0.3537, 0.3891, 0.2571], device='cuda:0')
2024-12-07 18:05:11,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 435: ref_distribution = tensor([0.3537, 0.3891, 0.2571], device='cuda:0'), new_distribution = tensor([0.3546, 0.3889, 0.2565], device='cuda:0')
2024-12-07 18:05:11,267 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 436: ref_distribution = tensor([0.3546, 0.3889, 0.2565], device='cuda:0'), new_distribution = tensor([0.3555, 0.3887, 0.2558], device='cuda:0')
2024-12-07 18:05:11,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 437: ref_distribution = tensor([0.3555, 0.3887, 0.2558], device='cuda:0'), new_distribution = tensor([0.3563, 0.3885, 0.2552], device='cuda:0')
2024-12-07 18:05:11,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 438: ref_distribution = tensor([0.3563, 0.3885, 0.2552], device='cuda:0'), new_distribution = tensor([0.3572, 0.3883, 0.2545], device='cuda:0')
2024-12-07 18:05:11,540 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 439: ref_distribution = tensor([0.3572, 0.3883, 0.2545], device='cuda:0'), new_distribution = tensor([0.3581, 0.3880, 0.2539], device='cuda:0')
2024-12-07 18:05:11,630 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 440: ref_distribution = tensor([0.3581, 0.3880, 0.2539], device='cuda:0'), new_distribution = tensor([0.3589, 0.3878, 0.2533], device='cuda:0')
2024-12-07 18:05:11,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 441: ref_distribution = tensor([0.3589, 0.3878, 0.2533], device='cuda:0'), new_distribution = tensor([0.3598, 0.3876, 0.2526], device='cuda:0')
2024-12-07 18:05:11,813 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 442: ref_distribution = tensor([0.3598, 0.3876, 0.2526], device='cuda:0'), new_distribution = tensor([0.3607, 0.3874, 0.2520], device='cuda:0')
2024-12-07 18:05:11,904 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 443: ref_distribution = tensor([0.3607, 0.3874, 0.2520], device='cuda:0'), new_distribution = tensor([0.3615, 0.3871, 0.2513], device='cuda:0')
2024-12-07 18:05:11,996 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 444: ref_distribution = tensor([0.3615, 0.3871, 0.2513], device='cuda:0'), new_distribution = tensor([0.3624, 0.3869, 0.2507], device='cuda:0')
2024-12-07 18:05:12,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 445: ref_distribution = tensor([0.3624, 0.3869, 0.2507], device='cuda:0'), new_distribution = tensor([0.3633, 0.3867, 0.2501], device='cuda:0')
2024-12-07 18:05:12,409 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 446: ref_distribution = tensor([0.3633, 0.3867, 0.2501], device='cuda:0'), new_distribution = tensor([0.3641, 0.3864, 0.2494], device='cuda:0')
2024-12-07 18:05:12,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 447: ref_distribution = tensor([0.3641, 0.3864, 0.2494], device='cuda:0'), new_distribution = tensor([0.3650, 0.3862, 0.2488], device='cuda:0')
2024-12-07 18:05:12,839 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 448: ref_distribution = tensor([0.3650, 0.3862, 0.2488], device='cuda:0'), new_distribution = tensor([0.3659, 0.3860, 0.2482], device='cuda:0')
2024-12-07 18:05:13,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 449: ref_distribution = tensor([0.3659, 0.3860, 0.2482], device='cuda:0'), new_distribution = tensor([0.3667, 0.3857, 0.2475], device='cuda:0')
2024-12-07 18:05:13,439 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 450: ref_distribution = tensor([0.3667, 0.3857, 0.2475], device='cuda:0'), new_distribution = tensor([0.3676, 0.3855, 0.2469], device='cuda:0')
2024-12-07 18:05:13,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 451: ref_distribution = tensor([0.3676, 0.3855, 0.2469], device='cuda:0'), new_distribution = tensor([0.3685, 0.3852, 0.2463], device='cuda:0')
2024-12-07 18:05:14,053 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 452: ref_distribution = tensor([0.3685, 0.3852, 0.2463], device='cuda:0'), new_distribution = tensor([0.3694, 0.3850, 0.2456], device='cuda:0')
2024-12-07 18:05:14,361 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 453: ref_distribution = tensor([0.3694, 0.3850, 0.2456], device='cuda:0'), new_distribution = tensor([0.3702, 0.3847, 0.2450], device='cuda:0')
2024-12-07 18:05:14,634 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 454: ref_distribution = tensor([0.3702, 0.3847, 0.2450], device='cuda:0'), new_distribution = tensor([0.3711, 0.3845, 0.2444], device='cuda:0')
2024-12-07 18:05:14,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 455: ref_distribution = tensor([0.3711, 0.3845, 0.2444], device='cuda:0'), new_distribution = tensor([0.3720, 0.3842, 0.2438], device='cuda:0')
2024-12-07 18:05:15,004 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 456: ref_distribution = tensor([0.3720, 0.3842, 0.2438], device='cuda:0'), new_distribution = tensor([0.3729, 0.3840, 0.2431], device='cuda:0')
2024-12-07 18:05:15,095 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 457: ref_distribution = tensor([0.3729, 0.3840, 0.2431], device='cuda:0'), new_distribution = tensor([0.3738, 0.3837, 0.2425], device='cuda:0')
2024-12-07 18:05:15,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 458: ref_distribution = tensor([0.3738, 0.3837, 0.2425], device='cuda:0'), new_distribution = tensor([0.3746, 0.3835, 0.2419], device='cuda:0')
2024-12-07 18:05:15,278 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 459: ref_distribution = tensor([0.3746, 0.3835, 0.2419], device='cuda:0'), new_distribution = tensor([0.3755, 0.3832, 0.2413], device='cuda:0')
2024-12-07 18:05:15,369 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 460: ref_distribution = tensor([0.3755, 0.3832, 0.2413], device='cuda:0'), new_distribution = tensor([0.3764, 0.3829, 0.2407], device='cuda:0')
2024-12-07 18:05:15,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 461: ref_distribution = tensor([0.3764, 0.3829, 0.2407], device='cuda:0'), new_distribution = tensor([0.3773, 0.3827, 0.2400], device='cuda:0')
2024-12-07 18:05:15,550 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 462: ref_distribution = tensor([0.3773, 0.3827, 0.2400], device='cuda:0'), new_distribution = tensor([0.3782, 0.3824, 0.2394], device='cuda:0')
2024-12-07 18:05:15,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 463: ref_distribution = tensor([0.3782, 0.3824, 0.2394], device='cuda:0'), new_distribution = tensor([0.3790, 0.3821, 0.2388], device='cuda:0')
2024-12-07 18:05:15,732 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 464: ref_distribution = tensor([0.3790, 0.3821, 0.2388], device='cuda:0'), new_distribution = tensor([0.3799, 0.3819, 0.2382], device='cuda:0')
2024-12-07 18:05:15,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 465: ref_distribution = tensor([0.3799, 0.3819, 0.2382], device='cuda:0'), new_distribution = tensor([0.3808, 0.3816, 0.2376], device='cuda:0')
2024-12-07 18:05:15,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 466: ref_distribution = tensor([0.3808, 0.3816, 0.2376], device='cuda:0'), new_distribution = tensor([0.3817, 0.3813, 0.2370], device='cuda:0')
2024-12-07 18:05:16,005 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 467: ref_distribution = tensor([0.3817, 0.3813, 0.2370], device='cuda:0'), new_distribution = tensor([0.3826, 0.3810, 0.2364], device='cuda:0')
2024-12-07 18:05:16,096 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 468: ref_distribution = tensor([0.3826, 0.3810, 0.2364], device='cuda:0'), new_distribution = tensor([0.3835, 0.3808, 0.2358], device='cuda:0')
2024-12-07 18:05:16,186 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 469: ref_distribution = tensor([0.3835, 0.3808, 0.2358], device='cuda:0'), new_distribution = tensor([0.3844, 0.3805, 0.2351], device='cuda:0')
2024-12-07 18:05:16,277 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 470: ref_distribution = tensor([0.3844, 0.3805, 0.2351], device='cuda:0'), new_distribution = tensor([0.3853, 0.3802, 0.2345], device='cuda:0')
2024-12-07 18:05:16,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 471: ref_distribution = tensor([0.3853, 0.3802, 0.2345], device='cuda:0'), new_distribution = tensor([0.3862, 0.3799, 0.2339], device='cuda:0')
2024-12-07 18:05:16,670 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 472: ref_distribution = tensor([0.3862, 0.3799, 0.2339], device='cuda:0'), new_distribution = tensor([0.3871, 0.3796, 0.2333], device='cuda:0')
2024-12-07 18:05:17,025 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 473: ref_distribution = tensor([0.3871, 0.3796, 0.2333], device='cuda:0'), new_distribution = tensor([0.3879, 0.3793, 0.2327], device='cuda:0')
2024-12-07 18:05:17,341 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 474: ref_distribution = tensor([0.3879, 0.3793, 0.2327], device='cuda:0'), new_distribution = tensor([0.3888, 0.3790, 0.2321], device='cuda:0')
2024-12-07 18:05:17,651 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 475: ref_distribution = tensor([0.3888, 0.3790, 0.2321], device='cuda:0'), new_distribution = tensor([0.3897, 0.3788, 0.2315], device='cuda:0')
2024-12-07 18:05:17,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 476: ref_distribution = tensor([0.3897, 0.3788, 0.2315], device='cuda:0'), new_distribution = tensor([0.3906, 0.3785, 0.2309], device='cuda:0')
2024-12-07 18:05:18,145 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 477: ref_distribution = tensor([0.3906, 0.3785, 0.2309], device='cuda:0'), new_distribution = tensor([0.3915, 0.3782, 0.2303], device='cuda:0')
2024-12-07 18:05:18,457 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 478: ref_distribution = tensor([0.3915, 0.3782, 0.2303], device='cuda:0'), new_distribution = tensor([0.3924, 0.3779, 0.2297], device='cuda:0')
2024-12-07 18:05:18,774 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 479: ref_distribution = tensor([0.3924, 0.3779, 0.2297], device='cuda:0'), new_distribution = tensor([0.3933, 0.3776, 0.2291], device='cuda:0')
2024-12-07 18:05:19,089 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 480: ref_distribution = tensor([0.3933, 0.3776, 0.2291], device='cuda:0'), new_distribution = tensor([0.3942, 0.3773, 0.2285], device='cuda:0')
2024-12-07 18:05:19,201 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 481: ref_distribution = tensor([0.3942, 0.3773, 0.2285], device='cuda:0'), new_distribution = tensor([0.3951, 0.3770, 0.2279], device='cuda:0')
2024-12-07 18:05:19,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 482: ref_distribution = tensor([0.3951, 0.3770, 0.2279], device='cuda:0'), new_distribution = tensor([0.3960, 0.3766, 0.2273], device='cuda:0')
2024-12-07 18:05:19,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 483: ref_distribution = tensor([0.3960, 0.3766, 0.2273], device='cuda:0'), new_distribution = tensor([0.3969, 0.3763, 0.2267], device='cuda:0')
2024-12-07 18:05:19,474 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 484: ref_distribution = tensor([0.3969, 0.3763, 0.2267], device='cuda:0'), new_distribution = tensor([0.3978, 0.3760, 0.2261], device='cuda:0')
2024-12-07 18:05:19,565 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 485: ref_distribution = tensor([0.3978, 0.3760, 0.2261], device='cuda:0'), new_distribution = tensor([0.3987, 0.3757, 0.2256], device='cuda:0')
2024-12-07 18:05:19,656 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 486: ref_distribution = tensor([0.3987, 0.3757, 0.2256], device='cuda:0'), new_distribution = tensor([0.3996, 0.3754, 0.2250], device='cuda:0')
2024-12-07 18:05:19,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 487: ref_distribution = tensor([0.3996, 0.3754, 0.2250], device='cuda:0'), new_distribution = tensor([0.4005, 0.3751, 0.2244], device='cuda:0')
2024-12-07 18:05:19,838 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 488: ref_distribution = tensor([0.4005, 0.3751, 0.2244], device='cuda:0'), new_distribution = tensor([0.4014, 0.3748, 0.2238], device='cuda:0')
2024-12-07 18:05:19,928 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 489: ref_distribution = tensor([0.4014, 0.3748, 0.2238], device='cuda:0'), new_distribution = tensor([0.4023, 0.3745, 0.2232], device='cuda:0')
2024-12-07 18:05:20,020 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 490: ref_distribution = tensor([0.4023, 0.3745, 0.2232], device='cuda:0'), new_distribution = tensor([0.4032, 0.3741, 0.2226], device='cuda:0')
2024-12-07 18:05:20,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 491: ref_distribution = tensor([0.4032, 0.3741, 0.2226], device='cuda:0'), new_distribution = tensor([0.4042, 0.3738, 0.2220], device='cuda:0')
2024-12-07 18:05:20,204 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 492: ref_distribution = tensor([0.4042, 0.3738, 0.2220], device='cuda:0'), new_distribution = tensor([0.4051, 0.3735, 0.2215], device='cuda:0')
2024-12-07 18:05:20,301 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 493: ref_distribution = tensor([0.4051, 0.3735, 0.2215], device='cuda:0'), new_distribution = tensor([0.4060, 0.3732, 0.2209], device='cuda:0')
2024-12-07 18:05:20,605 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 494: ref_distribution = tensor([0.4060, 0.3732, 0.2209], device='cuda:0'), new_distribution = tensor([0.4069, 0.3728, 0.2203], device='cuda:0')
2024-12-07 18:05:20,695 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 495: ref_distribution = tensor([0.4069, 0.3728, 0.2203], device='cuda:0'), new_distribution = tensor([0.4078, 0.3725, 0.2197], device='cuda:0')
2024-12-07 18:05:20,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 496: ref_distribution = tensor([0.4078, 0.3725, 0.2197], device='cuda:0'), new_distribution = tensor([0.4087, 0.3722, 0.2191], device='cuda:0')
2024-12-07 18:05:20,896 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 497: ref_distribution = tensor([0.4087, 0.3722, 0.2191], device='cuda:0'), new_distribution = tensor([0.4096, 0.3718, 0.2186], device='cuda:0')
2024-12-07 18:05:21,212 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 498: ref_distribution = tensor([0.4096, 0.3718, 0.2186], device='cuda:0'), new_distribution = tensor([0.4105, 0.3715, 0.2180], device='cuda:0')
2024-12-07 18:05:21,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 499: ref_distribution = tensor([0.4105, 0.3715, 0.2180], device='cuda:0'), new_distribution = tensor([0.4114, 0.3712, 0.2174], device='cuda:0')
2024-12-07 18:05:21,782 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 500: ref_distribution = tensor([0.4114, 0.3712, 0.2174], device='cuda:0'), new_distribution = tensor([0.4123, 0.3708, 0.2168], device='cuda:0')
2024-12-07 18:05:21,872 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 501: ref_distribution = tensor([0.4123, 0.3708, 0.2168], device='cuda:0'), new_distribution = tensor([0.4133, 0.3705, 0.2163], device='cuda:0')
2024-12-07 18:05:22,214 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 502: ref_distribution = tensor([0.4133, 0.3705, 0.2163], device='cuda:0'), new_distribution = tensor([0.4142, 0.3701, 0.2157], device='cuda:0')
2024-12-07 18:05:22,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 503: ref_distribution = tensor([0.4142, 0.3701, 0.2157], device='cuda:0'), new_distribution = tensor([0.4151, 0.3698, 0.2151], device='cuda:0')
2024-12-07 18:05:23,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 504: ref_distribution = tensor([0.4151, 0.3698, 0.2151], device='cuda:0'), new_distribution = tensor([0.4160, 0.3694, 0.2146], device='cuda:0')
2024-12-07 18:05:24,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 505: ref_distribution = tensor([0.4160, 0.3694, 0.2146], device='cuda:0'), new_distribution = tensor([0.4169, 0.3691, 0.2140], device='cuda:0')
2024-12-07 18:05:24,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 506: ref_distribution = tensor([0.4169, 0.3691, 0.2140], device='cuda:0'), new_distribution = tensor([0.4178, 0.3687, 0.2134], device='cuda:0')
2024-12-07 18:05:24,352 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 507: ref_distribution = tensor([0.4178, 0.3687, 0.2134], device='cuda:0'), new_distribution = tensor([0.4187, 0.3684, 0.2129], device='cuda:0')
2024-12-07 18:05:24,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 508: ref_distribution = tensor([0.4187, 0.3684, 0.2129], device='cuda:0'), new_distribution = tensor([0.4197, 0.3680, 0.2123], device='cuda:0')
2024-12-07 18:05:24,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 509: ref_distribution = tensor([0.4197, 0.3680, 0.2123], device='cuda:0'), new_distribution = tensor([0.4206, 0.3677, 0.2117], device='cuda:0')
2024-12-07 18:05:24,840 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 510: ref_distribution = tensor([0.4206, 0.3677, 0.2117], device='cuda:0'), new_distribution = tensor([0.4215, 0.3673, 0.2112], device='cuda:0')
2024-12-07 18:05:24,965 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 511: ref_distribution = tensor([0.4215, 0.3673, 0.2112], device='cuda:0'), new_distribution = tensor([0.4224, 0.3670, 0.2106], device='cuda:0')
2024-12-07 18:05:25,086 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 512: ref_distribution = tensor([0.4224, 0.3670, 0.2106], device='cuda:0'), new_distribution = tensor([0.4233, 0.3666, 0.2101], device='cuda:0')
2024-12-07 18:05:25,208 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 513: ref_distribution = tensor([0.4233, 0.3666, 0.2101], device='cuda:0'), new_distribution = tensor([0.4243, 0.3662, 0.2095], device='cuda:0')
2024-12-07 18:05:25,331 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 514: ref_distribution = tensor([0.4243, 0.3662, 0.2095], device='cuda:0'), new_distribution = tensor([0.4252, 0.3659, 0.2089], device='cuda:0')
2024-12-07 18:05:25,453 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 515: ref_distribution = tensor([0.4252, 0.3659, 0.2089], device='cuda:0'), new_distribution = tensor([0.4261, 0.3655, 0.2084], device='cuda:0')
2024-12-07 18:05:25,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 516: ref_distribution = tensor([0.4261, 0.3655, 0.2084], device='cuda:0'), new_distribution = tensor([0.4270, 0.3651, 0.2078], device='cuda:0')
2024-12-07 18:05:25,699 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 517: ref_distribution = tensor([0.4270, 0.3651, 0.2078], device='cuda:0'), new_distribution = tensor([0.4279, 0.3648, 0.2073], device='cuda:0')
2024-12-07 18:05:25,822 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 518: ref_distribution = tensor([0.4279, 0.3648, 0.2073], device='cuda:0'), new_distribution = tensor([0.4289, 0.3644, 0.2067], device='cuda:0')
2024-12-07 18:05:25,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 519: ref_distribution = tensor([0.4289, 0.3644, 0.2067], device='cuda:0'), new_distribution = tensor([0.4298, 0.3640, 0.2062], device='cuda:0')
2024-12-07 18:05:26,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 520: ref_distribution = tensor([0.4298, 0.3640, 0.2062], device='cuda:0'), new_distribution = tensor([0.4307, 0.3637, 0.2056], device='cuda:0')
2024-12-07 18:05:26,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 521: ref_distribution = tensor([0.4307, 0.3637, 0.2056], device='cuda:0'), new_distribution = tensor([0.4316, 0.3633, 0.2051], device='cuda:0')
2024-12-07 18:05:26,311 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 522: ref_distribution = tensor([0.4316, 0.3633, 0.2051], device='cuda:0'), new_distribution = tensor([0.4326, 0.3629, 0.2045], device='cuda:0')
2024-12-07 18:05:26,433 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 523: ref_distribution = tensor([0.4326, 0.3629, 0.2045], device='cuda:0'), new_distribution = tensor([0.4335, 0.3625, 0.2040], device='cuda:0')
2024-12-07 18:05:26,555 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 524: ref_distribution = tensor([0.4335, 0.3625, 0.2040], device='cuda:0'), new_distribution = tensor([0.4344, 0.3622, 0.2034], device='cuda:0')
2024-12-07 18:05:26,678 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 525: ref_distribution = tensor([0.4344, 0.3622, 0.2034], device='cuda:0'), new_distribution = tensor([0.4353, 0.3618, 0.2029], device='cuda:0')
2024-12-07 18:05:26,804 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 526: ref_distribution = tensor([0.4353, 0.3618, 0.2029], device='cuda:0'), new_distribution = tensor([0.4363, 0.3614, 0.2023], device='cuda:0')
2024-12-07 18:05:26,920 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 527: ref_distribution = tensor([0.4363, 0.3614, 0.2023], device='cuda:0'), new_distribution = tensor([0.4372, 0.3610, 0.2018], device='cuda:0')
2024-12-07 18:05:27,029 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 528: ref_distribution = tensor([0.4372, 0.3610, 0.2018], device='cuda:0'), new_distribution = tensor([0.4381, 0.3606, 0.2013], device='cuda:0')
2024-12-07 18:05:27,129 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 529: ref_distribution = tensor([0.4381, 0.3606, 0.2013], device='cuda:0'), new_distribution = tensor([0.4391, 0.3602, 0.2007], device='cuda:0')
2024-12-07 18:05:27,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 530: ref_distribution = tensor([0.4391, 0.3602, 0.2007], device='cuda:0'), new_distribution = tensor([0.4400, 0.3598, 0.2002], device='cuda:0')
2024-12-07 18:05:27,315 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 531: ref_distribution = tensor([0.4400, 0.3598, 0.2002], device='cuda:0'), new_distribution = tensor([0.4409, 0.3594, 0.1996], device='cuda:0')
2024-12-07 18:05:27,406 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 532: ref_distribution = tensor([0.4409, 0.3594, 0.1996], device='cuda:0'), new_distribution = tensor([0.4418, 0.3590, 0.1991], device='cuda:0')
2024-12-07 18:05:27,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 533: ref_distribution = tensor([0.4418, 0.3590, 0.1991], device='cuda:0'), new_distribution = tensor([0.4428, 0.3587, 0.1986], device='cuda:0')
2024-12-07 18:05:27,592 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 534: ref_distribution = tensor([0.4428, 0.3587, 0.1986], device='cuda:0'), new_distribution = tensor([0.4437, 0.3583, 0.1980], device='cuda:0')
2024-12-07 18:05:27,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 535: ref_distribution = tensor([0.4437, 0.3583, 0.1980], device='cuda:0'), new_distribution = tensor([0.4446, 0.3579, 0.1975], device='cuda:0')
2024-12-07 18:05:27,778 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 536: ref_distribution = tensor([0.4446, 0.3579, 0.1975], device='cuda:0'), new_distribution = tensor([0.4456, 0.3575, 0.1970], device='cuda:0')
2024-12-07 18:05:27,870 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 537: ref_distribution = tensor([0.4456, 0.3575, 0.1970], device='cuda:0'), new_distribution = tensor([0.4465, 0.3571, 0.1964], device='cuda:0')
2024-12-07 18:05:27,964 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 538: ref_distribution = tensor([0.4465, 0.3571, 0.1964], device='cuda:0'), new_distribution = tensor([0.4474, 0.3567, 0.1959], device='cuda:0')
2024-12-07 18:05:28,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 539: ref_distribution = tensor([0.4474, 0.3567, 0.1959], device='cuda:0'), new_distribution = tensor([0.4484, 0.3563, 0.1954], device='cuda:0')
2024-12-07 18:05:28,148 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 540: ref_distribution = tensor([0.4484, 0.3563, 0.1954], device='cuda:0'), new_distribution = tensor([0.4493, 0.3558, 0.1949], device='cuda:0')
2024-12-07 18:05:28,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 541: ref_distribution = tensor([0.4493, 0.3558, 0.1949], device='cuda:0'), new_distribution = tensor([0.4502, 0.3554, 0.1943], device='cuda:0')
2024-12-07 18:05:28,442 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 542: ref_distribution = tensor([0.4502, 0.3554, 0.1943], device='cuda:0'), new_distribution = tensor([0.4512, 0.3550, 0.1938], device='cuda:0')
2024-12-07 18:05:28,603 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 543: ref_distribution = tensor([0.4512, 0.3550, 0.1938], device='cuda:0'), new_distribution = tensor([0.4521, 0.3546, 0.1933], device='cuda:0')
2024-12-07 18:05:28,764 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 544: ref_distribution = tensor([0.4521, 0.3546, 0.1933], device='cuda:0'), new_distribution = tensor([0.4530, 0.3542, 0.1928], device='cuda:0')
2024-12-07 18:05:28,929 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 545: ref_distribution = tensor([0.4530, 0.3542, 0.1928], device='cuda:0'), new_distribution = tensor([0.4540, 0.3538, 0.1922], device='cuda:0')
2024-12-07 18:05:29,429 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 546: ref_distribution = tensor([0.4540, 0.3538, 0.1922], device='cuda:0'), new_distribution = tensor([0.4549, 0.3534, 0.1917], device='cuda:0')
2024-12-07 18:05:29,857 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 547: ref_distribution = tensor([0.4549, 0.3534, 0.1917], device='cuda:0'), new_distribution = tensor([0.4558, 0.3530, 0.1912], device='cuda:0')
2024-12-07 18:05:30,222 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 548: ref_distribution = tensor([0.4558, 0.3530, 0.1912], device='cuda:0'), new_distribution = tensor([0.4568, 0.3525, 0.1907], device='cuda:0')
2024-12-07 18:05:30,630 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 549: ref_distribution = tensor([0.4568, 0.3525, 0.1907], device='cuda:0'), new_distribution = tensor([0.4577, 0.3521, 0.1902], device='cuda:0')
2024-12-07 18:05:31,090 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 550: ref_distribution = tensor([0.4577, 0.3521, 0.1902], device='cuda:0'), new_distribution = tensor([0.4587, 0.3517, 0.1896], device='cuda:0')
2024-12-07 18:05:31,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 551: ref_distribution = tensor([0.4587, 0.3517, 0.1896], device='cuda:0'), new_distribution = tensor([0.4596, 0.3513, 0.1891], device='cuda:0')
2024-12-07 18:05:31,739 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 552: ref_distribution = tensor([0.4596, 0.3513, 0.1891], device='cuda:0'), new_distribution = tensor([0.4605, 0.3509, 0.1886], device='cuda:0')
2024-12-07 18:05:32,211 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 553: ref_distribution = tensor([0.4605, 0.3509, 0.1886], device='cuda:0'), new_distribution = tensor([0.4615, 0.3504, 0.1881], device='cuda:0')
2024-12-07 18:05:32,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 554: ref_distribution = tensor([0.4615, 0.3504, 0.1881], device='cuda:0'), new_distribution = tensor([0.4624, 0.3500, 0.1876], device='cuda:0')
2024-12-07 18:05:32,841 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 555: ref_distribution = tensor([0.4624, 0.3500, 0.1876], device='cuda:0'), new_distribution = tensor([0.4633, 0.3496, 0.1871], device='cuda:0')
2024-12-07 18:05:33,306 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 556: ref_distribution = tensor([0.4633, 0.3496, 0.1871], device='cuda:0'), new_distribution = tensor([0.4643, 0.3492, 0.1866], device='cuda:0')
2024-12-07 18:05:33,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 557: ref_distribution = tensor([0.4643, 0.3492, 0.1866], device='cuda:0'), new_distribution = tensor([0.4652, 0.3487, 0.1861], device='cuda:0')
2024-12-07 18:05:33,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 558: ref_distribution = tensor([0.4652, 0.3487, 0.1861], device='cuda:0'), new_distribution = tensor([0.4662, 0.3483, 0.1856], device='cuda:0')
2024-12-07 18:05:34,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 559: ref_distribution = tensor([0.4662, 0.3483, 0.1856], device='cuda:0'), new_distribution = tensor([0.4671, 0.3479, 0.1851], device='cuda:0')
2024-12-07 18:05:34,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 560: ref_distribution = tensor([0.4671, 0.3479, 0.1851], device='cuda:0'), new_distribution = tensor([0.4680, 0.3474, 0.1845], device='cuda:0')
2024-12-07 18:05:35,228 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 561: ref_distribution = tensor([0.4680, 0.3474, 0.1845], device='cuda:0'), new_distribution = tensor([0.4690, 0.3470, 0.1840], device='cuda:0')
2024-12-07 18:05:35,581 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 562: ref_distribution = tensor([0.4690, 0.3470, 0.1840], device='cuda:0'), new_distribution = tensor([0.4699, 0.3465, 0.1835], device='cuda:0')
2024-12-07 18:05:36,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 563: ref_distribution = tensor([0.4699, 0.3465, 0.1835], device='cuda:0'), new_distribution = tensor([0.4709, 0.3461, 0.1830], device='cuda:0')
2024-12-07 18:05:36,431 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 564: ref_distribution = tensor([0.4709, 0.3461, 0.1830], device='cuda:0'), new_distribution = tensor([0.4718, 0.3457, 0.1825], device='cuda:0')
2024-12-07 18:05:36,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 565: ref_distribution = tensor([0.4718, 0.3457, 0.1825], device='cuda:0'), new_distribution = tensor([0.4727, 0.3452, 0.1820], device='cuda:0')
2024-12-07 18:05:37,200 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 566: ref_distribution = tensor([0.4727, 0.3452, 0.1820], device='cuda:0'), new_distribution = tensor([0.4737, 0.3448, 0.1815], device='cuda:0')
2024-12-07 18:05:37,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 567: ref_distribution = tensor([0.4737, 0.3448, 0.1815], device='cuda:0'), new_distribution = tensor([0.4746, 0.3443, 0.1810], device='cuda:0')
2024-12-07 18:05:37,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 568: ref_distribution = tensor([0.4746, 0.3443, 0.1810], device='cuda:0'), new_distribution = tensor([0.4756, 0.3439, 0.1806], device='cuda:0')
2024-12-07 18:05:38,314 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 569: ref_distribution = tensor([0.4756, 0.3439, 0.1806], device='cuda:0'), new_distribution = tensor([0.4765, 0.3434, 0.1801], device='cuda:0')
2024-12-07 18:05:38,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 570: ref_distribution = tensor([0.4765, 0.3434, 0.1801], device='cuda:0'), new_distribution = tensor([0.4774, 0.3430, 0.1796], device='cuda:0')
2024-12-07 18:05:39,082 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 571: ref_distribution = tensor([0.4774, 0.3430, 0.1796], device='cuda:0'), new_distribution = tensor([0.4784, 0.3425, 0.1791], device='cuda:0')
2024-12-07 18:05:39,427 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 572: ref_distribution = tensor([0.4784, 0.3425, 0.1791], device='cuda:0'), new_distribution = tensor([0.4793, 0.3421, 0.1786], device='cuda:0')
2024-12-07 18:05:39,893 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 573: ref_distribution = tensor([0.4793, 0.3421, 0.1786], device='cuda:0'), new_distribution = tensor([0.4803, 0.3416, 0.1781], device='cuda:0')
2024-12-07 18:05:40,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 574: ref_distribution = tensor([0.4803, 0.3416, 0.1781], device='cuda:0'), new_distribution = tensor([0.4812, 0.3412, 0.1776], device='cuda:0')
2024-12-07 18:05:40,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 575: ref_distribution = tensor([0.4812, 0.3412, 0.1776], device='cuda:0'), new_distribution = tensor([0.4821, 0.3407, 0.1771], device='cuda:0')
2024-12-07 18:05:41,005 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 576: ref_distribution = tensor([0.4821, 0.3407, 0.1771], device='cuda:0'), new_distribution = tensor([0.4831, 0.3403, 0.1766], device='cuda:0')
2024-12-07 18:05:41,340 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 577: ref_distribution = tensor([0.4831, 0.3403, 0.1766], device='cuda:0'), new_distribution = tensor([0.4840, 0.3398, 0.1761], device='cuda:0')
2024-12-07 18:05:41,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 578: ref_distribution = tensor([0.4840, 0.3398, 0.1761], device='cuda:0'), new_distribution = tensor([0.4850, 0.3394, 0.1757], device='cuda:0')
2024-12-07 18:05:42,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 579: ref_distribution = tensor([0.4850, 0.3394, 0.1757], device='cuda:0'), new_distribution = tensor([0.4859, 0.3389, 0.1752], device='cuda:0')
2024-12-07 18:05:42,494 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 580: ref_distribution = tensor([0.4859, 0.3389, 0.1752], device='cuda:0'), new_distribution = tensor([0.4869, 0.3384, 0.1747], device='cuda:0')
2024-12-07 18:05:42,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 581: ref_distribution = tensor([0.4869, 0.3384, 0.1747], device='cuda:0'), new_distribution = tensor([0.4878, 0.3380, 0.1742], device='cuda:0')
2024-12-07 18:05:43,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 582: ref_distribution = tensor([0.4878, 0.3380, 0.1742], device='cuda:0'), new_distribution = tensor([0.4887, 0.3375, 0.1737], device='cuda:0')
2024-12-07 18:05:43,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 583: ref_distribution = tensor([0.4887, 0.3375, 0.1737], device='cuda:0'), new_distribution = tensor([0.4897, 0.3371, 0.1733], device='cuda:0')
2024-12-07 18:05:44,066 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 584: ref_distribution = tensor([0.4897, 0.3371, 0.1733], device='cuda:0'), new_distribution = tensor([0.4906, 0.3366, 0.1728], device='cuda:0')
2024-12-07 18:05:44,399 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 585: ref_distribution = tensor([0.4906, 0.3366, 0.1728], device='cuda:0'), new_distribution = tensor([0.4916, 0.3361, 0.1723], device='cuda:0')
2024-12-07 18:05:44,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 586: ref_distribution = tensor([0.4916, 0.3361, 0.1723], device='cuda:0'), new_distribution = tensor([0.4925, 0.3357, 0.1718], device='cuda:0')
2024-12-07 18:05:45,355 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 587: ref_distribution = tensor([0.4925, 0.3357, 0.1718], device='cuda:0'), new_distribution = tensor([0.4935, 0.3352, 0.1713], device='cuda:0')
2024-12-07 18:05:45,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 588: ref_distribution = tensor([0.4935, 0.3352, 0.1713], device='cuda:0'), new_distribution = tensor([0.4944, 0.3347, 0.1709], device='cuda:0')
2024-12-07 18:05:46,030 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 589: ref_distribution = tensor([0.4944, 0.3347, 0.1709], device='cuda:0'), new_distribution = tensor([0.4954, 0.3342, 0.1704], device='cuda:0')
2024-12-07 18:05:46,507 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 590: ref_distribution = tensor([0.4954, 0.3342, 0.1704], device='cuda:0'), new_distribution = tensor([0.4963, 0.3338, 0.1699], device='cuda:0')
2024-12-07 18:05:46,795 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 591: ref_distribution = tensor([0.4963, 0.3338, 0.1699], device='cuda:0'), new_distribution = tensor([0.4972, 0.3333, 0.1695], device='cuda:0')
2024-12-07 18:05:47,136 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 592: ref_distribution = tensor([0.4972, 0.3333, 0.1695], device='cuda:0'), new_distribution = tensor([0.4982, 0.3328, 0.1690], device='cuda:0')
2024-12-07 18:05:47,617 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 593: ref_distribution = tensor([0.4982, 0.3328, 0.1690], device='cuda:0'), new_distribution = tensor([0.4991, 0.3323, 0.1685], device='cuda:0')
2024-12-07 18:05:47,823 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 594: ref_distribution = tensor([0.4991, 0.3323, 0.1685], device='cuda:0'), new_distribution = tensor([0.5001, 0.3319, 0.1681], device='cuda:0')
2024-12-07 18:05:48,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 595: ref_distribution = tensor([0.5001, 0.3319, 0.1681], device='cuda:0'), new_distribution = tensor([0.5010, 0.3314, 0.1676], device='cuda:0')
2024-12-07 18:05:48,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 596: ref_distribution = tensor([0.5010, 0.3314, 0.1676], device='cuda:0'), new_distribution = tensor([0.5020, 0.3309, 0.1671], device='cuda:0')
2024-12-07 18:05:48,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 597: ref_distribution = tensor([0.5020, 0.3309, 0.1671], device='cuda:0'), new_distribution = tensor([0.5029, 0.3304, 0.1667], device='cuda:0')
2024-12-07 18:05:49,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 598: ref_distribution = tensor([0.5029, 0.3304, 0.1667], device='cuda:0'), new_distribution = tensor([0.5038, 0.3300, 0.1662], device='cuda:0')
2024-12-07 18:05:49,835 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 599: ref_distribution = tensor([0.5038, 0.3300, 0.1662], device='cuda:0'), new_distribution = tensor([0.5048, 0.3295, 0.1657], device='cuda:0')
2024-12-07 18:05:50,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 600: ref_distribution = tensor([0.5048, 0.3295, 0.1657], device='cuda:0'), new_distribution = tensor([0.5057, 0.3290, 0.1653], device='cuda:0')
2024-12-07 18:05:50,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 601: ref_distribution = tensor([0.5057, 0.3290, 0.1653], device='cuda:0'), new_distribution = tensor([0.5067, 0.3285, 0.1648], device='cuda:0')
2024-12-07 18:05:50,989 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 602: ref_distribution = tensor([0.5067, 0.3285, 0.1648], device='cuda:0'), new_distribution = tensor([0.5076, 0.3280, 0.1644], device='cuda:0')
2024-12-07 18:05:51,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 603: ref_distribution = tensor([0.5076, 0.3280, 0.1644], device='cuda:0'), new_distribution = tensor([0.5086, 0.3275, 0.1639], device='cuda:0')
2024-12-07 18:05:51,672 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 604: ref_distribution = tensor([0.5086, 0.3275, 0.1639], device='cuda:0'), new_distribution = tensor([0.5095, 0.3270, 0.1635], device='cuda:0')
2024-12-07 18:05:52,117 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 605: ref_distribution = tensor([0.5095, 0.3270, 0.1635], device='cuda:0'), new_distribution = tensor([0.5105, 0.3266, 0.1630], device='cuda:0')
2024-12-07 18:05:52,584 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 606: ref_distribution = tensor([0.5105, 0.3266, 0.1630], device='cuda:0'), new_distribution = tensor([0.5114, 0.3261, 0.1625], device='cuda:0')
2024-12-07 18:05:52,910 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 607: ref_distribution = tensor([0.5114, 0.3261, 0.1625], device='cuda:0'), new_distribution = tensor([0.5123, 0.3256, 0.1621], device='cuda:0')
2024-12-07 18:05:53,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 608: ref_distribution = tensor([0.5123, 0.3256, 0.1621], device='cuda:0'), new_distribution = tensor([0.5133, 0.3251, 0.1616], device='cuda:0')
2024-12-07 18:05:53,731 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 609: ref_distribution = tensor([0.5133, 0.3251, 0.1616], device='cuda:0'), new_distribution = tensor([0.5142, 0.3246, 0.1612], device='cuda:0')
2024-12-07 18:05:54,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 610: ref_distribution = tensor([0.5142, 0.3246, 0.1612], device='cuda:0'), new_distribution = tensor([0.5152, 0.3241, 0.1607], device='cuda:0')
2024-12-07 18:05:54,375 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 611: ref_distribution = tensor([0.5152, 0.3241, 0.1607], device='cuda:0'), new_distribution = tensor([0.5161, 0.3236, 0.1603], device='cuda:0')
2024-12-07 18:05:54,846 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 612: ref_distribution = tensor([0.5161, 0.3236, 0.1603], device='cuda:0'), new_distribution = tensor([0.5171, 0.3231, 0.1598], device='cuda:0')
2024-12-07 18:05:55,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 613: ref_distribution = tensor([0.5171, 0.3231, 0.1598], device='cuda:0'), new_distribution = tensor([0.5180, 0.3226, 0.1594], device='cuda:0')
2024-12-07 18:05:55,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 614: ref_distribution = tensor([0.5180, 0.3226, 0.1594], device='cuda:0'), new_distribution = tensor([0.5189, 0.3221, 0.1590], device='cuda:0')
2024-12-07 18:05:55,956 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 615: ref_distribution = tensor([0.5189, 0.3221, 0.1590], device='cuda:0'), new_distribution = tensor([0.5199, 0.3216, 0.1585], device='cuda:0')
2024-12-07 18:05:56,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 616: ref_distribution = tensor([0.5199, 0.3216, 0.1585], device='cuda:0'), new_distribution = tensor([0.5208, 0.3211, 0.1581], device='cuda:0')
2024-12-07 18:05:56,593 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 617: ref_distribution = tensor([0.5208, 0.3211, 0.1581], device='cuda:0'), new_distribution = tensor([0.5218, 0.3206, 0.1576], device='cuda:0')
2024-12-07 18:05:57,049 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 618: ref_distribution = tensor([0.5218, 0.3206, 0.1576], device='cuda:0'), new_distribution = tensor([0.5227, 0.3201, 0.1572], device='cuda:0')
2024-12-07 18:05:57,375 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 619: ref_distribution = tensor([0.5227, 0.3201, 0.1572], device='cuda:0'), new_distribution = tensor([0.5237, 0.3196, 0.1567], device='cuda:0')
2024-12-07 18:05:57,702 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 620: ref_distribution = tensor([0.5237, 0.3196, 0.1567], device='cuda:0'), new_distribution = tensor([0.5246, 0.3191, 0.1563], device='cuda:0')
2024-12-07 18:05:58,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 621: ref_distribution = tensor([0.5246, 0.3191, 0.1563], device='cuda:0'), new_distribution = tensor([0.5255, 0.3186, 0.1559], device='cuda:0')
2024-12-07 18:05:58,586 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 622: ref_distribution = tensor([0.5255, 0.3186, 0.1559], device='cuda:0'), new_distribution = tensor([0.5265, 0.3181, 0.1554], device='cuda:0')
2024-12-07 18:05:58,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 623: ref_distribution = tensor([0.5265, 0.3181, 0.1554], device='cuda:0'), new_distribution = tensor([0.5274, 0.3176, 0.1550], device='cuda:0')
2024-12-07 18:05:59,319 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 624: ref_distribution = tensor([0.5274, 0.3176, 0.1550], device='cuda:0'), new_distribution = tensor([0.5284, 0.3171, 0.1546], device='cuda:0')
2024-12-07 18:05:59,809 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 625: ref_distribution = tensor([0.5284, 0.3171, 0.1546], device='cuda:0'), new_distribution = tensor([0.5293, 0.3166, 0.1541], device='cuda:0')
2024-12-07 18:06:00,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 626: ref_distribution = tensor([0.5293, 0.3166, 0.1541], device='cuda:0'), new_distribution = tensor([0.5302, 0.3161, 0.1537], device='cuda:0')
2024-12-07 18:06:00,461 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 627: ref_distribution = tensor([0.5302, 0.3161, 0.1537], device='cuda:0'), new_distribution = tensor([0.5312, 0.3156, 0.1533], device='cuda:0')
2024-12-07 18:06:00,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 628: ref_distribution = tensor([0.5312, 0.3156, 0.1533], device='cuda:0'), new_distribution = tensor([0.5321, 0.3150, 0.1528], device='cuda:0')
2024-12-07 18:06:01,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 629: ref_distribution = tensor([0.5321, 0.3150, 0.1528], device='cuda:0'), new_distribution = tensor([0.5331, 0.3145, 0.1524], device='cuda:0')
2024-12-07 18:06:01,526 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 630: ref_distribution = tensor([0.5331, 0.3145, 0.1524], device='cuda:0'), new_distribution = tensor([0.5340, 0.3140, 0.1520], device='cuda:0')
2024-12-07 18:06:01,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 631: ref_distribution = tensor([0.5340, 0.3140, 0.1520], device='cuda:0'), new_distribution = tensor([0.5349, 0.3135, 0.1516], device='cuda:0')
2024-12-07 18:06:02,253 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 632: ref_distribution = tensor([0.5349, 0.3135, 0.1516], device='cuda:0'), new_distribution = tensor([0.5359, 0.3130, 0.1511], device='cuda:0')
2024-12-07 18:06:02,675 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 633: ref_distribution = tensor([0.5359, 0.3130, 0.1511], device='cuda:0'), new_distribution = tensor([0.5368, 0.3125, 0.1507], device='cuda:0')
2024-12-07 18:06:03,134 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 634: ref_distribution = tensor([0.5368, 0.3125, 0.1507], device='cuda:0'), new_distribution = tensor([0.5378, 0.3120, 0.1503], device='cuda:0')
2024-12-07 18:06:03,416 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 635: ref_distribution = tensor([0.5378, 0.3120, 0.1503], device='cuda:0'), new_distribution = tensor([0.5387, 0.3114, 0.1499], device='cuda:0')
2024-12-07 18:06:03,779 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 636: ref_distribution = tensor([0.5387, 0.3114, 0.1499], device='cuda:0'), new_distribution = tensor([0.5396, 0.3109, 0.1494], device='cuda:0')
2024-12-07 18:06:03,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 637: ref_distribution = tensor([0.5396, 0.3109, 0.1494], device='cuda:0'), new_distribution = tensor([0.5406, 0.3104, 0.1490], device='cuda:0')
2024-12-07 18:06:04,452 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 638: ref_distribution = tensor([0.5406, 0.3104, 0.1490], device='cuda:0'), new_distribution = tensor([0.5415, 0.3099, 0.1486], device='cuda:0')
2024-12-07 18:06:04,924 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 639: ref_distribution = tensor([0.5415, 0.3099, 0.1486], device='cuda:0'), new_distribution = tensor([0.5424, 0.3094, 0.1482], device='cuda:0')
2024-12-07 18:06:05,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 640: ref_distribution = tensor([0.5424, 0.3094, 0.1482], device='cuda:0'), new_distribution = tensor([0.5434, 0.3089, 0.1478], device='cuda:0')
2024-12-07 18:06:05,528 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 641: ref_distribution = tensor([0.5434, 0.3089, 0.1478], device='cuda:0'), new_distribution = tensor([0.5443, 0.3083, 0.1473], device='cuda:0')
2024-12-07 18:06:05,918 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 642: ref_distribution = tensor([0.5443, 0.3083, 0.1473], device='cuda:0'), new_distribution = tensor([0.5453, 0.3078, 0.1469], device='cuda:0')
2024-12-07 18:06:06,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 643: ref_distribution = tensor([0.5453, 0.3078, 0.1469], device='cuda:0'), new_distribution = tensor([0.5462, 0.3073, 0.1465], device='cuda:0')
2024-12-07 18:06:06,645 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 644: ref_distribution = tensor([0.5462, 0.3073, 0.1465], device='cuda:0'), new_distribution = tensor([0.5471, 0.3068, 0.1461], device='cuda:0')
2024-12-07 18:06:06,978 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 645: ref_distribution = tensor([0.5471, 0.3068, 0.1461], device='cuda:0'), new_distribution = tensor([0.5481, 0.3062, 0.1457], device='cuda:0')
2024-12-07 18:06:07,282 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 646: ref_distribution = tensor([0.5481, 0.3062, 0.1457], device='cuda:0'), new_distribution = tensor([0.5490, 0.3057, 0.1453], device='cuda:0')
2024-12-07 18:06:07,739 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 647: ref_distribution = tensor([0.5490, 0.3057, 0.1453], device='cuda:0'), new_distribution = tensor([0.5499, 0.3052, 0.1449], device='cuda:0')
2024-12-07 18:06:08,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 648: ref_distribution = tensor([0.5499, 0.3052, 0.1449], device='cuda:0'), new_distribution = tensor([0.5509, 0.3047, 0.1445], device='cuda:0')
2024-12-07 18:06:08,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 649: ref_distribution = tensor([0.5509, 0.3047, 0.1445], device='cuda:0'), new_distribution = tensor([0.5518, 0.3041, 0.1441], device='cuda:0')
2024-12-07 18:06:08,849 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 650: ref_distribution = tensor([0.5518, 0.3041, 0.1441], device='cuda:0'), new_distribution = tensor([0.5527, 0.3036, 0.1436], device='cuda:0')
2024-12-07 18:06:09,218 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 651: ref_distribution = tensor([0.5527, 0.3036, 0.1436], device='cuda:0'), new_distribution = tensor([0.5537, 0.3031, 0.1432], device='cuda:0')
2024-12-07 18:06:09,483 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 652: ref_distribution = tensor([0.5537, 0.3031, 0.1432], device='cuda:0'), new_distribution = tensor([0.5546, 0.3026, 0.1428], device='cuda:0')
2024-12-07 18:06:09,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 653: ref_distribution = tensor([0.5546, 0.3026, 0.1428], device='cuda:0'), new_distribution = tensor([0.5555, 0.3020, 0.1424], device='cuda:0')
2024-12-07 18:06:10,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 654: ref_distribution = tensor([0.5555, 0.3020, 0.1424], device='cuda:0'), new_distribution = tensor([0.5565, 0.3015, 0.1420], device='cuda:0')
2024-12-07 18:06:10,602 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 655: ref_distribution = tensor([0.5565, 0.3015, 0.1420], device='cuda:0'), new_distribution = tensor([0.5574, 0.3010, 0.1416], device='cuda:0')
2024-12-07 18:06:11,073 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 656: ref_distribution = tensor([0.5574, 0.3010, 0.1416], device='cuda:0'), new_distribution = tensor([0.5583, 0.3004, 0.1412], device='cuda:0')
2024-12-07 18:06:11,365 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 657: ref_distribution = tensor([0.5583, 0.3004, 0.1412], device='cuda:0'), new_distribution = tensor([0.5593, 0.2999, 0.1408], device='cuda:0')
2024-12-07 18:06:11,703 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 658: ref_distribution = tensor([0.5593, 0.2999, 0.1408], device='cuda:0'), new_distribution = tensor([0.5602, 0.2994, 0.1404], device='cuda:0')
2024-12-07 18:06:12,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 659: ref_distribution = tensor([0.5602, 0.2994, 0.1404], device='cuda:0'), new_distribution = tensor([0.5611, 0.2989, 0.1400], device='cuda:0')
2024-12-07 18:06:12,495 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 660: ref_distribution = tensor([0.5611, 0.2989, 0.1400], device='cuda:0'), new_distribution = tensor([0.5621, 0.2983, 0.1396], device='cuda:0')
2024-12-07 18:06:12,810 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 661: ref_distribution = tensor([0.5621, 0.2983, 0.1396], device='cuda:0'), new_distribution = tensor([0.5630, 0.2978, 0.1392], device='cuda:0')
2024-12-07 18:06:13,266 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 662: ref_distribution = tensor([0.5630, 0.2978, 0.1392], device='cuda:0'), new_distribution = tensor([0.5639, 0.2973, 0.1388], device='cuda:0')
2024-12-07 18:06:13,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 663: ref_distribution = tensor([0.5639, 0.2973, 0.1388], device='cuda:0'), new_distribution = tensor([0.5648, 0.2967, 0.1384], device='cuda:0')
2024-12-07 18:06:13,919 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 664: ref_distribution = tensor([0.5648, 0.2967, 0.1384], device='cuda:0'), new_distribution = tensor([0.5658, 0.2962, 0.1381], device='cuda:0')
2024-12-07 18:06:14,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 665: ref_distribution = tensor([0.5658, 0.2962, 0.1381], device='cuda:0'), new_distribution = tensor([0.5667, 0.2956, 0.1377], device='cuda:0')
2024-12-07 18:06:14,539 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 666: ref_distribution = tensor([0.5667, 0.2956, 0.1377], device='cuda:0'), new_distribution = tensor([0.5676, 0.2951, 0.1373], device='cuda:0')
2024-12-07 18:06:14,996 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 667: ref_distribution = tensor([0.5676, 0.2951, 0.1373], device='cuda:0'), new_distribution = tensor([0.5685, 0.2946, 0.1369], device='cuda:0')
2024-12-07 18:06:15,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 668: ref_distribution = tensor([0.5685, 0.2946, 0.1369], device='cuda:0'), new_distribution = tensor([0.5695, 0.2940, 0.1365], device='cuda:0')
2024-12-07 18:06:15,711 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 669: ref_distribution = tensor([0.5695, 0.2940, 0.1365], device='cuda:0'), new_distribution = tensor([0.5704, 0.2935, 0.1361], device='cuda:0')
2024-12-07 18:06:16,151 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 670: ref_distribution = tensor([0.5704, 0.2935, 0.1361], device='cuda:0'), new_distribution = tensor([0.5713, 0.2930, 0.1357], device='cuda:0')
2024-12-07 18:06:16,612 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 671: ref_distribution = tensor([0.5713, 0.2930, 0.1357], device='cuda:0'), new_distribution = tensor([0.5722, 0.2924, 0.1353], device='cuda:0')
2024-12-07 18:06:16,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 672: ref_distribution = tensor([0.5722, 0.2924, 0.1353], device='cuda:0'), new_distribution = tensor([0.5732, 0.2919, 0.1349], device='cuda:0')
2024-12-07 18:06:17,261 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 673: ref_distribution = tensor([0.5732, 0.2919, 0.1349], device='cuda:0'), new_distribution = tensor([0.5741, 0.2913, 0.1346], device='cuda:0')
2024-12-07 18:06:17,730 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 674: ref_distribution = tensor([0.5741, 0.2913, 0.1346], device='cuda:0'), new_distribution = tensor([0.5750, 0.2908, 0.1342], device='cuda:0')
2024-12-07 18:06:17,937 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 675: ref_distribution = tensor([0.5750, 0.2908, 0.1342], device='cuda:0'), new_distribution = tensor([0.5759, 0.2903, 0.1338], device='cuda:0')
2024-12-07 18:06:18,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 676: ref_distribution = tensor([0.5759, 0.2903, 0.1338], device='cuda:0'), new_distribution = tensor([0.5769, 0.2897, 0.1334], device='cuda:0')
2024-12-07 18:06:18,852 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 677: ref_distribution = tensor([0.5769, 0.2897, 0.1334], device='cuda:0'), new_distribution = tensor([0.5778, 0.2892, 0.1330], device='cuda:0')
2024-12-07 18:06:19,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 678: ref_distribution = tensor([0.5778, 0.2892, 0.1330], device='cuda:0'), new_distribution = tensor([0.5787, 0.2886, 0.1327], device='cuda:0')
2024-12-07 18:06:19,463 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 679: ref_distribution = tensor([0.5787, 0.2886, 0.1327], device='cuda:0'), new_distribution = tensor([0.5796, 0.2881, 0.1323], device='cuda:0')
2024-12-07 18:06:19,872 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 680: ref_distribution = tensor([0.5796, 0.2881, 0.1323], device='cuda:0'), new_distribution = tensor([0.5805, 0.2876, 0.1319], device='cuda:0')
2024-12-07 18:06:20,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 681: ref_distribution = tensor([0.5805, 0.2876, 0.1319], device='cuda:0'), new_distribution = tensor([0.5815, 0.2870, 0.1315], device='cuda:0')
2024-12-07 18:06:20,616 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 682: ref_distribution = tensor([0.5815, 0.2870, 0.1315], device='cuda:0'), new_distribution = tensor([0.5824, 0.2865, 0.1311], device='cuda:0')
2024-12-07 18:06:21,083 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 683: ref_distribution = tensor([0.5824, 0.2865, 0.1311], device='cuda:0'), new_distribution = tensor([0.5833, 0.2859, 0.1308], device='cuda:0')
2024-12-07 18:06:21,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 684: ref_distribution = tensor([0.5833, 0.2859, 0.1308], device='cuda:0'), new_distribution = tensor([0.5842, 0.2854, 0.1304], device='cuda:0')
2024-12-07 18:06:21,735 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 685: ref_distribution = tensor([0.5842, 0.2854, 0.1304], device='cuda:0'), new_distribution = tensor([0.5851, 0.2848, 0.1300], device='cuda:0')
2024-12-07 18:06:22,214 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 686: ref_distribution = tensor([0.5851, 0.2848, 0.1300], device='cuda:0'), new_distribution = tensor([0.5861, 0.2843, 0.1297], device='cuda:0')
2024-12-07 18:06:22,620 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 687: ref_distribution = tensor([0.5861, 0.2843, 0.1297], device='cuda:0'), new_distribution = tensor([0.5870, 0.2837, 0.1293], device='cuda:0')
2024-12-07 18:06:22,949 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 688: ref_distribution = tensor([0.5870, 0.2837, 0.1293], device='cuda:0'), new_distribution = tensor([0.5879, 0.2832, 0.1289], device='cuda:0')
2024-12-07 18:06:23,358 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 689: ref_distribution = tensor([0.5879, 0.2832, 0.1289], device='cuda:0'), new_distribution = tensor([0.5888, 0.2827, 0.1285], device='cuda:0')
2024-12-07 18:06:23,827 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 690: ref_distribution = tensor([0.5888, 0.2827, 0.1285], device='cuda:0'), new_distribution = tensor([0.5897, 0.2821, 0.1282], device='cuda:0')
2024-12-07 18:06:24,152 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 691: ref_distribution = tensor([0.5897, 0.2821, 0.1282], device='cuda:0'), new_distribution = tensor([0.5906, 0.2816, 0.1278], device='cuda:0')
2024-12-07 18:06:24,507 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 692: ref_distribution = tensor([0.5906, 0.2816, 0.1278], device='cuda:0'), new_distribution = tensor([0.5915, 0.2810, 0.1275], device='cuda:0')
2024-12-07 18:06:24,986 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 693: ref_distribution = tensor([0.5915, 0.2810, 0.1275], device='cuda:0'), new_distribution = tensor([0.5925, 0.2805, 0.1271], device='cuda:0')
2024-12-07 18:06:25,348 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 694: ref_distribution = tensor([0.5925, 0.2805, 0.1271], device='cuda:0'), new_distribution = tensor([0.5934, 0.2799, 0.1267], device='cuda:0')
2024-12-07 18:06:25,642 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 695: ref_distribution = tensor([0.5934, 0.2799, 0.1267], device='cuda:0'), new_distribution = tensor([0.5943, 0.2794, 0.1264], device='cuda:0')
2024-12-07 18:06:26,101 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 696: ref_distribution = tensor([0.5943, 0.2794, 0.1264], device='cuda:0'), new_distribution = tensor([0.5952, 0.2788, 0.1260], device='cuda:0')
2024-12-07 18:06:26,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 697: ref_distribution = tensor([0.5952, 0.2788, 0.1260], device='cuda:0'), new_distribution = tensor([0.5961, 0.2783, 0.1256], device='cuda:0')
2024-12-07 18:06:26,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 698: ref_distribution = tensor([0.5961, 0.2783, 0.1256], device='cuda:0'), new_distribution = tensor([0.5970, 0.2777, 0.1253], device='cuda:0')
2024-12-07 18:06:27,197 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:555] - INFO: Iteration 699: ref_distribution = tensor([0.5970, 0.2777, 0.1253], device='cuda:0'), new_distribution = tensor([0.5979, 0.2772, 0.1249], device='cuda:0')
2024-12-07 18:14:06,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: -0.0774 reward: 0.0774 ref_reward: 0.0771 improvement: 0.34%
2024-12-07 18:14:08,328 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: -0.0799 reward: 0.0799 ref_reward: 0.0771 improvement: 3.63%
2024-12-07 18:14:09,785 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: -0.0801 reward: 0.0801 ref_reward: 0.0771 improvement: 3.85%
2024-12-07 18:14:11,263 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: -0.0796 reward: 0.0796 ref_reward: 0.0771 improvement: 3.22%
2024-12-07 18:14:12,761 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: -0.0797 reward: 0.0797 ref_reward: 0.0771 improvement: 3.35%
2024-12-07 18:14:14,269 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: -0.0801 reward: 0.0801 ref_reward: 0.0771 improvement: 3.83%
2024-12-07 18:14:15,820 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:17,285 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: -0.0801 reward: 0.0801 ref_reward: 0.0771 improvement: 3.89%
2024-12-07 18:14:18,784 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: -0.0800 reward: 0.0800 ref_reward: 0.0771 improvement: 3.75%
2024-12-07 18:14:20,163 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: -0.0800 reward: 0.0800 ref_reward: 0.0771 improvement: 3.79%
2024-12-07 18:14:21,641 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: -0.0801 reward: 0.0801 ref_reward: 0.0771 improvement: 3.94%
2024-12-07 18:14:23,000 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:24,467 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 3.98%
2024-12-07 18:14:25,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: -0.0801 reward: 0.0801 ref_reward: 0.0771 improvement: 3.92%
2024-12-07 18:14:27,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: -0.0801 reward: 0.0801 ref_reward: 0.0771 improvement: 3.94%
2024-12-07 18:14:28,971 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 3.99%
2024-12-07 18:14:30,353 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:31,792 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.00%
2024-12-07 18:14:33,068 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 3.98%
2024-12-07 18:14:34,582 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 3.99%
2024-12-07 18:14:35,854 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.01%
2024-12-07 18:14:37,623 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:39,176 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.01%
2024-12-07 18:14:40,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.00%
2024-12-07 18:14:41,956 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.01%
2024-12-07 18:14:43,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:44,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:46,073 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.01%
2024-12-07 18:14:46,387 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.01%
2024-12-07 18:14:47,724 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:49,250 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:50,514 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:51,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:53,322 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:54,529 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:55,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:57,249 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:14:58,775 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:15:00,303 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:15:01,720 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:15:03,177 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:15:04,578 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:15:05,999 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:15:07,557 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:15:08,961 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:15:10,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:15:11,941 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:15:13,412 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:15:14,769 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:15:16,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: -0.0802 reward: 0.0802 ref_reward: 0.0771 improvement: 4.02%
2024-12-07 18:15:17,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: 0.2428 reward: -0.2428 ref_reward: 0.0843 improvement: -388.12%
2024-12-07 18:15:19,430 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: 0.2103 reward: -0.2103 ref_reward: 0.0843 improvement: -349.57%
2024-12-07 18:15:20,747 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: 0.1801 reward: -0.1801 ref_reward: 0.0843 improvement: -313.77%
2024-12-07 18:15:22,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: 0.1520 reward: -0.1520 ref_reward: 0.0843 improvement: -280.33%
2024-12-07 18:15:23,632 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: 0.1248 reward: -0.1248 ref_reward: 0.0843 improvement: -248.14%
2024-12-07 18:15:25,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: 0.0987 reward: -0.0987 ref_reward: 0.0843 improvement: -217.18%
2024-12-07 18:15:26,684 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: 0.0736 reward: -0.0736 ref_reward: 0.0843 improvement: -187.33%
2024-12-07 18:15:28,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: 0.0495 reward: -0.0495 ref_reward: 0.0843 improvement: -158.79%
2024-12-07 18:15:29,644 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: 0.0270 reward: -0.0270 ref_reward: 0.0843 improvement: -132.10%
2024-12-07 18:15:30,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: 0.0060 reward: -0.0060 ref_reward: 0.0843 improvement: -107.13%
2024-12-07 18:15:32,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: -0.0132 reward: 0.0132 ref_reward: 0.0843 improvement: -84.37%
2024-12-07 18:15:33,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: -0.0304 reward: 0.0304 ref_reward: 0.0843 improvement: -63.93%
2024-12-07 18:15:35,373 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: -0.0454 reward: 0.0454 ref_reward: 0.0843 improvement: -46.14%
2024-12-07 18:15:36,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: -0.0579 reward: 0.0579 ref_reward: 0.0843 improvement: -31.29%
2024-12-07 18:15:38,343 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: -0.0678 reward: 0.0678 ref_reward: 0.0843 improvement: -19.55%
2024-12-07 18:15:39,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: -0.0751 reward: 0.0751 ref_reward: 0.0843 improvement: -10.89%
2024-12-07 18:15:41,456 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: -0.0799 reward: 0.0799 ref_reward: 0.0843 improvement: -5.12%
2024-12-07 18:15:43,255 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: -0.0827 reward: 0.0827 ref_reward: 0.0843 improvement: -1.84%
2024-12-07 18:15:44,619 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: -0.0839 reward: 0.0839 ref_reward: 0.0843 improvement: -0.47%
2024-12-07 18:15:46,107 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: -0.0840 reward: 0.0840 ref_reward: 0.0843 improvement: -0.33%
2024-12-07 18:15:47,614 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: -0.0836 reward: 0.0836 ref_reward: 0.0843 improvement: -0.84%
2024-12-07 18:15:49,037 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: -0.0830 reward: 0.0830 ref_reward: 0.0843 improvement: -1.48%
2024-12-07 18:15:50,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: -0.0826 reward: 0.0826 ref_reward: 0.0843 improvement: -1.94%
2024-12-07 18:15:51,794 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: -0.0825 reward: 0.0825 ref_reward: 0.0843 improvement: -2.06%
2024-12-07 18:15:53,337 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: -0.0827 reward: 0.0827 ref_reward: 0.0843 improvement: -1.82%
2024-12-07 18:15:54,729 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: -0.0832 reward: 0.0832 ref_reward: 0.0843 improvement: -1.31%
2024-12-07 18:15:56,281 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: -0.0837 reward: 0.0837 ref_reward: 0.0843 improvement: -0.66%
2024-12-07 18:15:57,576 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: -0.0843 reward: 0.0843 ref_reward: 0.0843 improvement: 0.00%
2024-12-07 18:15:59,108 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: -0.0847 reward: 0.0847 ref_reward: 0.0843 improvement: 0.58%
2024-12-07 18:16:00,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: -0.0851 reward: 0.0851 ref_reward: 0.0843 improvement: 1.00%
2024-12-07 18:16:01,970 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: -0.0853 reward: 0.0853 ref_reward: 0.0843 improvement: 1.26%
2024-12-07 18:16:03,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: -0.0854 reward: 0.0854 ref_reward: 0.0843 improvement: 1.37%
2024-12-07 18:16:04,884 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: -0.0854 reward: 0.0854 ref_reward: 0.0843 improvement: 1.37%
2024-12-07 18:16:06,438 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: -0.0854 reward: 0.0854 ref_reward: 0.0843 improvement: 1.31%
2024-12-07 18:16:07,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: -0.0853 reward: 0.0853 ref_reward: 0.0843 improvement: 1.24%
2024-12-07 18:16:09,400 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: -0.0853 reward: 0.0853 ref_reward: 0.0843 improvement: 1.19%
2024-12-07 18:16:10,963 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: -0.0853 reward: 0.0853 ref_reward: 0.0843 improvement: 1.18%
2024-12-07 18:16:12,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: -0.0853 reward: 0.0853 ref_reward: 0.0843 improvement: 1.20%
2024-12-07 18:16:13,808 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: -0.0853 reward: 0.0853 ref_reward: 0.0843 improvement: 1.25%
2024-12-07 18:16:15,364 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: -0.0854 reward: 0.0854 ref_reward: 0.0843 improvement: 1.32%
2024-12-07 18:16:16,810 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: -0.0854 reward: 0.0854 ref_reward: 0.0843 improvement: 1.38%
2024-12-07 18:16:18,314 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: -0.0855 reward: 0.0855 ref_reward: 0.0843 improvement: 1.43%
2024-12-07 18:16:19,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: -0.0855 reward: 0.0855 ref_reward: 0.0843 improvement: 1.47%
2024-12-07 18:16:21,022 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: -0.0855 reward: 0.0855 ref_reward: 0.0843 improvement: 1.49%
2024-12-07 18:16:22,552 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: -0.0855 reward: 0.0855 ref_reward: 0.0843 improvement: 1.50%
2024-12-07 18:16:24,040 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: -0.0855 reward: 0.0855 ref_reward: 0.0843 improvement: 1.50%
2024-12-07 18:16:25,388 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: -0.0855 reward: 0.0855 ref_reward: 0.0843 improvement: 1.50%
2024-12-07 18:16:26,951 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: -0.0855 reward: 0.0855 ref_reward: 0.0843 improvement: 1.49%
2024-12-07 18:16:28,411 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: -0.0855 reward: 0.0855 ref_reward: 0.0843 improvement: 1.49%
2024-12-07 18:16:29,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: -0.0855 reward: 0.0855 ref_reward: 0.0843 improvement: 1.49%
2024-12-07 18:16:31,442 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: 14.5298 reward: -14.5298 ref_reward: 0.0729 improvement: -20036.41%
2024-12-07 18:16:32,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: 13.8886 reward: -13.8886 ref_reward: 0.0729 improvement: -19156.72%
2024-12-07 18:16:34,293 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: 13.2499 reward: -13.2499 ref_reward: 0.0729 improvement: -18280.24%
2024-12-07 18:16:35,610 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: 12.5943 reward: -12.5943 ref_reward: 0.0729 improvement: -17380.68%
2024-12-07 18:16:37,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: 11.9013 reward: -11.9013 ref_reward: 0.0729 improvement: -16429.88%
2024-12-07 18:16:38,460 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: 11.1713 reward: -11.1713 ref_reward: 0.0729 improvement: -15428.22%
2024-12-07 18:16:39,961 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: 10.4313 reward: -10.4313 ref_reward: 0.0729 improvement: -14412.82%
2024-12-07 18:16:41,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: 9.6692 reward: -9.6692 ref_reward: 0.0729 improvement: -13367.23%
2024-12-07 18:16:42,826 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: 8.9012 reward: -8.9012 ref_reward: 0.0729 improvement: -12313.41%
2024-12-07 18:16:44,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: 8.1368 reward: -8.1368 ref_reward: 0.0729 improvement: -11264.51%
2024-12-07 18:16:45,790 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: 7.3522 reward: -7.3522 ref_reward: 0.0729 improvement: -10188.07%
2024-12-07 18:16:47,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: 6.5572 reward: -6.5572 ref_reward: 0.0729 improvement: -9097.15%
2024-12-07 18:16:48,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: 5.7655 reward: -5.7655 ref_reward: 0.0729 improvement: -8010.88%
2024-12-07 18:16:50,187 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: 4.9914 reward: -4.9914 ref_reward: 0.0729 improvement: -6948.80%
2024-12-07 18:16:51,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: 4.2508 reward: -4.2508 ref_reward: 0.0729 improvement: -5932.60%
2024-12-07 18:16:52,768 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: 3.5649 reward: -3.5649 ref_reward: 0.0729 improvement: -4991.47%
2024-12-07 18:16:54,301 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: 2.9479 reward: -2.9479 ref_reward: 0.0729 improvement: -4144.90%
2024-12-07 18:16:55,778 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: 2.4084 reward: -2.4084 ref_reward: 0.0729 improvement: -3404.52%
2024-12-07 18:16:57,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: 1.9487 reward: -1.9487 ref_reward: 0.0729 improvement: -2773.77%
2024-12-07 18:16:58,803 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: 1.5660 reward: -1.5660 ref_reward: 0.0729 improvement: -2248.77%
2024-12-07 18:17:00,206 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: 1.2537 reward: -1.2537 ref_reward: 0.0729 improvement: -1820.23%
2024-12-07 18:17:01,706 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: 1.0026 reward: -1.0026 ref_reward: 0.0729 improvement: -1475.71%
2024-12-07 18:17:02,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: 0.8030 reward: -0.8030 ref_reward: 0.0729 improvement: -1201.74%
2024-12-07 18:17:04,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: 0.6452 reward: -0.6452 ref_reward: 0.0729 improvement: -985.35%
2024-12-07 18:17:05,881 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: 0.5211 reward: -0.5211 ref_reward: 0.0729 improvement: -814.95%
2024-12-07 18:17:07,382 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: 0.4233 reward: -0.4233 ref_reward: 0.0729 improvement: -680.75%
2024-12-07 18:17:08,746 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: 0.3460 reward: -0.3460 ref_reward: 0.0729 improvement: -574.78%
2024-12-07 18:17:10,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: 0.2847 reward: -0.2847 ref_reward: 0.0729 improvement: -490.70%
2024-12-07 18:17:11,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: 0.2358 reward: -0.2358 ref_reward: 0.0729 improvement: -423.57%
2024-12-07 18:17:13,110 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: 0.1965 reward: -0.1965 ref_reward: 0.0729 improvement: -369.59%
2024-12-07 18:17:14,545 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: 0.1646 reward: -0.1646 ref_reward: 0.0729 improvement: -325.83%
2024-12-07 18:17:16,091 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: 0.1385 reward: -0.1385 ref_reward: 0.0729 improvement: -290.05%
2024-12-07 18:17:17,622 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: 0.1170 reward: -0.1170 ref_reward: 0.0729 improvement: -260.55%
2024-12-07 18:17:19,057 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: 0.0991 reward: -0.0991 ref_reward: 0.0729 improvement: -236.01%
2024-12-07 18:17:20,503 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: 0.0841 reward: -0.0841 ref_reward: 0.0729 improvement: -215.41%
2024-12-07 18:17:21,883 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: 0.0714 reward: -0.0714 ref_reward: 0.0729 improvement: -197.97%
2024-12-07 18:17:23,307 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: 0.0605 reward: -0.0605 ref_reward: 0.0729 improvement: -183.07%
2024-12-07 18:17:24,819 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: 0.0512 reward: -0.0512 ref_reward: 0.0729 improvement: -170.25%
2024-12-07 18:17:26,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: 0.0431 reward: -0.0431 ref_reward: 0.0729 improvement: -159.13%
2024-12-07 18:17:27,798 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: 0.0360 reward: -0.0360 ref_reward: 0.0729 improvement: -149.40%
2024-12-07 18:17:29,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: 0.0298 reward: -0.0298 ref_reward: 0.0729 improvement: -140.82%
2024-12-07 18:17:30,827 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: 0.0242 reward: -0.0242 ref_reward: 0.0729 improvement: -133.22%
2024-12-07 18:17:32,318 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: 0.0193 reward: -0.0193 ref_reward: 0.0729 improvement: -126.42%
2024-12-07 18:17:33,878 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: 0.0148 reward: -0.0148 ref_reward: 0.0729 improvement: -120.31%
2024-12-07 18:17:35,289 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: 0.0108 reward: -0.0108 ref_reward: 0.0729 improvement: -114.78%
2024-12-07 18:17:36,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: 0.0071 reward: -0.0071 ref_reward: 0.0729 improvement: -109.76%
2024-12-07 18:17:37,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: 0.0038 reward: -0.0038 ref_reward: 0.0729 improvement: -105.16%
2024-12-07 18:17:39,547 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: 0.0007 reward: -0.0007 ref_reward: 0.0729 improvement: -100.93%
2024-12-07 18:17:40,997 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: -0.0022 reward: 0.0022 ref_reward: 0.0729 improvement: -97.04%
2024-12-07 18:17:42,496 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: -0.0048 reward: 0.0048 ref_reward: 0.0729 improvement: -93.42%
2024-12-07 18:17:44,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: 0.1529 reward: -0.1529 ref_reward: 0.0503 improvement: -403.71%
2024-12-07 18:17:45,501 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: 0.1146 reward: -0.1146 ref_reward: 0.0503 improvement: -327.69%
2024-12-07 18:17:46,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: 0.0837 reward: -0.0837 ref_reward: 0.0503 improvement: -266.32%
2024-12-07 18:17:48,433 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: 0.0591 reward: -0.0591 ref_reward: 0.0503 improvement: -217.48%
2024-12-07 18:17:49,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: 0.0378 reward: -0.0378 ref_reward: 0.0503 improvement: -175.01%
2024-12-07 18:17:51,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: 0.0191 reward: -0.0191 ref_reward: 0.0503 improvement: -137.92%
2024-12-07 18:17:52,962 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: 0.0033 reward: -0.0033 ref_reward: 0.0503 improvement: -106.51%
2024-12-07 18:17:54,484 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: -0.0099 reward: 0.0099 ref_reward: 0.0503 improvement: -80.39%
2024-12-07 18:17:56,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: -0.0214 reward: 0.0214 ref_reward: 0.0503 improvement: -57.48%
2024-12-07 18:17:57,346 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: -0.0313 reward: 0.0313 ref_reward: 0.0503 improvement: -37.87%
2024-12-07 18:17:58,862 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: -0.0393 reward: 0.0393 ref_reward: 0.0503 improvement: -21.98%
2024-12-07 18:18:00,310 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: -0.0453 reward: 0.0453 ref_reward: 0.0503 improvement: -9.98%
2024-12-07 18:18:01,705 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: -0.0494 reward: 0.0494 ref_reward: 0.0503 improvement: -1.78%
2024-12-07 18:18:03,142 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: -0.0519 reward: 0.0519 ref_reward: 0.0503 improvement: 3.12%
2024-12-07 18:18:04,696 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: -0.0530 reward: 0.0530 ref_reward: 0.0503 improvement: 5.35%
2024-12-07 18:18:06,215 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: -0.0533 reward: 0.0533 ref_reward: 0.0503 improvement: 5.83%
2024-12-07 18:18:07,605 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: -0.0531 reward: 0.0531 ref_reward: 0.0503 improvement: 5.49%
2024-12-07 18:18:09,071 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: -0.0529 reward: 0.0529 ref_reward: 0.0503 improvement: 5.01%
2024-12-07 18:18:10,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: -0.0527 reward: 0.0527 ref_reward: 0.0503 improvement: 4.73%
2024-12-07 18:18:11,902 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: -0.0527 reward: 0.0527 ref_reward: 0.0503 improvement: 4.66%
2024-12-07 18:18:13,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: -0.0527 reward: 0.0527 ref_reward: 0.0503 improvement: 4.69%
2024-12-07 18:18:14,858 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: -0.0527 reward: 0.0527 ref_reward: 0.0503 improvement: 4.67%
2024-12-07 18:18:16,166 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: -0.0527 reward: 0.0527 ref_reward: 0.0503 improvement: 4.63%
2024-12-07 18:18:17,585 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: -0.0527 reward: 0.0527 ref_reward: 0.0503 improvement: 4.65%
2024-12-07 18:18:19,098 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: -0.0528 reward: 0.0528 ref_reward: 0.0503 improvement: 4.87%
2024-12-07 18:18:20,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: -0.0530 reward: 0.0530 ref_reward: 0.0503 improvement: 5.28%
2024-12-07 18:18:22,052 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: -0.0533 reward: 0.0533 ref_reward: 0.0503 improvement: 5.82%
2024-12-07 18:18:23,599 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: -0.0535 reward: 0.0535 ref_reward: 0.0503 improvement: 6.33%
2024-12-07 18:18:25,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: -0.0537 reward: 0.0537 ref_reward: 0.0503 improvement: 6.72%
2024-12-07 18:18:26,552 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: -0.0538 reward: 0.0538 ref_reward: 0.0503 improvement: 6.96%
2024-12-07 18:18:28,112 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: -0.0539 reward: 0.0539 ref_reward: 0.0503 improvement: 7.08%
2024-12-07 18:18:29,447 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: -0.0539 reward: 0.0539 ref_reward: 0.0503 improvement: 7.11%
2024-12-07 18:18:30,838 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: -0.0539 reward: 0.0539 ref_reward: 0.0503 improvement: 7.12%
2024-12-07 18:18:32,336 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: -0.0539 reward: 0.0539 ref_reward: 0.0503 improvement: 7.12%
2024-12-07 18:18:33,865 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: -0.0539 reward: 0.0539 ref_reward: 0.0503 improvement: 7.12%
2024-12-07 18:18:35,345 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: -0.0539 reward: 0.0539 ref_reward: 0.0503 improvement: 7.12%
2024-12-07 18:18:36,880 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: -0.0539 reward: 0.0539 ref_reward: 0.0503 improvement: 7.11%
2024-12-07 18:18:38,397 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: -0.0539 reward: 0.0539 ref_reward: 0.0503 improvement: 7.10%
2024-12-07 18:18:39,886 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: -0.0539 reward: 0.0539 ref_reward: 0.0503 improvement: 7.09%
2024-12-07 18:18:41,419 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: -0.0539 reward: 0.0539 ref_reward: 0.0503 improvement: 7.09%
2024-12-07 18:18:42,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: -0.0539 reward: 0.0539 ref_reward: 0.0503 improvement: 7.11%
2024-12-07 18:18:44,260 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: -0.0539 reward: 0.0539 ref_reward: 0.0503 improvement: 7.13%
2024-12-07 18:18:45,745 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: -0.0539 reward: 0.0539 ref_reward: 0.0503 improvement: 7.16%
2024-12-07 18:18:47,181 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: -0.0540 reward: 0.0540 ref_reward: 0.0503 improvement: 7.18%
2024-12-07 18:18:48,757 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: -0.0540 reward: 0.0540 ref_reward: 0.0503 improvement: 7.19%
2024-12-07 18:18:50,188 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: -0.0540 reward: 0.0540 ref_reward: 0.0503 improvement: 7.20%
2024-12-07 18:18:51,277 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: -0.0540 reward: 0.0540 ref_reward: 0.0503 improvement: 7.20%
2024-12-07 18:18:52,806 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: -0.0540 reward: 0.0540 ref_reward: 0.0503 improvement: 7.20%
2024-12-07 18:18:54,146 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: -0.0540 reward: 0.0540 ref_reward: 0.0503 improvement: 7.20%
2024-12-07 18:18:55,674 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: -0.0540 reward: 0.0540 ref_reward: 0.0503 improvement: 7.20%
2024-12-07 18:20:41,009 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 0 loss: 0.6647 acc: 0.93
2024-12-07 18:20:41,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 2 loss: 0.6594 acc: 0.93
2024-12-07 18:20:41,021 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 4 loss: 0.6542 acc: 0.93
2024-12-07 18:20:41,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 6 loss: 0.6490 acc: 0.93
2024-12-07 18:20:41,033 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 8 loss: 0.6439 acc: 0.93
2024-12-07 18:20:41,039 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 10 loss: 0.6389 acc: 0.93
2024-12-07 18:20:41,045 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 12 loss: 0.6338 acc: 0.93
2024-12-07 18:20:41,050 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 14 loss: 0.6288 acc: 0.93
2024-12-07 18:20:41,056 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 16 loss: 0.6239 acc: 0.93
2024-12-07 18:20:41,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:122] - INFO: [Reward] Epoch 18 loss: 0.6190 acc: 0.93
2024-12-07 18:20:43,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: 0.0359 reward: -0.0359 ref_reward: -0.0284 improvement: -26.28%
2024-12-07 18:20:44,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: 0.0267 reward: -0.0267 ref_reward: -0.0284 improvement: 5.87%
2024-12-07 18:20:46,172 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: 0.0215 reward: -0.0215 ref_reward: -0.0284 improvement: 24.39%
2024-12-07 18:20:47,650 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: 0.0194 reward: -0.0194 ref_reward: -0.0284 improvement: 31.67%
2024-12-07 18:20:49,165 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: 0.0192 reward: -0.0192 ref_reward: -0.0284 improvement: 32.27%
2024-12-07 18:20:50,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: 0.0199 reward: -0.0199 ref_reward: -0.0284 improvement: 30.03%
2024-12-07 18:20:52,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: 0.0206 reward: -0.0206 ref_reward: -0.0284 improvement: 27.65%
2024-12-07 18:20:53,654 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: 0.0207 reward: -0.0207 ref_reward: -0.0284 improvement: 27.13%
2024-12-07 18:20:55,157 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: 0.0203 reward: -0.0203 ref_reward: -0.0284 improvement: 28.61%
2024-12-07 18:20:56,510 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: 0.0196 reward: -0.0196 ref_reward: -0.0284 improvement: 30.84%
2024-12-07 18:20:58,062 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: 0.0192 reward: -0.0192 ref_reward: -0.0284 improvement: 32.57%
2024-12-07 18:20:59,587 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.30%
2024-12-07 18:21:00,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.19%
2024-12-07 18:21:02,525 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: 0.0191 reward: -0.0191 ref_reward: -0.0284 improvement: 32.73%
2024-12-07 18:21:03,879 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: 0.0192 reward: -0.0192 ref_reward: -0.0284 improvement: 32.34%
2024-12-07 18:21:05,359 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: 0.0192 reward: -0.0192 ref_reward: -0.0284 improvement: 32.23%
2024-12-07 18:21:06,895 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: 0.0192 reward: -0.0192 ref_reward: -0.0284 improvement: 32.43%
2024-12-07 18:21:08,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: 0.0191 reward: -0.0191 ref_reward: -0.0284 improvement: 32.80%
2024-12-07 18:21:09,843 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.15%
2024-12-07 18:21:11,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.35%
2024-12-07 18:21:12,688 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.35%
2024-12-07 18:21:14,215 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.24%
2024-12-07 18:21:15,538 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.15%
2024-12-07 18:21:16,888 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.14%
2024-12-07 18:21:18,367 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.20%
2024-12-07 18:21:19,900 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.28%
2024-12-07 18:21:21,292 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.35%
2024-12-07 18:21:22,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:21:24,235 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.35%
2024-12-07 18:21:25,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.32%
2024-12-07 18:21:26,967 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.31%
2024-12-07 18:21:28,332 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.33%
2024-12-07 18:21:29,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.35%
2024-12-07 18:21:31,154 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.36%
2024-12-07 18:21:32,624 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:21:33,922 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.36%
2024-12-07 18:21:35,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.36%
2024-12-07 18:21:36,816 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.36%
2024-12-07 18:21:38,339 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.36%
2024-12-07 18:21:39,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:21:41,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:21:42,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:21:44,027 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:21:45,276 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:21:46,752 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:21:48,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:21:49,724 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:21:51,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:21:52,559 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:21:53,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:21:55,636 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: 0.2749 reward: -0.2749 ref_reward: 0.0634 improvement: -533.51%
2024-12-07 18:21:57,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: 0.2280 reward: -0.2280 ref_reward: 0.0634 improvement: -459.48%
2024-12-07 18:21:58,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: 0.1861 reward: -0.1861 ref_reward: 0.0634 improvement: -393.50%
2024-12-07 18:21:59,953 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: 0.1481 reward: -0.1481 ref_reward: 0.0634 improvement: -333.48%
2024-12-07 18:22:01,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: 0.1136 reward: -0.1136 ref_reward: 0.0634 improvement: -279.09%
2024-12-07 18:22:02,930 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: 0.0827 reward: -0.0827 ref_reward: 0.0634 improvement: -230.44%
2024-12-07 18:22:04,436 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: 0.0557 reward: -0.0557 ref_reward: 0.0634 improvement: -187.87%
2024-12-07 18:22:05,875 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: 0.0314 reward: -0.0314 ref_reward: 0.0634 improvement: -149.47%
2024-12-07 18:22:07,443 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: 0.0096 reward: -0.0096 ref_reward: 0.0634 improvement: -115.06%
2024-12-07 18:22:08,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: -0.0094 reward: 0.0094 ref_reward: 0.0634 improvement: -85.12%
2024-12-07 18:22:10,471 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: -0.0254 reward: 0.0254 ref_reward: 0.0634 improvement: -59.93%
2024-12-07 18:22:11,934 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: -0.0387 reward: 0.0387 ref_reward: 0.0634 improvement: -39.02%
2024-12-07 18:22:13,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: -0.0491 reward: 0.0491 ref_reward: 0.0634 improvement: -22.52%
2024-12-07 18:22:15,016 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: -0.0569 reward: 0.0569 ref_reward: 0.0634 improvement: -10.31%
2024-12-07 18:22:16,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: -0.0621 reward: 0.0621 ref_reward: 0.0634 improvement: -2.08%
2024-12-07 18:22:17,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: -0.0651 reward: 0.0651 ref_reward: 0.0634 improvement: 2.71%
2024-12-07 18:22:19,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: -0.0665 reward: 0.0665 ref_reward: 0.0634 improvement: 4.83%
2024-12-07 18:22:20,980 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: -0.0667 reward: 0.0667 ref_reward: 0.0634 improvement: 5.14%
2024-12-07 18:22:22,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: -0.0663 reward: 0.0663 ref_reward: 0.0634 improvement: 4.48%
2024-12-07 18:22:23,585 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: -0.0657 reward: 0.0657 ref_reward: 0.0634 improvement: 3.54%
2024-12-07 18:22:24,972 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: -0.0652 reward: 0.0652 ref_reward: 0.0634 improvement: 2.80%
2024-12-07 18:22:26,500 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: -0.0650 reward: 0.0650 ref_reward: 0.0634 improvement: 2.49%
2024-12-07 18:22:27,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: -0.0651 reward: 0.0651 ref_reward: 0.0634 improvement: 2.66%
2024-12-07 18:22:29,401 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: -0.0655 reward: 0.0655 ref_reward: 0.0634 improvement: 3.20%
2024-12-07 18:22:30,944 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: -0.0659 reward: 0.0659 ref_reward: 0.0634 improvement: 3.94%
2024-12-07 18:22:32,389 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: -0.0664 reward: 0.0664 ref_reward: 0.0634 improvement: 4.70%
2024-12-07 18:22:33,810 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: -0.0668 reward: 0.0668 ref_reward: 0.0634 improvement: 5.33%
2024-12-07 18:22:35,207 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: -0.0671 reward: 0.0671 ref_reward: 0.0634 improvement: 5.77%
2024-12-07 18:22:36,676 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: -0.0672 reward: 0.0672 ref_reward: 0.0634 improvement: 6.01%
2024-12-07 18:22:37,995 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: -0.0673 reward: 0.0673 ref_reward: 0.0634 improvement: 6.10%
2024-12-07 18:22:39,394 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: -0.0673 reward: 0.0673 ref_reward: 0.0634 improvement: 6.12%
2024-12-07 18:22:40,915 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: -0.0673 reward: 0.0673 ref_reward: 0.0634 improvement: 6.13%
2024-12-07 18:22:42,415 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: -0.0673 reward: 0.0673 ref_reward: 0.0634 improvement: 6.18%
2024-12-07 18:22:43,897 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: -0.0674 reward: 0.0674 ref_reward: 0.0634 improvement: 6.28%
2024-12-07 18:22:45,418 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: -0.0675 reward: 0.0675 ref_reward: 0.0634 improvement: 6.41%
2024-12-07 18:22:46,931 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: -0.0676 reward: 0.0676 ref_reward: 0.0634 improvement: 6.55%
2024-12-07 18:22:48,424 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.67%
2024-12-07 18:22:49,938 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.76%
2024-12-07 18:22:51,422 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.80%
2024-12-07 18:22:52,841 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.82%
2024-12-07 18:22:54,258 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.81%
2024-12-07 18:22:55,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.80%
2024-12-07 18:22:57,193 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.78%
2024-12-07 18:22:58,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.77%
2024-12-07 18:23:00,153 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.76%
2024-12-07 18:23:01,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.77%
2024-12-07 18:23:03,054 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.78%
2024-12-07 18:23:04,572 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.79%
2024-12-07 18:23:05,949 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.80%
2024-12-07 18:23:07,462 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.81%
2024-12-07 18:23:09,113 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: 15.9628 reward: -15.9628 ref_reward: 0.1106 improvement: -14537.92%
2024-12-07 18:23:10,532 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: 15.5686 reward: -15.5686 ref_reward: 0.1106 improvement: -14181.39%
2024-12-07 18:23:11,949 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: 15.1653 reward: -15.1653 ref_reward: 0.1106 improvement: -13816.61%
2024-12-07 18:23:13,380 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: 14.7508 reward: -14.7508 ref_reward: 0.1106 improvement: -13441.70%
2024-12-07 18:23:14,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: 14.3283 reward: -14.3283 ref_reward: 0.1106 improvement: -13059.54%
2024-12-07 18:23:16,149 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: 13.9029 reward: -13.9029 ref_reward: 0.1106 improvement: -12674.76%
2024-12-07 18:23:17,662 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: 13.4656 reward: -13.4656 ref_reward: 0.1106 improvement: -12279.24%
2024-12-07 18:23:18,972 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: 13.0295 reward: -13.0295 ref_reward: 0.1106 improvement: -11884.79%
2024-12-07 18:23:20,451 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: 12.5832 reward: -12.5832 ref_reward: 0.1106 improvement: -11481.12%
2024-12-07 18:23:21,885 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: 12.1483 reward: -12.1483 ref_reward: 0.1106 improvement: -11087.76%
2024-12-07 18:23:23,366 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: 11.7153 reward: -11.7153 ref_reward: 0.1106 improvement: -10696.18%
2024-12-07 18:23:24,850 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: 11.2549 reward: -11.2549 ref_reward: 0.1106 improvement: -10279.73%
2024-12-07 18:23:26,225 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: 10.7639 reward: -10.7639 ref_reward: 0.1106 improvement: -9835.61%
2024-12-07 18:23:27,800 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: 10.2475 reward: -10.2475 ref_reward: 0.1106 improvement: -9368.56%
2024-12-07 18:23:29,275 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: 9.7023 reward: -9.7023 ref_reward: 0.1106 improvement: -8875.48%
2024-12-07 18:23:30,661 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: 9.1278 reward: -9.1278 ref_reward: 0.1106 improvement: -8355.81%
2024-12-07 18:23:31,914 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: 8.5270 reward: -8.5270 ref_reward: 0.1106 improvement: -7812.42%
2024-12-07 18:23:33,400 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: 7.9047 reward: -7.9047 ref_reward: 0.1106 improvement: -7249.61%
2024-12-07 18:23:34,926 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: 7.2731 reward: -7.2731 ref_reward: 0.1106 improvement: -6678.28%
2024-12-07 18:23:36,450 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: 6.6401 reward: -6.6401 ref_reward: 0.1106 improvement: -6105.77%
2024-12-07 18:23:37,786 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: 6.0070 reward: -6.0070 ref_reward: 0.1106 improvement: -5533.18%
2024-12-07 18:23:39,306 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: 5.3836 reward: -5.3836 ref_reward: 0.1106 improvement: -4969.33%
2024-12-07 18:23:40,799 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: 4.7798 reward: -4.7798 ref_reward: 0.1106 improvement: -4423.22%
2024-12-07 18:23:42,238 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: 4.2052 reward: -4.2052 ref_reward: 0.1106 improvement: -3903.44%
2024-12-07 18:23:43,748 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: 3.6679 reward: -3.6679 ref_reward: 0.1106 improvement: -3417.47%
2024-12-07 18:23:45,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: 3.1744 reward: -3.1744 ref_reward: 0.1106 improvement: -2971.12%
2024-12-07 18:23:46,664 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: 2.7288 reward: -2.7288 ref_reward: 0.1106 improvement: -2568.16%
2024-12-07 18:23:48,100 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: 2.3331 reward: -2.3331 ref_reward: 0.1106 improvement: -2210.21%
2024-12-07 18:23:49,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: 1.9867 reward: -1.9867 ref_reward: 0.1106 improvement: -1896.87%
2024-12-07 18:23:51,032 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: 1.6872 reward: -1.6872 ref_reward: 0.1106 improvement: -1626.07%
2024-12-07 18:23:52,454 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: 1.4312 reward: -1.4312 ref_reward: 0.1106 improvement: -1394.52%
2024-12-07 18:23:54,010 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: 1.2142 reward: -1.2142 ref_reward: 0.1106 improvement: -1198.21%
2024-12-07 18:23:55,553 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: 1.0314 reward: -1.0314 ref_reward: 0.1106 improvement: -1032.83%
2024-12-07 18:23:56,954 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: 0.8779 reward: -0.8779 ref_reward: 0.1106 improvement: -894.07%
2024-12-07 18:23:58,064 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: 0.7495 reward: -0.7495 ref_reward: 0.1106 improvement: -777.93%
2024-12-07 18:23:59,414 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: 0.6421 reward: -0.6421 ref_reward: 0.1106 improvement: -680.76%
2024-12-07 18:24:00,946 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: 0.5522 reward: -0.5522 ref_reward: 0.1106 improvement: -599.40%
2024-12-07 18:24:02,520 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: 0.4767 reward: -0.4767 ref_reward: 0.1106 improvement: -531.14%
2024-12-07 18:24:03,794 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: 0.4131 reward: -0.4131 ref_reward: 0.1106 improvement: -473.68%
2024-12-07 18:24:05,317 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: 0.3595 reward: -0.3595 ref_reward: 0.1106 improvement: -425.12%
2024-12-07 18:24:06,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: 0.3139 reward: -0.3139 ref_reward: 0.1106 improvement: -383.91%
2024-12-07 18:24:08,208 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: 0.2750 reward: -0.2750 ref_reward: 0.1106 improvement: -348.76%
2024-12-07 18:24:09,572 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: 0.2417 reward: -0.2417 ref_reward: 0.1106 improvement: -318.61%
2024-12-07 18:24:11,132 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: 0.2130 reward: -0.2130 ref_reward: 0.1106 improvement: -292.62%
2024-12-07 18:24:12,584 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: 0.1880 reward: -0.1880 ref_reward: 0.1106 improvement: -270.08%
2024-12-07 18:24:14,060 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: 0.1663 reward: -0.1663 ref_reward: 0.1106 improvement: -250.43%
2024-12-07 18:24:15,626 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: 0.1473 reward: -0.1473 ref_reward: 0.1106 improvement: -233.20%
2024-12-07 18:24:17,014 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: 0.1305 reward: -0.1305 ref_reward: 0.1106 improvement: -218.01%
2024-12-07 18:24:18,467 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: 0.1156 reward: -0.1156 ref_reward: 0.1106 improvement: -204.54%
2024-12-07 18:24:19,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: 0.1023 reward: -0.1023 ref_reward: 0.1106 improvement: -192.53%
2024-12-07 18:24:21,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: 0.1881 reward: -0.1881 ref_reward: -0.1118 improvement: -68.20%
2024-12-07 18:24:23,160 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: 0.1646 reward: -0.1646 ref_reward: -0.1118 improvement: -47.25%
2024-12-07 18:24:24,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: 0.1459 reward: -0.1459 ref_reward: -0.1118 improvement: -30.45%
2024-12-07 18:24:26,189 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: 0.1315 reward: -0.1315 ref_reward: -0.1118 improvement: -17.65%
2024-12-07 18:24:27,479 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: 0.1206 reward: -0.1206 ref_reward: -0.1118 improvement: -7.88%
2024-12-07 18:24:28,837 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: 0.1130 reward: -0.1130 ref_reward: -0.1118 improvement: -1.03%
2024-12-07 18:24:30,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: 0.1083 reward: -0.1083 ref_reward: -0.1118 improvement: 3.17%
2024-12-07 18:24:31,533 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: 0.1058 reward: -0.1058 ref_reward: -0.1118 improvement: 5.39%
2024-12-07 18:24:32,940 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: 0.1048 reward: -0.1048 ref_reward: -0.1118 improvement: 6.24%
2024-12-07 18:24:34,434 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: 0.1048 reward: -0.1048 ref_reward: -0.1118 improvement: 6.27%
2024-12-07 18:24:35,725 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: 0.1052 reward: -0.1052 ref_reward: -0.1118 improvement: 5.90%
2024-12-07 18:24:37,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: 0.1058 reward: -0.1058 ref_reward: -0.1118 improvement: 5.39%
2024-12-07 18:24:38,583 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: 0.1064 reward: -0.1064 ref_reward: -0.1118 improvement: 4.87%
2024-12-07 18:24:40,116 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: 0.1067 reward: -0.1067 ref_reward: -0.1118 improvement: 4.54%
2024-12-07 18:24:41,697 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: 0.1068 reward: -0.1068 ref_reward: -0.1118 improvement: 4.50%
2024-12-07 18:24:43,126 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: 0.1065 reward: -0.1065 ref_reward: -0.1118 improvement: 4.72%
2024-12-07 18:24:44,719 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: 0.1061 reward: -0.1061 ref_reward: -0.1118 improvement: 5.08%
2024-12-07 18:24:46,011 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: 0.1057 reward: -0.1057 ref_reward: -0.1118 improvement: 5.48%
2024-12-07 18:24:47,558 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: 0.1053 reward: -0.1053 ref_reward: -0.1118 improvement: 5.86%
2024-12-07 18:24:49,029 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: 0.1049 reward: -0.1049 ref_reward: -0.1118 improvement: 6.17%
2024-12-07 18:24:50,505 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: 0.1047 reward: -0.1047 ref_reward: -0.1118 improvement: 6.40%
2024-12-07 18:24:51,905 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.53%
2024-12-07 18:24:53,412 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:24:54,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.55%
2024-12-07 18:24:56,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: 0.1046 reward: -0.1046 ref_reward: -0.1118 improvement: 6.49%
2024-12-07 18:24:57,773 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: 0.1046 reward: -0.1046 ref_reward: -0.1118 improvement: 6.45%
2024-12-07 18:24:59,345 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: 0.1046 reward: -0.1046 ref_reward: -0.1118 improvement: 6.42%
2024-12-07 18:25:00,705 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: 0.1046 reward: -0.1046 ref_reward: -0.1118 improvement: 6.42%
2024-12-07 18:25:02,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: 0.1046 reward: -0.1046 ref_reward: -0.1118 improvement: 6.43%
2024-12-07 18:25:03,815 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: 0.1046 reward: -0.1046 ref_reward: -0.1118 improvement: 6.46%
2024-12-07 18:25:05,230 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.50%
2024-12-07 18:25:06,709 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.53%
2024-12-07 18:25:08,076 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.55%
2024-12-07 18:25:09,579 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:25:10,856 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:25:12,114 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:25:13,467 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.56%
2024-12-07 18:25:14,974 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.56%
2024-12-07 18:25:16,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.55%
2024-12-07 18:25:17,909 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.55%
2024-12-07 18:25:19,367 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.56%
2024-12-07 18:25:20,736 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.56%
2024-12-07 18:25:22,305 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:25:23,643 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:25:25,184 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:25:26,573 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:25:28,057 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:25:29,392 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:25:30,891 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:25:32,350 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:37:55,527 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: 0.0466 reward: -0.0466 ref_reward: -0.0284 improvement: -63.97%
2024-12-07 18:37:57,215 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: 0.0369 reward: -0.0369 ref_reward: -0.0284 improvement: -29.99%
2024-12-07 18:37:58,812 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: 0.0296 reward: -0.0296 ref_reward: -0.0284 improvement: -4.33%
2024-12-07 18:38:00,269 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: 0.0246 reward: -0.0246 ref_reward: -0.0284 improvement: 13.50%
2024-12-07 18:38:01,647 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: 0.0213 reward: -0.0213 ref_reward: -0.0284 improvement: 24.95%
2024-12-07 18:38:03,171 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: 0.0195 reward: -0.0195 ref_reward: -0.0284 improvement: 31.29%
2024-12-07 18:38:04,458 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.30%
2024-12-07 18:38:05,913 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: 0.0191 reward: -0.0191 ref_reward: -0.0284 improvement: 32.69%
2024-12-07 18:38:07,244 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: 0.0196 reward: -0.0196 ref_reward: -0.0284 improvement: 30.92%
2024-12-07 18:38:08,548 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: 0.0200 reward: -0.0200 ref_reward: -0.0284 improvement: 29.52%
2024-12-07 18:38:10,000 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: 0.0201 reward: -0.0201 ref_reward: -0.0284 improvement: 29.14%
2024-12-07 18:38:11,407 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: 0.0200 reward: -0.0200 ref_reward: -0.0284 improvement: 29.71%
2024-12-07 18:38:12,925 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: 0.0197 reward: -0.0197 ref_reward: -0.0284 improvement: 30.76%
2024-12-07 18:38:14,264 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: 0.0194 reward: -0.0194 ref_reward: -0.0284 improvement: 31.85%
2024-12-07 18:38:15,756 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: 0.0191 reward: -0.0191 ref_reward: -0.0284 improvement: 32.68%
2024-12-07 18:38:17,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.14%
2024-12-07 18:38:18,605 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.30%
2024-12-07 18:38:20,091 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.25%
2024-12-07 18:38:21,618 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.13%
2024-12-07 18:38:23,102 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.01%
2024-12-07 18:38:24,466 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 32.94%
2024-12-07 18:38:25,948 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 32.95%
2024-12-07 18:38:27,475 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.01%
2024-12-07 18:38:28,890 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.11%
2024-12-07 18:38:30,409 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: 0.0190 reward: -0.0190 ref_reward: -0.0284 improvement: 33.21%
2024-12-07 18:38:31,766 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.30%
2024-12-07 18:38:33,283 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.35%
2024-12-07 18:38:34,722 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.36%
2024-12-07 18:38:36,175 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.35%
2024-12-07 18:38:37,631 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.33%
2024-12-07 18:38:39,013 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.32%
2024-12-07 18:38:40,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.31%
2024-12-07 18:38:42,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.32%
2024-12-07 18:38:43,515 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.34%
2024-12-07 18:38:44,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.35%
2024-12-07 18:38:46,362 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.36%
2024-12-07 18:38:47,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:38:49,221 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:38:50,701 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.36%
2024-12-07 18:38:52,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.36%
2024-12-07 18:38:53,655 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.36%
2024-12-07 18:38:54,968 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.36%
2024-12-07 18:38:56,325 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.36%
2024-12-07 18:38:57,863 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:38:59,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:39:00,671 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:39:02,178 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:39:03,551 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:39:04,975 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:39:06,251 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: 0.0189 reward: -0.0189 ref_reward: -0.0284 improvement: 33.37%
2024-12-07 18:39:07,728 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: 0.2938 reward: -0.2938 ref_reward: 0.0634 improvement: -563.26%
2024-12-07 18:39:09,246 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: 0.2524 reward: -0.2524 ref_reward: 0.0634 improvement: -497.89%
2024-12-07 18:39:10,663 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: 0.2137 reward: -0.2137 ref_reward: 0.0634 improvement: -436.94%
2024-12-07 18:39:12,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: 0.1778 reward: -0.1778 ref_reward: 0.0634 improvement: -380.26%
2024-12-07 18:39:13,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: 0.1433 reward: -0.1433 ref_reward: 0.0634 improvement: -326.00%
2024-12-07 18:39:14,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: 0.1111 reward: -0.1111 ref_reward: 0.0634 improvement: -275.11%
2024-12-07 18:39:16,455 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: 0.0805 reward: -0.0805 ref_reward: 0.0634 improvement: -226.92%
2024-12-07 18:39:17,859 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: 0.0521 reward: -0.0521 ref_reward: 0.0634 improvement: -182.10%
2024-12-07 18:39:19,302 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: 0.0263 reward: -0.0263 ref_reward: 0.0634 improvement: -141.48%
2024-12-07 18:39:20,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: 0.0037 reward: -0.0037 ref_reward: 0.0634 improvement: -105.86%
2024-12-07 18:39:22,273 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: -0.0153 reward: 0.0153 ref_reward: 0.0634 improvement: -75.88%
2024-12-07 18:39:23,787 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: -0.0305 reward: 0.0305 ref_reward: 0.0634 improvement: -51.86%
2024-12-07 18:39:25,268 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: -0.0420 reward: 0.0420 ref_reward: 0.0634 improvement: -33.73%
2024-12-07 18:39:26,686 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: -0.0501 reward: 0.0501 ref_reward: 0.0634 improvement: -21.01%
2024-12-07 18:39:28,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: -0.0554 reward: 0.0554 ref_reward: 0.0634 improvement: -12.72%
2024-12-07 18:39:29,577 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: -0.0586 reward: 0.0586 ref_reward: 0.0634 improvement: -7.58%
2024-12-07 18:39:30,973 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: -0.0606 reward: 0.0606 ref_reward: 0.0634 improvement: -4.50%
2024-12-07 18:39:32,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: -0.0618 reward: 0.0618 ref_reward: 0.0634 improvement: -2.57%
2024-12-07 18:39:33,990 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: -0.0627 reward: 0.0627 ref_reward: 0.0634 improvement: -1.15%
2024-12-07 18:39:35,441 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: -0.0635 reward: 0.0635 ref_reward: 0.0634 improvement: 0.14%
2024-12-07 18:39:36,928 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: -0.0643 reward: 0.0643 ref_reward: 0.0634 improvement: 1.41%
2024-12-07 18:39:38,435 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: -0.0651 reward: 0.0651 ref_reward: 0.0634 improvement: 2.64%
2024-12-07 18:39:39,884 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: -0.0659 reward: 0.0659 ref_reward: 0.0634 improvement: 3.88%
2024-12-07 18:39:41,458 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: -0.0666 reward: 0.0666 ref_reward: 0.0634 improvement: 4.99%
2024-12-07 18:39:42,930 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: -0.0671 reward: 0.0671 ref_reward: 0.0634 improvement: 5.86%
2024-12-07 18:39:44,444 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: -0.0675 reward: 0.0675 ref_reward: 0.0634 improvement: 6.40%
2024-12-07 18:39:45,952 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: -0.0676 reward: 0.0676 ref_reward: 0.0634 improvement: 6.63%
2024-12-07 18:39:47,193 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: -0.0676 reward: 0.0676 ref_reward: 0.0634 improvement: 6.59%
2024-12-07 18:39:48,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: -0.0675 reward: 0.0675 ref_reward: 0.0634 improvement: 6.41%
2024-12-07 18:39:50,133 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: -0.0673 reward: 0.0673 ref_reward: 0.0634 improvement: 6.19%
2024-12-07 18:39:51,633 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: -0.0672 reward: 0.0672 ref_reward: 0.0634 improvement: 6.03%
2024-12-07 18:39:53,099 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: -0.0672 reward: 0.0672 ref_reward: 0.0634 improvement: 5.98%
2024-12-07 18:39:54,504 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: -0.0673 reward: 0.0673 ref_reward: 0.0634 improvement: 6.03%
2024-12-07 18:39:56,006 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: -0.0673 reward: 0.0673 ref_reward: 0.0634 improvement: 6.16%
2024-12-07 18:39:57,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: -0.0674 reward: 0.0674 ref_reward: 0.0634 improvement: 6.32%
2024-12-07 18:39:58,714 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: -0.0675 reward: 0.0675 ref_reward: 0.0634 improvement: 6.46%
2024-12-07 18:40:00,150 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: -0.0676 reward: 0.0676 ref_reward: 0.0634 improvement: 6.57%
2024-12-07 18:40:01,652 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: -0.0676 reward: 0.0676 ref_reward: 0.0634 improvement: 6.64%
2024-12-07 18:40:03,097 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.67%
2024-12-07 18:40:04,640 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.69%
2024-12-07 18:40:06,003 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.70%
2024-12-07 18:40:07,499 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.71%
2024-12-07 18:40:08,729 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.73%
2024-12-07 18:40:10,233 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.75%
2024-12-07 18:40:11,751 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.78%
2024-12-07 18:40:13,259 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.80%
2024-12-07 18:40:14,697 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.81%
2024-12-07 18:40:16,243 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.82%
2024-12-07 18:40:17,765 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: -0.0678 reward: 0.0678 ref_reward: 0.0634 improvement: 6.82%
2024-12-07 18:40:19,237 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: -0.0677 reward: 0.0677 ref_reward: 0.0634 improvement: 6.82%
2024-12-07 18:40:21,069 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: 13.6866 reward: -13.6866 ref_reward: 0.1106 improvement: -12479.16%
2024-12-07 18:40:22,436 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: 12.9910 reward: -12.9910 ref_reward: 0.1106 improvement: -11849.95%
2024-12-07 18:40:23,942 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: 12.2873 reward: -12.2873 ref_reward: 0.1106 improvement: -11213.52%
2024-12-07 18:40:25,417 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: 11.5879 reward: -11.5879 ref_reward: 0.1106 improvement: -10580.89%
2024-12-07 18:40:26,884 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: 10.9234 reward: -10.9234 ref_reward: 0.1106 improvement: -9979.89%
2024-12-07 18:40:28,405 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: 10.2748 reward: -10.2748 ref_reward: 0.1106 improvement: -9393.24%
2024-12-07 18:40:29,778 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: 9.6287 reward: -9.6287 ref_reward: 0.1106 improvement: -8808.88%
2024-12-07 18:40:31,295 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: 8.9832 reward: -8.9832 ref_reward: 0.1106 improvement: -8225.03%
2024-12-07 18:40:32,570 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: 8.3468 reward: -8.3468 ref_reward: 0.1106 improvement: -7649.39%
2024-12-07 18:40:34,017 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: 7.7156 reward: -7.7156 ref_reward: 0.1106 improvement: -7078.55%
2024-12-07 18:40:35,463 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: 7.0877 reward: -7.0877 ref_reward: 0.1106 improvement: -6510.65%
2024-12-07 18:40:36,898 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: 6.4791 reward: -6.4791 ref_reward: 0.1106 improvement: -5960.12%
2024-12-07 18:40:38,320 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: 5.9082 reward: -5.9082 ref_reward: 0.1106 improvement: -5443.77%
2024-12-07 18:40:39,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: 5.3614 reward: -5.3614 ref_reward: 0.1106 improvement: -4949.22%
2024-12-07 18:40:41,309 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: 4.8310 reward: -4.8310 ref_reward: 0.1106 improvement: -4469.50%
2024-12-07 18:40:42,727 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: 4.3231 reward: -4.3231 ref_reward: 0.1106 improvement: -4010.10%
2024-12-07 18:40:44,274 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: 3.8432 reward: -3.8432 ref_reward: 0.1106 improvement: -3576.02%
2024-12-07 18:40:45,726 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: 3.3958 reward: -3.3958 ref_reward: 0.1106 improvement: -3171.37%
2024-12-07 18:40:47,231 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: 2.9842 reward: -2.9842 ref_reward: 0.1106 improvement: -2799.13%
2024-12-07 18:40:48,449 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: 2.6104 reward: -2.6104 ref_reward: 0.1106 improvement: -2461.07%
2024-12-07 18:40:50,038 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: 2.2750 reward: -2.2750 ref_reward: 0.1106 improvement: -2157.70%
2024-12-07 18:40:51,290 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: 1.9773 reward: -1.9773 ref_reward: 0.1106 improvement: -1888.41%
2024-12-07 18:40:52,776 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: 1.7155 reward: -1.7155 ref_reward: 0.1106 improvement: -1651.63%
2024-12-07 18:40:54,182 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: 1.4872 reward: -1.4872 ref_reward: 0.1106 improvement: -1445.13%
2024-12-07 18:40:55,704 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: 1.2894 reward: -1.2894 ref_reward: 0.1106 improvement: -1266.22%
2024-12-07 18:40:57,057 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: 1.1189 reward: -1.1189 ref_reward: 0.1106 improvement: -1111.99%
2024-12-07 18:40:58,566 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: 0.9724 reward: -0.9724 ref_reward: 0.1106 improvement: -979.53%
2024-12-07 18:41:00,067 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: 0.8469 reward: -0.8469 ref_reward: 0.1106 improvement: -866.02%
2024-12-07 18:41:01,586 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: 0.7395 reward: -0.7395 ref_reward: 0.1106 improvement: -768.84%
2024-12-07 18:41:03,101 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: 0.6475 reward: -0.6475 ref_reward: 0.1106 improvement: -685.63%
2024-12-07 18:41:04,459 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: 0.5686 reward: -0.5686 ref_reward: 0.1106 improvement: -614.31%
2024-12-07 18:41:05,943 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: 0.5009 reward: -0.5009 ref_reward: 0.1106 improvement: -553.07%
2024-12-07 18:41:07,267 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: 0.4426 reward: -0.4426 ref_reward: 0.1106 improvement: -500.34%
2024-12-07 18:41:08,683 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: 0.3918 reward: -0.3918 ref_reward: 0.1106 improvement: -454.33%
2024-12-07 18:41:09,987 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: 0.3473 reward: -0.3473 ref_reward: 0.1106 improvement: -414.15%
2024-12-07 18:41:11,473 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: 0.3083 reward: -0.3083 ref_reward: 0.1106 improvement: -378.89%
2024-12-07 18:41:12,886 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: 0.2740 reward: -0.2740 ref_reward: 0.1106 improvement: -347.79%
2024-12-07 18:41:14,334 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: 0.2435 reward: -0.2435 ref_reward: 0.1106 improvement: -320.23%
2024-12-07 18:41:15,681 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: 0.2163 reward: -0.2163 ref_reward: 0.1106 improvement: -295.68%
2024-12-07 18:41:17,170 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: 0.1921 reward: -0.1921 ref_reward: 0.1106 improvement: -273.71%
2024-12-07 18:41:18,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: 0.1702 reward: -0.1702 ref_reward: 0.1106 improvement: -253.96%
2024-12-07 18:41:20,180 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: 0.1505 reward: -0.1505 ref_reward: 0.1106 improvement: -236.13%
2024-12-07 18:41:21,571 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: 0.1327 reward: -0.1327 ref_reward: 0.1106 improvement: -219.98%
2024-12-07 18:41:23,044 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: 0.1164 reward: -0.1164 ref_reward: 0.1106 improvement: -205.30%
2024-12-07 18:41:24,513 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: 0.1016 reward: -0.1016 ref_reward: 0.1106 improvement: -191.91%
2024-12-07 18:41:25,903 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: 0.0881 reward: -0.0881 ref_reward: 0.1106 improvement: -179.67%
2024-12-07 18:41:27,453 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: 0.0757 reward: -0.0757 ref_reward: 0.1106 improvement: -168.45%
2024-12-07 18:41:28,866 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: 0.0643 reward: -0.0643 ref_reward: 0.1106 improvement: -158.13%
2024-12-07 18:41:30,379 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: 0.0538 reward: -0.0538 ref_reward: 0.1106 improvement: -148.63%
2024-12-07 18:41:31,886 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: 0.0441 reward: -0.0441 ref_reward: 0.1106 improvement: -139.86%
2024-12-07 18:41:33,627 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 0 loss: 0.1689 reward: -0.1689 ref_reward: -0.1118 improvement: -51.05%
2024-12-07 18:41:34,977 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 2 loss: 0.1534 reward: -0.1534 ref_reward: -0.1118 improvement: -37.18%
2024-12-07 18:41:36,508 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 4 loss: 0.1407 reward: -0.1407 ref_reward: -0.1118 improvement: -25.88%
2024-12-07 18:41:37,968 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 6 loss: 0.1311 reward: -0.1311 ref_reward: -0.1118 improvement: -17.22%
2024-12-07 18:41:39,357 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 8 loss: 0.1239 reward: -0.1239 ref_reward: -0.1118 improvement: -10.81%
2024-12-07 18:41:40,868 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 10 loss: 0.1187 reward: -0.1187 ref_reward: -0.1118 improvement: -6.20%
2024-12-07 18:41:42,254 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 12 loss: 0.1151 reward: -0.1151 ref_reward: -0.1118 improvement: -2.94%
2024-12-07 18:41:43,767 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 14 loss: 0.1122 reward: -0.1122 ref_reward: -0.1118 improvement: -0.36%
2024-12-07 18:41:45,144 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 16 loss: 0.1097 reward: -0.1097 ref_reward: -0.1118 improvement: 1.88%
2024-12-07 18:41:46,679 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 18 loss: 0.1076 reward: -0.1076 ref_reward: -0.1118 improvement: 3.81%
2024-12-07 18:41:48,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 20 loss: 0.1059 reward: -0.1059 ref_reward: -0.1118 improvement: 5.30%
2024-12-07 18:41:49,543 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 22 loss: 0.1049 reward: -0.1049 ref_reward: -0.1118 improvement: 6.21%
2024-12-07 18:41:51,059 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 24 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.55%
2024-12-07 18:41:52,522 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 26 loss: 0.1046 reward: -0.1046 ref_reward: -0.1118 improvement: 6.45%
2024-12-07 18:41:54,032 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 28 loss: 0.1049 reward: -0.1049 ref_reward: -0.1118 improvement: 6.17%
2024-12-07 18:41:55,536 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 30 loss: 0.1052 reward: -0.1052 ref_reward: -0.1118 improvement: 5.91%
2024-12-07 18:41:57,024 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 32 loss: 0.1053 reward: -0.1053 ref_reward: -0.1118 improvement: 5.81%
2024-12-07 18:41:58,526 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 34 loss: 0.1053 reward: -0.1053 ref_reward: -0.1118 improvement: 5.84%
2024-12-07 18:41:59,871 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 36 loss: 0.1052 reward: -0.1052 ref_reward: -0.1118 improvement: 5.94%
2024-12-07 18:42:01,383 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 38 loss: 0.1051 reward: -0.1051 ref_reward: -0.1118 improvement: 6.03%
2024-12-07 18:42:02,791 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 40 loss: 0.1050 reward: -0.1050 ref_reward: -0.1118 improvement: 6.09%
2024-12-07 18:42:04,216 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 42 loss: 0.1049 reward: -0.1049 ref_reward: -0.1118 improvement: 6.15%
2024-12-07 18:42:05,561 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 44 loss: 0.1049 reward: -0.1049 ref_reward: -0.1118 improvement: 6.22%
2024-12-07 18:42:07,084 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 46 loss: 0.1047 reward: -0.1047 ref_reward: -0.1118 improvement: 6.33%
2024-12-07 18:42:08,554 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 48 loss: 0.1046 reward: -0.1046 ref_reward: -0.1118 improvement: 6.44%
2024-12-07 18:42:10,026 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 50 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.52%
2024-12-07 18:42:11,586 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 52 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.56%
2024-12-07 18:42:13,015 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 54 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.56%
2024-12-07 18:42:14,426 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 56 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.55%
2024-12-07 18:42:15,917 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 58 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.53%
2024-12-07 18:42:17,408 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 60 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.53%
2024-12-07 18:42:18,921 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 62 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.53%
2024-12-07 18:42:20,454 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 64 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.54%
2024-12-07 18:42:21,916 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 66 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.54%
2024-12-07 18:42:23,425 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 68 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.54%
2024-12-07 18:42:24,780 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 70 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.54%
2024-12-07 18:42:26,272 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 72 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.55%
2024-12-07 18:42:27,825 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 74 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.56%
2024-12-07 18:42:29,183 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 76 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.56%
2024-12-07 18:42:30,710 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 78 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:42:32,104 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 80 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:42:33,542 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 82 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:42:34,933 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 84 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:42:36,370 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 86 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:42:37,807 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 88 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:42:39,296 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 90 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:42:40,750 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 92 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:42:42,182 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 94 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:42:43,680 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 96 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
2024-12-07 18:42:44,957 - /home/hanwen/policy_optimization/exp/algorithm_single_state.py[line:219] - INFO: [Policy] Epoch 98 loss: 0.1045 reward: -0.1045 ref_reward: -0.1118 improvement: 6.57%
